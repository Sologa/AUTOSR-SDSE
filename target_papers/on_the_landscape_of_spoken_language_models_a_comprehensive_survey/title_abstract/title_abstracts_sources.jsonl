{"key": "agostinelli2023musiclm", "title": "MusicLM: Generating Music From Text", "source": "arxiv", "source_id": "2301.11325v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "algayres2022speech", "title": "Speech Sequence Embeddings using Nearest Neighbors Contrastive Learning", "source": "arxiv", "source_id": "2204.05148v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "tGSLM", "title": "Generative Spoken Language Model based on continuous word-sized audio tokens", "source": "arxiv", "source_id": "2310.05224v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "an2024funaudiollm", "title": "FunAudioLLM: Voice Understanding and Generation Foundation Models for Natural Interaction Between Humans and LLMs", "source": "arxiv", "source_id": "2407.04051v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "ao2024sd", "title": "SD-Eval: A Benchmark Dataset for Spoken Dialogue Understanding Beyond Words", "source": "arxiv", "source_id": "2406.13340v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "arora2023universlu", "title": "UniverSLU: Universal Spoken Language Understanding for Diverse Tasks with Natural Language Instructions", "source": "arxiv", "source_id": "2310.02973v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wav2vec2", "title": "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations", "source": "arxiv", "source_id": "2006.11477v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "bai2023qwen", "title": "Qwen Technical Report", "source": "arxiv", "source_id": "2309.16609v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "berant2013semantic", "title": "Semantic Parsing on Freebase from Question-Answer Pairs", "source": "semantic_scholar", "source_id": "b29447ba499507a259ae9d8f685d60cc1597d7d3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "audiolm", "title": "AudioLM: a Language Modeling Approach to Audio Generation", "source": "arxiv", "source_id": "2209.03143v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "borsos2023soundstorm", "title": "SoundStorm: Efficient Parallel Audio Generation", "source": "arxiv", "source_id": "2305.09636v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "brown2020language", "title": "Language Models are Few-Shot Learners", "source": "arxiv", "source_id": "2005.14165v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chan2016listen", "title": "Listen, Attend and Spell", "source": "arxiv", "source_id": "1508.01211v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chang2022maskgit", "title": "MaskGIT: Masked Generative Image Transformer", "source": "arxiv", "source_id": "2202.04200v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chang2024speechprompt", "title": "SpeechPrompt: Prompting Speech Language Models for Speech Processing Tasks", "source": "arxiv", "source_id": "2408.13040v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chen2023x", "title": "X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages", "source": "arxiv", "source_id": "2305.04160v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chen2024next", "title": "Next Token Prediction Towards Multimodal Intelligence: A Comprehensive Survey", "source": "arxiv", "source_id": "2412.18619v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chen2025minmo", "title": "MinMo: A Multimodal Large Language Model for Seamless Voice Interaction", "source": "arxiv", "source_id": "2501.06282v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wavlm", "title": "WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing", "source": "arxiv", "source_id": "2110.13900v5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wang2023neural", "title": "Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers", "source": "arxiv", "source_id": "2301.02111v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chen2024slam", "title": "SLAM-Omni: Timbre-Controllable Voice Interaction System with Single-Stage Training", "source": "arxiv", "source_id": "2412.15649v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chen2024voicebench", "title": "VoiceBench: Benchmarking LLM-Based Voice Assistants", "source": "arxiv", "source_id": "2410.17196v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chen2024salm", "title": "SALM: Speech-augmented Language Model with In-context Learning for Speech Recognition and Translation", "source": "arxiv", "source_id": "2310.09424v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "bestow2024chen", "title": "BESTOW: Efficient and Streamable Speech Language Model with the Best of Two Worlds in GPT and T5", "source": "arxiv", "source_id": "2406.19954v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chou2023toward", "title": "Toward Joint Language Modeling for Speech Units and Text", "source": "arxiv", "source_id": "2310.08715v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chu2023qwen", "title": "Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models", "source": "arxiv", "source_id": "2311.07919v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chu2024qwen2audio", "title": "Qwen2-Audio Technical Report", "source": "arxiv", "source_id": "2407.10759v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "copet2024simple", "title": "Simple and Controllable Music Generation", "source": "arxiv", "source_id": "2306.05284v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "scaling-slms", "title": "Scaling Properties of Speech Language Models", "source": "arxiv", "source_id": "2404.00685v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "cui2024recentadvancesspeechlanguage", "title": "Recent Advances in Speech Language Models: A Survey", "source": "arxiv", "source_id": "2410.03751v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "das2024speechverse", "title": "SpeechVerse: A Large-scale Generalizable Audio Language Model", "source": "arxiv", "source_id": "2405.08295v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "de2023prosaudit", "title": "ProsAudit, a prosodic benchmark for self-supervised speech models", "source": "arxiv", "source_id": "2302.12057v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "encodec", "title": "High Fidelity Neural Audio Compression", "source": "arxiv", "source_id": "2210.13438v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "defossezmoshi", "title": "Moshi: a speech-text foundation model for real-time dialogue", "source": "arxiv", "source_id": "2410.00037v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wav2prompt", "title": "Wav2Prompt: End-to-End Speech Prompt Generation and Tuning For LLM in Zero and Few-shot Learning", "source": "arxiv", "source_id": "2406.00522v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "bert", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "source": "arxiv", "source_id": "1810.04805v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "usm-lite", "title": "USM-Lite: Quantization and Sparsity Aware Fine-tuning for Speech Recognition with Universal Speech Models", "source": "arxiv", "source_id": "2312.08553v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "du2025codecfake", "title": "{CodecFake-Omni}: A large-scale codec-based deepfake speech dataset", "source": null, "source_id": null, "match_status": "missing", "abstract_present": false, "abstract_source": "missing", "abstract_source_reason": "missing:abstract_unavailable"}
{"key": "du2024cosyvoice", "title": "CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens", "source": "arxiv", "source_id": "2407.05407v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "dunbar2021zero", "title": "The Zero Resource Speech Challenge 2021: Spoken language modelling", "source": "arxiv", "source_id": "2104.14700v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "ekstedt-skantze-2020-turngpt", "title": "TurnGPT: a Transformer-based Language Model for Predicting Turn-taking in Spoken Dialog", "source": "arxiv", "source_id": "2010.10874v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "fan2024alignformer", "title": "AlignFormer: Modality Matching Can Achieve Better Zero-shot Instruction-Following Speech-LLM", "source": "arxiv", "source_id": "2412.01145v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "fang2024llama", "title": "LLaMA-Omni: Seamless Speech Interaction with Large Language Models", "source": "semantic_scholar", "source_id": "218ddd5ca9e959c91ad6b48a379397e4cb0d47d8", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "audiochatllama", "title": "AudioChatLlama: Towards General-Purpose Speech Abilities for LLMs", "source": "semantic_scholar", "source_id": "e4a9a026a40a58cee4d6509d2ef817a86a11a760", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "bpe", "title": "A new algorithm for data compression", "source": null, "source_id": null, "match_status": "missing", "abstract_present": false, "abstract_source": "missing", "abstract_source_reason": "missing:abstract_unavailable"}
{"key": "gaido2021ctc", "title": "CTC-based Compression for Direct Speech Translation", "source": "semantic_scholar", "source_id": "62316c538d3d9dcb6ae8a3567433f7417eab1f32", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "gao2022wavprompt", "title": "WAVPROMPT: Towards Few-Shot Spoken Language Understanding with Frozen Language Models", "source": "arxiv", "source_id": "2203.15863v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "geminiteam2024gemini15unlockingmultimodal", "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context", "source": "arxiv", "source_id": "2403.05530v5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "team2024gemma", "title": "Gemma: Open Models Based on Gemini Research and Technology", "source": "arxiv", "source_id": "2403.08295v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "gong2023whisperat", "title": "Whisper-AT: Noise-Robust Automatic Speech Recognizers are Also Strong General Audio Event Taggers", "source": "arxiv", "source_id": "2307.03183v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "gong2023joint", "title": "Joint Audio and Speech Understanding", "source": "arxiv", "source_id": "2309.14405v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "gong2023listen", "title": "Listen, Think, and Understand", "source": "arxiv", "source_id": "2305.10790v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "llama3", "title": "The Llama 3 Herd of Models", "source": "arxiv", "source_id": "2407.21783v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "graves2006connectionist", "title": "Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks", "source": null, "source_id": null, "match_status": "missing", "abstract_present": false, "abstract_source": "missing", "abstract_source_reason": "missing:abstract_unavailable"}
{"key": "VQ", "title": "Vector quantization", "source": null, "source_id": null, "match_status": "missing", "abstract_present": false, "abstract_source": "missing", "abstract_source_reason": "missing:abstract_unavailable"}
{"key": "gu2021efficiently", "title": "Efficiently Modeling Long Sequences with Structured State Spaces", "source": "arxiv", "source_id": "2111.00396v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "guo2025recent", "title": "Recent Advances in Discrete Speech Tokens: A Review", "source": "arxiv", "source_id": "2502.06490v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "twist", "title": "Textually Pretrained Speech Language Models", "source": "arxiv", "source_id": "2305.13009v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "diva", "title": "Distilling an End-to-End Voice Assistant Without Instruction Training Data", "source": "arxiv", "source_id": "2410.02678v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "hernandez2018ted", "title": "TED-LIUM 3: twice as much data and corpus repartition for experiments on speaker adaptation", "source": "arxiv", "source_id": "1805.04699v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "holtzman2020the", "title": "The Curious Case of Neural Text Degeneration", "source": "arxiv", "source_id": "1904.09751v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "houlsby2019parameter", "title": "Parameter-Efficient Transfer Learning for NLP", "source": "arxiv", "source_id": "1902.00751v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "hubert", "title": "HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units", "source": "arxiv", "source_id": "2106.07447v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "lora", "title": "LoRA: Low-Rank Adaptation of Large Language Models", "source": "arxiv", "source_id": "2106.09685v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "hu2024chain", "title": "Chain-of-Thought Prompting for Speech Translation", "source": "arxiv", "source_id": "2409.11538v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wavllm", "title": "WavLLM: Towards Robust and Adaptive Speech Large Language Model", "source": "semantic_scholar", "source_id": "1a41d449f2ed4051ac4c763fb8b1b07357eaf5f4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "huang2024dynamic", "title": "Dynamic-SUPERB: Towards A Dynamic, Collaborative, and Comprehensive Instruction-Tuning Benchmark for Speech", "source": "arxiv", "source_id": "2309.09510v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "huang2025dynamicsuperb", "title": "Dynamic-SUPERB Phase-2: A Collaboratively Expanding Benchmark for Measuring the Capabilities of Spoken Language Models with 180 Tasks", "source": "arxiv", "source_id": "2411.05361v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "huang2001spoken", "title": "Spoken Language Processing: A Guide to Theory, Algorithm, and System Development", "source": "openalex", "source_id": "https://openalex.org/W1578856370", "match_status": "exact_title", "abstract_present": true, "abstract_source": "openalex", "abstract_source_reason": "openalex:exact_title"}
{"key": "ji2024wavchat", "title": "WavChat: A Survey of Spoken Dialogue Models", "source": "arxiv", "source_id": "2411.13577v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "jimenez2023swe", "title": "SWE-bench: Can Language Models Resolve Real-World GitHub Issues?", "source": "arxiv", "source_id": "2310.06770v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "joshi2017triviaqa", "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension", "source": "arxiv", "source_id": "1705.03551v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "ke2023continual", "title": "Continual Pre-training of Language Models", "source": "arxiv", "source_id": "2302.03241v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "keuleers2010wuggy", "title": "Wuggy: A multilingual pseudoword generator", "source": null, "source_id": null, "match_status": "missing", "abstract_present": false, "abstract_source": "missing", "abstract_source_reason": "missing:abstract_unavailable"}
{"key": "kharitonov2022textless", "title": "textless-lib: a Library for Textless Spoken Language Processing", "source": "arxiv", "source_id": "2202.07359v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "pGSLM", "title": "Text-Free Prosody-Aware Generative Spoken Language Modeling", "source": "arxiv", "source_id": "2109.03264v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "kharitonov2023speak", "title": "Speak, Read and Prompt: High-Fidelity Text-to-Speech with Minimal Supervision", "source": "arxiv", "source_id": "2302.03540v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "Kirkpatrick2017overcoming", "title": "Overcoming catastrophic forgetting in neural networks", "source": "arxiv", "source_id": "1612.00796v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "koizumi2022wavefit", "title": "WaveFit: An Iterative and Non-autoregressive Neural Vocoder based on Fixed-Point Iteration", "source": "arxiv", "source_id": "2210.01029v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "kong2020hifi", "title": "HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis", "source": "arxiv", "source_id": "2010.05646v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "kreuk2022textless", "title": "Textless Speech Emotion Conversion using Discrete & Decomposed Representations", "source": "semantic_scholar", "source_id": "44ff1432414805bbbff7b7c814c758989d3028c9", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "kuan2024largeaudiolanguagemodelstruly", "title": "Can Large Audio-Language Models Truly Hear? Tackling Hallucinations with Multi-Task Assessment and Stepwise Audio Reasoning", "source": "arxiv", "source_id": "2410.16130v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "kuan2024audiohallucination", "title": "Understanding Sounds, Missing the Questions: The Challenge of Object Hallucination in Large Audio-Language Models", "source": "arxiv", "source_id": "2406.08402v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "parp", "title": "PARP: Prune, Adjust and Re-Prune for Self-Supervised Speech Recognition", "source": "arxiv", "source_id": "2106.05933v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "lai2023instruction", "title": "Instruction-Following Speech Recognition", "source": "arxiv", "source_id": "2309.09843v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "GSLM", "title": "On Generative Spoken Language Modeling from Raw Audio", "source": "semantic_scholar", "source_id": "7c39adb2049e79951dd6b92c970abaa4d81819b1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "latif2023sparks", "title": "Sparks of Large Audio Models: A Survey and Outlook", "source": "arxiv", "source_id": "2308.12792v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "the2024large", "title": "Large Concept Models: Language Modeling in a Sentence Representation Space", "source": "arxiv", "source_id": "2412.08821v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "le2024voicebox", "title": "Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale", "source": "arxiv", "source_id": "2306.15687v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "lee2022direct", "title": "Direct speech-to-speech translation with discrete units", "source": "arxiv", "source_id": "2107.05604v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "lee2022textless", "title": "Textless Speech-to-Speech Translation on Real Data", "source": "arxiv", "source_id": "2112.08352v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "lee2022autoregressive", "title": "Autoregressive Image Generation using Residual Quantization", "source": "arxiv", "source_id": "2203.01941v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "q-former", "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models", "source": "arxiv", "source_id": "2301.12597v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "lin2024advancing", "title": "Advancing Large Language Models to Capture Varied Speaking Styles and Respond Properly in Spoken Conversations", "source": "arxiv", "source_id": "2402.12786v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "lin2024alignslmtextlessspokenlanguage", "title": "Align-SLM: Textless Spoken Language Models with Reinforcement Learning from AI Feedback", "source": "arxiv", "source_id": "2411.01834v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "biasspeechSLT24", "title": "Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models", "source": "arxiv", "source_id": "2408.07665v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "biascontentSLT24", "title": "Listen and Speak Fairly: A Study on Semantic Gender Bias in Speech Integrated Large Language Models", "source": "arxiv", "source_id": "2407.06957v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "prompt1", "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing", "source": "arxiv", "source_id": "2107.13586v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "lo2019mosnet", "title": "MOSNet: Deep Learning based Objective Assessment for Voice Conversion", "source": "arxiv", "source_id": "1904.08352v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "desta", "title": "DeSTA: Enhancing Speech Language Models through Descriptive Speech-Text Alignment", "source": "arxiv", "source_id": "2406.18871v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "desta2", "title": "DeSTA2: Developing Instruction-Following Speech Language Model Without Speech Instruction-Tuning Data", "source": "arxiv", "source_id": "2409.20007v2", "match_status": "fuzzy_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:fuzzy_title"}
{"key": "ma2024languagemodellistenspeaking", "title": "Language Model Can Listen While Speaking", "source": "openalex", "source_id": "https://openalex.org/W4409348167", "match_status": "exact_title", "abstract_present": true, "abstract_source": "openalex", "abstract_source_reason": "openalex:exact_title"}
{"key": "maimon2023speaking", "title": "Speaking Style Conversion in the Waveform Domain Using Discrete Self-Supervised Units", "source": "arxiv", "source_id": "2212.09730v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "maimon2024suite", "title": "Salmon: A Suite for Acoustic Language Model Evaluation", "source": "arxiv", "source_id": "2409.07437v3", "match_status": "fuzzy_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:fuzzy_title"}
{"key": "maimon2025slamming", "title": "Slamming: Training a Speech Language Model on One GPU in a Day", "source": "arxiv", "source_id": "2502.15814v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "maiti2024voxtlm", "title": "Voxtlm: unified decoder-only models for consolidating speech recognition/synthesis and speech/text continuation tasks", "source": "arxiv", "source_id": "2309.07937v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "masumura-etal-2018-neural", "title": "Neural Dialogue Context Online End-of-Turn Detection", "source": "semantic_scholar", "source_id": "31e63d59c8b86c2b153b7e57711efc4da2e06913", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "MEENA2014903", "title": "Data-driven models for timing feedback responses in a map task dialogue system", "source": null, "source_id": null, "match_status": "missing", "abstract_present": false, "abstract_source": "missing", "abstract_source_reason": "missing:abstract_unavailable"}
{"key": "Parrot2024", "title": "Parrot: Autoregressive spoken dialogue language modeling with decoder-only transformers", "source": null, "source_id": null, "match_status": "missing", "abstract_present": false, "abstract_source": "missing", "abstract_source_reason": "missing:abstract_unavailable"}
{"key": "messica2024nast", "title": "NAST: Noise Aware Speech Tokenization for Speech Language Models", "source": "arxiv", "source_id": "2406.11037v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "phi4mini", "title": "Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs", "source": "arxiv", "source_id": "2503.01743v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "mohamed2022self", "title": "Self-Supervised Speech Representation Learning: A Review", "source": "arxiv", "source_id": "2205.10643v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "mostafazadeh2016corpus", "title": "A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense Stories", "source": "semantic_scholar", "source_id": "85b68477a6e031d88b963833e15a4b4fc6855264", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "mousavi2024dasb", "title": "DASB - Discrete Audio and Speech Benchmark", "source": "arxiv", "source_id": "2406.14294v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "mousavi2024should", "title": "How Should We Extract Discrete Audio Tokens from Self-Supervised Models?", "source": "arxiv", "source_id": "2406.10735v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "nachmani2023spoken", "title": "Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM", "source": "arxiv", "source_id": "2305.15255v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "dGSLM", "title": "Generative Spoken Dialogue Language Modeling", "source": "arxiv", "source_id": "2203.16502v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "nguyen2024spirit", "title": "Spirit LM: Interleaved Spoken and Written Language Model", "source": "arxiv", "source_id": "2402.05755v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "gpt4osafety", "title": "Gpt-4o system card, 2024", "source": null, "source_id": null, "match_status": "missing", "abstract_present": false, "abstract_source": "missing", "abstract_source_reason": "missing:abstract_unavailable"}
{"key": "gpt4", "title": "GPT-4 Technical Report", "source": "arxiv", "source_id": "2303.08774v6", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "ouyang2022training", "title": "Training language models to follow instructions with human feedback", "source": "arxiv", "source_id": "2203.02155v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "pan2023cosmic", "title": "COSMIC: Data Efficient Instruction-tuning For Speech In-Context Learning", "source": "arxiv", "source_id": "2311.02248v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "park2024long", "title": "Long-Form Speech Generation with Spoken Language Models", "source": "arxiv", "source_id": "2412.18603v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "pasad2023comparative", "title": "Comparative layer-wise analysis of self-supervised speech models", "source": "arxiv", "source_id": "2211.03929v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "peng2024surveyspeechlargelanguage", "title": "A survey on speech large language models", "source": null, "source_id": null, "match_status": "missing", "abstract_present": false, "abstract_source": "missing", "abstract_source_reason": "missing:abstract_unavailable"}
{"key": "dphubert", "title": "DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models", "source": "arxiv", "source_id": "2305.17651v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "owsm", "title": "Reproducing Whisper-Style Training Using An Open-Source Toolkit And Publicly Available Data", "source": "semantic_scholar", "source_id": "d43338451cd8676548811e1ff8f9c92ea987c5bd", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "peng2024voicetextblenderaugmentinglargelanguage", "title": "VoiceTextBlender: Augmenting Large Language Models with Speech Capabilities via Single-Stage Joint Speech-Text Supervised Fine-Tuning", "source": "arxiv", "source_id": "2410.17485v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "owsm-ctc", "title": "OWSM-CTC: An Open Encoder-Only Speech Foundation Model for Speech Recognition, Translation, and Language Identification", "source": "arxiv", "source_id": "2402.12654v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "polyak21_interspeech", "title": "Speech Resynthesis from Discrete Disentangled Self-Supervised Representations", "source": "arxiv", "source_id": "2104.00355v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "puvvada2024less", "title": "Less is More: Accurate Speech Recognition & Translation without Web-Scale Data", "source": "arxiv", "source_id": "2406.19674v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "radford2019language", "title": "Language models are unsupervised multitask learners, 2019", "source": null, "source_id": null, "match_status": "missing", "abstract_present": false, "abstract_source": "missing", "abstract_source_reason": "missing:abstract_unavailable"}
{"key": "whisper", "title": "Robust Speech Recognition via Large-Scale Weak Supervision", "source": "arxiv", "source_id": "2212.04356v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "rafailov2023direct", "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model", "source": "arxiv", "source_id": "2305.18290v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "turntakeingIS18", "title": "Investigating Speech Features for Continuous Turn-Taking Prediction Using LSTMs", "source": "semantic_scholar", "source_id": "ede28e0b075c294c5d66a75711c960c84f2fd234", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "sakshi2024mmau", "title": "MMAU: A Massive Multi-Task Audio Understanding and Reasoning Benchmark", "source": "arxiv", "source_id": "2410.19168v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "schatz2013evaluating", "title": "Evaluating speech features with the minimal-pair ABX task: analysis of the classical MFC/PLP pipeline", "source": "openalex", "source_id": "https://openalex.org/W2395899413", "match_status": "exact_title", "abstract_present": true, "abstract_source": "openalex", "abstract_source_reason": "openalex:exact_title"}
{"key": "aBPE", "title": "Acoustic BPE for Speech Generation with Discrete Tokens", "source": "arxiv", "source_id": "2310.14580v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "shen2018natural", "title": "Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions", "source": "arxiv", "source_id": "1712.05884v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "shi2024espnet", "title": "ESPnet-Codec: Comprehensive Training and Evaluation of Neural Codecs for Audio, Music, and Speech", "source": "arxiv", "source_id": "2409.15897v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "shon2022slue", "title": "SLUE: New Benchmark Tasks for Spoken Language Understanding Evaluation on Natural Speech", "source": "arxiv", "source_id": "2111.10367v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "shon2024discreteslu", "title": "DiscreteSLU: A Large Language Model with Self-Supervised Discrete Speech Units for Spoken Language Understanding", "source": "semantic_scholar", "source_id": "4626971b4b3a7ae5cdae61ca81ff97e06fc365eb", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "shu2023llasm", "title": "LLaSM: Large Language and Speech Model", "source": "arxiv", "source_id": "2308.15930v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "sicherman2023analysing", "title": "Analysing Discrete Self Supervised Speech Representation for Spoken Language Modeling", "source": "arxiv", "source_id": "2301.00591v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "siuzdak2024snac", "title": "SNAC: Multi-Scale Neural Audio Codec", "source": "arxiv", "source_id": "2410.14411v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "skantze-2017-towards", "title": "Towards a General, Continuous Model of Turn-taking in Spoken Dialogue using LSTM Recurrent Neural Networks", "source": "semantic_scholar", "source_id": "04af90e58c35798bf7c0f80c9f5457bb06fe01f5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "bigbench", "title": "Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models", "source": "arxiv", "source_id": "2206.04615v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "tang2023salmonn", "title": "SALMONN: Towards Generic Hearing Abilities for Large Language Models", "source": "arxiv", "source_id": "2310.13289v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "tian2025espnet", "title": "ESPnet-SpeechLM: An Open Speech Language Model Toolkit", "source": "arxiv", "source_id": "2502.15218v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "touvron2023llama", "title": "LLaMA: Open and Efficient Foundation Language Models", "source": "arxiv", "source_id": "2302.13971v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "touvron2023llama2", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models", "source": "arxiv", "source_id": "2307.09288v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "tsunoo24_interspeech", "title": "Decoder-only Architecture for Streaming End-to-end Speech Recognition", "source": "arxiv", "source_id": "2406.16107v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "turetzky2024last", "title": "LAST: Language Model Aware Speech Tokenization", "source": "arxiv", "source_id": "2409.03701v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "van2017neural", "title": "Neural Discrete Representation Learning", "source": "arxiv", "source_id": "1711.00937v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "veluri2024turnbasedinterfacessynchronousllms", "title": "Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents", "source": "semantic_scholar", "source_id": "77c12b7565774bc18e420f91336d02ba5bd6309f", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "wang2024audiobench", "title": "AudioBench: A Universal Benchmark for Audio Large Language Models", "source": "arxiv", "source_id": "2406.16020v5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "blsp", "title": "BLSP: Bootstrapping Language-Speech Pre-training via Behavior Alignment of Continuation Writing", "source": "arxiv", "source_id": "2309.00916v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wang2023slm", "title": "SLM: Bridge the thin gap between speech and text foundation models", "source": "arxiv", "source_id": "2310.00230v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "duplextimeNuerIPS24", "title": "A Full-duplex Speech Dialogue Scheme Based On Large Language Models", "source": "arxiv", "source_id": "2405.19487v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wang2024freezeomnismartlowlatency", "title": "Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model with Frozen LLM", "source": "arxiv", "source_id": "2411.00774v5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "warstadt2020blimp", "title": "BLiMP: The Benchmark of Linguistic Minimal Pairs for English", "source": "crossref", "source_id": "10.1162/tacl_a_00321", "match_status": "exact_title", "abstract_present": true, "abstract_source": "crossref", "abstract_source_reason": "crossref:exact_title"}
{"key": "FLAN", "title": "Finetuned Language Models Are Zero-Shot Learners", "source": "arxiv", "source_id": "2109.01652v5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "CoT", "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models", "source": "arxiv", "source_id": "2201.11903v6", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "WhisperSpeech", "title": "{WhisperSpeech}: An open source text-to-speech system built by inverting {Whisper}, 2024", "source": null, "source_id": null, "match_status": "missing", "abstract_present": false, "abstract_source": "missing", "abstract_source_reason": "missing:abstract_unavailable"}
{"key": "wav2seq", "title": "Wav2Seq: Pre-training Speech-to-Text Encoder-Decoder Models Using Pseudo Languages", "source": "arxiv", "source_id": "2205.01086v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wu2024towards", "title": "Towards audio language modeling -- an overview", "source": "arxiv", "source_id": "2402.13236v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wu2024codec", "title": "Codec-SUPERB @ SLT 2024: A lightweight benchmark for neural audio codec models", "source": "arxiv", "source_id": "2409.14085v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wu-etal-2024-codec", "title": "Codec-SUPERB: An In-Depth Analysis of Sound Codec Models", "source": "arxiv", "source_id": "2402.13071v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wu2024ts3", "title": "TS3-Codec: Transformer-Based Simple Streaming Single Codec", "source": "arxiv", "source_id": "2411.18803v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wu2024codecfake", "title": "CodecFake: Enhancing Anti-Spoofing Models Against Deepfake Audios from Codec-Based Speech Synthesis Systems", "source": "arxiv", "source_id": "2406.07237v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wu2023decoder", "title": "On decoder-only architecture for speech-to-text and large language model integration", "source": "arxiv", "source_id": "2307.03917v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "xie2024mini", "title": "Mini-Omni: Language Models Can Hear, Talk While Thinking in Streaming", "source": "arxiv", "source_id": "2408.16725v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "xie2024mini2", "title": "Mini-Omni2: Towards Open-source GPT-4o with Vision, Speech and Duplex Capabilities", "source": "semantic_scholar", "source_id": "b4c98b8c624f288db2f1dba8a71e4c4962bff192", "match_status": "fuzzy_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:fuzzy_title"}
{"key": "xin2024bigcodec", "title": "BigCodec: Pushing the Limits of Low-Bitrate Neural Speech Codec", "source": "arxiv", "source_id": "2409.05377v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "xu2024enablingrealtimeconversationsminimal", "title": "Enabling Real-Time Conversations with Minimal Training Costs", "source": "arxiv", "source_id": "2409.11727v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "xue2024chat", "title": "E-chat: Emotion-sensitive Spoken Dialogue System with Large Language Models", "source": "arxiv", "source_id": "2401.00475v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "yang2023uniaudio", "title": "{U}ni{A}udio: Towards universal audio generation with large language models", "source": null, "source_id": null, "match_status": "missing", "abstract_present": false, "abstract_source": "missing", "abstract_source_reason": "missing:abstract_unavailable"}
{"key": "airbench", "title": "AIR-Bench: Benchmarking Large Audio-Language Models via Generative Comprehension", "source": "arxiv", "source_id": "2402.07729v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "yu2023megabyte", "title": "MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers", "source": "arxiv", "source_id": "2305.07185v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "yu2024connecting", "title": "Connecting Speech Encoder and Large Language Model for ASR", "source": "arxiv", "source_id": "2309.13963v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "Flow-Omni", "title": "Continuous Speech Tokens Makes LLMs Robust Multi-Modality Learners", "source": "arxiv", "source_id": "2412.04917v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "soundstream", "title": "SoundStream: An End-to-End Neural Audio Codec", "source": "arxiv", "source_id": "2107.03312v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zellers2019hellaswag", "title": "HellaSwag: Can a Machine Really Finish Your Sentence?", "source": "arxiv", "source_id": "1905.07830v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zeng2024glm", "title": "GLM-4-Voice: Towards Intelligent and Human-Like End-to-End Spoken Chatbot", "source": "arxiv", "source_id": "2412.02612v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zeng2024scaling", "title": "Scaling Speech-Text Pre-training with Synthetic Interleaved Data", "source": "arxiv", "source_id": "2411.17607v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "anygpt", "title": "AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling", "source": "arxiv", "source_id": "2402.12226v5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zhang2023speechgpt", "title": "SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities", "source": "arxiv", "source_id": "2305.11000v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zhang2024mm", "title": "MM-LLMs: Recent Advances in MultiModal Large Language Models", "source": "semantic_scholar", "source_id": "a050c9b0c321839e4427ab9defa3463be7825ac4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "zhang2025omniflattenendtoendgptmodel", "title": "OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation", "source": "arxiv", "source_id": "2410.17799v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zhang2022opt", "title": "OPT: Open Pre-trained Transformer Language Models", "source": "arxiv", "source_id": "2205.01068v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "speechtokenizer", "title": "SpeechTokenizer: Unified Speech Tokenizer for Speech Large Language Models", "source": "semantic_scholar", "source_id": "5fc1a1f79ea4d1a1c6e8da1a40ae08022a6d7308", "match_status": "fuzzy_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:fuzzy_title"}
{"key": "zhang2024turnbasedgameenablingrealtime", "title": "Beyond the Turn-Based Game: Enabling Real-Time Conversations with Duplex Models", "source": "arxiv", "source_id": "2406.15718v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "usm", "title": "Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages", "source": "arxiv", "source_id": "2303.01037v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zheng2023judging", "title": "Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena", "source": "arxiv", "source_id": "2306.05685v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
