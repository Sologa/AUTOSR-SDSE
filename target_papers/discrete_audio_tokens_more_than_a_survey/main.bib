@string{icassp = "Proc. ICASSP"}
@string{interspeech = "Proc. Interspeech"}
@string{neurips = "Proc. NeurIPS"}
@string{waspaa = "Proc. WASPAA"}
@string{emnlp = "Proc. EMNLP"}
@string{slt = "Proc. SLT"}
@string{ismir = "Proc. ISMIR"}
@string{iclr = "Proc. ICLR"}
@string{icml = "Proc. ICML"}
@string{cvpr = "Proc. CVPR"}
@string{asru = "Proc. ASRU"}
@string{acl = "Proc. ACL"}
@string{naacl = "Proc. NAACL"}
@string{aaai = "Proc. AAAI"}
@string{icasspw = "Proc. ICASSPW"}
@string{lrec = "Proc. LREC"}
@string{LREC-COLING = "Proc. LREC-COLING"}
@string{APSIPA_ASC = "Proc. APSIPA ASC"}
@string{eccv = "Proc. ECCV"}



@article{itakura1968analysis,
  title={Analysis synthesis telephony based on the maximum likelihood method},
  author={Itakura, Fumitada},
  journal={Reports of the 6th Int. Cong. Acoust.},
  year={1968}
} 

@article{atal1970speech,
  title={Speech analysis and synthesis by linear prediction of the speech wave},
  author={Atal, Bishnu S},
  journal={The journal of the acoustical society of America},
  volume={47},
  number={1A\_Supplement},
  pages={65--65},
  year={1970},
  publisher={Acoustical Society of America}
}

@inproceedings{schroeder1985code,
  title={Code-excited linear prediction (CELP): High-quality speech at very low bit rates},
  author={Schroeder, Manfred and Atal, B},
  booktitle=icassp,
  year={1985},
}

@inproceedings{tian2025espnet,
  title={{ESP}net-{S}peech{LM}: An open speech language model toolkit},
  author={Tian, Jinchuan and Shi, Jiatong and Chen, William and Arora, Siddhant and Masuyama, Yoshiki and Maekaku, Takashi and Wu, Yihan and Peng, Junyi and Bharadwaj, Shikhar and Zhao, Yiwen and others},
  booktitle=naacl,
  year={2025}
}

@article{hayashi2020discretalk,
  title={Discretalk: Text-to-speech as a machine translation problem},
  author={Hayashi, Tomoki and Watanabe, Shinji},
  journal={arXiv preprint arXiv:2005.05525},
  year={2020}
}


@inproceedings{vqvae2017,
author = {van den Oord, Aaron and Vinyals, Oriol and Kavukcuoglu, Koray},
title = {Neural discrete representation learning},
year = {2017},
booktitle = neurips,
location = {Long Beach, California, USA},
}

@article{zeghidour2021soundstream,
    author = {Zeghidour, Neil and Luebs, Alejandro and Omran, Ahmed and Skoglund, Jan and Tagliasacchi, Marco},
    title = {{SoundStream}: An End-to-End Neural Audio Codec},
    year = {2021},
    journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
    pages = {495--507},
}

@inproceedings{shi2024versa,
  title={{VERSA}: A Versatile Evaluation Toolkit for Speech, Audio, and Music},
  author={Shi, Jiatong and Shim, Hye-jin and Tian, Jinchuan and Arora, Siddhant and Wu, Haibin and Petermann, Darius and Yip, Jia Qi and Zhang, You and Tang, Yuxun and Zhang, Wangyou and others},
  booktitle=naacl,
  year={2025}
}

@article{wu2024towards,
  title={Towards audio language modeling-an overview},
  author={Wu, Haibin and Chen, Xuanjun and Lin, Yi-Cheng and Chang, Kai-Wei and Chung, Ho-Lam and Liu, Alexander H. and Lee, {Hung-yi}},
  journal={arXiv preprint arXiv:2402.13236},
  year={2024}
}

@inproceedings{jiang2023disentangled,
  title={Disentangled feature learning for real-time neural speech coding},
  author={Jiang, Xue and Peng, Xiulian and Zhang, Yuan and Lu, Yan},
  booktitle=icassp,
  year={2023},
}

@article{lakhotia2021generative,
  title={On generative spoken language modeling from raw audio},
  author={Lakhotia, Kushal and Kharitonov, Eugene and Hsu, Wei-Ning and Adi, Yossi and Polyak, Adam and Bolte, Benjamin and Nguyen, Tu-Anh and Copet, Jade and Baevski, Alexei and Mohamed, Abdelrahman and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={1336--1354},
  year={2021},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{wu2023speechgen,
  title={Speechgen: Unlocking the generative power of speech language models with prompts},
  author={Wu, Haibin and Chang, Kai-Wei and Wu, Yuan-Kuei and Lee, Hung-yi},
  journal={arXiv preprint arXiv:2306.02207},
  year={2023}
}

@article{zhen2020psychoacoustic,
  author={Zhen, Kai and Lee, Mi Suk and Sung, Jongmo and Beack, Seungkwon and Kim, Minje},
  journal={IEEE Signal Processing Letters}, 
  title={Psychoacoustic Calibration of Loss Functions for Efficient End-to-End Neural Audio Coding}, 
  year={2020},
  volume={27},
  number={},
  pages={2159-2163},
  keywords={Decoding;Masking threshold;Psychoacoustics;Bit rate;Quantization (signal);Kernel;Audio coding;Audio coding;deep neural networks;psychoacoustics;network compression},
  doi={10.1109/LSP.2020.3039765}}

@inproceedings{garbacea2019low,
  title={Low bit-rate speech coding with VQ-VAE and a WaveNet decoder},
  author={G{\^a}rbacea, Cristina and van den Oord, A{\"a}ron and Li, Yazhe and Lim, Felicia SC and Luebs, Alejandro and Vinyals, Oriol and Walters, Thomas C},
  booktitle=icassp, 
  year={2019}
}

@inproceedings{jang2024personalized,
  title={Personalized neural speech codec},
  author={Jang, Inseon and Yang, Haici and Lim, Wootaek and Beack, Seungkwon and Kim, Minje},
  booktitle=icassp,
  year={2024},
}

@INPROCEEDINGS{Kleijn2018wavenet,
  author={Kleijn, W. Bastiaan and Lim, Felicia S. C. and Luebs, Alejandro and Skoglund, Jan and Stimberg, Florian and Wang, Quan and Walters, Thomas C.},
  booktitle=icassp, 
  title={Wavenet Based Low Rate Speech Coding}, 
  year={2018},
}

@inproceedings{valin2019real,
  title={A real-time wideband neural vocoder at 1.6 kb/s using LPCNet},
  author={Valin, Jean-Marc and Skoglund, Jan},
  booktitle=interspeech,
  year={2019}
}

@inproceedings{valin2019lpcnet,
  title={{LPCN}et: Improving neural speech synthesis through linear prediction},
  author={Valin, Jean-Marc and Skoglund, Jan},
  booktitle=icassp, 
  year={2019},
}

@inproceedings{yang2023neural,
  title={Neural feature predictor and discriminative residual coding for low-bitrate speech coding},
  author={Yang, Haici and Lim, Wootaek and Kim, Minje},
  booktitle=icassp,
  year={2023},
}

@inproceedings{Jang2016Gumbel,
  title={Categorical reparameterization with gumbel-softmax},
  author={Jang, E. and Gu, S. and Poole, B.},
  booktitle=iclr,
  year={2017}
}

@inproceedings{maddison2016concrete,
  title={The concrete distribution: A continuous relaxation of discrete random variables},
  author={Maddison, Chris J and Mnih, Andriy and Teh, Yee Whye},
  booktitle=iclr,
  year={2017}
}

@article{della2025focalcodec,
  title={FocalCodec: Low-Bitrate Speech Coding via Focal Modulation Networks},
  author={Della Libera, Luca and Paissan, Francesco and Subakan, Cem and Ravanelli, Mirco},
  journal={arXiv preprint arXiv:2502.04465},
  year={2025}
}

@inproceedings{petermann2021harp,
  title={Harp-net: Hyper-autoencoded reconstruction propagation for scalable neural audio coding},
  author={Petermann, Darius and Beack, Seungkwon and Kim, Minje},
  booktitle=waspaa,
  year={2021},
}

@inproceedings{Jiang2022EndtoEndNS,
  title={End-to-End Neural Speech Coding for Real-Time Communications},
  author={Xue Jiang and Xiulian Peng and Chengyu Zheng and Huaying Xue and Yuan Zhang and Yan Lu},
  booktitle=icassp,
  year={2022},
}

@inproceedings{wu2024codecslt,
  title={Codec-{SUPERB}@ {SLT} 2024: A lightweight benchmark for neural audio codec models},
  author={Wu, Haibin and Chen, Xuanjun and Lin, Yi-Cheng and Chang, Kai-wei and Du, Jiawei and Lu, Ke-Han and Liu, Alexander H and Chung, Ho-Lam and Wu, Yuan-Kuei and Yang, Dongchao and others},
  booktitle=slt,
  year={2024},
}

@inproceedings{yang2021source,
  title={Source-aware neural speech coding for noisy speech compression},
  author={Yang, Haici and Zhen, Kai and Beack, Seungkwon and Kim, Minje},
  booktitle=icassp, 
  year={2021},
}
@inproceedings{omran2023disentangling,
  title={Disentangling speech from surroundings with neural embeddings},
  author={Omran, Ahmed and Zeghidour, Neil and Borsos, Zal{\'a}n and de Chaumont Quitry, F{\'e}lix and Slaney, Malcolm and Tagliasacchi, Marco},
  booktitle=icassp, 
  year={2023},
}

@article{Ji2024LanguageCodecRT,
  title={Language-Codec: Reducing the Gaps Between Discrete Codec Representation and Speech Language Models},
  author={Shengpeng Ji and Minghui Fang and Ziyue Jiang and Rongjie Huang and Jialung Zuo and Shulei Wang and Zhou Zhao},
  journal={arXiv preprint arXiv:2402.12208},
  year={2024},
}

@article{Pan2024PSCodecAS,
  title={PSCodec: A Series of High-Fidelity Low-bitrate Neural Speech Codecs Leveraging Prompt Encoders},
  author={Pan, Yu and Zhang, Xiang and Yang, Yuguang and Yao, Jixun and Hu, Yanni and Ye, Jianhao and Zhou, Hongbin and Ma, Lei and Zhao, Jianjun},
  journal={arXiv preprint arXiv:2404.02702},
  year={2024}
}

@inproceedings{yang24h_interspeech,
  title     = {Genhancer: High-Fidelity Speech Enhancement via Generative Modeling on Discrete Codec Tokens},
  author    = {Haici Yang and Jiaqi Su and Minje Kim and Zeyu Jin},
  year      = {2024},
  booktitle = interspeech,
}

@INPROCEEDINGS{xue24lowlatency,
  author={Xue, Huaying and Peng, Xiulian and Lu, Yan},
  booktitle=icassp,
  title={Low-Latency Speech Enhancement via Speech Token Generation}, 
  year={2024},
}

@article{Ahn2024HILCodecHA,
  title={HILCodec: High-Fidelity and Lightweight Neural Audio Codec},
  author={Ahn, Sung Hwan and Woo, Beom Jun and Han, Mingrui and Moon, Chan Yeong and Kim, Nam Soo},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  year={2024},
  volume={18},
  pages={1517-1530},
}

@inproceedings{Ye2024CodecDM,
  title={Codec does matter: Exploring the semantic shortcoming of codec for audio language model},
  author={Ye, Zhen and Sun, Peiwen and Lei, Jiahe and Lin, Hongzhan and Tan, Xu and Dai, Zheqi and Kong, Qiuqiang and Chen, Jianyi and Pan, Jiahao and Liu, Qifeng and others},
  booktitle=aaai,
  year={2025}
}


@inproceedings{Guo2024AddressingIC,
  title={Addressing Index Collapse of Large-Codebook Speech Tokenizer With Dual-Decoding Product-Quantized Variational Auto-Encoder},
  author={Haohan Guo and Fenglong Xie and Dongchao Yang and Hui Lu and Xixin Wu and Helen M. Meng},
  booktitle=slt,
  year={2024},
}


@article{Zhou2024WMCodecEN,
      title={WMCodec: End-to-End Neural Speech Codec with Deep Watermarking for Authenticity Verification}, 
      author={Junzuo Zhou and Jiangyan Yi and Yong Ren and Jianhua Tao and Tao Wang and Chu Yuan Zhang},
      journal={arXiv preprint arXiv:2409.12121},
      year={2024}
}

@article{Wu2024TS3CodecTS,
  title={TS3-Codec: Transformer-Based Simple Streaming Single Codec},
  author={Wu, Haibin and Kanda, Naoyuki and Eskimez, Sefik Emre and Li, Jinyu},
  journal={arXiv preprint arXiv:2411.18803},
  year={2024}
}

@inproceedings{Jiang2024MDCTCodecAL,
  title={MDCTCodec: A Lightweight MDCT-Based Neural Audio Codec Towards High Sampling Rate and Low Bitrate Scenarios},
  author={Xiao-Hang Jiang and Yang Ai and Ruixin Zheng and Hui-Peng Du and Ye-Xin Lu and Zhenhua Ling},
  booktitle=slt,
  year={2024},
}

@inproceedings{Guo2024LSCodecLA,
  title={LSCodec: Low-Bitrate and Speaker-Decoupled Discrete Speech Codec},
  author={Yiwei Guo and Zhihan Li and Chenpeng Du and Hankun Wang and Xie Chen and Kai Yu},
  booktitle=interspeech,
  year={2025},
}


@inproceedings{zaiem2023icassp,
    title={Fine-tuning Strategies for Faster Inference using Speech Self-Supervised Models: A Comparative Study},
    author={Zaiem, Salah and Algayres, Robin and Parcollet, Titouan and Slim, Essid and Ravanelli, Mirco},
    booktitle=icasspw,
    year={2023},
}

@inproceedings{yang2021superb,
    author={Shu-wen Yang and Po-Han Chi and Yung-Sung Chuang and Cheng-I Jeff Lai and Kushal Lakhotia and Yist Y. Lin and Andy T. Liu and Jiatong Shi and Xuankai Chang and Guan-Ting Lin and others},
    title={{SUPERB: Speech Processing Universal PERformance Benchmark}},
    year=2021,
    booktitle=interspeech,
}

@book{Rabiner:1993dq,
    author = {Rabiner, Lawrence and Juang, Biing-Hwang},
    publisher = {Prentice-Hall Signal Processing Series},
    title = {Fundamentals of Speech Recognition},
    year = 1993
}, 
@article{busso2008iemocap,
    title={{IEMOCAP}: Interactive emotional dyadic motion capture database},
    author={Busso, Carlos and Bulut, Murtaza and Lee, Chi-Chun and Kazemzadeh, Abe and Mower, Emily and Kim, Samuel and Chang, Jeannette N and Lee, Sungbok and Narayanan, Shrikanth S},
    journal={Language resources and evaluation},
    volume={42},
    pages={335--359},
    year={2008},
}

@article{lecun2015deep,
    author = {Yann LeCun and Yoshua Bengio and Geoffrey Hinton},
    title = {Deep learning},
    journal = {Nature},
    year = {2015},
    volume = {521},
    number = {7553},
    pages = {436--444},
}

@book{GoodBengCour16,
    title={Deep Learning},
    author={Ian J. Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    year={2016},
}

@article{geminiteam2023gemini,
    title={Gemini: A Family of Highly Capable Multimodal Models}, 
    author={{\relax Gemini Team, Google}},
    year={2023},
    journal={arXiv preprint arXiv:2312.11805},
}

@article{wu2025esi,
  title={Towards Efficient Speech-Text Jointly Decoding within One Speech Language Model},
  author={Wu, Haibin and Hu, Yuxuan and Fan, Ruchao and Wang, Xiaofei and Kumatani, Kenichi and Ren, Bo and Yu, Jianwei and Lu, Heng and Wang, Lijuan and Qian, Yao and others},
  journal={arXiv preprint arXiv:2506.04518},
  year={2025}
}

@inproceedings{kumar2023high,
    title={High-Fidelity Audio Compression with Improved {RVQGAN}},
    author={Rithesh Kumar and Prem Seetharaman and Alejandro Luebs and Ishaan Kumar and Kundan Kumar},
    booktitle=neurips,
    year={2023},
}

@inproceedings{zhang2023speechtokenizer,
    title={{SpeechTokenizer}: Unified speech tokenizer for speech large language models},
    author={Zhang, Xin and Zhang, Dong and Li, Shimin and Zhou, Yaqian and Qiu, Xipeng},
    booktitle=iclr,
    year={2024}
}

@inproceedings{wu2023audiodec,
    author={Wu, Yi-Chiao and Gebru, Israel D. and Marković, Dejan and Richard, Alexander},
    booktitle=icassp,
    title={Audiodec: An Open-Source Streaming High-Fidelity Neural Audio Codec}, 
    year={2023},
}

@article{yang2023hifi,
    title={{HiFi-Codec}: Group-residual Vector quantization for High Fidelity Audio Codec},
    author={Dongchao Yang and Songxiang Liu and Rongjie Huang and Jinchuan Tian and Chao Weng and Yuexian Zou},
    journal={arXiv preprint arXiv:2305.02765},
    year={2023}
}

@article{du2023funcodec,
    title={{FunCodec}: A Fundamental, Reproducible and Integrable Open-source Toolkit for Neural Speech Codec},
    author={Zhihao Du and Shiliang Zhang and Kai Hu and Siqi Zheng},
    year={2023},
    journal={arXiv preprint arXiv:2309.07405},
}

@article{borsos2023audiolm,
    author={Borsos, Zalán and Marinier, Raphaël and Vincent, Damien and Kharitonov, Eugene and Pietquin, Olivier and Sharifi, Matt and Roblek, Dominik and Teboul, Olivier and Grangier, David and Tagliasacchi, Marco and Zeghidour, Neil},
    journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
    title={{AudioLM}: A Language Modeling Approach to Audio Generation}, 
    year={2023},
    volume={31},
    number={},
    pages={2523--2533},
}


@article{rubenstein2023audiopalm,
    title={{AudioPaLM}: A Large Language Model That Can Speak and Listen},
    author={Paul K. Rubenstein and Chulayuth Asawaroengchai and Duc Dung Nguyen and Ankur Bapna and Zalán Borsos and Félix de Chaumont Quitry and Peter Chen and Dalia El Badawy and Wei Han and Eugene Kharitonov and Hannah Muckenhirn and others},
    journal={arXiv preprint arXiv:2306.12925},
    year={2023}
}

@article{wang2024viola,
  title={Viola: Conditional language models for speech recognition, synthesis, and translation},
  author={Wang, Tianrui and Zhou, Long and Zhang, Ziqiang and Wu, Yu and Liu, Shujie and Gaur, Yashesh and Chen, Zhuo and Li, Jinyu and Wei, Furu},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2024},
  pages={3709-3716},
  publisher={IEEE}
}

@inproceedings{sicherman2023analysing,
  title={Analysing discrete self supervised speech representation for spoken language modeling},
  author={Sicherman, Amitay and Adi, Yossi},
  booktitle=icassp,
  year={2023},
}

@article{arora2025landscape,
  title={On The Landscape of Spoken Language Models: A Comprehensive Survey},
  author={Arora, Siddhant and Chang, Kai-Wei and Chien, Chung-Ming and Peng, Yifan and Wu, Haibin and Adi, Yossi and Dupoux, Emmanuel and Lee, Hung-Yi and Livescu, Karen and Watanabe, Shinji},
  journal={arXiv preprint arXiv:2504.08528},
  year={2025}
}

@inproceedings{chen2023lauragpt,
    title={{LauraGPT}: Listen, attend, understand, and regenerate audio with {GPT}},
    author={Jiaming Wang and Zhihao Du and Qian Chen and Yunfei Chu and Zhifu Gao and Zerui Li and Kai Hu and Xiaohuan Zhou and Jin Xu and Ziyang Ma and Wen Wang and Siqi Zheng and Chang Zhou and Zhijie Yan and Shiliang Zhang},
    booktitle=iclr,
    year={2024}
}

@article{borsos2023soundstorm,
    title={{SoundStorm}: Efficient Parallel Audio Generation},
    author={Borsos, Zal{\'a}n and Sharifi, Matt and Vincent, Damien and Kharitonov, Eugene and Zeghidour, Neil and Tagliasacchi, Marco},
    journal={arXiv preprint arXiv:2305.09636},
    year={2023}
}

@article{wang2023viola,
    title={{VioLA}: Unified Codec Language Models for Speech Recognition, Synthesis, and Translation},
    author={Tianrui Wang and Long Zhou and Ziqiang Zhang and Yu Wu and Shujie Liu and Yashesh Gaur and Zhuo Chen and Jinyu Li and Furu Wei},
    journal={arXiv preprint arXiv:2305.16107},
    year={2023}
}


@article{wang2023speechx,
    title={SpeechX: Neural Codec Language Model as a Versatile Speech Transformer}, 
    author={Wang, Xiaofei and Thakker, Manthan and Chen, Zhuo and Kanda, Naoyuki and Eskimez, Sefik Emre and Chen, Sanyuan and Tang, Min and Liu, Shujie and Li, Jinyu and Yoshioka, Takuya},
    journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
    year={2024},
    volume={32},
    number={},
    pages={3355-3364},
}

@inproceedings{kreuk2022audiogen,
    title={{AudioGen}: Textually Guided Audio Generation},
    author={Kreuk, Felix and Synnaeve, Gabriel and Polyak, Adam and Singer, Uriel and D{\'e}fossez, Alexandre and Copet, Jade and Parikh, Devi and Taigman, Yaniv and Adi, Yossi},
    booktitle=iclr, 
    year={2023},
}

@inproceedings{desplanques2020ecapa,
    title={{ECAPA-TDNN}: Emphasized channel attention, propagation and aggregation in {TDNN} based speaker verification},
    author={Desplanques, Brecht and Thienpondt, Jenthe and Demuynck, Kris},
    booktitle=interspeech, 
    year={2020}
}

@inproceedings{ardila2019common,
    title = "{Common Voice}: A Massively-Multilingual Speech Corpus",
    author = "Ardila, Rosana  and
    Branson, Megan  and
    Davis, Kelly  and
    Kohler, Michael  and
    Meyer, Josh  and
    Henretty, Michael  and
    Morais, Reuben  and
    Saunders, Lindsay  and
    Tyers, Francis  and
    Weber, Gregor",
    booktitle = lrec,
    year = "2020",
}

@article{agostinelli2023musiclm,
    title={{MusicLM}: Generating music from text},
    author={Agostinelli, Andrea and others},
    journal={arXiv preprint arXiv:2301.11325},
    year={2023}
}

@inproceedings{yang2023uniaudio,
  title={{UniAudio}: Towards universal audio generation with large language models},
  author={Yang, Dongchao and Tian, Jinchuan and Tan, Xu and Huang, Rongjie and Liu, Songxiang and Guo, Haohan and Chang, Xuankai and Shi, Jiatong and Bian, Jiang and Zhao, Zhou and others},
  booktitle=icml,
  year={2024}
}

@inproceedings{wells2022phonetic,
    title={Phonetic analysis of self-supervised representations of {E}nglish speech},
    author={Wells, Dan and Tang, Hao and Richmond, Korin},
    booktitle=interspeech, 
    year={2022},
}

@inproceedings{polyak2021speech,
    author={Adam Polyak and Yossi Adi and Jade Copet and 
          Eugene Kharitonov and Kushal Lakhotia and 
          Wei-Ning Hsu and Abdelrahman Mohamed and Emmanuel Dupoux},
    title={Speech Resynthesis from Discrete Disentangled Self-Supervised Representations},
    year={2021},
    booktitle=interspeech, 
}

@article{du2025codecfake,
  title={CodecFake-Omni: A Large-Scale Codec-based Deepfake Speech Dataset},
  author={Du, Jiawei and Chen, Xuanjun and Wu, Haibin and Zhang, Lin and Lin, I and Chiu, I and Ren, Wenze and Tseng, Yuan and Tsao, Yu and Jang, Jyh-Shing Roger and others},
  journal={arXiv preprint arXiv:2501.08238},
  year={2025}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{defossez2024moshi,
  title={Moshi: a speech-text foundation model for real-time dialogue},
  author={D{\'e}fossez, Alexandre and Mazar{\'e}, Laurent and Orsini, Manu and Royer, Am{\'e}lie and P{\'e}rez, Patrick and J{\'e}gou, Herv{\'e} and Grave, Edouard and Zeghidour, Neil},
  journal={arXiv preprint arXiv:2410.00037},
  year={2024}
}

@inproceedings{kharitonov2021text,
    title = "Text-Free Prosody-Aware Generative Spoken Language Modeling",
    author = "Kharitonov, Eugene  and
      Lee, Ann  and
      Polyak, Adam  and
      Adi, Yossi  and
      Copet, Jade  and
      Lakhotia, Kushal  and
      Nguyen, Tu Anh  and
      Riviere, Morgane  and
      Mohamed, Abdelrahman  and
      Dupoux, Emmanuel  and
      Hsu, Wei-Ning",
    booktitle = acl,
    year = "2022",
}

@article{nguyen2023generative,
    title={Generative spoken dialogue language modeling},
    author={Nguyen, Tu Anh and Kharitonov, Eugene and Copet, Jade and Adi, Yossi and Hsu, Wei-Ning and Elkahky, Ali and Tomasello, Paden and Algayres, Robin and Sagot, Benoit and Mohamed, Abdelrahman and others},
    journal={Transactions of the Association for Computational Linguistics},
    volume={11},
    pages={250--266},
    year={2023},
}

@inproceedings{popuri2022enhanced,
  title={Enhanced Direct Speech-to-Speech Translation Using Self-supervised Pre-training and Data Augmentation},
  author={Popuri, Sravya and Chen, Peng-Jen and Wang, Changhan and Pino, Juan and Adi, Yossi and Gu, Jiatao and Hsu, Wei-Ning and Lee, Ann},
  booktitle=interspeech,
  year={2022}
}

@inproceedings{inaguma2022unity,
  title={UnitY: Two-pass Direct Speech-to-speech Translation with Discrete Units},
  author={Inaguma, Hirofumi and Popuri, Sravya and Kulikov, Ilia and Chen, Peng-Jen and Wang, Changhan and Chung, Yu-An and Tang, Yun and Lee, Ann and Watanabe, Shinji and Pino, Juan},
  booktitle=acl,
  year={2023}
}

@inproceedings{chang2022speechprompt,
  title={SpeechPrompt: An exploration of prompt tuning on generative spoken language model for speech processing tasks},
  author={Chang, Kai-Wei and Tseng, Wei-Cheng and Li, Shang-Wen and Lee, Hung-yi},
  booktitle=interspeech,
  year={2022}
}
@article{chang2023speechprompt,
  title={Speechprompt v2: Prompt tuning for speech classification tasks},
  author={Chang, Kai-Wei and Wang, Yu-Kai and Shen, Hua and Kang, Iu-thing and Tseng, Wei-Cheng and Li, Shang-Wen and Lee, Hung-yi},
  journal={arXiv preprint arXiv:2303.00733},
  year={2023}
}

@inproceedings{hsu2023exploration,
  title={An exploration of in-context learning for speech language model},
  author={Hsu, Ming-Hao and Chang, Kai-Wei and Li, Shang-Wen and Lee, Hung-yi},
  booktitle=interspeech,
  year={2024}
}
@inproceedings{kuan2023towards,
  title={Towards General-Purpose Text-Instruction-Guided Voice Conversion},
  author={Kuan, Chun-Yi and Li, Chen-An and Hsu, Tsu-Yuan and Lin, Tse-Yang and Chung, Ho-Lam and Chang, Kai-Wei and Chang, Shuo-Yiin and Lee, Hung-yi},
  booktitle=asru,
  year={2023},
  organization={IEEE}
}

@article{zeng2024glm,
  title={G{LM}-4-voice: Towards intelligent and human-like end-to-end spoken chatbot},
  author={Zeng, Aohan and Du, Zhengxiao and Liu, Mingdao and Wang, Kedong and Jiang, Shengmin and Zhao, Lei and Dong, Yuxiao and Tang, Jie},
  journal={arXiv preprint arXiv:2412.02612},
  year={2024}
}

@inproceedings{huang2023dynamic,
  title={Dynamic-{SUPERB}: Towards a dynamic, collaborative, and comprehensive instruction-tuning benchmark for speech},
  author={Huang, Chien-yu and Lu, Ke-Han and Wang, Shih-Heng and Hsiao, Chi-Yuan and Kuan, Chun-Yi and Wu, Haibin and Arora, Siddhant and Chang, Kai-Wei and Shi, Jiatong and Peng, Yifan and others},
  booktitle=icassp, 
  pages={12136--12140},
  year={2024},
}

@inproceedings{huang2024dynamic,
  title={Dynamic-superb phase-2: A collaboratively expanding benchmark for measuring the capabilities of spoken language models with 180 tasks},
  author={Huang, Chien-yu and Chen, Wei-Chih and Yang, Shu-wen and Liu, Andy T and Li, Chen-An and Lin, Yu-Xiang and Tseng, Wei-Cheng and Diwan, Anuj and Shih, Yi-Jen and Shi, Jiatong and others},
  booktitle=iclr,
  year={2025}
}

@article{xu2025qwen2,
  title={Qwen2. 5-omni technical report},
  author={Xu, Jin and Guo, Zhifang and He, Jinzheng and Hu, Hangrui and He, Ting and Bai, Shuai and Chen, Keqin and Wang, Jialin and Fan, Yang and Dang, Kai and others},
  journal={arXiv preprint arXiv:2503.20215},
  year={2025}
}

@article{liu2023pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={ACM Computing Surveys},
  volume={55},
  number={9},
  pages={1--35},
  year={2023},
  publisher={ACM New York, NY}
}
@inproceedings{lester2021power,
  title={The power of scale for parameter-efficient prompt tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  booktitle=emnlp,
  year={2021}
}

@inproceedings{chang2023exploring,
  author={Chang, Xuankai and Yan, Brian and Choi, Kwanghee and Jung, Jee-Weon and Lu, Yichen and Maiti, Soumi and Sharma, Roshan and Shi, Jiatong and Tian, Jinchuan and Watanabe, Shinji and Fujita, Yuya and others},
  booktitle=icassp, 
  title={Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study}, 
  year={2024},
  volume={},
  number={},
}

@inproceedings{wang2023selm,
    title={{SELM}: Speech Enhancement Using Discrete Tokens and Language Models}, 
    author={Wang, Ziqian and Zhu, Xinfa and Zhang, Zihan and Lv, YuanJun and Jiang, Ning and Zhao, Guoqing and Xie, Lei},
    booktitle=icassp, 
    year={2024},
}

@inproceedings{wu2024codec,
  title={{Codec-SUPERB}: An In-Depth Analysis of Sound Codec Models},
  author={Wu, Haibin and Chung, Ho-Lam and Lin, Yi-Cheng and Wu, Yuan-Kuei and Chen, Xuanjun and Pai, Yu-Chi and Wang, Hsiu-Hsuan and Chang, Kai-Wei and Liu, Alexander H and Lee, Hung-yi},
  booktitle = acl,
  year={2024}
}


@inproceedings{zhang2023dub,
    title = "{DUB}: Discrete Unit Back-translation for Speech Translation",
    author = "Zhang, Dong  and
      Ye, Rong  and
      Ko, Tom  and
      Wang, Mingxuan  and
      Zhou, Yaqian",
    booktitle = acl,
    year = "2023",
}

@inproceedings{wu2024toksing,
  title={TokSing: Singing Voice Synthesis based on Discrete Tokens},
  author={Wu, Yuning and Zhang, Chunlei and Shi, Jiatong and Tang, Yuxun and Yang, Shan and Jin, Qin},
  booktitle=interspeech, 
  year={2024}
}

@inproceedings{yip2024towards,
  title={Towards audio codec-based speech separation},
  author={Yip, Jia Qi and Zhao, Shengkui and Ng, Dianwen and Chng, Eng Siong and Ma, Bin},
  booktitle=interspeech, 
  year={2024}
}

@inproceedings{chung2021w2v,
  author={Chung, Yu-An and Zhang, Yu and Han, Wei and Chiu, Chung-Cheng and Qin, James and Pang, Ruoming and Wu, Yonghui},
  booktitle=asru, 
  title={{w2v-BERT}: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training}, 
  year={2021},
}

@article{hsu2021hubert,
    title={{HuBERT}: Self-supervised speech representation learning by masked prediction of hidden units},
    author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
    journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
    volume={29},
    pages={3451--3460},
    year={2021},
}

@article{chen2022wavlm,
    title={{WavLM}: Large-scale self-supervised pre-training for full stack speech processing},
    author={Chen, Sanyuan and Wang, Chengyi and Chen, Zhengyang and Wu, Yu and Liu, Shujie and Chen, Zhuo and Li, Jinyu and Kanda, Naoyuki and Yoshioka, Takuya and Xiao, Xiong and others},
    journal={IEEE Journal of Selected Topics in Signal Processing},
    volume={16},
    number={6},
    pages={1505--1518},
    year={2022},
}

@inproceedings{baevski2020wav2vec,
    title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
    author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
    booktitle=neurips,
    year={2020},
}

@inproceedings{chang2023exploration,
  author={Xuankai Chang and Brian Yan and Yuya Fujita and Takashi Maekaku and Shinji Watanabe},
  title={Exploration of Efficient End-to-End {ASR} using Discretized Input from Self-Supervised Learning},
  year=2023,
  booktitle=interspeech, 
}

@inproceedings{pasad2023comparative,
  title={Comparative layer-wise analysis of self-supervised speech models},
  author={Pasad, Ankita and Shi, Bowen and Livescu, Karen},
  booktitle=icassp, 
  year={2023},
}

@article{goodfellow2020generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Communications of the ACM},
  volume={63},
  number={11},
  pages={139--144},
  year={2020},
  publisher={ACM New York, NY, USA}
}


@inproceedings{kong2020hifigan,
    author = {Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung},
    title = {{HiFi-GAN}: generative adversarial networks for efficient and high fidelity speech synthesis},
    year = {2020},
    booktitle = neurips,
}



@article{oord2016wavenet,
      title={WaveNet: A Generative Model for Raw Audio}, 
      author={Aaron van den Oord and Sander Dieleman and Heiga Zen and Karen Simonyan and Oriol Vinyals and Alex Graves and Nal Kalchbrenner and Andrew Senior and Koray Kavukcuoglu},
      year={2016},
      journal={arXiv preprint arXiv:1609.03499},
}

@inproceedings{prenger2018waveglow,
  author={Prenger, Ryan and Valle, Rafael and Catanzaro, Bryan},
  booktitle=icassp, 
  title={Waveglow: A Flow-based Generative Network for Speech Synthesis}, 
  year={2019},
}

@inproceedings{transformer,
    author = {Ashish Vaswani and
                  Noam Shazeer and
                  Niki Parmar and
                  Jakob Uszkoreit and
                  Llion Jones and
                  Aidan N. Gomez and
                  Lukasz Kaiser and
                  Illia Polosukhin},
    title = {Attention is All You Need},
    year = {2017},
    booktitle=neurips,
}


@inproceedings{somos,
  title={{SOMOS: The Samsung Open MOS Dataset for the Evaluation of Neural Text-to-Speech Synthesis}},
  author={Georgia Maniati and Alexandra Vioni and Nikolaos Ellinas and Karolos Nikitaras and Konstantinos Klapsas and June Sig Sung and Gunu Jho and Aimilios Chalamandaris and Pirros Tsiakoulis},
  booktitle=interspeech,
  year={2022},
}


@inproceedings{yang2023towards,
    title={Towards Universal Speech Discrete Tokens: A Case Study for {ASR} and {TTS}}, 
    author={Yang, Yifan and Shen, Feiyu and Du, Chenpeng and Ma, Ziyang and Yu, Kai and Povey, Daniel and Chen, Xie},
    booktitle = icassp, 
    year={2024},
}


@inproceedings{wang2021dwer,
    author={Wang, Zhong-Qiu and others},
    booktitle=slt,
    title={Sequential Multi-Frame Neural Beamforming for Speech Separation and Enhancement}, 
    year={2021},
}


@inproceedings{wichern2019wham,
    title={{WHAM!}: Extending Speech Separation to Noisy Environments}, 
    author={Gordon Wichern and others},
    year={2019},
    booktitle=interspeech, 
}

@inproceedings{le2019sdr,
    title={{SDR}--half-baked or well done?},
    author={Le Roux, J. and Wisdom, S. and Erdogan, H. and Hershey, J. R.},
    booktitle=icassp,
    year={2019},
}   


@misc{ljspeech17,
  author       = {Keith Ito},
  title        = {The {LJ} Speech Dataset},
  howpublished = {\url{https://keithito.com/LJ-Speech-Dataset/} },
  year         = 2017
}
@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and others},
  journal={The journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@inproceedings{nagrani2017voxceleb,
  author={Arsha Nagrani and Joon Son Chung and Andrew Zisserman},
  title={{VoxCeleb}: A Large-Scale Speaker Identification Dataset},
  year=2017,
  booktitle=interspeech,
}

@inproceedings{1360861705599880960,
    author="Saeki, Takaaki, and others",
    title="{{UTMOS: UTokyo-SaruLab System for VoiceMOS Challenge 2022}}",
    booktitle=interspeech,
    year="2022",
}


@article{zaiem2025speech,
  title={Speech self-supervised representations benchmarking: a case for larger probing heads},
  author={Zaiem, Salah and Kemiche, Youcef and Parcollet, Titouan and Essid, Slim and Ravanelli, Mirco},
  journal={Computer Speech \& Language},
  volume={89},
  pages={101695},
  year={2025},
  publisher={Elsevier}
}



@article{
defossez2022high,
title={High Fidelity Neural Audio Compression},
author={Alexandre D{\'e}fossez and Jade Copet and Gabriel Synnaeve and Yossi Adi},
journal={Transactions on Machine Learning Research},
year={2023},
}

@inproceedings{DevlinCLT19,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = naacl,
    year = "2019",
}

@inproceedings{newell2020useful,
  title={How useful is self-supervised pretraining for visual tasks?},
  author={Newell, Alejandro and Deng, Jia},
  booktitle=cvpr,
  year={2020}
}

@article{liu2021self,
  title={Self-supervised learning: Generative or contrastive},
  author={Liu, Xiao and Zhang, Fanjin and Hou, Zhenyu and Mian, Li and Wang, Zhaoyu and Zhang, Jing and Tang, Jie},
  journal={IEEE Transactions on knowledge and data engineering},
  volume={35},
  number={1},
  pages={857--876},
  year={2021},
  publisher={IEEE}
}

@article{JMLR:v24:22-1144,
    author = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
    title = {{PaLM}: scaling language modeling with pathways},
    year = {2024},
    volume = {24},
    journal = {Journal of Machine Learning Research},
}

@article{liu2023gpt,
    title={{GPT} understands, too},
    author={Liu, Xiao and Zheng, Yanan and Du, Zhengxiao and Ding, Ming and Qian, Yujie and Yang, Zhilin and Tang, Jie},
    journal={AI Open},
    year={2023},
}

@article{speechbrain_ravanelli,
  title={Open-source conversational ai with speechbrain 1.0},
  author={Ravanelli, Mirco and Parcollet, Titouan and Moumen, Adel and de Langen, Sylvain and Subakan, Cem and Plantinga, Peter and Wang, Yingzhi and Mousavi, Pooneh and Della Libera, Luca and Ploujnikov, Artem and others},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={333},
  pages={1--11},
  year={2024}
}
@inproceedings{wang2024evaluating,
  title={Evaluating Text-to-Speech Synthesis from a Large Discrete Token-based Speech Language Model},
  author={Wang, Siyang and Sz{\'e}kely, {\'E}va},
  booktitle=LREC-COLING,
  year={2024}
}

@article{wang2023neural,
  author={Chen, Sanyuan and Wang, Chengyi and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and He, Lei and Zhao, Sheng and Wei, Furu},
  journal={IEEE Transactions on Audio, Speech and Language Processing}, 
  title={Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers}, 
  year={2025},
  volume={33},
  number={},
  pages={705-718},
}

@article{kharitonov2023speak,
  title={Speak, read and prompt: High-fidelity text-to-speech with minimal supervision},
  author={Kharitonov, Eugene and Vincent, Damien and Borsos, Zal{\'a}n and Marinier, Rapha{\"e}l and Girgin, Sertan and Pietquin, Olivier and Sharifi, Matt and Tagliasacchi, Marco and Zeghidour, Neil},
  journal={Transactions of the Association for Computational Linguistics},
  volume={11},
  pages={1703--1718},
  year={2023},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{shi2021discretization,
  title={Discretization and re-synthesis: an alternative method to solve the cocktail party problem},
  author={Shi, Jing and Chang, Xuankai and Hayashi, Tomoki and Lu, Yen-Ju and Watanabe, Shinji and Xu, Bo},
  journal={arXiv preprint arXiv:2112.09382},
  year={2021}
}

@inproceedings{erdogan2023tokensplit,
    title={{TokenSplit}: Using Discrete Speech Representations for Direct, Refined, and Transcript-Conditioned Speech Separation and Recognition}, 
  author={Erdogan, Hakan and Wisdom, Scott and Chang, Xuankai and Borsos, Zal{\'a}n and Tagliasacchi, Marco and Zeghidour, Neil and Hershey, John R},
    year={2023},
    booktitle=interspeech,
}

@inproceedings{puvvada2023discrete,
    author={Puvvada, Krishna C. and Rao Koluguri, Nithin and Dhawan, Kunal and Balam, Jagadeesh and Ginsburg, Boris},
    booktitle=icassp, 
    title={Discrete Audio Representation as an Alternative to {M}el-Spectrograms for Speaker and Speech Recognition}, 
    year={2024},
}

@inproceedings{wu2024codecfake,
  title={Codecfake: Enhancing anti-spoofing models against deepfake audios from codec-based speech synthesis systems},
  author={Wu, Haibin and Tseng, Yuan and Lee, Hung-yi},
  booktitle=interspeech,
  year={2024}
}

@inproceedings{ren2024emo,
  title={EMO-Codec: An In-Depth Look at Emotion Preservation Capacity of Legacy and Neural Codec Models with Subjective and Objective Evaluations},
  author={Ren, Wenze and Lin, Yi-Cheng and Chou, Huang-Cheng and Wu, Haibin and Wu, Yi-Chiao and Lee, Chi-Chun and Lee, Hung-yi and Wang, Hsin-Min and Tsao, Yu},
  booktitle=APSIPA_ASC,
  year={2024},
}


@inproceedings{mousavi2024,
  title={Semantic Token Tuning: How Should We Extract Discrete Audio Tokens from Self-Supervised Models?},
  author={Mousavi, Pooneh and Duret, Jarod and Zaiem, Salah and Della Libera, Luca and Ploujnikov, Artem and Subakan, Cem and Ravanelli, Mirco},
  booktitle=interspeech,
  year={2024},
}


@inproceedings{korvas_2014,
    title = "Free {E}nglish and {C}zech telephone speech corpus shared under the {CC}-{BY}-{SA} 3.0 license",
    author = "Korvas, Mat{\v{e}}j  and
      Pl{\'a}tek, Ond{\v{r}}ej  and
      Du{\v{s}}ek, Ond{\v{r}}ej  and
      {\v{Z}}ilka, Luk{\'a}{\v{s}}  and
      Jur{\v{c}}{\'\i}{\v{c}}ek, Filip",
    booktitle = lrec,
    year = "2014",
}

@inproceedings{han2020contextnet,
  author={Wei Han and Zhengdong Zhang and Yu Zhang and Jiahui Yu and Chung-Cheng Chiu and James Qin and Anmol Gulati and Ruoming Pang and Yonghui Wu},
  title={{ContextNet}: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context},
  year=2020,
  booktitle=interspeech,
}


@inproceedings{snyder2018x,
  title={X-vectors: Robust {DNN} embeddings for speaker recognition},
  author={Snyder, David and Garcia-Romero, Daniel and Sell, Gregory and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle=icassp, 
  year={2018},
}

@article{wang2018additive,
  title={Additive margin softmax for face verification},
  author={Wang, Feng and Cheng, Jian and Liu, Weiyang and Liu, Haijun},
  journal={IEEE Signal Processing Letters},
  volume={25},
  number={7},
  pages={926--930},
  year={2018},
}

@inproceedings{bastianelli2020slurp,
    title = "{SLURP}: A Spoken Language Understanding Resource Package",
    author = "Bastianelli, Emanuele  and
      Vanzo, Andrea  and
      Swietojanski, Pawel  and
      Rieser, Verena",
    booktitle = emnlp,
    year = "2020",
}


@article{warden2017speech,
    author={Warden, Pete},
    title = {{Speech Commands}: A Dataset for Limited-Vocabulary Speech Recognition},
    journal={arXiv preprint arXiv:1804.03209},
    year = 2018,
}


@inproceedings{tacotron2,
  author={Shen, Jonathan and Pang, Ruoming and Weiss, Ron J. and Schuster, Mike and Jaitly, Navdeep and Yang, Zongheng and Chen, Zhifeng and Zhang, Yu and Wang, Yuxuan and Skerrv-Ryan, Rj and Saurous, Rif A. and Agiomvrgiannakis, Yannis and Wu, Yonghui},
  booktitle=icassp, 
  title={Natural {TTS} Synthesis by Conditioning {WaveNet} on {Mel} Spectrogram Predictions}, 
  year={2018},
}


@inproceedings{guided-attention,
    author={Tachibana, Hideyuki and Uenoyama, Katsuya and Aihara, Shunsuke},
    booktitle=icassp, 
    title={Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention}, 
    year={2018},
}


@article{levenshtein,
  author = {Levenshtein, Vladimir I},
  journal = {Soviet Physics Doklady},
  pages = 707,
  title = {Binary Codes Capable of Correcting Deletions, Insertions and Reversals},
  volume = 10,
  year = 1966
}

@article{dwer,
  author = {Wang, Zhong{-}Qiu and Wisdom, Scott and Wilson, Kevin W. and Hershey, John R.},
  title = {Alternating Between Spectral and Spatial Estimation for Speech Separation and Enhancement},
  journal={arXiv preprint arXiv:1911.07953},
  year={2019},
}

@article{abouelenin2025phi,
  title={Phi-4-mini technical report: Compact yet powerful multimodal language models via mixture-of-loras},
  author={Abouelenin, Abdelrahman and Ashfaq, Atabak and Atkinson, Adam and Awadalla, Hany and Bach, Nguyen and Bao, Jianmin and Benhaim, Alon and Cai, Martin and Chaudhary, Vishrav and Chen, Congcong and others},
  journal={arXiv preprint arXiv:2503.01743},
  year={2025}
}

@article{chang2024speechprompt,
  title={Speechprompt: Prompting speech language models for speech processing tasks},
  author={Chang, Kai-Wei and Wu, Haibin and Wang, Yu-Kai and Wu, Yuan-Kuei and Shen, Hua and Tseng, Wei-Cheng and Kang, Iu-thing and Li, Shang-Wen and Lee, Hung-yi},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2024},
  publisher={IEEE}
}

@article{cp-decomposition,
  title={The Expression of a Tensor or a Polyadic as a Sum of Products},
  author={Hitchcock, Frank Lauren},
  journal={Journal of Mathematics and Physics},
  year={1927},
  volume={6},
  pages={164-189},
}
@article{dubey2024icassp,
  title={{ICASSP} 2023 deep noise suppression challenge},
  author={Dubey, Harishchandra and Aazami, Ashkan and Gopal, Vishak and Naderi, Babak and Braun, Sebastian and Cutler, Ross and Ju, Alex and Zohourian, Mehdi and Tang, Min and Golestaneh, Mehrsa and others},
  journal={IEEE Open Journal of Signal Processing},
  year={2024},
}

@inproceedings{gemmeke2017audio,
  title={{Audio Set}: An ontology and human-labeled dataset for audio events},
  author={Gemmeke, Jort F and Ellis, Daniel PW and Freedman, Dylan and Jansen, Aren and Lawrence, Wade and Moore, R Channing and Plakal, Manoj and Ritter, Marvin},
  booktitle=icassp, 
  year={2017},
}

@article{fonseca2021fsd50k,
  title={{FSD50K}: an open dataset of human-labeled sound events},
  author={Fonseca, Eduardo and Favory, Xavier and Pons, Jordi and Font, Frederic and Serra, Xavier},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={30},
  pages={829--852},
  year={2021},
}

@inproceedings{bogdanov2019mtg,
  title={The {MTG-Jamendo} dataset for automatic music tagging},
  author={Bogdanov, Dmitry and Won, Minz and Tovstogan, Philip and Porter, Alastair and Serra, Xavier},
  year={2019},
  booktitle=icml
}

@article{mysore2014can,
  title={Can we automatically transform speech recorded on common consumer devices in real-world environments into professional production quality speech?—{A} dataset, insights, and challenges},
  author={Mysore, Gautham J},
  journal={IEEE Signal Processing Letters},
  volume={22},
  number={8},
  pages={1006--1010},
  year={2014},
  publisher={IEEE}
}


@misc{vctk2017,
  author={Yamagishi, Junichi and Veaux, Christophe and MacDonald, Kirsten},
  title={{CSTR VCTK Corpus}: English Multi-speaker Corpus for {CSTR} Voice Cloning Toolkit (version 0.92)},
  publisher={University of Edinburgh. The Centre for Speech Technology Research (CSTR)},
  year=2019,
  doi={10.7488/ds/2645},
}


@inproceedings{reddy2022dnsmos,
    title={{DNSMOS P.835}: A non-intrusive perceptual objective speech quality metric to evaluate noise suppressors},
    author={Reddy, Chandan KA and Gopal, Vishak and Cutler, Ross},
    booktitle=icassp,
    year={2022}, 
}


@inproceedings{valentinibotinhao2016voicebank,
    title={Investigating {RNN}-based speech enhancement methods for noise-robust Text-to-Speech},
    author={Cassia Valentini-Botinhao and Xin Wang and Shinji Takaki and Junichi Yamagishi},
    booktitle={Speech Synthesis Workshop},
    year={2016},
    pages = {146--152},
}

@article{cosentino2020librimix,
    title={{LibriMix}: An Open-Source Dataset for Generalizable Speech Separation},
    author={Joris Cosentino and Manuel Pariente and Samuele Cornell and Antoine Deleforge and Emmanuel Vincent},
    journal={arXiv preprint arXiv:2005.11262},
    year={2020},
}

@inproceedings{gulati_conformer,
  author={Anmol Gulati and James Qin and Chung-Cheng Chiu and Niki Parmar and Yu Zhang and Jiahui Yu and Wei Han and Shibo Wang and Zhengdong Zhang and Yonghui Wu and Ruoming Pang},
  title={Conformer: Convolution-augmented Transformer for Speech Recognition},
  year=2020,
  booktitle=interspeech,
}

@inproceedings{zhan2024anygpt,
  title={AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling},
  author={Zhan, Jun and Dai, Junqi and Ye, Jiasheng and Zhou, Yunhua and Zhang, Dong and Liu, Zhigeng and Zhang, Xin and Yuan, Ruibin and Zhang, Ge and Li, Linyang and others},
  booktitle = acl,
  year={2024}
}

@article{xin2024bigcodec,
  title={Bigcodec: Pushing the limits of low-bitrate neural speech codec},
  author={Xin, Detai and Tan, Xu and Takamichi, Shinnosuke and Saruwatari, Hiroshi},
  journal={arXiv preprint arXiv:2409.05377},
  year={2024}
}

@inproceedings{niu2024ndvq,
  title={{NDVQ}: Robust neural audio codec with normal distribution-based vector quantization},
  author={Niu, Zhikang and Chen, Sanyuan and Zhou, Long and Ma, Ziyang and Chen, Xie and Liu, Shujie},
  booktitle=slt,
  year={2024},
}

@article{siuzdak2024snac,
  title={{SNAC}: Multi-scale neural audio codec},
  author={Siuzdak, Hubert and Gr{\"o}tschla, Florian and Lanzend{\"o}rfer, Luca A},
  journal={arXiv preprint arXiv:2410.14411},
  year={2024}
}

@inproceedings{chiu2022bestrq,
  title={Self-supervised learning with random-projection quantizer for speech recognition},
  author={Chiu, Chung-Cheng and Qin, James and Zhang, Yu and Yu, Jiahui and Wu, Yonghui},
  booktitle=icml,
  year={2022},
}

@article{zhang2023googleusm,
  title={Google {USM}: Scaling automatic speech recognition beyond 100 languages},
  author={Zhang, Yu and Han, Wei and Qin, James and Wang, Yongqiang and Bapna, Ankur and Chen, Zhehuai and Chen, Nanxin and Li, Bo and Axelrod, Vera and Wang, Gary and others},
  journal={arXiv preprint arXiv:2303.01037},
  year={2023}
}

@article{langman2024spectral,
  title={Spectral codecs: Spectrogram-based audio codecs for high quality speech synthesis},
  author={Langman, Ryan and Juki{\'c}, Ante and Dhawan, Kunal and Koluguri, Nithin Rao and Ginsburg, Boris},
  journal={arXiv preprint arXiv:2406.05298},
  year={2024}
}

@inproceedings{gu2024esc,
  title={Esc: Efficient speech coding with cross-scale residual vector quantized transformers},
  author={Gu, Yuzhe and Diao, Enmao},
  booktitle=emnlp,
  year={2024}
}

@inproceedings{tang2024singomd,
  title={Sing{OMD}: Singing Oriented Multi-resolution Discrete Representation Construction from Speech Models},
  author={Tang, Yuxun and Wu, Yuning and Shi, Jiatong and Jin, Qin},
  booktitle=interspeech,
  year={2024}
}

@inproceedings{shi2024mmm,
  title={{MMM}: Multi-Layer Multi-Residual Multi-Stream Discrete Speech Representation from Self-supervised Learning Model},
  author={Shi, Jiatong and Ma, Xutai and Inaguma, Hirofumi and Sun, Anna and Watanabe, Shinji},
  booktitle=interspeech,
  year={2024}
}


@inproceedings{messica2024nast,
  title={Nast: Noise aware speech tokenization for speech language models},
  author={Messica, Shoval and Adi, Yossi},
  booktitle=interspeech,
  year={2024}
}

@inproceedings{chen-etal-2024-towards-robust,
    title = "Towards Robust Speech Representation Learning for Thousands of Languages",
    author = "Chen, William  and
      Zhang, Wangyou  and
      Peng, Yifan  and
      Li, Xinjian  and
      Tian, Jinchuan  and
      Shi, Jiatong  and
      Chang, Xuankai  and
      Maiti, Soumi  and
      Livescu, Karen  and
      Watanabe, Shinji",
    booktitle =emnlp,
    year = "2024",
}

@inproceedings{zhang2023speechgpt,
  title={Speechgpt: Empowering large language models with intrinsic cross-modal conversational abilities},
  author={Zhang, Dong and Li, Shimin and Zhang, Xin and Zhan, Jun and Wang, Pengyu and Zhou, Yaqian and Qiu, Xipeng},
  booktitle=emnlp,
  year={2023}
}

@misc{valin2012definition,
  title={RFC 6716: Definition of the Opus audio codec},
  author={Valin, Jean-Marc and Vos, Koen and Terriberry, T},
  year={2012},
  publisher={RFC Editor}
}

@inproceedings{dietz2015overview,
  title={Overview of the {EVS} codec architecture},
  author={Dietz, Martin and Multrus, Markus and Eksler, Vaclav and Malenovsky, Vladimir and Norvell, Erik and Pobloth, Harald and Miao, Lei and Wang, Zhe and Laaksonen, Lasse and Vasilache, Adriana and others},
  booktitle=icassp,
  year={2015},
}

@inproceedings{fma_dataset,
  title = {{FMA}: A Dataset for Music Analysis},
  author = {Defferrard, Micha\"el and Benzi, Kirell and Vandergheynst, Pierre and Bresson, Xavier},
  booktitle = ismir, 
  year = {2017},
}


@inproceedings{evans2025stable,
  title={Stable audio open},
  author={Evans, Zach and Parker, Julian D and Carr, CJ and Zukowski, Zack and Taylor, Josiah and Pons, Jordi},
  booktitle=icassp,
  year={2025},
}

@inproceedings{van2022comparison,
  title={A comparison of discrete and soft speech units for improved voice conversion},
  author={van Niekerk, Benjamin and Carbonneau, Marc-Andr{\'e} and Za{\"\i}di, Julian and Baas, Matthew and Seut{\'e}, Hugo and Kamper, Herman},
  booktitle=icassp,
  year={2022},
}

@INPROCEEDINGS{guo2024socodec,
  author={Guo, Haohan and Xie, Fenglong and Xie, Kun and Yang, Dongchao and Guo, Dake and Wu, Xixin and Meng, Helen},
  booktitle=slt,
  title={SoCodec: A Semantic-Ordered Multi-Stream Speech Codec For Efficient Language Model Based Text-to-Speech Synthesis}, 
  year={2024},
 }

@inproceedings{casanova2024lfsc,
  title={Low frame-rate speech codec: a codec designed for fast high-quality speech {LLM} training and inference},
  author={Casanova, Edresson and Langman, Ryan and Neekhara, Paarth and Hussain, Shehzeen and Li, Jason and Ghosh, Subhankar and Juki{\'c}, Ante and Lee, Sang-gil},
  booktitle=icassp,
  year={2025},
}

@inproceedings{ren2024ticodec,
  title={Fewer-token neural speech codec with time-invariant codes},
  author={Ren, Yong and Wang, Tao and Yi, Jiangyan and Xu, Le and Tao, Jianhua and Zhang, Chu Yuan and Zhou, Junzuo},
  booktitle=icassp,
  year={2024},
}

@inproceedings{
parker2024scaling,
title={Scaling Transformers for Low-Bitrate High-Quality Speech Coding},
author={Julian D Parker and Anton Smirnov and Jordi Pons and CJ Carr and Zack Zukowski and Zach Evans and Xubo Liu},
booktitle=icml,
year={2025},
}

@article{bai2024dmel,
  title={{D}mel: Speech tokenization made simple},
  author={Bai, He and Likhomanenko, Tatiana and Zhang, Ruixiang and Gu, Zijin and Aldeneh, Zakaria and Jaitly, Navdeep},
  journal={arXiv preprint arXiv:2407.15835},
  year={2024}
}

@article{ai2024apcodec,
  title={APCodec: A neural audio codec with parallel amplitude and phase spectrum encoding and decoding},
  author={Ai, Yang and Jiang, Xiao-Hang and Lu, Ye-Xin and Du, Hui-Peng and Ling, Zhen-Hua},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2024},
  publisher={IEEE}
}

@article{kolbaek2017multitalker,
  title={{M}ultitalker speech separation with utterance-level permutation invariant training of deep recurrent neural networks},
  author={Kolb{\ae}k, M. and Yu, D. and Tan, Z.-H. and Jensen, J.},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={25},
  pages={1901--1913},
  year={2017},
}


@inproceedings{piczak2015esc,
  title={ESC: Dataset for environmental sound classification},
  author={Piczak, Karol J},
  booktitle={Proc. ACM},
  year={2015}
}

@article{tzanetakis2002musical,
  title={Musical genre classification of audio signals},
  author={Tzanetakis, George and Cook, Perry},
  journal={IEEE Transactions on speech and audio processing},
  volume={10},
  number={5},
  pages={293--302},
  year={2002},
  publisher={IEEE}
}

@inproceedings{
li2023mert,
title={{MERT}: Acoustic Music Understanding Model with Large-Scale Self-supervised Training},
author={Yizhi LI and Ruibin Yuan and Ge Zhang and Yinghao Ma and Xingran Chen and Hanzhi Yin and Chenghao Xiao and Chenghua Lin and Anton Ragni and Emmanouil Benetos and Norbert Gyenge and Roger Dannenberg and Ruibo Liu and Wenhu Chen and Gus Xia and Yemin Shi and Wenhao Huang and Zili Wang and Yike Guo and Jie Fu},
booktitle=iclr,
year={2024},
}

@article{kong2020panns,
  title={Panns: Large-scale pretrained audio neural networks for audio pattern recognition},
  author={Kong, Qiuqiang and Cao, Yin and Iqbal, Turab and Wang, Yuxuan and Wang, Wenwu and Plumbley, Mark D},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={28},
  pages={2880--2894},
  year={2020},
  publisher={IEEE}
}

@article{wang2022usb,
  title={Usb: A unified semi-supervised learning benchmark for classification},
  author={Wang, Yidong and Chen, Hao and Fan, Yue and Sun, Wang and Tao, Ran and Hou, Wenxin and Wang, Renjie and Yang, Linyi and Zhou, Zhi and Guo, Lan-Zhe and others},
  journal={neurips},
  year={2022}
}

@article{mousavi2024dasb,
  title={DASB--Discrete Audio and Speech Benchmark},
  author={Mousavi, Pooneh and Della Libera, Luca and Duret, Jarod and Ploujnikov, Artem and Subakan, Cem and Ravanelli, Mirco},
  journal={arXiv preprint arXiv:2406.14294},
  year={2024}
}

@article{wang2023lmvc,
  title={Lm-vc: Zero-shot voice conversion via speech generation based on language models},
  author={Wang, Zhichao and Chen, Yuanzhe and Xie, Lei and Tian, Qiao and Wang, Yuping},
  journal={IEEE Signal Processing Letters},
  volume={30},
  pages={1157--1161},
  year={2023},
  publisher={IEEE}
}

@inproceedings{maimon2023speaking,
  title={Speaking Style Conversion in the Waveform Domain Using Discrete Self-Supervised Units},
  author={Maimon, Gallil and Adi, Yossi},
  booktitle=emnlp,
  year={2023}
}

@inproceedings{wang2024streamvoice,
  title={StreamVoice: Streamable Context-Aware Language Modeling for Real-time Zero-Shot Voice Conversion},
  author={Wang, Zhichao and Chen, Yuanzhe and Wang, Xinsheng and Xie, Lei and Wang, Yuping},
  booktitle=acl,
  year={2024}
}



@inproceedings{shi2024espnet,
  title={{ESPnet-Codec}: Comprehensive training and evaluation of neural codecs for audio, music, and speech},
  author={Shi, Jiatong and Tian, Jinchuan and Wu, Yihan and Jung, Jee-weon and Yip, Jia Qi and Masuyama, Yoshiki and Chen, William and Wu, Yuning and Tang, Yuxun and Baali, Massa and others},
  booktitle=slt,
  year={2024},
}

@article{vashishth2024stab,
  title={{STAB}: Speech Tokenizer Assessment Benchmark},
  author={Vashishth, Shikhar and Singh, Harman and Bharadwaj, Shikhar and Ganapathy, Sriram and Asawaroengchai, Chulayuth and Audhkhasi, Kartik and Rosenberg, Andrew and Bapna, Ankur and Ramabhadran, Bhuvana},
  journal={arXiv preprint arXiv:2409.02384},
  year={2024}
}

@inproceedings{zen2019libritts,
  title={Libri{TTS}: A Corpus Derived from LibriSpeech for Text-to-Speech},
  author={Zen, Heiga and Dang, Viet and Clark, Rob and Zhang, Yu and Weiss, Ron J and Jia, Ye and Chen, Zhifeng and Wu, Yonghui},
  booktitle=interspeech,
  year={2019}
}

@INPROCEEDINGS{7178964,
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle=icassp, 
  title={Librispeech: An ASR corpus based on public domain audio books}, 
  year={2015},
}


@inproceedings{lam2023efficient,
  title={Efficient neural music generation},
  author={Lam, Max WY and Tian, Qiao and Li, Tang and Yin, Zongyu and Feng, Siyuan and Tu, Ming and Ji, Yuliang and Xia, Rui and Ma, Mingbo and Song, Xuchen and others},
  booktitle=neurips,
  year={2023}
}

@inproceedings{rouard2024audio,
  title={Audio conditioning for music generation via discrete bottleneck features},
  author={Rouard, Simon and Adi, Yossi and Copet, Jade and Roebel, Axel and D{\'e}fossez, Alexandre},
  booktitle=ismir,
  year={2024}
}

@inproceedings{chen2024musicldm,
  title={Musicldm: Enhancing novelty in text-to-music generation using beat-synchronous mixup strategies},
  author={Chen, Ke and Wu, Yusong and Liu, Haohe and Nezhurina, Marianna and Berg-Kirkpatrick, Taylor and Dubnov, Shlomo},
  booktitle=icassp, 
  year={2024},
}

@inproceedings{yang2024generative,
  title={Generative de-quantization for neural speech codec via latent diffusion},
  author={Yang, Haici and Jang, Inseon and Kim, Minje},
  booktitle=icassp,
  year={2024},
}

@inproceedings{li2024single,
  title={Single-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation},
  author={Li, Hanzhao and Xue, Liumeng and Guo, Haohan and Zhu, Xinfa and Lv, Yuanjun and Xie, Lei and Chen, Yunlin and Yin, Hao and Li, Zhifei},
  booktitle=interspeech,
  year={2024}
}


@inproceedings{huang2023repcodec,
    title = "{R}ep{C}odec: A Speech Representation Codec for Speech Tokenization",
    author = "Huang, Zhichao  and
      Meng, Chutong  and
      Ko, Tom",
    booktitle = acl,
    year = "2024",
}

@inproceedings{
siuzdak2023vocos,
title={Vocos: Closing the gap between time-domain and Fourier-based neural vocoders for high-quality audio synthesis},
author={Hubert Siuzdak},
booktitle=iclr,
year={2024},
}

@inproceedings{kang2024libriheavy,
  title={Libriheavy: A 50,000 hours ASR corpus with punctuation casing and context},
  author={Kang, Wei and Yang, Xiaoyu and Yao, Zengwei and Kuang, Fangjun and Yang, Yifan and Guo, Liyong and Lin, Long and Povey, Daniel},
  booktitle=icassp, 
  year={2024},
}

@INPROCEEDINGS{maimon2024suite,
  author={Maimon, Gallil and Roth, Amit and Adi, Yossi},
  booktitle=icassp, 
  title={Salmon: A Suite for Acoustic Language Model Evaluation}, 
  year={2025},
}

@inproceedings{LMCodec,
    title = "Towards Codec-{LM} Co-design for Neural Codec Language Models",
    author = "Wu, Shih-Lun  and
      Lahoti, Aakash  and
      Desai, Arjun D  and
      Goel, Karan  and
      Donahue, Chris  and
      Gu, Albert",
    booktitle = naacl,
    year = "2025"
}
@inproceedings{bie2024learning,
  title={Learning source disentanglement in neural audio codec},
  author={Bie, Xiaoyu and Liu, Xubo and Richard, Ga{\"e}l},
  booktitle=icassp,
  year={2025}
}


@article{liu2024semanticodec,
  title={Semanticodec: An ultra low bitrate semantic audio codec for general sound},
  author={Liu, Haohe and Xu, Xuenan and Yuan, Yi and Wu, Mengyue and Wang, Wenwu and Plumbley, Mark D},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  year={2024},
  publisher={IEEE}
}

@inproceedings{jiang22_interspeech,
  title     = {Cross-Scale Vector Quantization for Scalable Neural Speech Coding},
  author    = {Xue Jiang and Xiulian Peng and Huaying Xue and Yuan Zhang and Yan Lu},
  year      = {2022},
  booktitle = interspeech,
}

@article{yang2024qwen2,
  title={Qwen2 technical report},
  author={Yang, An and Yang, Baosong and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Zhou, Chang and Li, Chengpeng and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and others},
  journal={arXiv preprint arXiv:2407.10671},
  year={2024}
}

@inproceedings{huang2022mulan,
  title={MuLan: A Joint Embedding of Music Audio and Natural Language},
  author={Huang, Qingqing and Jansen, Aren and Lee, Joonseok and Ganti, Ravi and Li, Judith Yue and Ellis, Daniel PW},
  booktitle=ismir,
  year={2022}
}

@article{turetzky_last_2024,
	title = {{LAST}: {Language} {Model} {Aware} {Speech} {Tokenization}},
    author={Arnon Turetzky and Yossi Adi},
    journal={arXiv preprint arXiv:arXiv:2409.03701},
    year={2024}
}

@article{nguyen2024spiritlminterleavedspokenwritten,
    title = "{S}pi{R}it-{LM}: Interleaved Spoken and Written Language Model",
    author = "Nguyen, Tu Anh  and
      Muller, Benjamin  and
      Yu, Bokai  and
      Costa-jussa, Marta R.  and
      Elbayad, Maha  and
      Popuri, Sravya  and
      Ropers, Christophe  and
      Duquenne, Paul-Ambroise  and
      Algayres, Robin  and
      Mavlyutov, Ruslan  and
      Gat, Itai  and
      Williamson, Mary  and
      Synnaeve, Gabriel  and
      Pino, Juan  and
      Sagot, Beno{\^i}t  and
      Dupoux, Emmanuel",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "13",
    year = "2025",
    pages = "30--52",
}

\@inproceedings{nguyen2020zeroresourcespeechbenchmark,
  title={The Zero Resource Speech Benchmark 2021: Metrics and baselines for unsupervised spoken language modeling},
  author={Nguyen, Tu Anh and de Seyssel, Maureen and Roz{\'e}, Patricia and Rivi{\`e}re, Morgane and Kharitonov, Evgeny and Baevski, Alexei and Dunbar, Ewan and Dupoux, Emmanuel},
  booktitle=neurips,
  year={2020}
}

@inproceedings{manilow2019cutting,
  title={Cutting music source separation some Slakh: A dataset to study the impact of training data quality and quantity},
  author={Manilow, Ethan and Wichern, Gordon and Seetharaman, Prem and Le Roux, Jonathan},
  booktitle=waspaa,
  year={2019},
  organization={IEEE}
}

@article{arnault2020urban,
  title={Urban Sound Classification: striving towards a fair comparison},
  author={Arnault, Augustin and Hanssens, Baptiste and Riche, Nicolas},
  journal={arXiv preprint arXiv:2010.11805},
  year={2020}
}

@inproceedings{wisdom2021s,
  title={What’s all the fuss about free universal sound separation data?},
  author={Wisdom, Scott and Erdogan, Hakan and Ellis, Daniel PW and Serizel, Romain and Turpault, Nicolas and Fonseca, Eduardo and Salamon, Justin and Seetharaman, Prem and Hershey, John R},
  booktitle=icassp, 
  year={2021},
}

@inproceedings{hershey2016deep,
  title={Deep clustering: Discriminative embeddings for segmentation and separation},
  author={Hershey, John R and Chen, Zhuo and Le Roux, Jonathan and Watanabe, Shinji},
  booktitle=icassp,
  year={2016}
}

@inproceedings{liu2024revisiting,
  title={Revisiting Self-supervised Learning of Speech Representation from a Mutual Information Perspective},
  author={Liu, Alexander H and Yeh, Sung-Lin and Glass, James R},
  booktitle=icassp,
  year={2024},
}

@article{chung2025kad,
  title={KAD: No More FAD! An Effective and Efficient Evaluation Metric for Audio Generation},
  author={Chung, Yoonjin and Eu, Pilsun and Lee, Junwon and Choi, Keunwoo and Nam, Juhan and Chon, Ben Sangbae},
  journal={arXiv preprint arXiv:2502.15602},
  year={2025}
}

@misc{musdb18,
  author       = {Rafii, Zafar and
                  Liutkus, Antoine and
                  Fabian-Robert St{\"o}ter and
                  Mimilakis, Stylianos Ioannis and
                  Bittner, Rachel},
  title        = {The {MUSDB18} corpus for music separation},
  month        = dec,
  year         = 2017,
  doi          = {10.5281/zenodo.1117372},
  url          = {https://doi.org/10.5281/zenodo.1117372}
}

@inproceedings{fadtk,
  title={Adapting frechet audio distance for generative music evaluation},
  author={Gui, Azalea and Gamper, Hannes and Braun, Sebastian and Emmanouilidou, Dimitra},
  booktitle=icassp, 
  year={2024},
}

@inproceedings{koutini2021passt,
  title     = {Efficient Training of Audio Transformers with Patchout},
  author    = {Khaled Koutini and Jan Schlüter and Hamid Eghbal-zadeh and Gerhard Widmer},
  year      = {2022},
  booktitle = interspeech,
}

@inproceedings{san2023discrete,
  title={From discrete tokens to high-fidelity audio using multi-band diffusion},
  author={San Roman, Robin and Adi, Yossi and Deleforge, Antoine and Serizel, Romain and Synnaeve, Gabriel and D{\'e}fossez, Alexandre},
  booktitle=neurips,
  year={2023}
}

@article{yang2023diffsound,
  title={Diffsound: Discrete diffusion model for text-to-sound generation},
  author={Yang, Dongchao and Yu, Jianwei and Wang, Helin and Wang, Wen and Weng, Chao and Zou, Yuexian and Yu, Dong},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={31},
  pages={1720--1733},
  year={2023},
  publisher={IEEE}
}

@inproceedings{wu2023large,
  title={Large-scale contrastive language-audio pretraining with feature fusion and keyword-to-caption augmentation},
  author={Wu, Yusong and Chen, Ke and Zhang, Tianyu and Hui, Yuchen and Berg-Kirkpatrick, Taylor and Dubnov, Shlomo},
  booktitle=icassp,
  year={2023},
}


@inproceedings{huang2023make,
  title={Make-an-audio: Text-to-audio generation with prompt-enhanced diffusion models},
  author={Huang, Rongjie and Huang, Jiawei and Yang, Dongchao and Ren, Yi and Liu, Luping and Li, Mingze and Ye, Zhenhui and Liu, Jinglin and Yin, Xiang and Zhao, Zhou},
  booktitle=icml, 
  year={2023},
}


@inproceedings{audiocaps,
  title={AudioCaps: Generating Captions for Audios in The Wild},
  author={Kim, Chris Dongjoo and Kim, Byeongchang and Lee, Hyunmin and Kim, Gunhee},
  booktitle=naacl,
  year={2019}
}

@inproceedings{macs,
  title={Diversity and bias in audio captioning datasets},
  author={Morato, Irene Martin and Mesaros, Annamaria},
  booktitle={Proc. DCASE},
  year={2021}
}

@InProceedings{liu2023audioldm,
  title = 	 {{A}udio{LDM}: Text-to-Audio Generation with Latent Diffusion Models},
  author =       {Liu, Haohe and Chen, Zehua and Yuan, Yi and Mei, Xinhao and Liu, Xubo and Mandic, Danilo and Wang, Wenwu and Plumbley, Mark D},
  booktitle = icml,
  year = 	 {2023},
}


@article{liu2024audioldm2,
  title={Audio{LDM} 2: Learning holistic audio generation with self-supervised pretraining},
  author={Liu, Haohe and Yuan, Yi and Liu, Xubo and Mei, Xinhao and Kong, Qiuqiang and Tian, Qiao and Wang, Yuping and Wang, Wenwu and Wang, Yuxuan and Plumbley, Mark D},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2024},
  publisher={IEEE}
}


@inproceedings{wang2024v2a,
  title={V2a-mapper: A lightweight solution for vision-to-audio generation by connecting foundation models},
  author={Wang, Heng and Ma, Jianbo and Pascual, Santiago and Cartwright, Richard and Cai, Weidong},
  booktitle=aaai,
  year={2024}
}

@inproceedings{pascual2024masked,
  title={Masked generative video-to-audio transformers with enhanced synchronicity},
  author={Pascual, Santiago and Yeh, Chunghsin and Tsiamas, Ioannis and Serr{\`a}, Joan},
  booktitle=eccv,
  year={2024},
}

@article{zhang2024foleycrafter,
  title={Foleycrafter: Bring silent videos to life with lifelike and synchronized sounds},
  author={Zhang, Yiming and Gu, Yicheng and Zeng, Yanhong and Xing, Zhening and Wang, Yuancheng and Wu, Zhizheng and Chen, Kai},
  journal={arXiv preprint arXiv:2407.01494},
  year={2024}
}


@inproceedings{dong2023clipsonic,
  title={Clipsonic: Text-to-audio synthesis with unlabeled videos and pretrained language-vision models},
  author={Dong, Hao-Wen and Liu, Xiaoyu and Pons, Jordi and Bhattacharya, Gautam and Pascual, Santiago and Serr{\`a}, Joan and Berg-Kirkpatrick, Taylor and McAuley, Julian},
  booktitle=waspaa,
  year={2023},
}

@inproceedings{jeong2024read,
  title={Read, watch and scream! sound generation from text and video},
  author={Jeong, Yujin and Kim, Yunji and Chun, Sanghyuk and Lee, Jiyoung},
  booktitle=aaai,
  year={2025}
}


@article{chen2024video,
  title={Video-guided foley sound generation with multimodal controls},
  author={Chen, Ziyang and Seetharaman, Prem and Russell, Bryan and Nieto, Oriol and Bourgin, David and Owens, Andrew and Salamon, Justin},
  journal={arXiv preprint arXiv:2411.17698},
  year={2024}
}

@inproceedings{saito2024soundctm,
title={Sound{CTM}: Uniting Score-based and Consistency Models for Text-to-Sound Generation},
author={Koichi Saito and Dongjun Kim and Takashi Shibuya and Chieh-Hsin Lai and Zhi Zhong and Yuhta Takida and Yuki Mitsufuji},
booktitle={Proc. NeurIPS Workshops},
year={2024},
}

@inproceedings{wang2025frieren,
  title={Frieren: Efficient Video-to-Audio Generation Network with Rectified Flow Matching},
  author={Wang, Yongqi and Guo, Wenxiang and Huang, Rongjie and Huang, Jiawei and Wang, Zehan and You, Fuming and Li, Ruiqi and Zhao, Zhou},
  booktitle=neurips,
  year={2025}
}

@inproceedings{luo2023diff,
  title={Diff-foley: Synchronized video-to-audio synthesis with latent diffusion models},
  author={Luo, Simian and Yan, Chuanhao and Hu, Chenxu and Zhao, Hang},
  booktitle=neurips,
  year={2023}
}

@inproceedings{sheffer2023hear,
  title={I hear your true colors: Image guided audio generation},
  author={Sheffer, Roy and Adi, Yossi},
  booktitle=icassp,
  year={2023},
}


@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@article{peng2024survey,
  title={A survey on speech large language models},
  author={Peng, Jing and Wang, Yucheng and Xi, Yu and Li, Xu and Zhang, Xizhuo and Yu, Kai},
  journal={arXiv preprint arXiv:2410.18908},
  year={2024}
}

@article{cui2024recent,
  title={Recent advances in speech language models: A survey},
  author={Cui, Wenqian and Yu, Dianzhi and Jiao, Xiaoqi and Meng, Ziqiao and Zhang, Guangyan and Wang, Qichao and Guo, Yiwen and King, Irwin},
  journal={arXiv preprint arXiv:2410.03751},
  year={2024}
}

@article{ji2024wavchat,
  title={Wavchat: A survey of spoken dialogue models},
  author={Ji, Shengpeng and Chen, Yifu and Fang, Minghui and Zuo, Jialong and Lu, Jingyu and Wang, Hanting and Jiang, Ziyue and Zhou, Long and Liu, Shujie and Cheng, Xize and others},
  journal={arXiv preprint arXiv:2411.13577},
  year={2024}
}

@article{latif2023sparks,
  title={Sparks of large audio models: A survey and outlook},
  author={Latif, Siddique and Shoukat, Moazzam and Shamshad, Fahad and Usama, Muhammad and Ren, Yi and Cuay{\'a}huitl, Heriberto and Wang, Wenwu and Zhang, Xulong and Togneri, Roberto and Cambria, Erik and others},
  journal={arXiv preprint arXiv:2308.12792},
  year={2023}
}

@inproceedings{dunbar2021zero,
  title     = {The Zero Resource Speech Challenge 2021: Spoken Language Modelling},
  author    = {Ewan Dunbar and Mathieu Bernard and Nicolas Hamilakis and Tu Anh Nguyen and Maureen de Seyssel and Patricia Rozé and Morgane Rivière and Eugene Kharitonov and Emmanuel Dupoux},
  year      = {2021},
  booktitle = interspeech,
}

@article{lin2024alignslm,
  title={Align-SLM: Textless Spoken Language Models with Reinforcement Learning from AI Feedback},
  author={Lin, Guan-Ting and Shivakumar, Prashanth Gurunath and Gourav, Aditya and Gu, Yile and Gandhe, Ankur and Lee, Hung-yi and Bulyko, Ivan},
  journal={arXiv preprint arXiv:2411.01834},
  year={2024}
}

@inproceedings{radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle=icml,
  year={2023},
}

@inproceedings{mostafazadeh2016corpus,
    title = "A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense Stories",
    author = "Mostafazadeh, Nasrin  and
      Chambers, Nathanael  and
      He, Xiaodong  and
      Parikh, Devi  and
      Batra, Dhruv  and
      Vanderwende, Lucy  and
      Kohli, Pushmeet  and
      Allen, James",
    booktitle = naacl,
    year = "2016",
}

@inproceedings{
yang2024uniaudio,
title={Uni{A}udio 1.5: Large Language Model-Driven Audio Codec is A Few-Shot Audio Task Learner},
author={Dongchao Yang and Haohan Guo and Yuanyuan Wang and Rongjie Huang and Xiang Li and Xu Tan and Xixin Wu and Helen M. Meng},
booktitle=neurips,
year={2024},
}

@article{park2024long,
  author       = {Se Jin Park and
                  Julian Salazar and
                  Aren Jansen and
                  Keisuke Kinoshita and
                  Yong Man Ro and
                  R. J. Skerry{-}Ryan},
  title        = {Long-Form Speech Generation with Spoken Language Models},
 journal={arXiv preprint arXiv:2412.18603},
  year         = {2024}
}

@article{dhariwal2020jukebox,
  title={Jukebox: A generative model for music},
  author={Dhariwal, Prafulla and Jun, Heewoo and Payne, Christine and Kim, Jong Wook and Radford, Alec and Sutskever, Ilya},
  journal={arXiv preprint arXiv:2005.00341},
  year={2020}
}

@inproceedings{ziv2024masked,
  title={Masked Audio Generation using a Single Non-Autoregressive Transformer},
  author={Ziv, Alon and Gat, Itai and Le Lan, Ga{\"e}l and Remez, Tal and Kreuk, Felix and Copet, Jade and D{\'e}fossez, Alexandre and Synnaeve, Gabriel and Adi, Yossi},
  booktitle=iclr,
  year={2024}
}

@inproceedings{garcia2023vampnet,
  title={VampNet: Music Generation via Masked Acoustic Token Modeling},
  author={Garcia, Hugo F Flores and Seetharaman, Prem and Kumar, Rithesh and Pardo, Bryan},
  booktitle=ismir,
  year={2023}
}

@inproceedings{
gu2021efficiently,
title={Efficiently Modeling Long Sequences with Structured State Spaces},
author={Albert Gu and Karan Goel and Christopher Re},
booktitle=iclr,
year={2022},
}

@article{elmakies2025unsupervised,
      title={Unsupervised Speech Segmentation: A General Approach Using Speech Language Models}, 
      author={Avishai Elmakies and Omri Abend and Yossi Adi},
      journal={arXiv preprint arXiv:2501.03711},
      year={2025}
}

@inproceedings{
salmonn,
title={{SALMONN}: Towards Generic Hearing Abilities for Large Language Models},
author={Changli Tang and Wenyi Yu and Guangzhi Sun and Xianzhao Chen and Tian Tan and Wei Li and Lu Lu and Zejun MA and Chao Zhang},
booktitle=iclr,
year={2024}
}
@article{qwen_audio,
  title={Qwen-audio: Advancing universal audio understanding via unified large-scale audio-language models},
  author={Chu, Yunfei and Xu, Jin and Zhou, Xiaohuan and Yang, Qian and Zhang, Shiliang and Yan, Zhijie and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2311.07919},
  year={2023}
}

@article{maimon2025slamming,
  title={Slamming: Training a Speech Language Model on One GPU in a Day},
  author={Maimon, Gallil and Elmakies, Avishai and Adi, Yossi},
  journal={arXiv preprint arXiv:2502.15814},
  year={2025}
}



@inproceedings{shi2021aishell,
  title={{AISHELL-3}: A Multi-Speaker Mandarin {TTS} Corpus},
  author={Shi, Yao and Bu, Hui and Xu, Xin and Zhang, Shaoji and Li, Ming},
  year={2021},
  booktitle=interspeech,
}

@inproceedings{shi2021highland,
  title={Highland {P}uebla {N}ahuatl speech translation corpus for endangered language documentation},
  author={Shi, Jiatong and Amith, Jonathan D and Chang, Xuankai and Dalmia, Siddharth and Yan, Brian and Watanabe, Shinji},
  booktitle={Proc. AmericasNLP},
  year={2021}
}

@inproceedings{shi2021leveraging,
  title={Leveraging End-to-End {ASR} for Endangered Language Documentation: An Empirical Study on {Y}ol{\'o}xochitl {M}ixtec},
  author={Shi, Jiatong and Amith, Jonathan D and Garc{\'\i}a, Rey Castillo and Sierra, Esteban Guadalupe and Duh, Kevin and Watanabe, Shinji},
  booktitle={Proc. EACL},
  year={2021}
}

@inproceedings{huang2021multi,
  title={Multi-singer: Fast multi-singer singing voice vocoder with a large-scale corpus},
  author={Huang, Rongjie and Chen, Feiyang and Ren, Yi and Liu, Jinglin and Cui, Chenye and Zhao, Zhou},
  booktitle={Proc. ACMMM},
  year={2021}
}


@inproceedings{dai2023singstyle111,
  title={Singstyle111: A multilingual singing dataset with style transfer},
  author={Dai, Shuqi and Chen, Siqi and Wu, Yuxuan and Diao, Ruxin and Huang, Roy and Dannenberg, Roger B},
  booktitle=ismir,
  year={2023}
}

@inproceedings{zhang2022m4singer,
  title={M4singer: A multi-style, multi-singer and musical score provided mandarin singing corpus},
  author={Zhang, Lichao and Li, Ruiqi and Wang, Shoutong and Deng, Liqun and Liu, Jinglin and Ren, Yi and He, Jinzheng and Huang, Rongjie and Zhu, Jieming and Chen, Xiao and others},
  booktitle=neurips,
  year={2022}
}

@article{ogawa2021tohoku,
  title={Tohoku {K}iritan singing database: A singing database for statistical parametric singing synthesis using Japanese pop songs},
  author={Ogawa, Itsuki and Morise, Masanori},
  journal={AST},
  volume={42},
  number={3},
  pages={140--145},
  year={2021},
  publisher={Acoustical Society of Japan}
}

@inproceedings{wang2022opencpop,
  title={Opencpop: A High-Quality Open Source Chinese Popular Song Corpus for Singing Voice Synthesis},
  author={Wang, Yu and Wang, Xinsheng and Zhu, Pengcheng and Wu, Jie and Li, Hanzhao and Xue, Heyang and Zhang, Yongmao and Xie, Lei and Bi, Mengxiao},
  year={2022},
  booktitle=interspeech,
}

@inproceedings{shi2024singing,
  title={Singing Voice Data Scaling-up: An Introduction to {ACE-Opencpop and ACE-KiSing}},
  author={Shi, Jiatong and Lin, Yueqian and Bai, Xinyi and Zhang, Keyi and Wu, Yuning and Tang, Yuxun and Yu, Yifeng and Jin, Qin and Watanabe, Shinji},
  booktitle=interspeech,
  year={2024}
}

@inproceedings{koguchi2020pjs,
  title={{PJS}: Phoneme-balanced Japanese singing-voice corpus},
  author={Koguchi, Junya and Takamichi, Shinnosuke and Morise, Masanori},
  booktitle={Proc. APSIPA ASC},
  year={2020},
}

@article{takamichi2020jsut,
  title={{JSUT and JVS}: Free Japanese voice corpora for accelerating speech synthesis research},
  author={Takamichi, Shinnosuke and Sonobe, Ryosuke and Mitsui, Kentaro and Saito, Yuki and Koriyama, Tomoki and Tanji, Naoko and Saruwatari, Hiroshi},
  journal={AST},
  volume={41},
  number={5},
  pages={761--768},
  year={2020},
}

@misc{amith_yoloxochitl_mixtec,
  author = {Amith, Jonathan D. and Castillo Castillo, Rey},
  title = {Audio corpus of Yoloxóchitl Mixtec with accompanying time-coded transcriptions in ELAN},
  year=2021,
url={https://www.openslr.org/89/}
}

@misc{amith_audio_corpus_sierra,
  author = {Amith, Jonathan D. and Domínguez Alcántara, Amelia and Salazar Osollo, Hermelindo and Salgado Castañeda, Ceferino and Gorostiza Salazar, Eleuterio},
  title = {Audio corpus of Sierra Nororiental and Sierra Norte de Puebla Nahuat(l) with accompanying time-code transcriptions in ELAN},
  year=2021,
url={https://www.openslr.org/92/}
}

@misc{amith_totonac,
  author = {Amith, Jonathan D. and López Francisco, Osbel},
  title = {Audio corpus of Totonac recordings from northern Puebla and adjacent areas of Veracruz},
  year=2022,
  url = {https://www.openslr.org/107/}
}


@inproceedings{kuhn2014daps,
  title={{DAPS}: Intelligent delay-aware packet scheduling for multipath transport},
  author={Kuhn, Nicolas and Lochin, Emmanuel and Mifdaoui, Ahlem and Sarwar, Golam and Mehani, Olivier and Boreli, Roksana},
  booktitle={Proc. ICC},
  year={2014},
}

@article{yamagishi2019cstr,
  title={{CSTR VCTK} Corpus: English multi-speaker corpus for {CSTR} voice cloning toolkit (version 0.92)},
  author={Yamagishi, Junichi and Veaux, Christophe and MacDonald, Kirsten and others},
  journal={University of Edinburgh. The Centre for Speech Technology Research (CSTR)},
  pages={271--350},
  year={2019}
}

@inproceedings{yan2023espnet,
  title={{ESPnet-ST-v2}: Multipurpose Spoken Language Translation Toolkit},
  author={Yan, Brian and Shi, Jiatong and Tang, Yun and Inaguma, Hirofumi and Peng, Yifan and Dalmia, Siddharth and Polak, Peter and Fernandes, Patrick and Berrebbi, Dan and Hayashi, Tomoki and others},
  booktitle=acl,
  year={2023}
}

@article{vincent2006bss,
  author={Vincent, E. and Gribonval, R. and Fevotte, C.},
  journal={IEEE Transactions on Audio, Speech, and Language Processing}, 
  title={Performance measurement in blind audio source separation}, 
  year={2006},
  volume={14},
  number={4},
  pages={1462-1469},
}


@misc{allal2024SmolLM,
      title={SmolLM - blazingly fast and remarkably powerful}, 
      author={Loubna Ben Allal and Anton Lozhkov and Elie Bakouch and Leandro von Werra and Thomas Wolf},
      year={2024},
}


@inproceedings{rouard2022hybrid,
  title={Hybrid transformers for music source separation},
  author={Rouard, Simon and Massa, Francisco and D{\'e}fossez, Alexandre},
  booktitle=icassp,
  year={2023},
}

@article{LuoY2019conv-tasnet,
  title={Conv-tasnet: Surpassing ideal time--frequency magnitude masking for speech separation},
  author={Luo, Yi and Mesgarani, Nima},
  journal={IEEE/ACM Transactions on audio, speech, and language processing},
  volume={27},
  number={8},
  pages={1256--1266},
  year={2019},
  publisher={IEEE}
}

@Inproceedings{Saijo2024_TFLoco,
  author    =  {Saijo, Kohei and Wichern, Gordon and Germain, Fran\c{c}ois G. and Pan, Zexu and {Le Roux}, Jonathan},
  title     =  {TF-Locoformer: Transformer with Local Modeling by Convolution for Speech Separation and Enhancement},
  booktitle =  {Proc. IWAENC},
  year      =  2024,
}



@inproceedings{Kavalerov2019UniversalSS,
  title={Universal Sound Separation},
  author={Ilya Kavalerov and Scott Wisdom and Hakan Erdogan and Brian Patton and Kevin W. Wilson and Jonathan Le Roux and John R. Hershey},
  booktitle=waspaa,
  year={2019},
}

@inproceedings{espnet,
  title     = {{ESPnet}: End-to-End Speech Processing Toolkit},
  author    = {Shinji Watanabe and Takaaki Hori and Shigeki Karita and Tomoki Hayashi and Jiro Nishitoba and Yuya Unno and Nelson {Enrique Yalta Soplin} and Jahn Heymann and Matthew Wiesner and Nanxin Chen and Adithya Renduchintala and Tsubasa Ochiai},
  year      = {2018},
  booktitle = interspeech, 
}


@article{mars6,
  title={MARS6: A Small and Robust Hierarchical-Codec Text-to-Speech Model},
  author={Matthew Baas and Pieter Scholtz and Arnav Mehta and Elliott Dyson and Akshat Prakash and Herman Kamper},
  year={2025},
  journal={arXiv preprint arXiv:2501.05787},
}

@inproceedings{simplespeech,
  title={SimpleSpeech: Towards Simple and Efficient Text-to-Speech with Scalar Latent Transformer Diffusion Models},
  author={Yang, Dongchao and Wang, Dingdong and Guo, Haohan and Chen, Xueyuan and Wu, Xixin and Meng, Helen},
  booktitle=interspeech,
  year={2024}
}

@inproceedings{cuervo2024scalingpropertiesspeechlanguag,
  TITLE = {{Scaling Properties of Speech Language Models}},
  AUTHOR = {Cuervo, Santiago and Marxer, Ricard},
  BOOKTITLE = emnlp,
  YEAR = {2024},
}

@inproceedings{hassid2023textually,
  title={Textually pretrained speech language models},
  author={Hassid, Michael and Remez, Tal and Nguyen, Tu Anh and Gat, Itai and Conneau, Alexis and Kreuk, Felix and Copet, Jade and Defossez, Alexandre and Synnaeve, Gabriel and Dupoux, Emmanuel and others},
  booktitle=neurips,
  year={2023}
}


@inproceedings{copet2024musicgen,
  title={Simple and controllable music generation},
  author={Copet, Jade and Kreuk, Felix and Gat, Itai and Remez, Tal and Kant, David and Synnaeve, Gabriel and Adi, Yossi and D{\'e}fossez, Alexandre},
  booktitle=neurips,
  year={2023}
}

@misc{wolf2020huggingfacestransformersstateoftheartnatural,
      title={HuggingFace's Transformers: State-of-the-art Natural Language Processing}, 
      author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
      year={2019},
      journal={arXiv preprint arXiv:1910.03771},
}

@inproceedings{ji2024wavtokenizer,
  title={WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling},
  author={Ji, Shengpeng and Jiang, Ziyue and Cheng, Xize and Chen, Yifu and Fang, Minghui and Zuo, Jialong and Yang, Qian and Li, Ruiqi and Zhang, Ziang and Yang, Xiaoda and others},
  booktitle=iclr,
  year={2024}
}

@article{gpt,
  author       = {Tom B. Brown and
                  Benjamin Mann and
                  Nick Ryder and
                  Melanie Subbiah and
                  Jared Kaplan and
                  Prafulla Dhariwal and
                  Arvind Neelakantan and
                  Pranav Shyam and
                  Girish Sastry and
                  Amanda Askell and
                  Sandhini Agarwal and
                  Ariel Herbert{-}Voss and
                  Gretchen Krueger and
                  Tom Henighan and
                  Rewon Child and
                  Aditya Ramesh and
                  Daniel M. Ziegler and
                  Jeffrey Wu and
                  Clemens Winter and
                  Christopher Hesse and
                  Mark Chen and
                  Eric Sigler and
                  Mateusz Litwin and
                  Scott Gray and
                  Benjamin Chess and
                  Jack Clark and
                  Christopher Berner and
                  Sam McCandlish and
                  Alec Radford and
                  Ilya Sutskever and
                  Dario Amodei},
  title        = {Language Models are Few-Shot Learners},
  journal={arXiv preprint arXiv:2005.14165},
  year         = {2020},
}

@misc{bark2023,
  author       = {Suno AI},
  title        = {Bark: Text-Prompted Generative Audio Model},
  year         = {2023},
  howpublished = {\url{https://github.com/suno-ai/bark}},
  note         = {Accessed: 2025-03-21}
}

@article{guo2025recent,
  title={Recent Advances in Discrete Speech Tokens: A Review},
  author={Guo, Yiwei and Li, Zhihan and Wang, Hankun and Li, Bohan and Shao, Chongtian and Zhang, Hanglei and Du, Chenpeng and Chen, Xie and Liu, Shujie and Yu, Kai},
  journal={arXiv preprint arXiv:2502.06490},
  year={2025}
}

@inproceedings{zaiem2023speech,
    title={Speech Self-Supervised Representation Benchmarking: Are We Doing it Right?},
    author={Zaiem, Salah and Kemiche, Youcef and Parcollet, Titouan and Essid, Slim and Ravanelli, Mirco},
    booktitle=interspeech,
    year={2023}
}

@article{watanabe2023tree,
  title={Tree-structured parzen estimator: Understanding its algorithm components and their roles for better empirical performance},
  author={Watanabe, Shuhei},
  journal={arXiv preprint arXiv:2304.11127},
  year={2023}
}

@misc{xavier_bouthillier_2022_0_2_6,
  author       = {Bouthillier, Xavier  and
                  Tsirigotis, Christos and
                  Corneau-Tremblay, François and
                  Schweizer, Thomas and
                  Dong, Lin and
                  Delaunay, Pierre and
                  Normandin, Fabrice and
                  Bronzi, Mirko and
                  Suhubdy, Dendi and
                  Askari, Reyhane and
                  Noukhovitch, Michael and
                  Xue, Chao and
                  Ortiz-Gagné, Satya and
                  Breuleux, Olivier and
                  Bergeron, Arnaud and
                  Bilaniuk, Olexa and
                  Bocco, Steven and
                  Bertrand, Hadrien and
                  Alain, Guillaume and
                  Serdyuk, Dmitriy and
                  Henderson, Peter and
                  Lamblin, Pascal and
                  Beckham, Christopher},
  title        = {{Epistimio/orion: Asynchronous Distributed Hyperparameter Optimization}},
  month        = "Aug",
  year         = 2022,
  publisher    = {Zenodo},
  version      = {v0.2.6},
  doi          = {10.5281/zenodo.3478592},
  url          = {https://doi.org/10.5281/zenodo.3478592}
}

@inproceedings{mentzer2023finite,
  title={Finite Scalar Quantization: VQ-VAE Made Simple},
  author={Mentzer, Fabian and Minnen, David and Agustsson, Eirikur and Tschannen, Michael},
  booktitle=iclr, 
  year=2024,

}

@article{du2024cosyvoiceAS,
  title={CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens},
  author={Du, Zhihao and Chen, Qian and Zhang, Shiliang and Hu, Kai and Lu, Heng and Yang, Yexin and Hu, Hangrui and Zheng, Siqi and Gu, Yue and Ma, Ziyang and others},
  journal={arXiv preprint arXiv:2407.05407},
  year={2024}
}

@article{du2024cosyvoice,
  title={Cosyvoice 2: Scalable streaming speech synthesis with large language models},
  author={Du, Zhihao and Wang, Yuxuan and Chen, Qian and Shi, Xian and Lv, Xiang and Zhao, Tianyu and Gao, Zhifu and Yang, Yexin and Gao, Changfeng and Wang, Hui and others},
  journal={arXiv preprint arXiv:2412.10117},
  year={2024}
}

@article{tong2023improving,
  title={Improving and Generalizing Flow-Based Generative Models with Minibatch Optimal Transport},
  author={Tong, Alexander and Malkin, Nikolay and Huguet, Guillaume and Zhang, Yanlei and Rector-Brooks, Jarrid and FATRAS, Kilian and Wolf, Guy and Bengio, Yoshua},
  journal={Transactions on Machine Learning Research}, 
  year={2024}
}


@inproceedings{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  booktitle=neurips,
  year={2020}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle=cvpr,
  year={2022}
}

@article{kim2024neural,
  title={Neural speech and audio coding},
  author={Kim, Minje and Skoglund, Jan},
  journal={arXiv preprint arXiv:2408.06954},
  year={2024}
}

@article{anees2024speech,
  title={Speech coding techniques and challenges: A comprehensive literature survey},
  author={Anees, Mohamed},
  journal={Multimedia Tools and Applications},
  volume={83},
  number={10},
  pages={29859--29879},
  year={2024},
  publisher={Springer}
}

@article{shannon1948mathematical,
  title={A mathematical theory of communication},
  author={Shannon, Claude E},
  journal={The Bell system technical journal},
  volume={27},
  number={3},
  pages={379--423},
  year={1948},
  publisher={Nokia Bell Labs}
}

@article{nyquist1928certain,
  title={Certain topics in telegraph transmission theory},
  author={Nyquist, Harry},
  journal={Transactions of the American Institute of Electrical Engineers},
  volume={47},
  pages={617-644},
  year={1928},
}

@article{o1988linear,
  title={Linear predictive coding},
  author={O'Shaughnessy, Douglas},
  journal={IEEE potentials},
  volume={7},
  number={1},
  pages={29--32},
  year={1988},
  publisher={IEEE}
}

@article{wang2003modified,
  title={Modified discrete cosine transform: Its implications for audio coding and error concealment},
  author={Wang, Ye and Vilermo, Mikka},
  journal={Journal of the Audio Engineering Society},
  volume={51},
  number={1/2},
  pages={52--61},
  year={2003},
  publisher={Audio Engineering Society}
}

@article{noll1997mpeg,
  title={MPEG digital audio coding},
  author={Noll, Peter},
  journal={IEEE signal processing magazine},
  volume={14},
  number={5},
  pages={59--81},
  year={1997},
  publisher={IEEE}
}

@article{painter2000perceptual,
  title={Perceptual coding of digital audio},
  author={Painter, Ted and Spanias, Andreas},
  journal={Proceedings of the IEEE},
  volume={88},
  number={4},
  pages={451--515},
  year={2000},
  publisher={IEEE}
}

@inproceedings{jage2016celp,
  title={CELP and MELP speech coding techniques},
  author={Jage, Rhutuja and Upadhya, Savitha},
  booktitle={Proc. WiSPNET},
  year={2016},
}


@article{maimon2025scaling,
  title={Scaling Analysis of Interleaved Speech-Text Language Models},
  author={Maimon, Gallil and Hassid, Michael and Roth, Amit and Adi, Yossi},
  journal={arXiv preprint arXiv:2504.02398},
  year={2025}
}

@article{qwen2025qwen25technicalreport,
      title={Qwen2.5 Technical Report}, 
      author={An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tianyi Tang and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu},
      journal={arXiv preprint arXiv:2412.15115},
      year={2024},
}

@article{cuervo2025textspeechlanguagemodelsimproved,
      title={Text-Speech Language Models with Improved Cross-Modal Transfer by Aligning Abstraction Levels}, 
      author={Santiago Cuervo and Adel Moumen and Yanis Labrak and Sameer Khurana and Antoine Laurent and Mickael Rouvier and Ricard Marxer},
      year={2025},
      journal={arXiv preprint arXiv:2503.06211},
}

@inproceedings{kharitonov2022textfreeprosodyawaregenerativespoken,
  title={Text-Free Prosody-Aware Generative Spoken Language Modeling},
  author={Kharitonov, Eugene and Lee, Ann and Polyak, Adam and Adi, Yossi and Copet, Jade and Lakhotia, Kushal and Nguyen, Tu-Anh and Rivi{\`e}re, Morgane and Mohamed, Abdelrahman and Dupoux, Emmanuel and others},
  booktitle=acl,
  year={2022},
  organization={MIT Press}
}

@inproceedings{agustsson2017soft,
  title={Soft-to-hard vector quantization for end-to-end learning compressible representations},
  author={Agustsson, Eirikur and Mentzer, Fabian and Tschannen, Michael and Cavigelli, Lukas and Timofte, Radu and Benini, Luca and Gool, Luc V},
  booktitle=neurips,
  year={2017}
}

@inproceedings{kankanahalli2018end,
  title={End-to-end optimized speech coding with deep neural networks},
  author={Kankanahalli, Srihari},
  booktitle=icassp, 
  year={2018},
}


@inproceedings{choi2024selfsupervisedspeechrepresentationsphonetic,
  title={Self-Supervised Speech Representations are More Phonetic than Semantic},
  author={Choi, Kwanghee and Pasad, Ankita and Nakamura, Tomohiko and Fukayama, Satoru and Livescu, Karen and Watanabe, Shinji},
  booktitle=interspeech,
  year={2024}
}

@article{grattafiori2024llama3herdmodels,
  title={The llama 3 herd of models},
  author={Grattafiori, Aaron and Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Vaughan, Alex and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}


@inproceedings{radhakrishnan2023whispering,
  title={Whispering LLaMA: A Cross-Modal Generative Error Correction Framework for Speech Recognition},
  author={Radhakrishnan, Srijith and Yang, Chao-Han Huck and Khan, Sumeer Ahmad and Kumar, Rohit and Kiani, Narsis A. and Gomez-Cabrero, David and Tegner, Jesper N.},
  booktitle=emnlp,
  year={2023}
}

@misc{libritts-alignments,
  author = {Christoph Minixhofer},
  title = {LibriTTS-Phones-and-Mel},
  year = {2023},
  publisher = {Hugging Face},
  note = {\url{https://huggingface.co/datasets/cdminix/libritts-phones-and-mel}},
  howpublished = {\url{https://huggingface.co/datasets/cdminix/libritts-phones-and-mel}},
}

@inproceedings{ren2019fastspeech,
  title={Fastspeech: Fast, robust and controllable text to speech},
  author={Ren, Yi and Ruan, Yangjun and Tan, Xu and Qin, Tao and Zhao, Sheng and Zhao, Zhou and Liu, Tie-Yan},
  booktitle=neurips,
  year={2019}
}

@article{morise2016world,
  title={WORLD: a vocoder-based high-quality speech synthesis system for real-time applications},
  author={Morise, Masanori and Yokomori, Fumiya and Ozawa, Kenji},
  journal={IEICE TRANSACTIONS on Information and Systems},
  volume={99},
  number={7},
  pages={1877--1884},
  year={2016},
  publisher={The Institute of Electronics, Information and Communication Engineers}
}


@inproceedings{
ren2020fastspeech,
title={FastSpeech 2: Fast and High-Quality End-to-End Text to Speech},
author={Yi Ren and Chenxu Hu and Xu Tan and Tao Qin and Sheng Zhao and Zhou Zhao and Tie-Yan Liu},
booktitle=iclr,
year={2021},
}

@inproceedings{kim2021conditional,
  title={Conditional variational autoencoder with adversarial learning for end-to-end text-to-speech},
  author={Kim, Jaehyeon and Kong, Jungil and Son, Juhee},
  booktitle=icml,
  year={2021},
}

@inproceedings{ju2024naturalspeech,
  title={NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models},
  author={Ju, Zeqian and Wang, Yuancheng and Shen, Kai and Tan, Xu and Xin, Detai and Yang, Dongchao and Liu, Eric and Leng, Yichong and Song, Kaitao and Tang, Siliang and others},
  booktitle=icml,
  year={2024},
}

@inproceedings{mcauliffe2017montreal,
  title={Montreal forced aligner: Trainable text-speech alignment using {k}aldi.},
  author={McAuliffe, Michael and Socolof, Michaela and Mihuc, Sarah and Wagner, Michael and Sonderegger, Morgan},
  booktitle=interspeech,
  year={2017}
}

@article{har2025past,
  title={PAST: Phonetic-Acoustic Speech Tokenizer},
  author={Har-Tuv, Nadav and Tal, Or and Adi, Yossi},
  journal={arXiv preprint arXiv:2505.14470},
  year={2025}
}


@INPROCEEDINGS{10889092,
  author={Wang, Yingzhi and Mousavi, Pooneh and Ploujnikov, Artem and Ravanelli, Mirco},
  title={What Are They Doing? Joint Audio-Speech Co-Reasoning}, 
  year={2025},
  booktitle=icassp,
}


@inproceedings{zengscaling,
  title={Scaling Speech-Text Pre-training with Synthetic Interleaved Data},
  author={Zeng, Aohan and Du, Zhengxiao and Liu, Mingdao and Zhang, Lei and Dong, Yuxiao and Tang, Jie and others},
  booktitle=iclr,
  year={2025},
  
}

@article{yosha2025stresstest,
  title={{StressTest}: Can YOUR Speech {LM} Handle the Stress?},
  author={Yosha, Iddo and Maimon, Gallil and Adi, Yossi},
  journal={arXiv preprint arXiv:2505.22765},
  year={2025}
}

@article{mousavi2025listen,
  title={LiSTEN: Learning Soft Token Embeddings for Neural Audio LLMs},
  author={Mousavi, Pooneh and Gupta, Shubham and Subakan, Cem and Ravanelli, Mirco},
  journal={arXiv preprint arXiv:2505.18517},
  year={2025}
}

@article{kumar2024sila,
  title={SILA: Signal-to-Language Augmentation for Enhanced Control in Text-to-Audio Generation},
  author={Kumar, Sonal and Seetharaman, Prem and Salamon, Justin and Manocha, Dinesh and Nieto, Oriol},
  journal={arXiv preprint arXiv:2412.09789},
  year={2024}
}

@inproceedings{chen2025video,
  title={Video-guided foley sound generation with multimodal controls},
  author={Chen, Ziyang and Seetharaman, Prem and Russell, Bryan and Nieto, Oriol and Bourgin, David and Owens, Andrew and Salamon, Justin},
  booktitle=cvpr,
  year={2025}
}

@article{international1993coding,
  title={Coding of moving pictures and associated audio for digital storage media at up to about 1.5 Mbit/s},
  author={ISO/IEC JTC1/SC29 and others},
  journal={ISO/IEC 11172},
  year={1993}
}

@ARTICLE{6530580,
  author={Quackenbush, Schuyler},
  journal={IEEE MultiMedia}, 
  title={MPEG Unified Speech and Audio Coding}, 
  year={2013},
  volume={20},
  number={2},
  pages={72-78},
}


@inproceedings{devlin2019bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle=naacl,
  year={2019}
}


@article{turetzky2024last,
  title={Last: Language model aware speech tokenization},
  author={Turetzky, Arnon and Adi, Yossi},
  journal={arXiv preprint arXiv:2409.03701},
  year={2024}
}

@article{zheng2025ervq,
  title={ERVQ: Enhanced residual vector quantization with intra-and-inter-codebook optimization for neural audio codecs},
  author={Zheng, Rui-Chen and Du, Hui-Peng and Jiang, Xiao-Hang and Ai, Yang and Ling, Zhen-Hua},
  journal={IEEE Transactions on Audio, Speech and Language Processing},
  year={2025},
  booktitle={IEEE}
}

@inproceedings{esser2021taming,
  title={Taming transformers for high-resolution image synthesis},
  author={Esser, Patrick and Rombach, Robin and Ommer, Bjorn},
  booktitle=cvpr,
  year={2021}
}