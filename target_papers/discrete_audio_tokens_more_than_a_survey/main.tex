
\documentclass[10pt]{article} % For LaTeX2e
% \usepackage[preprint]{tmlr}
% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{tmlr}

% To de-anonymize and remove mentions to TMLR (for example for posting to preprint servers), instead use the following:
%\usepackage[preprint]{tmlr}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{comment}
\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{wrapfig,lipsum}
\usepackage{multirow,array}
\usepackage{adjustbox}
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage{float}
\usepackage{amssymb}
\usepackage{pifont}
\usepackage{xcolor}
\usepackage{enumitem}
\usepackage{makecell}
\usepackage{adjustbox}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\renewcommand{\arraystretch}{1.3}  % Adjust value as needed

\definecolor{darkgreen}{RGB}{0,100,0} % Adjust RGB values as needed
\definecolor{teal}{RGB}{0,128,128}       % Teal (Cyan-Green)
\definecolor{brown}{RGB}{139,69,19}      % Brown (Dark Earthy Tone)
\newcommand{\Pooneh}[1]{\textcolor{red}{#1}}
\newcommand{\Darius}[1]{\textcolor{cyan}{#1}}
\newcommand{\Haici}[1]{\textcolor{orange}{#1}}
\newcommand{\adel}[1]{\textcolor{brown}{#1}}
\newcommand{\haibin}[1]{\textcolor{teal}{#1}}
\newcommand{\GM}[1]{\textcolor{purple}{#1}}
\newcommand{\jiatong}[1]{\textcolor{darkgreen}{#1}}
\newcommand{\Anastasia}[1]{\textcolor{magenta}{#1}}
\newcommand{\rebuttal}[1]{\textcolor{black}{#1}}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[symbol]{footmisc}

\newcommand{\bcell}[2]{\begin{tabular}[c]{@{}c@{}}\textbf{#1} \\ \textbf{#2}\end{tabular}}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}


\title{Discrete Audio Tokens: More Than a Survey!}

% Authors must not appear in the submitted version. They should be hidden
% as long as the tmlr package is used without the [accepted] or [preprint] options.
% Non-anonymous submissions will be rejected without review.

% \author{\name Kyunghyun Cho \email kyunghyun.cho@nyu.edu \\
%       \addr Department of Computer Science\\
%       University of New York
%       \AND
%       \name Raia Hadsell \email raia@google.com \\
%       \addr DeepMind
%       \AND
%       \name Hugo Larochelle \email hugolarochelle@google.com\\
%       \addr Mila, Universit\'e de Montr\'eal \\
%       Google Research\\
%       CIFAR Fellow}

% \author{
%   \small
%   \textbf{Pooneh Mousavi}\textsuperscript{1,2},
%   \textbf{Gallil Maimon*}\textsuperscript{3},
%   \textbf{Jiatong Shi*}\textsuperscript{4},
%   \textbf{Haibin Wu*}\textsuperscript{12},
%   \textbf{Darius Petermann*}\textsuperscript{7},
%   \textbf{Adel Moumen*}\textsuperscript{6},
%   \textbf{Haici Yang*}\textsuperscript{7},
%   \textbf{Anastasia Kuznetsova}\textsuperscript{5,2},
%   \textbf{Artem Ploujnikov}\textsuperscript{5,2},
%   \textbf{Ricard Marxer}\textsuperscript{9},
%   \textbf{Bhuvana Ramabhadran}\textsuperscript{11},
%   \textbf{Benjamin Elizalde}\textsuperscript{13},
%   \textbf{Loren Lugosch}\textsuperscript{13},
%   \textbf{Jinyu Li}\textsuperscript{12},
%   \textbf{Cem Subakan}\textsuperscript{10,2,1},
%   \textbf{Phil Woodland}\textsuperscript{6},
%   \textbf{Minje Kim}\textsuperscript{7},
%   \textbf{Hung-yi Lee }\textsuperscript{8},
%   \textbf{Shinji Watanabe}\textsuperscript{4},
%   \textbf{Yossi Ad}\textsuperscript{3},
%   \textbf{Mirco Ravanelli}\textsuperscript{1,2,5} \\
%   \textsuperscript{1}Concordia University,
%   \textsuperscript{2}Mila-Quebec AI Institute,
%   \textsuperscript{3}The Hebrew University of Jerusalem,
%   \textsuperscript{4}Carnegie Mellon University,
%   \textsuperscript{5}Université de Montréal,
%   \textsuperscript{6}University of Cambridge,
%   \textsuperscript{7}University of Illinois at Urbana-Champaign,
%   \textsuperscript{8}National Taiwan University,
%   \textsuperscript{9}Université de Toulon,
%   \textsuperscript{10}Laval University,
%   \textsuperscript{11}Google,
%   \textsuperscript{12}Microsoft,
%   \textsuperscript{13}Apple
% }


\author{
  \small
  \textbf{Pooneh Mousavi*\dag}\textsuperscript{1,2},
  \textbf{Gallil Maimon*}\textsuperscript{3},
  \textbf{Adel Moumen*}\textsuperscript{4},
  \textbf{Darius Petermann*}\textsuperscript{5},
  \textbf{Jiatong Shi*}\textsuperscript{6},
  \textbf{Haibin Wu*}\textsuperscript{7},
  \textbf{Haici Yang*}\textsuperscript{5},
  \textbf{Anastasia Kuznetsova*}\textsuperscript{5},
  \textbf{Artem Ploujnikov}\textsuperscript{8,2},
  \textbf{Ricard Marxer}\textsuperscript{9},
  \textbf{Bhuvana Ramabhadran}\textsuperscript{10},
  \textbf{Benjamin Elizalde}\textsuperscript{11},
  \textbf{Loren Lugosch}\textsuperscript{11},
  \textbf{Jinyu Li}\textsuperscript{7},
  \textbf{Cem Subakan}\textsuperscript{12,2,1},
  \textbf{Phil Woodland}\textsuperscript{4},
  \textbf{Minje Kim}\textsuperscript{14},
  \textbf{Hung-yi Lee}\textsuperscript{13},
  \textbf{Shinji Watanabe}\textsuperscript{6},
  \textbf{Yossi Adi}\textsuperscript{3},
  \textbf{Mirco Ravanelli}\textsuperscript{1,2,8} \\
  \\
  \normalfont
  \textsuperscript{1}Concordia University,
  \textsuperscript{2}Mila-Quebec AI Institute,
  \textsuperscript{3}The Hebrew University of Jerusalem,
  \textsuperscript{4}University of Cambridge,
  \textsuperscript{5}Indiana University,
  \textsuperscript{6}Carnegie Mellon University,
  \textsuperscript{7}Microsoft,
  \textsuperscript{8}Université de Montréal,
  \textsuperscript{9}Université de Toulon,
  \textsuperscript{10}Google,
  \textsuperscript{11}Apple
   \textsuperscript{12}Laval University,
   \textsuperscript{13}National Taiwan University,
  \textsuperscript{14}University of Illinois at Urbana-Champaign
}

% The \author macro works with any number of authors. Use \AND 
% to separate the names and addresses of multiple authors.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\def\month{MM}  % Insert correct month for camera-ready version
\def\year{YYYY} % Insert correct year for camera-ready version
\def\openreview{\url{https://openreview.net/forum?id=XXXX}} % Insert correct link to OpenReview for camera-ready version

% \newcommand\blfootnote[1]{%
%   \begingroup
%   \renewcommand\thefootnote{}\footnote{#1}%
%   \addtocounter{footnote}{-1}%
%   \endgroup
% }

\begin{document}
% \blfootnote{† Project lead, Corresponding author (pooneh.mousavi@mail.concordia.ca)}
% \blfootnote{* Equal contribution, Core Team. The authors are listed alphabetically by the last name.}




\maketitle

\footnotetext[2]{Project lead, Corresponding author (pooneh.mousavi@mail.concordia.ca)}
\footnotetext[1]{Equal contribution, Core Team.}

\renewcommand{\thefootnote}{\arabic{footnote}}
\setcounter{footnote}{0}

\begin{abstract}
Discrete audio tokens are compact representations that aim to preserve perceptual quality, phonetic content, and speaker characteristics while enabling efficient storage and inference, as well as competitive performance across diverse downstream tasks.
They provide a practical alternative to continuous features, enabling the integration of speech and audio into modern large language models (LLMs).
As interest in token-based audio processing grows, various tokenization methods have emerged, and several surveys have reviewed the latest progress in the field.
However, existing studies often focus on specific domains or tasks and lack a unified comparison across various benchmarks. This paper presents a systematic review and benchmark of discrete audio tokenizers, covering three domains: speech, music, and general audio. We propose a taxonomy of tokenization approaches based on encoder-decoder, quantization techniques, training paradigm, streamability, and application domains. We evaluate tokenizers on multiple benchmarks for reconstruction, downstream performance, and acoustic language modeling, and analyze trade-offs through controlled ablation studies. Our findings highlight key limitations, practical considerations, and open challenges, providing insight and guidance for future research in this rapidly evolving area. For more information, including our main results and tokenizer database, please refer to our website: \url{https://poonehmousavi.github.io/dates-website/}.
\end{abstract}
\input{sections/1_introduction}

\input{sections/2_literature}

\input{sections/3-benchmark}

\input{sections/4_ablation}

\input{sections/5_conclusion}


\subsubsection*{Author Contributions}
All core members participated equally in the project. While this section outlines the primary responsibilities of each core contributor, many also contributed to other aspects of the project. Pooneh Mousavi led the overall survey and benchmarking effort. Haibin Wu, Pooneh Mousavi, and Anastasia Kuznetsova co-led the design of the tokenizer taxonomy, with collaboration with Haici Yang and Gallil Maimon. Haibin Wu, Jiatong Shi, and Darius Petermann conducted the reconstruction experiments. Pooneh Mousavi led the development of the downstream section, with contributions from Darius Petermann, and Anastasia Kuznetsova. Adel Moumen led the development of the SpeechLM evaluations. Artem Ploujnikov was responsible for the TTS evaluation experiments. Gallil Maimon conducted the AudioLM experiments. Haici Yang led the MusicLM evaluation. Jiatong Shi performed the ablation study in controlled setup. All authors participated in writing, editing, and refining the paper. The advisors provided guidance and critical feedback throughout the project.


\subsubsection*{Acknowledgments}
We thank Jinchuan Tian for valuable discussions with TTS. We also greatly thank Dongchao Yang for sharing his in-depth, hands-on experience with SQ-Codec development and thoughts about the tokenizer taxonomy design, which helped clarify important aspects of our survey. We are grateful to Huizhong Lu for computing support. We thank the NVIDIA Academic Grant Program for donating GPU hours used for this project. This work was supported by the Cambridge Commonwealth, European \& International Trust 
(scholarship to Adel Moumen); the Natural Sciences and Engineering Research Council of Canada (NSERC); the Digital Research Alliance of Canada (alliancecan.ca); The Israel Science Foundaton, grant 2049/22 (scholarship to Gallil Maimon); an Amazon Research Award (ARA); Electronics and Telecommunications Research Institute (ETRI) grant funded by the Korean government [24ZC1100, The research of the basic media/contents technologies]. We also thank Jean Zay GENCI-IDRIS for their support in computing (Grant 2024-AD011015344 and Grant 2024–A0161015099). Cem Subakan is supported by Discovery Grant RGPIN 2023-05759.  

Part of the experiments used the Bridges2 at PSC and Delta/DeltaAI NCSA computing systems through allocation CIS210014 from the Advanced Cyberinfrastructure Coordination Ecosystem: Services \& Support (ACCESS) program, supported by National Science Foundation grants 2138259, 2138286, 2138307, 2137603, and 2138296. 



\bibliography{main}
\bibliographystyle{tmlr}

\appendix
% \section{Appendix}
\input{sections/appendix}

\end{document}
