{"key": "itakura1968analysis", "entry_type": "article", "query_title": "{Analysis synthesis telephony based on the maximum likelihood method}", "normalized_title": "analysis synthesis telephony based on the maximum likelihood method", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Analysis synthesis telephony based on the maximum likelihood method}", "author": "{Itakura, Fumitada}", "journal": "{Reports of the 6th Int. Cong. Acoust.}", "year": "{1968}"}}}
{"key": "atal1970speech", "entry_type": "article", "query_title": "{Speech analysis and synthesis by linear prediction of the speech wave}", "normalized_title": "speech analysis and synthesis by linear prediction of the speech wave", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Speech analysis and synthesis by linear prediction of the speech wave}", "author": "{Atal, Bishnu S}", "journal": "{The journal of the acoustical society of America}", "volume": "{47}", "number": "{1A\\_Supplement}", "pages": "{65--65}", "year": "{1970}", "publisher": "{Acoustical Society of America}"}}}
{"key": "schroeder1985code", "entry_type": "inproceedings", "query_title": "{Code-excited linear prediction (CELP): High-quality speech at very low bit rates}", "normalized_title": "code excited linear prediction celp high quality speech at very low bit rates", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Code-excited linear prediction (CELP): High-quality speech at very low bit rates}", "author": "{Schroeder, Manfred and Atal, B}", "booktitle": "icassp", "year": "{1985}"}}}
{"key": "tian2025espnet", "entry_type": "inproceedings", "query_title": "{{ESP}net-{S}peech{LM}: An open speech language model toolkit}", "normalized_title": "espnet speechlm an open speech language model toolkit", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{ESP}net-{S}peech{LM}: An open speech language model toolkit}", "author": "{Tian, Jinchuan and Shi, Jiatong and Chen, William and Arora, Siddhant and Masuyama, Yoshiki and Maekaku, Takashi and Wu, Yihan and Peng, Junyi and Bharadwaj, Shikhar and Zhao, Yiwen and others}", "booktitle": "naacl", "year": "{2025}"}}}
{"key": "hayashi2020discretalk", "entry_type": "article", "query_title": "{Discretalk: Text-to-speech as a machine translation problem}", "normalized_title": "discretalk text to speech as a machine translation problem", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Discretalk: Text-to-speech as a machine translation problem}", "author": "{Hayashi, Tomoki and Watanabe, Shinji}", "journal": "{arXiv preprint arXiv:2005.05525}", "year": "{2020}"}}}
{"key": "vqvae2017", "entry_type": "inproceedings", "query_title": "{Neural discrete representation learning}", "normalized_title": "neural discrete representation learning", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{van den Oord, Aaron and Vinyals, Oriol and Kavukcuoglu, Koray}", "title": "{Neural discrete representation learning}", "year": "{2017}", "booktitle": "neurips", "location": "{Long Beach, California, USA}"}}}
{"key": "zeghidour2021soundstream", "entry_type": "article", "query_title": "{{SoundStream}: An End-to-End Neural Audio Codec}", "normalized_title": "soundstream an end to end neural audio codec", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Zeghidour, Neil and Luebs, Alejandro and Omran, Ahmed and Skoglund, Jan and Tagliasacchi, Marco}", "title": "{{SoundStream}: An End-to-End Neural Audio Codec}", "year": "{2021}", "journal": "{IEEE/ACM Transactions on Audio, Speech, and Language Processing}", "pages": "{495--507}"}}}
{"key": "shi2024versa", "entry_type": "inproceedings", "query_title": "{{VERSA}: A Versatile Evaluation Toolkit for Speech, Audio, and Music}", "normalized_title": "versa a versatile evaluation toolkit for speech audio and music", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{VERSA}: A Versatile Evaluation Toolkit for Speech, Audio, and Music}", "author": "{Shi, Jiatong and Shim, Hye-jin and Tian, Jinchuan and Arora, Siddhant and Wu, Haibin and Petermann, Darius and Yip, Jia Qi and Zhang, You and Tang, Yuxun and Zhang, Wangyou and others}", "booktitle": "naacl", "year": "{2025}"}}}
{"key": "wu2024towards", "entry_type": "article", "query_title": "{Towards audio language modeling-an overview}", "normalized_title": "towards audio language modeling an overview", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Towards audio language modeling-an overview}", "author": "{Wu, Haibin and Chen, Xuanjun and Lin, Yi-Cheng and Chang, Kai-Wei and Chung, Ho-Lam and Liu, Alexander H. and Lee, {Hung-yi}}", "journal": "{arXiv preprint arXiv:2402.13236}", "year": "{2024}"}}}
{"key": "jiang2023disentangled", "entry_type": "inproceedings", "query_title": "{Disentangled feature learning for real-time neural speech coding}", "normalized_title": "disentangled feature learning for real time neural speech coding", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Disentangled feature learning for real-time neural speech coding}", "author": "{Jiang, Xue and Peng, Xiulian and Zhang, Yuan and Lu, Yan}", "booktitle": "icassp", "year": "{2023}"}}}
{"key": "lakhotia2021generative", "entry_type": "article", "query_title": "{On generative spoken language modeling from raw audio}", "normalized_title": "on generative spoken language modeling from raw audio", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{On generative spoken language modeling from raw audio}", "author": "{Lakhotia, Kushal and Kharitonov, Eugene and Hsu, Wei-Ning and Adi, Yossi and Polyak, Adam and Bolte, Benjamin and Nguyen, Tu-Anh and Copet, Jade and Baevski, Alexei and Mohamed, Abdelrahman and others}", "journal": "{Transactions of the Association for Computational Linguistics}", "volume": "{9}", "pages": "{1336--1354}", "year": "{2021}", "publisher": "{MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~\u2026}"}}}
{"key": "wu2023speechgen", "entry_type": "article", "query_title": "{Speechgen: Unlocking the generative power of speech language models with prompts}", "normalized_title": "speechgen unlocking the generative power of speech language models with prompts", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Speechgen: Unlocking the generative power of speech language models with prompts}", "author": "{Wu, Haibin and Chang, Kai-Wei and Wu, Yuan-Kuei and Lee, Hung-yi}", "journal": "{arXiv preprint arXiv:2306.02207}", "year": "{2023}"}}}
{"key": "zhen2020psychoacoustic", "entry_type": "article", "query_title": "{Psychoacoustic Calibration of Loss Functions for Efficient End-to-End Neural Audio Coding}", "normalized_title": "psychoacoustic calibration of loss functions for efficient end to end neural audio coding", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Zhen, Kai and Lee, Mi Suk and Sung, Jongmo and Beack, Seungkwon and Kim, Minje}", "journal": "{IEEE Signal Processing Letters}", "title": "{Psychoacoustic Calibration of Loss Functions for Efficient End-to-End Neural Audio Coding}", "year": "{2020}", "volume": "{27}", "number": "{}", "pages": "{2159-2163}", "keywords": "{Decoding;Masking threshold;Psychoacoustics;Bit rate;Quantization (signal);Kernel;Audio coding;Audio coding;deep neural networks;psychoacoustics;network compression}", "doi": "{10.1109/LSP.2020.3039765}"}}}
{"key": "garbacea2019low", "entry_type": "inproceedings", "query_title": "{Low bit-rate speech coding with VQ-VAE and a WaveNet decoder}", "normalized_title": "low bit rate speech coding with vq vae and a wavenet decoder", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Low bit-rate speech coding with VQ-VAE and a WaveNet decoder}", "author": "{G{\\^a}rbacea, Cristina and van den Oord, A{\\\"a}ron and Li, Yazhe and Lim, Felicia SC and Luebs, Alejandro and Vinyals, Oriol and Walters, Thomas C},\n  booktitle=icassp, \n  year={2019}"}}}
{"key": "jang2024personalized", "entry_type": "inproceedings", "query_title": "{Personalized neural speech codec}", "normalized_title": "personalized neural speech codec", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Personalized neural speech codec}", "author": "{Jang, Inseon and Yang, Haici and Lim, Wootaek and Beack, Seungkwon and Kim, Minje}", "booktitle": "icassp", "year": "{2024}"}}}
{"key": "Kleijn2018wavenet", "entry_type": "inproceedings", "query_title": "{Wavenet Based Low Rate Speech Coding}", "normalized_title": "wavenet based low rate speech coding", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Kleijn, W. Bastiaan and Lim, Felicia S. C. and Luebs, Alejandro and Skoglund, Jan and Stimberg, Florian and Wang, Quan and Walters, Thomas C.}", "booktitle": "icassp", "title": "{Wavenet Based Low Rate Speech Coding}", "year": "{2018}"}}}
{"key": "valin2019real", "entry_type": "inproceedings", "query_title": "{A real-time wideband neural vocoder at 1.6 kb/s using LPCNet}", "normalized_title": "a real time wideband neural vocoder at 1 6 kb s using lpcnet", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{A real-time wideband neural vocoder at 1.6 kb/s using LPCNet}", "author": "{Valin, Jean-Marc and Skoglund, Jan}", "booktitle": "interspeech", "year": "{2019}"}}}
{"key": "valin2019lpcnet", "entry_type": "inproceedings", "query_title": "{{LPCN}et: Improving neural speech synthesis through linear prediction}", "normalized_title": "lpcnet improving neural speech synthesis through linear prediction", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{LPCN}et: Improving neural speech synthesis through linear prediction}", "author": "{Valin, Jean-Marc and Skoglund, Jan}", "booktitle": "icassp", "year": "{2019}"}}}
{"key": "yang2023neural", "entry_type": "inproceedings", "query_title": "{Neural feature predictor and discriminative residual coding for low-bitrate speech coding}", "normalized_title": "neural feature predictor and discriminative residual coding for low bitrate speech coding", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Neural feature predictor and discriminative residual coding for low-bitrate speech coding}", "author": "{Yang, Haici and Lim, Wootaek and Kim, Minje}", "booktitle": "icassp", "year": "{2023}"}}}
{"key": "Jang2016Gumbel", "entry_type": "inproceedings", "query_title": "{Categorical reparameterization with gumbel-softmax}", "normalized_title": "categorical reparameterization with gumbel softmax", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Categorical reparameterization with gumbel-softmax}", "author": "{Jang, E. and Gu, S. and Poole, B.}", "booktitle": "iclr", "year": "{2017}"}}}
{"key": "maddison2016concrete", "entry_type": "inproceedings", "query_title": "{The concrete distribution: A continuous relaxation of discrete random variables}", "normalized_title": "the concrete distribution a continuous relaxation of discrete random variables", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{The concrete distribution: A continuous relaxation of discrete random variables}", "author": "{Maddison, Chris J and Mnih, Andriy and Teh, Yee Whye}", "booktitle": "iclr", "year": "{2017}"}}}
{"key": "della2025focalcodec", "entry_type": "article", "query_title": "{FocalCodec: Low-Bitrate Speech Coding via Focal Modulation Networks}", "normalized_title": "focalcodec low bitrate speech coding via focal modulation networks", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{FocalCodec: Low-Bitrate Speech Coding via Focal Modulation Networks}", "author": "{Della Libera, Luca and Paissan, Francesco and Subakan, Cem and Ravanelli, Mirco}", "journal": "{arXiv preprint arXiv:2502.04465}", "year": "{2025}"}}}
{"key": "petermann2021harp", "entry_type": "inproceedings", "query_title": "{Harp-net: Hyper-autoencoded reconstruction propagation for scalable neural audio coding}", "normalized_title": "harp net hyper autoencoded reconstruction propagation for scalable neural audio coding", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Harp-net: Hyper-autoencoded reconstruction propagation for scalable neural audio coding}", "author": "{Petermann, Darius and Beack, Seungkwon and Kim, Minje}", "booktitle": "waspaa", "year": "{2021}"}}}
{"key": "Jiang2022EndtoEndNS", "entry_type": "inproceedings", "query_title": "{End-to-End Neural Speech Coding for Real-Time Communications}", "normalized_title": "end to end neural speech coding for real time communications", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{End-to-End Neural Speech Coding for Real-Time Communications}", "author": "{Xue Jiang and Xiulian Peng and Chengyu Zheng and Huaying Xue and Yuan Zhang and Yan Lu}", "booktitle": "icassp", "year": "{2022}"}}}
{"key": "wu2024codecslt", "entry_type": "inproceedings", "query_title": "{Codec-{SUPERB}@ {SLT} 2024: A lightweight benchmark for neural audio codec models}", "normalized_title": "codec superb at slt 2024 a lightweight benchmark for neural audio codec models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Codec-{SUPERB}@ {SLT} 2024: A lightweight benchmark for neural audio codec models}", "author": "{Wu, Haibin and Chen, Xuanjun and Lin, Yi-Cheng and Chang, Kai-wei and Du, Jiawei and Lu, Ke-Han and Liu, Alexander H and Chung, Ho-Lam and Wu, Yuan-Kuei and Yang, Dongchao and others}", "booktitle": "slt", "year": "{2024}"}}}
{"key": "yang2021source", "entry_type": "inproceedings", "query_title": "{Source-aware neural speech coding for noisy speech compression}", "normalized_title": "source aware neural speech coding for noisy speech compression", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Source-aware neural speech coding for noisy speech compression}", "author": "{Yang, Haici and Zhen, Kai and Beack, Seungkwon and Kim, Minje}", "booktitle": "icassp", "year": "{2021}"}}}
{"key": "omran2023disentangling", "entry_type": "inproceedings", "query_title": "{Disentangling speech from surroundings with neural embeddings}", "normalized_title": "disentangling speech from surroundings with neural embeddings", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Disentangling speech from surroundings with neural embeddings}", "author": "{Omran, Ahmed and Zeghidour, Neil and Borsos, Zal{\\'a}n and de Chaumont Quitry, F{\\'e}lix and Slaney, Malcolm and Tagliasacchi, Marco}", "booktitle": "icassp", "year": "{2023}"}}}
{"key": "Ji2024LanguageCodecRT", "entry_type": "article", "query_title": "{Language-Codec: Reducing the Gaps Between Discrete Codec Representation and Speech Language Models}", "normalized_title": "language codec reducing the gaps between discrete codec representation and speech language models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Language-Codec: Reducing the Gaps Between Discrete Codec Representation and Speech Language Models}", "author": "{Shengpeng Ji and Minghui Fang and Ziyue Jiang and Rongjie Huang and Jialung Zuo and Shulei Wang and Zhou Zhao}", "journal": "{arXiv preprint arXiv:2402.12208}", "year": "{2024}"}}}
{"key": "Pan2024PSCodecAS", "entry_type": "article", "query_title": "{PSCodec: A Series of High-Fidelity Low-bitrate Neural Speech Codecs Leveraging Prompt Encoders}", "normalized_title": "pscodec a series of high fidelity low bitrate neural speech codecs leveraging prompt encoders", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{PSCodec: A Series of High-Fidelity Low-bitrate Neural Speech Codecs Leveraging Prompt Encoders}", "author": "{Pan, Yu and Zhang, Xiang and Yang, Yuguang and Yao, Jixun and Hu, Yanni and Ye, Jianhao and Zhou, Hongbin and Ma, Lei and Zhao, Jianjun}", "journal": "{arXiv preprint arXiv:2404.02702}", "year": "{2024}"}}}
{"key": "yang24h_interspeech", "entry_type": "inproceedings", "query_title": "{Genhancer: High-Fidelity Speech Enhancement via Generative Modeling on Discrete Codec Tokens}", "normalized_title": "genhancer high fidelity speech enhancement via generative modeling on discrete codec tokens", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Genhancer: High-Fidelity Speech Enhancement via Generative Modeling on Discrete Codec Tokens}", "author": "{Haici Yang and Jiaqi Su and Minje Kim and Zeyu Jin}", "year": "{2024}", "booktitle": "interspeech"}}}
{"key": "xue24lowlatency", "entry_type": "inproceedings", "query_title": "{Low-Latency Speech Enhancement via Speech Token Generation}", "normalized_title": "low latency speech enhancement via speech token generation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Xue, Huaying and Peng, Xiulian and Lu, Yan}", "booktitle": "icassp", "title": "{Low-Latency Speech Enhancement via Speech Token Generation}", "year": "{2024}"}}}
{"key": "Ahn2024HILCodecHA", "entry_type": "article", "query_title": "{HILCodec: High-Fidelity and Lightweight Neural Audio Codec}", "normalized_title": "hilcodec high fidelity and lightweight neural audio codec", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{HILCodec: High-Fidelity and Lightweight Neural Audio Codec}", "author": "{Ahn, Sung Hwan and Woo, Beom Jun and Han, Mingrui and Moon, Chan Yeong and Kim, Nam Soo}", "journal": "{IEEE Journal of Selected Topics in Signal Processing}", "year": "{2024}", "volume": "{18}", "pages": "{1517-1530}"}}}
{"key": "Ye2024CodecDM", "entry_type": "inproceedings", "query_title": "{Codec does matter: Exploring the semantic shortcoming of codec for audio language model}", "normalized_title": "codec does matter exploring the semantic shortcoming of codec for audio language model", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Codec does matter: Exploring the semantic shortcoming of codec for audio language model}", "author": "{Ye, Zhen and Sun, Peiwen and Lei, Jiahe and Lin, Hongzhan and Tan, Xu and Dai, Zheqi and Kong, Qiuqiang and Chen, Jianyi and Pan, Jiahao and Liu, Qifeng and others}", "booktitle": "aaai", "year": "{2025}"}}}
{"key": "Guo2024AddressingIC", "entry_type": "inproceedings", "query_title": "{Addressing Index Collapse of Large-Codebook Speech Tokenizer With Dual-Decoding Product-Quantized Variational Auto-Encoder}", "normalized_title": "addressing index collapse of large codebook speech tokenizer with dual decoding product quantized variational auto encoder", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Addressing Index Collapse of Large-Codebook Speech Tokenizer With Dual-Decoding Product-Quantized Variational Auto-Encoder}", "author": "{Haohan Guo and Fenglong Xie and Dongchao Yang and Hui Lu and Xixin Wu and Helen M. Meng}", "booktitle": "slt", "year": "{2024}"}}}
{"key": "Zhou2024WMCodecEN", "entry_type": "article", "query_title": "{WMCodec: End-to-End Neural Speech Codec with Deep Watermarking for Authenticity Verification}", "normalized_title": "wmcodec end to end neural speech codec with deep watermarking for authenticity verification", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{WMCodec: End-to-End Neural Speech Codec with Deep Watermarking for Authenticity Verification}", "author": "{Junzuo Zhou and Jiangyan Yi and Yong Ren and Jianhua Tao and Tao Wang and Chu Yuan Zhang}", "journal": "{arXiv preprint arXiv:2409.12121}", "year": "{2024}"}}}
{"key": "Wu2024TS3CodecTS", "entry_type": "article", "query_title": "{TS3-Codec: Transformer-Based Simple Streaming Single Codec}", "normalized_title": "ts3 codec transformer based simple streaming single codec", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{TS3-Codec: Transformer-Based Simple Streaming Single Codec}", "author": "{Wu, Haibin and Kanda, Naoyuki and Eskimez, Sefik Emre and Li, Jinyu}", "journal": "{arXiv preprint arXiv:2411.18803}", "year": "{2024}"}}}
{"key": "Jiang2024MDCTCodecAL", "entry_type": "inproceedings", "query_title": "{MDCTCodec: A Lightweight MDCT-Based Neural Audio Codec Towards High Sampling Rate and Low Bitrate Scenarios}", "normalized_title": "mdctcodec a lightweight mdct based neural audio codec towards high sampling rate and low bitrate scenarios", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{MDCTCodec: A Lightweight MDCT-Based Neural Audio Codec Towards High Sampling Rate and Low Bitrate Scenarios}", "author": "{Xiao-Hang Jiang and Yang Ai and Ruixin Zheng and Hui-Peng Du and Ye-Xin Lu and Zhenhua Ling}", "booktitle": "slt", "year": "{2024}"}}}
{"key": "Guo2024LSCodecLA", "entry_type": "inproceedings", "query_title": "{LSCodec: Low-Bitrate and Speaker-Decoupled Discrete Speech Codec}", "normalized_title": "lscodec low bitrate and speaker decoupled discrete speech codec", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{LSCodec: Low-Bitrate and Speaker-Decoupled Discrete Speech Codec}", "author": "{Yiwei Guo and Zhihan Li and Chenpeng Du and Hankun Wang and Xie Chen and Kai Yu}", "booktitle": "interspeech", "year": "{2025}"}}}
{"key": "zaiem2023icassp", "entry_type": "inproceedings", "query_title": "{Fine-tuning Strategies for Faster Inference using Speech Self-Supervised Models: A Comparative Study}", "normalized_title": "fine tuning strategies for faster inference using speech self supervised models a comparative study", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Fine-tuning Strategies for Faster Inference using Speech Self-Supervised Models: A Comparative Study}", "author": "{Zaiem, Salah and Algayres, Robin and Parcollet, Titouan and Slim, Essid and Ravanelli, Mirco}", "booktitle": "icasspw", "year": "{2023}"}}}
{"key": "yang2021superb", "entry_type": "inproceedings", "query_title": "{{SUPERB: Speech Processing Universal PERformance Benchmark}}", "normalized_title": "superb speech processing universal performance benchmark", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Shu-wen Yang and Po-Han Chi and Yung-Sung Chuang and Cheng-I Jeff Lai and Kushal Lakhotia and Yist Y. Lin and Andy T. Liu and Jiatong Shi and Xuankai Chang and Guan-Ting Lin and others}", "title": "{{SUPERB: Speech Processing Universal PERformance Benchmark}}", "year": "2021", "booktitle": "interspeech"}}}
{"key": "Rabiner:1993dq", "entry_type": "book", "query_title": "{Fundamentals of Speech Recognition}", "normalized_title": "fundamentals of speech recognition", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Rabiner, Lawrence and Juang, Biing-Hwang}", "publisher": "{Prentice-Hall Signal Processing Series}", "title": "{Fundamentals of Speech Recognition}", "year": "1993"}}}
{"key": "busso2008iemocap", "entry_type": "article", "query_title": "{{IEMOCAP}: Interactive emotional dyadic motion capture database}", "normalized_title": "iemocap interactive emotional dyadic motion capture database", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{IEMOCAP}: Interactive emotional dyadic motion capture database}", "author": "{Busso, Carlos and Bulut, Murtaza and Lee, Chi-Chun and Kazemzadeh, Abe and Mower, Emily and Kim, Samuel and Chang, Jeannette N and Lee, Sungbok and Narayanan, Shrikanth S}", "journal": "{Language resources and evaluation}", "volume": "{42}", "pages": "{335--359}", "year": "{2008}"}}}
{"key": "lecun2015deep", "entry_type": "article", "query_title": "{Deep learning}", "normalized_title": "deep learning", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Yann LeCun and Yoshua Bengio and Geoffrey Hinton}", "title": "{Deep learning}", "journal": "{Nature}", "year": "{2015}", "volume": "{521}", "number": "{7553}", "pages": "{436--444}"}}}
{"key": "GoodBengCour16", "entry_type": "book", "query_title": "{Deep Learning}", "normalized_title": "deep learning", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Deep Learning}", "author": "{Ian J. Goodfellow and Yoshua Bengio and Aaron Courville}", "publisher": "{MIT Press}", "year": "{2016}"}}}
{"key": "geminiteam2023gemini", "entry_type": "article", "query_title": "{Gemini: A Family of Highly Capable Multimodal Models}", "normalized_title": "gemini a family of highly capable multimodal models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Gemini: A Family of Highly Capable Multimodal Models}", "author": "{{\\relax Gemini Team, Google}}", "year": "{2023}", "journal": "{arXiv preprint arXiv:2312.11805}"}}}
{"key": "wu2025esi", "entry_type": "article", "query_title": "{Towards Efficient Speech-Text Jointly Decoding within One Speech Language Model}", "normalized_title": "towards efficient speech text jointly decoding within one speech language model", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Towards Efficient Speech-Text Jointly Decoding within One Speech Language Model}", "author": "{Wu, Haibin and Hu, Yuxuan and Fan, Ruchao and Wang, Xiaofei and Kumatani, Kenichi and Ren, Bo and Yu, Jianwei and Lu, Heng and Wang, Lijuan and Qian, Yao and others}", "journal": "{arXiv preprint arXiv:2506.04518}", "year": "{2025}"}}}
{"key": "kumar2023high", "entry_type": "inproceedings", "query_title": "{High-Fidelity Audio Compression with Improved {RVQGAN}}", "normalized_title": "high fidelity audio compression with improved rvqgan", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{High-Fidelity Audio Compression with Improved {RVQGAN}}", "author": "{Rithesh Kumar and Prem Seetharaman and Alejandro Luebs and Ishaan Kumar and Kundan Kumar}", "booktitle": "neurips", "year": "{2023}"}}}
{"key": "zhang2023speechtokenizer", "entry_type": "inproceedings", "query_title": "{{SpeechTokenizer}: Unified speech tokenizer for speech large language models}", "normalized_title": "speechtokenizer unified speech tokenizer for speech large language models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{SpeechTokenizer}: Unified speech tokenizer for speech large language models}", "author": "{Zhang, Xin and Zhang, Dong and Li, Shimin and Zhou, Yaqian and Qiu, Xipeng}", "booktitle": "iclr", "year": "{2024}"}}}
{"key": "wu2023audiodec", "entry_type": "inproceedings", "query_title": "{Audiodec: An Open-Source Streaming High-Fidelity Neural Audio Codec}", "normalized_title": "audiodec an open source streaming high fidelity neural audio codec", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Wu, Yi-Chiao and Gebru, Israel D. and Markovi\u0107, Dejan and Richard, Alexander}", "booktitle": "icassp", "title": "{Audiodec: An Open-Source Streaming High-Fidelity Neural Audio Codec}", "year": "{2023}"}}}
{"key": "yang2023hifi", "entry_type": "article", "query_title": "{{HiFi-Codec}: Group-residual Vector quantization for High Fidelity Audio Codec}", "normalized_title": "hifi codec group residual vector quantization for high fidelity audio codec", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{HiFi-Codec}: Group-residual Vector quantization for High Fidelity Audio Codec}", "author": "{Dongchao Yang and Songxiang Liu and Rongjie Huang and Jinchuan Tian and Chao Weng and Yuexian Zou}", "journal": "{arXiv preprint arXiv:2305.02765}", "year": "{2023}"}}}
{"key": "du2023funcodec", "entry_type": "article", "query_title": "{{FunCodec}: A Fundamental, Reproducible and Integrable Open-source Toolkit for Neural Speech Codec}", "normalized_title": "funcodec a fundamental reproducible and integrable open source toolkit for neural speech codec", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{FunCodec}: A Fundamental, Reproducible and Integrable Open-source Toolkit for Neural Speech Codec}", "author": "{Zhihao Du and Shiliang Zhang and Kai Hu and Siqi Zheng}", "year": "{2023}", "journal": "{arXiv preprint arXiv:2309.07405}"}}}
{"key": "borsos2023audiolm", "entry_type": "article", "query_title": "{{AudioLM}: A Language Modeling Approach to Audio Generation}", "normalized_title": "audiolm a language modeling approach to audio generation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Borsos, Zal\u00e1n and Marinier, Rapha\u00ebl and Vincent, Damien and Kharitonov, Eugene and Pietquin, Olivier and Sharifi, Matt and Roblek, Dominik and Teboul, Olivier and Grangier, David and Tagliasacchi, Marco and Zeghidour, Neil}", "journal": "{IEEE/ACM Transactions on Audio, Speech, and Language Processing}", "title": "{{AudioLM}: A Language Modeling Approach to Audio Generation}", "year": "{2023}", "volume": "{31}", "number": "{}", "pages": "{2523--2533}"}}}
{"key": "rubenstein2023audiopalm", "entry_type": "article", "query_title": "{{AudioPaLM}: A Large Language Model That Can Speak and Listen}", "normalized_title": "audiopalm a large language model that can speak and listen", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{AudioPaLM}: A Large Language Model That Can Speak and Listen}", "author": "{Paul K. Rubenstein and Chulayuth Asawaroengchai and Duc Dung Nguyen and Ankur Bapna and Zal\u00e1n Borsos and F\u00e9lix de Chaumont Quitry and Peter Chen and Dalia El Badawy and Wei Han and Eugene Kharitonov and Hannah Muckenhirn and others}", "journal": "{arXiv preprint arXiv:2306.12925}", "year": "{2023}"}}}
{"key": "wang2024viola", "entry_type": "article", "query_title": "{Viola: Conditional language models for speech recognition, synthesis, and translation}", "normalized_title": "viola conditional language models for speech recognition synthesis and translation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Viola: Conditional language models for speech recognition, synthesis, and translation}", "author": "{Wang, Tianrui and Zhou, Long and Zhang, Ziqiang and Wu, Yu and Liu, Shujie and Gaur, Yashesh and Chen, Zhuo and Li, Jinyu and Wei, Furu}", "journal": "{IEEE/ACM Transactions on Audio, Speech, and Language Processing}", "year": "{2024}", "pages": "{3709-3716}", "publisher": "{IEEE}"}}}
{"key": "sicherman2023analysing", "entry_type": "inproceedings", "query_title": "{Analysing discrete self supervised speech representation for spoken language modeling}", "normalized_title": "analysing discrete self supervised speech representation for spoken language modeling", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Analysing discrete self supervised speech representation for spoken language modeling}", "author": "{Sicherman, Amitay and Adi, Yossi}", "booktitle": "icassp", "year": "{2023}"}}}
{"key": "arora2025landscape", "entry_type": "article", "query_title": "{On The Landscape of Spoken Language Models: A Comprehensive Survey}", "normalized_title": "on the landscape of spoken language models a comprehensive survey", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{On The Landscape of Spoken Language Models: A Comprehensive Survey}", "author": "{Arora, Siddhant and Chang, Kai-Wei and Chien, Chung-Ming and Peng, Yifan and Wu, Haibin and Adi, Yossi and Dupoux, Emmanuel and Lee, Hung-Yi and Livescu, Karen and Watanabe, Shinji}", "journal": "{arXiv preprint arXiv:2504.08528}", "year": "{2025}"}}}
{"key": "chen2023lauragpt", "entry_type": "inproceedings", "query_title": "{{LauraGPT}: Listen, attend, understand, and regenerate audio with {GPT}}", "normalized_title": "lauragpt listen attend understand and regenerate audio with gpt", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{LauraGPT}: Listen, attend, understand, and regenerate audio with {GPT}}", "author": "{Jiaming Wang and Zhihao Du and Qian Chen and Yunfei Chu and Zhifu Gao and Zerui Li and Kai Hu and Xiaohuan Zhou and Jin Xu and Ziyang Ma and Wen Wang and Siqi Zheng and Chang Zhou and Zhijie Yan and Shiliang Zhang}", "booktitle": "iclr", "year": "{2024}"}}}
{"key": "borsos2023soundstorm", "entry_type": "article", "query_title": "{{SoundStorm}: Efficient Parallel Audio Generation}", "normalized_title": "soundstorm efficient parallel audio generation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{SoundStorm}: Efficient Parallel Audio Generation}", "author": "{Borsos, Zal{\\'a}n and Sharifi, Matt and Vincent, Damien and Kharitonov, Eugene and Zeghidour, Neil and Tagliasacchi, Marco}", "journal": "{arXiv preprint arXiv:2305.09636}", "year": "{2023}"}}}
{"key": "wang2023viola", "entry_type": "article", "query_title": "{{VioLA}: Unified Codec Language Models for Speech Recognition, Synthesis, and Translation}", "normalized_title": "viola unified codec language models for speech recognition synthesis and translation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{VioLA}: Unified Codec Language Models for Speech Recognition, Synthesis, and Translation}", "author": "{Tianrui Wang and Long Zhou and Ziqiang Zhang and Yu Wu and Shujie Liu and Yashesh Gaur and Zhuo Chen and Jinyu Li and Furu Wei}", "journal": "{arXiv preprint arXiv:2305.16107}", "year": "{2023}"}}}
{"key": "wang2023speechx", "entry_type": "article", "query_title": "{SpeechX: Neural Codec Language Model as a Versatile Speech Transformer}", "normalized_title": "speechx neural codec language model as a versatile speech transformer", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{SpeechX: Neural Codec Language Model as a Versatile Speech Transformer}", "author": "{Wang, Xiaofei and Thakker, Manthan and Chen, Zhuo and Kanda, Naoyuki and Eskimez, Sefik Emre and Chen, Sanyuan and Tang, Min and Liu, Shujie and Li, Jinyu and Yoshioka, Takuya}", "journal": "{IEEE/ACM Transactions on Audio, Speech, and Language Processing}", "year": "{2024}", "volume": "{32}", "number": "{}", "pages": "{3355-3364}"}}}
{"key": "kreuk2022audiogen", "entry_type": "inproceedings", "query_title": "{{AudioGen}: Textually Guided Audio Generation}", "normalized_title": "audiogen textually guided audio generation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{AudioGen}: Textually Guided Audio Generation}", "author": "{Kreuk, Felix and Synnaeve, Gabriel and Polyak, Adam and Singer, Uriel and D{\\'e}fossez, Alexandre and Copet, Jade and Parikh, Devi and Taigman, Yaniv and Adi, Yossi}", "booktitle": "iclr", "year": "{2023}"}}}
{"key": "desplanques2020ecapa", "entry_type": "inproceedings", "query_title": "{{ECAPA-TDNN}: Emphasized channel attention, propagation and aggregation in {TDNN} based speaker verification}", "normalized_title": "ecapa tdnn emphasized channel attention propagation and aggregation in tdnn based speaker verification", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{ECAPA-TDNN}: Emphasized channel attention, propagation and aggregation in {TDNN} based speaker verification}", "author": "{Desplanques, Brecht and Thienpondt, Jenthe and Demuynck, Kris}", "booktitle": "interspeech", "year": "{2020}"}}}
{"key": "ardila2019common", "entry_type": "inproceedings", "query_title": "\"{Common Voice}: A Massively-Multilingual Speech Corpus\"", "normalized_title": "common voice a massively multilingual speech corpus", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "\"{Common Voice}: A Massively-Multilingual Speech Corpus\"", "author": "\"Ardila, Rosana  and\n    Branson, Megan  and\n    Davis, Kelly  and\n    Kohler, Michael  and\n    Meyer, Josh  and\n    Henretty, Michael  and\n    Morais, Reuben  and\n    Saunders, Lindsay  and\n    Tyers, Francis  and\n    Weber, Gregor\"", "booktitle": "lrec", "year": "\"2020\""}}}
{"key": "agostinelli2023musiclm", "entry_type": "article", "query_title": "{{MusicLM}: Generating music from text}", "normalized_title": "musiclm generating music from text", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{MusicLM}: Generating music from text}", "author": "{Agostinelli, Andrea and others}", "journal": "{arXiv preprint arXiv:2301.11325}", "year": "{2023}"}}}
{"key": "yang2023uniaudio", "entry_type": "inproceedings", "query_title": "{{UniAudio}: Towards universal audio generation with large language models}", "normalized_title": "uniaudio towards universal audio generation with large language models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{UniAudio}: Towards universal audio generation with large language models}", "author": "{Yang, Dongchao and Tian, Jinchuan and Tan, Xu and Huang, Rongjie and Liu, Songxiang and Guo, Haohan and Chang, Xuankai and Shi, Jiatong and Bian, Jiang and Zhao, Zhou and others}", "booktitle": "icml", "year": "{2024}"}}}
{"key": "wells2022phonetic", "entry_type": "inproceedings", "query_title": "{Phonetic analysis of self-supervised representations of {E}nglish speech}", "normalized_title": "phonetic analysis of self supervised representations of english speech", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Phonetic analysis of self-supervised representations of {E}nglish speech}", "author": "{Wells, Dan and Tang, Hao and Richmond, Korin}", "booktitle": "interspeech", "year": "{2022}"}}}
{"key": "polyak2021speech", "entry_type": "inproceedings", "query_title": "{Speech Resynthesis from Discrete Disentangled Self-Supervised Representations}", "normalized_title": "speech resynthesis from discrete disentangled self supervised representations", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Adam Polyak and Yossi Adi and Jade Copet and \n          Eugene Kharitonov and Kushal Lakhotia and \n          Wei-Ning Hsu and Abdelrahman Mohamed and Emmanuel Dupoux}", "title": "{Speech Resynthesis from Discrete Disentangled Self-Supervised Representations}", "year": "{2021}", "booktitle": "interspeech"}}}
{"key": "du2025codecfake", "entry_type": "article", "query_title": "{CodecFake-Omni: A Large-Scale Codec-based Deepfake Speech Dataset}", "normalized_title": "codecfake omni a large scale codec based deepfake speech dataset", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{CodecFake-Omni: A Large-Scale Codec-based Deepfake Speech Dataset}", "author": "{Du, Jiawei and Chen, Xuanjun and Wu, Haibin and Zhang, Lin and Lin, I and Chiu, I and Ren, Wenze and Tseng, Yuan and Tsao, Yu and Jang, Jyh-Shing Roger and others}", "journal": "{arXiv preprint arXiv:2501.08238}", "year": "{2025}"}}}
{"key": "touvron2023llama", "entry_type": "article", "query_title": "{Llama 2: Open foundation and fine-tuned chat models}", "normalized_title": "llama 2 open foundation and fine tuned chat models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Llama 2: Open foundation and fine-tuned chat models}", "author": "{Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others}", "journal": "{arXiv preprint arXiv:2307.09288}", "year": "{2023}"}}}
{"key": "defossez2024moshi", "entry_type": "article", "query_title": "{Moshi: a speech-text foundation model for real-time dialogue}", "normalized_title": "moshi a speech text foundation model for real time dialogue", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Moshi: a speech-text foundation model for real-time dialogue}", "author": "{D{\\'e}fossez, Alexandre and Mazar{\\'e}, Laurent and Orsini, Manu and Royer, Am{\\'e}lie and P{\\'e}rez, Patrick and J{\\'e}gou, Herv{\\'e} and Grave, Edouard and Zeghidour, Neil}", "journal": "{arXiv preprint arXiv:2410.00037}", "year": "{2024}"}}}
{"key": "kharitonov2021text", "entry_type": "inproceedings", "query_title": "\"Text-Free Prosody-Aware Generative Spoken Language Modeling\"", "normalized_title": "text free prosody aware generative spoken language modeling", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "\"Text-Free Prosody-Aware Generative Spoken Language Modeling\"", "author": "\"Kharitonov, Eugene  and\n      Lee, Ann  and\n      Polyak, Adam  and\n      Adi, Yossi  and\n      Copet, Jade  and\n      Lakhotia, Kushal  and\n      Nguyen, Tu Anh  and\n      Riviere, Morgane  and\n      Mohamed, Abdelrahman  and\n      Dupoux, Emmanuel  and\n      Hsu, Wei-Ning\"", "booktitle": "acl", "year": "\"2022\""}}}
{"key": "nguyen2023generative", "entry_type": "article", "query_title": "{Generative spoken dialogue language modeling}", "normalized_title": "generative spoken dialogue language modeling", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Generative spoken dialogue language modeling}", "author": "{Nguyen, Tu Anh and Kharitonov, Eugene and Copet, Jade and Adi, Yossi and Hsu, Wei-Ning and Elkahky, Ali and Tomasello, Paden and Algayres, Robin and Sagot, Benoit and Mohamed, Abdelrahman and others}", "journal": "{Transactions of the Association for Computational Linguistics}", "volume": "{11}", "pages": "{250--266}", "year": "{2023}"}}}
{"key": "popuri2022enhanced", "entry_type": "inproceedings", "query_title": "{Enhanced Direct Speech-to-Speech Translation Using Self-supervised Pre-training and Data Augmentation}", "normalized_title": "enhanced direct speech to speech translation using self supervised pre training and data augmentation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Enhanced Direct Speech-to-Speech Translation Using Self-supervised Pre-training and Data Augmentation}", "author": "{Popuri, Sravya and Chen, Peng-Jen and Wang, Changhan and Pino, Juan and Adi, Yossi and Gu, Jiatao and Hsu, Wei-Ning and Lee, Ann}", "booktitle": "interspeech", "year": "{2022}"}}}
{"key": "inaguma2022unity", "entry_type": "inproceedings", "query_title": "{UnitY: Two-pass Direct Speech-to-speech Translation with Discrete Units}", "normalized_title": "unity two pass direct speech to speech translation with discrete units", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{UnitY: Two-pass Direct Speech-to-speech Translation with Discrete Units}", "author": "{Inaguma, Hirofumi and Popuri, Sravya and Kulikov, Ilia and Chen, Peng-Jen and Wang, Changhan and Chung, Yu-An and Tang, Yun and Lee, Ann and Watanabe, Shinji and Pino, Juan}", "booktitle": "acl", "year": "{2023}"}}}
{"key": "chang2022speechprompt", "entry_type": "inproceedings", "query_title": "{SpeechPrompt: An exploration of prompt tuning on generative spoken language model for speech processing tasks}", "normalized_title": "speechprompt an exploration of prompt tuning on generative spoken language model for speech processing tasks", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{SpeechPrompt: An exploration of prompt tuning on generative spoken language model for speech processing tasks}", "author": "{Chang, Kai-Wei and Tseng, Wei-Cheng and Li, Shang-Wen and Lee, Hung-yi}", "booktitle": "interspeech", "year": "{2022}"}}}
{"key": "chang2023speechprompt", "entry_type": "article", "query_title": "{Speechprompt v2: Prompt tuning for speech classification tasks}", "normalized_title": "speechprompt v2 prompt tuning for speech classification tasks", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Speechprompt v2: Prompt tuning for speech classification tasks}", "author": "{Chang, Kai-Wei and Wang, Yu-Kai and Shen, Hua and Kang, Iu-thing and Tseng, Wei-Cheng and Li, Shang-Wen and Lee, Hung-yi}", "journal": "{arXiv preprint arXiv:2303.00733}", "year": "{2023}"}}}
{"key": "hsu2023exploration", "entry_type": "inproceedings", "query_title": "{An exploration of in-context learning for speech language model}", "normalized_title": "an exploration of in context learning for speech language model", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{An exploration of in-context learning for speech language model}", "author": "{Hsu, Ming-Hao and Chang, Kai-Wei and Li, Shang-Wen and Lee, Hung-yi}", "booktitle": "interspeech", "year": "{2024}"}}}
{"key": "kuan2023towards", "entry_type": "inproceedings", "query_title": "{Towards General-Purpose Text-Instruction-Guided Voice Conversion}", "normalized_title": "towards general purpose text instruction guided voice conversion", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Towards General-Purpose Text-Instruction-Guided Voice Conversion}", "author": "{Kuan, Chun-Yi and Li, Chen-An and Hsu, Tsu-Yuan and Lin, Tse-Yang and Chung, Ho-Lam and Chang, Kai-Wei and Chang, Shuo-Yiin and Lee, Hung-yi}", "booktitle": "asru", "year": "{2023}", "organization": "{IEEE}"}}}
{"key": "zeng2024glm", "entry_type": "article", "query_title": "{G{LM}-4-voice: Towards intelligent and human-like end-to-end spoken chatbot}", "normalized_title": "glm 4 voice towards intelligent and human like end to end spoken chatbot", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{G{LM}-4-voice: Towards intelligent and human-like end-to-end spoken chatbot}", "author": "{Zeng, Aohan and Du, Zhengxiao and Liu, Mingdao and Wang, Kedong and Jiang, Shengmin and Zhao, Lei and Dong, Yuxiao and Tang, Jie}", "journal": "{arXiv preprint arXiv:2412.02612}", "year": "{2024}"}}}
{"key": "huang2023dynamic", "entry_type": "inproceedings", "query_title": "{Dynamic-{SUPERB}: Towards a dynamic, collaborative, and comprehensive instruction-tuning benchmark for speech}", "normalized_title": "dynamic superb towards a dynamic collaborative and comprehensive instruction tuning benchmark for speech", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Dynamic-{SUPERB}: Towards a dynamic, collaborative, and comprehensive instruction-tuning benchmark for speech}", "author": "{Huang, Chien-yu and Lu, Ke-Han and Wang, Shih-Heng and Hsiao, Chi-Yuan and Kuan, Chun-Yi and Wu, Haibin and Arora, Siddhant and Chang, Kai-Wei and Shi, Jiatong and Peng, Yifan and others}", "booktitle": "icassp", "pages": "{12136--12140}", "year": "{2024}"}}}
{"key": "huang2024dynamic", "entry_type": "inproceedings", "query_title": "{Dynamic-superb phase-2: A collaboratively expanding benchmark for measuring the capabilities of spoken language models with 180 tasks}", "normalized_title": "dynamic superb phase 2 a collaboratively expanding benchmark for measuring the capabilities of spoken language models with 180 tasks", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Dynamic-superb phase-2: A collaboratively expanding benchmark for measuring the capabilities of spoken language models with 180 tasks}", "author": "{Huang, Chien-yu and Chen, Wei-Chih and Yang, Shu-wen and Liu, Andy T and Li, Chen-An and Lin, Yu-Xiang and Tseng, Wei-Cheng and Diwan, Anuj and Shih, Yi-Jen and Shi, Jiatong and others}", "booktitle": "iclr", "year": "{2025}"}}}
{"key": "xu2025qwen2", "entry_type": "article", "query_title": "{Qwen2. 5-omni technical report}", "normalized_title": "qwen2 5 omni technical report", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Qwen2. 5-omni technical report}", "author": "{Xu, Jin and Guo, Zhifang and He, Jinzheng and Hu, Hangrui and He, Ting and Bai, Shuai and Chen, Keqin and Wang, Jialin and Fan, Yang and Dang, Kai and others}", "journal": "{arXiv preprint arXiv:2503.20215}", "year": "{2025}"}}}
{"key": "liu2023pre", "entry_type": "article", "query_title": "{Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing}", "normalized_title": "pre train prompt and predict a systematic survey of prompting methods in natural language processing", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing}", "author": "{Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham}", "journal": "{ACM Computing Surveys}", "volume": "{55}", "number": "{9}", "pages": "{1--35}", "year": "{2023}", "publisher": "{ACM New York, NY}"}}}
{"key": "lester2021power", "entry_type": "inproceedings", "query_title": "{The power of scale for parameter-efficient prompt tuning}", "normalized_title": "the power of scale for parameter efficient prompt tuning", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{The power of scale for parameter-efficient prompt tuning}", "author": "{Lester, Brian and Al-Rfou, Rami and Constant, Noah}", "booktitle": "emnlp", "year": "{2021}"}}}
{"key": "chang2023exploring", "entry_type": "inproceedings", "query_title": "{Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study}", "normalized_title": "exploring speech recognition translation and understanding with discrete speech units a comparative study", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Chang, Xuankai and Yan, Brian and Choi, Kwanghee and Jung, Jee-Weon and Lu, Yichen and Maiti, Soumi and Sharma, Roshan and Shi, Jiatong and Tian, Jinchuan and Watanabe, Shinji and Fujita, Yuya and others}", "booktitle": "icassp", "title": "{Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study}", "year": "{2024}", "volume": "{}", "number": "{}"}}}
{"key": "wang2023selm", "entry_type": "inproceedings", "query_title": "{{SELM}: Speech Enhancement Using Discrete Tokens and Language Models}", "normalized_title": "selm speech enhancement using discrete tokens and language models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{SELM}: Speech Enhancement Using Discrete Tokens and Language Models}", "author": "{Wang, Ziqian and Zhu, Xinfa and Zhang, Zihan and Lv, YuanJun and Jiang, Ning and Zhao, Guoqing and Xie, Lei}", "booktitle": "icassp", "year": "{2024}"}}}
{"key": "wu2024codec", "entry_type": "inproceedings", "query_title": "{{Codec-SUPERB}: An In-Depth Analysis of Sound Codec Models}", "normalized_title": "codec superb an in depth analysis of sound codec models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{Codec-SUPERB}: An In-Depth Analysis of Sound Codec Models}", "author": "{Wu, Haibin and Chung, Ho-Lam and Lin, Yi-Cheng and Wu, Yuan-Kuei and Chen, Xuanjun and Pai, Yu-Chi and Wang, Hsiu-Hsuan and Chang, Kai-Wei and Liu, Alexander H and Lee, Hung-yi}", "booktitle": "acl", "year": "{2024}"}}}
{"key": "zhang2023dub", "entry_type": "inproceedings", "query_title": "\"{DUB}: Discrete Unit Back-translation for Speech Translation\"", "normalized_title": "dub discrete unit back translation for speech translation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "\"{DUB}: Discrete Unit Back-translation for Speech Translation\"", "author": "\"Zhang, Dong  and\n      Ye, Rong  and\n      Ko, Tom  and\n      Wang, Mingxuan  and\n      Zhou, Yaqian\"", "booktitle": "acl", "year": "\"2023\""}}}
{"key": "wu2024toksing", "entry_type": "inproceedings", "query_title": "{TokSing: Singing Voice Synthesis based on Discrete Tokens}", "normalized_title": "toksing singing voice synthesis based on discrete tokens", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{TokSing: Singing Voice Synthesis based on Discrete Tokens}", "author": "{Wu, Yuning and Zhang, Chunlei and Shi, Jiatong and Tang, Yuxun and Yang, Shan and Jin, Qin}", "booktitle": "interspeech", "year": "{2024}"}}}
{"key": "yip2024towards", "entry_type": "inproceedings", "query_title": "{Towards audio codec-based speech separation}", "normalized_title": "towards audio codec based speech separation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Towards audio codec-based speech separation}", "author": "{Yip, Jia Qi and Zhao, Shengkui and Ng, Dianwen and Chng, Eng Siong and Ma, Bin}", "booktitle": "interspeech", "year": "{2024}"}}}
{"key": "chung2021w2v", "entry_type": "inproceedings", "query_title": "{{w2v-BERT}: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training}", "normalized_title": "w2v bert combining contrastive learning and masked language modeling for self supervised speech pre training", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Chung, Yu-An and Zhang, Yu and Han, Wei and Chiu, Chung-Cheng and Qin, James and Pang, Ruoming and Wu, Yonghui}", "booktitle": "asru", "title": "{{w2v-BERT}: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training}", "year": "{2021}"}}}
{"key": "hsu2021hubert", "entry_type": "article", "query_title": "{{HuBERT}: Self-supervised speech representation learning by masked prediction of hidden units}", "normalized_title": "hubert self supervised speech representation learning by masked prediction of hidden units", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{HuBERT}: Self-supervised speech representation learning by masked prediction of hidden units}", "author": "{Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman}", "journal": "{IEEE/ACM Transactions on Audio, Speech, and Language Processing}", "volume": "{29}", "pages": "{3451--3460}", "year": "{2021}"}}}
{"key": "chen2022wavlm", "entry_type": "article", "query_title": "{{WavLM}: Large-scale self-supervised pre-training for full stack speech processing}", "normalized_title": "wavlm large scale self supervised pre training for full stack speech processing", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{WavLM}: Large-scale self-supervised pre-training for full stack speech processing}", "author": "{Chen, Sanyuan and Wang, Chengyi and Chen, Zhengyang and Wu, Yu and Liu, Shujie and Chen, Zhuo and Li, Jinyu and Kanda, Naoyuki and Yoshioka, Takuya and Xiao, Xiong and others}", "journal": "{IEEE Journal of Selected Topics in Signal Processing}", "volume": "{16}", "number": "{6}", "pages": "{1505--1518}", "year": "{2022}"}}}
{"key": "baevski2020wav2vec", "entry_type": "inproceedings", "query_title": "{wav2vec 2.0: A framework for self-supervised learning of speech representations}", "normalized_title": "wav2vec 2 0 a framework for self supervised learning of speech representations", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{wav2vec 2.0: A framework for self-supervised learning of speech representations}", "author": "{Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael}", "booktitle": "neurips", "year": "{2020}"}}}
{"key": "chang2023exploration", "entry_type": "inproceedings", "query_title": "{Exploration of Efficient End-to-End {ASR} using Discretized Input from Self-Supervised Learning}", "normalized_title": "exploration of efficient end to end asr using discretized input from self supervised learning", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Xuankai Chang and Brian Yan and Yuya Fujita and Takashi Maekaku and Shinji Watanabe}", "title": "{Exploration of Efficient End-to-End {ASR} using Discretized Input from Self-Supervised Learning}", "year": "2023", "booktitle": "interspeech"}}}
{"key": "pasad2023comparative", "entry_type": "inproceedings", "query_title": "{Comparative layer-wise analysis of self-supervised speech models}", "normalized_title": "comparative layer wise analysis of self supervised speech models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Comparative layer-wise analysis of self-supervised speech models}", "author": "{Pasad, Ankita and Shi, Bowen and Livescu, Karen}", "booktitle": "icassp", "year": "{2023}"}}}
{"key": "goodfellow2020generative", "entry_type": "article", "query_title": "{Generative adversarial networks}", "normalized_title": "generative adversarial networks", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Generative adversarial networks}", "author": "{Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua}", "journal": "{Communications of the ACM}", "volume": "{63}", "number": "{11}", "pages": "{139--144}", "year": "{2020}", "publisher": "{ACM New York, NY, USA}"}}}
{"key": "kong2020hifigan", "entry_type": "inproceedings", "query_title": "{{HiFi-GAN}: generative adversarial networks for efficient and high fidelity speech synthesis}", "normalized_title": "hifi gan generative adversarial networks for efficient and high fidelity speech synthesis", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung}", "title": "{{HiFi-GAN}: generative adversarial networks for efficient and high fidelity speech synthesis}", "year": "{2020}", "booktitle": "neurips"}}}
{"key": "oord2016wavenet", "entry_type": "article", "query_title": "{WaveNet: A Generative Model for Raw Audio}", "normalized_title": "wavenet a generative model for raw audio", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{WaveNet: A Generative Model for Raw Audio}", "author": "{Aaron van den Oord and Sander Dieleman and Heiga Zen and Karen Simonyan and Oriol Vinyals and Alex Graves and Nal Kalchbrenner and Andrew Senior and Koray Kavukcuoglu}", "year": "{2016}", "journal": "{arXiv preprint arXiv:1609.03499}"}}}
{"key": "prenger2018waveglow", "entry_type": "inproceedings", "query_title": "{Waveglow: A Flow-based Generative Network for Speech Synthesis}", "normalized_title": "waveglow a flow based generative network for speech synthesis", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Prenger, Ryan and Valle, Rafael and Catanzaro, Bryan}", "booktitle": "icassp", "title": "{Waveglow: A Flow-based Generative Network for Speech Synthesis}", "year": "{2019}"}}}
{"key": "transformer", "entry_type": "inproceedings", "query_title": "{Attention is All You Need}", "normalized_title": "attention is all you need", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Ashish Vaswani and\n                  Noam Shazeer and\n                  Niki Parmar and\n                  Jakob Uszkoreit and\n                  Llion Jones and\n                  Aidan N. Gomez and\n                  Lukasz Kaiser and\n                  Illia Polosukhin}", "title": "{Attention is All You Need}", "year": "{2017}", "booktitle": "neurips"}}}
{"key": "somos", "entry_type": "inproceedings", "query_title": "{{SOMOS: The Samsung Open MOS Dataset for the Evaluation of Neural Text-to-Speech Synthesis}}", "normalized_title": "somos the samsung open mos dataset for the evaluation of neural text to speech synthesis", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{SOMOS: The Samsung Open MOS Dataset for the Evaluation of Neural Text-to-Speech Synthesis}}", "author": "{Georgia Maniati and Alexandra Vioni and Nikolaos Ellinas and Karolos Nikitaras and Konstantinos Klapsas and June Sig Sung and Gunu Jho and Aimilios Chalamandaris and Pirros Tsiakoulis}", "booktitle": "interspeech", "year": "{2022}"}}}
{"key": "yang2023towards", "entry_type": "inproceedings", "query_title": "{Towards Universal Speech Discrete Tokens: A Case Study for {ASR} and {TTS}}", "normalized_title": "towards universal speech discrete tokens a case study for asr and tts", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Towards Universal Speech Discrete Tokens: A Case Study for {ASR} and {TTS}}", "author": "{Yang, Yifan and Shen, Feiyu and Du, Chenpeng and Ma, Ziyang and Yu, Kai and Povey, Daniel and Chen, Xie}", "booktitle": "icassp", "year": "{2024}"}}}
{"key": "wang2021dwer", "entry_type": "inproceedings", "query_title": "{Sequential Multi-Frame Neural Beamforming for Speech Separation and Enhancement}", "normalized_title": "sequential multi frame neural beamforming for speech separation and enhancement", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Wang, Zhong-Qiu and others}", "booktitle": "slt", "title": "{Sequential Multi-Frame Neural Beamforming for Speech Separation and Enhancement}", "year": "{2021}"}}}
{"key": "wichern2019wham", "entry_type": "inproceedings", "query_title": "{{WHAM!}: Extending Speech Separation to Noisy Environments}", "normalized_title": "wham extending speech separation to noisy environments", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{WHAM!}: Extending Speech Separation to Noisy Environments}", "author": "{Gordon Wichern and others}", "year": "{2019}", "booktitle": "interspeech"}}}
{"key": "le2019sdr", "entry_type": "inproceedings", "query_title": "{{SDR}--half-baked or well done?}", "normalized_title": "sdr half baked or well done", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{SDR}--half-baked or well done?}", "author": "{Le Roux, J. and Wisdom, S. and Erdogan, H. and Hershey, J. R.}", "booktitle": "icassp", "year": "{2019}"}}}
{"key": "ljspeech17", "entry_type": "misc", "query_title": "{The {LJ} Speech Dataset}", "normalized_title": "the lj speech dataset", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Keith Ito}", "title": "{The {LJ} Speech Dataset}", "howpublished": "{\\url{https://keithito.com/LJ-Speech-Dataset/} }", "year": "2017"}}}
{"key": "srivastava2014dropout", "entry_type": "article", "query_title": "{Dropout: a simple way to prevent neural networks from overfitting}", "normalized_title": "dropout a simple way to prevent neural networks from overfitting", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Dropout: a simple way to prevent neural networks from overfitting}", "author": "{Srivastava, Nitish and others}", "journal": "{The journal of machine learning research}", "volume": "{15}", "number": "{1}", "pages": "{1929--1958}", "year": "{2014}", "publisher": "{JMLR. org}"}}}
{"key": "nagrani2017voxceleb", "entry_type": "inproceedings", "query_title": "{{VoxCeleb}: A Large-Scale Speaker Identification Dataset}", "normalized_title": "voxceleb a large scale speaker identification dataset", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Arsha Nagrani and Joon Son Chung and Andrew Zisserman}", "title": "{{VoxCeleb}: A Large-Scale Speaker Identification Dataset}", "year": "2017", "booktitle": "interspeech"}}}
{"key": "1360861705599880960", "entry_type": "inproceedings", "query_title": "\"{{UTMOS: UTokyo-SaruLab System for VoiceMOS Challenge 2022}}\"", "normalized_title": "utmos utokyo sarulab system for voicemos challenge 2022", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "\"Saeki, Takaaki, and others\"", "title": "\"{{UTMOS: UTokyo-SaruLab System for VoiceMOS Challenge 2022}}\"", "booktitle": "interspeech", "year": "\"2022\""}}}
{"key": "zaiem2025speech", "entry_type": "article", "query_title": "{Speech self-supervised representations benchmarking: a case for larger probing heads}", "normalized_title": "speech self supervised representations benchmarking a case for larger probing heads", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Speech self-supervised representations benchmarking: a case for larger probing heads}", "author": "{Zaiem, Salah and Kemiche, Youcef and Parcollet, Titouan and Essid, Slim and Ravanelli, Mirco}", "journal": "{Computer Speech \\& Language}", "volume": "{89}", "pages": "{101695}", "year": "{2025}", "publisher": "{Elsevier}"}}}
{"key": "defossez2022high", "entry_type": "article", "query_title": "{High Fidelity Neural Audio Compression}", "normalized_title": "high fidelity neural audio compression", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{High Fidelity Neural Audio Compression}", "author": "{Alexandre D{\\'e}fossez and Jade Copet and Gabriel Synnaeve and Yossi Adi}", "journal": "{Transactions on Machine Learning Research}", "year": "{2023}"}}}
{"key": "DevlinCLT19", "entry_type": "inproceedings", "query_title": "\"{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding\"", "normalized_title": "bert pre training of deep bidirectional transformers for language understanding", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "\"{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding\"", "author": "\"Devlin, Jacob  and\n      Chang, Ming-Wei  and\n      Lee, Kenton  and\n      Toutanova, Kristina\"", "editor": "\"Burstein, Jill  and\n      Doran, Christy  and\n      Solorio, Thamar\"", "booktitle": "naacl", "year": "\"2019\""}}}
{"key": "newell2020useful", "entry_type": "inproceedings", "query_title": "{How useful is self-supervised pretraining for visual tasks?}", "normalized_title": "how useful is self supervised pretraining for visual tasks", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{How useful is self-supervised pretraining for visual tasks?}", "author": "{Newell, Alejandro and Deng, Jia}", "booktitle": "cvpr", "year": "{2020}"}}}
{"key": "liu2021self", "entry_type": "article", "query_title": "{Self-supervised learning: Generative or contrastive}", "normalized_title": "self supervised learning generative or contrastive", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Self-supervised learning: Generative or contrastive}", "author": "{Liu, Xiao and Zhang, Fanjin and Hou, Zhenyu and Mian, Li and Wang, Zhaoyu and Zhang, Jing and Tang, Jie}", "journal": "{IEEE Transactions on knowledge and data engineering}", "volume": "{35}", "number": "{1}", "pages": "{857--876}", "year": "{2021}", "publisher": "{IEEE}"}}}
{"key": "JMLR:v24:22-1144", "entry_type": "article", "query_title": "{{PaLM}: scaling language modeling with pathways}", "normalized_title": "palm scaling language modeling with pathways", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others}", "title": "{{PaLM}: scaling language modeling with pathways}", "year": "{2024}", "volume": "{24}", "journal": "{Journal of Machine Learning Research}"}}}
{"key": "liu2023gpt", "entry_type": "article", "query_title": "{{GPT} understands, too}", "normalized_title": "gpt understands too", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{GPT} understands, too}", "author": "{Liu, Xiao and Zheng, Yanan and Du, Zhengxiao and Ding, Ming and Qian, Yujie and Yang, Zhilin and Tang, Jie}", "journal": "{AI Open}", "year": "{2023}"}}}
{"key": "speechbrain_ravanelli", "entry_type": "article", "query_title": "{Open-source conversational ai with speechbrain 1.0}", "normalized_title": "open source conversational ai with speechbrain 1 0", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Open-source conversational ai with speechbrain 1.0}", "author": "{Ravanelli, Mirco and Parcollet, Titouan and Moumen, Adel and de Langen, Sylvain and Subakan, Cem and Plantinga, Peter and Wang, Yingzhi and Mousavi, Pooneh and Della Libera, Luca and Ploujnikov, Artem and others}", "journal": "{Journal of Machine Learning Research}", "volume": "{25}", "number": "{333}", "pages": "{1--11}", "year": "{2024}"}}}
{"key": "wang2024evaluating", "entry_type": "inproceedings", "query_title": "{Evaluating Text-to-Speech Synthesis from a Large Discrete Token-based Speech Language Model}", "normalized_title": "evaluating text to speech synthesis from a large discrete token based speech language model", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Evaluating Text-to-Speech Synthesis from a Large Discrete Token-based Speech Language Model}", "author": "{Wang, Siyang and Sz{\\'e}kely, {\\'E}va}", "booktitle": "LREC-COLING", "year": "{2024}"}}}
{"key": "wang2023neural", "entry_type": "article", "query_title": "{Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers}", "normalized_title": "neural codec language models are zero shot text to speech synthesizers", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Chen, Sanyuan and Wang, Chengyi and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and He, Lei and Zhao, Sheng and Wei, Furu}", "journal": "{IEEE Transactions on Audio, Speech and Language Processing}", "title": "{Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers}", "year": "{2025}", "volume": "{33}", "number": "{}", "pages": "{705-718}"}}}
{"key": "kharitonov2023speak", "entry_type": "article", "query_title": "{Speak, read and prompt: High-fidelity text-to-speech with minimal supervision}", "normalized_title": "speak read and prompt high fidelity text to speech with minimal supervision", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Speak, read and prompt: High-fidelity text-to-speech with minimal supervision}", "author": "{Kharitonov, Eugene and Vincent, Damien and Borsos, Zal{\\'a}n and Marinier, Rapha{\\\"e}l and Girgin, Sertan and Pietquin, Olivier and Sharifi, Matt and Tagliasacchi, Marco and Zeghidour, Neil},\n  journal={Transactions of the Association for Computational Linguistics},\n  volume={11},\n  pages={1703--1718},\n  year={2023},\n  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~\u2026}"}}}
{"key": "shi2021discretization", "entry_type": "article", "query_title": "{Discretization and re-synthesis: an alternative method to solve the cocktail party problem}", "normalized_title": "discretization and re synthesis an alternative method to solve the cocktail party problem", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Discretization and re-synthesis: an alternative method to solve the cocktail party problem}", "author": "{Shi, Jing and Chang, Xuankai and Hayashi, Tomoki and Lu, Yen-Ju and Watanabe, Shinji and Xu, Bo}", "journal": "{arXiv preprint arXiv:2112.09382}", "year": "{2021}"}}}
{"key": "erdogan2023tokensplit", "entry_type": "inproceedings", "query_title": "{{TokenSplit}: Using Discrete Speech Representations for Direct, Refined, and Transcript-Conditioned Speech Separation and Recognition}", "normalized_title": "tokensplit using discrete speech representations for direct refined and transcript conditioned speech separation and recognition", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{TokenSplit}: Using Discrete Speech Representations for Direct, Refined, and Transcript-Conditioned Speech Separation and Recognition}", "author": "{Erdogan, Hakan and Wisdom, Scott and Chang, Xuankai and Borsos, Zal{\\'a}n and Tagliasacchi, Marco and Zeghidour, Neil and Hershey, John R}", "year": "{2023}", "booktitle": "interspeech"}}}
{"key": "puvvada2023discrete", "entry_type": "inproceedings", "query_title": "{Discrete Audio Representation as an Alternative to {M}el-Spectrograms for Speaker and Speech Recognition}", "normalized_title": "discrete audio representation as an alternative to mel spectrograms for speaker and speech recognition", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Puvvada, Krishna C. and Rao Koluguri, Nithin and Dhawan, Kunal and Balam, Jagadeesh and Ginsburg, Boris}", "booktitle": "icassp", "title": "{Discrete Audio Representation as an Alternative to {M}el-Spectrograms for Speaker and Speech Recognition}", "year": "{2024}"}}}
{"key": "wu2024codecfake", "entry_type": "inproceedings", "query_title": "{Codecfake: Enhancing anti-spoofing models against deepfake audios from codec-based speech synthesis systems}", "normalized_title": "codecfake enhancing anti spoofing models against deepfake audios from codec based speech synthesis systems", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Codecfake: Enhancing anti-spoofing models against deepfake audios from codec-based speech synthesis systems}", "author": "{Wu, Haibin and Tseng, Yuan and Lee, Hung-yi}", "booktitle": "interspeech", "year": "{2024}"}}}
{"key": "ren2024emo", "entry_type": "inproceedings", "query_title": "{EMO-Codec: An In-Depth Look at Emotion Preservation Capacity of Legacy and Neural Codec Models with Subjective and Objective Evaluations}", "normalized_title": "emo codec an in depth look at emotion preservation capacity of legacy and neural codec models with subjective and objective evaluations", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{EMO-Codec: An In-Depth Look at Emotion Preservation Capacity of Legacy and Neural Codec Models with Subjective and Objective Evaluations}", "author": "{Ren, Wenze and Lin, Yi-Cheng and Chou, Huang-Cheng and Wu, Haibin and Wu, Yi-Chiao and Lee, Chi-Chun and Lee, Hung-yi and Wang, Hsin-Min and Tsao, Yu}", "booktitle": "APSIPA_ASC", "year": "{2024}"}}}
{"key": "mousavi2024", "entry_type": "inproceedings", "query_title": "{Semantic Token Tuning: How Should We Extract Discrete Audio Tokens from Self-Supervised Models?}", "normalized_title": "semantic token tuning how should we extract discrete audio tokens from self supervised models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Semantic Token Tuning: How Should We Extract Discrete Audio Tokens from Self-Supervised Models?}", "author": "{Mousavi, Pooneh and Duret, Jarod and Zaiem, Salah and Della Libera, Luca and Ploujnikov, Artem and Subakan, Cem and Ravanelli, Mirco}", "booktitle": "interspeech", "year": "{2024}"}}}
{"key": "korvas_2014", "entry_type": "inproceedings", "query_title": "\"Free {E}nglish and {C}zech telephone speech corpus shared under the {CC}-{BY}-{SA} 3.0 license\"", "normalized_title": "free english and czech telephone speech corpus shared under the cc by sa 3 0 license", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "\"Free {E}nglish and {C}zech telephone speech corpus shared under the {CC}-{BY}-{SA} 3.0 license\"", "author": "\"Korvas, Mat{\\v{e}}j  and\n      Pl{\\'a}tek, Ond{\\v{r}}ej  and\n      Du{\\v{s}}ek, Ond{\\v{r}}ej  and\n      {\\v{Z}}ilka, Luk{\\'a}{\\v{s}}  and\n      Jur{\\v{c}}{\\'\\i}{\\v{c}}ek, Filip\"", "booktitle": "lrec", "year": "\"2014\""}}}
{"key": "han2020contextnet", "entry_type": "inproceedings", "query_title": "{{ContextNet}: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context}", "normalized_title": "contextnet improving convolutional neural networks for automatic speech recognition with global context", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Wei Han and Zhengdong Zhang and Yu Zhang and Jiahui Yu and Chung-Cheng Chiu and James Qin and Anmol Gulati and Ruoming Pang and Yonghui Wu}", "title": "{{ContextNet}: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context}", "year": "2020", "booktitle": "interspeech"}}}
{"key": "snyder2018x", "entry_type": "inproceedings", "query_title": "{X-vectors: Robust {DNN} embeddings for speaker recognition}", "normalized_title": "x vectors robust dnn embeddings for speaker recognition", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{X-vectors: Robust {DNN} embeddings for speaker recognition}", "author": "{Snyder, David and Garcia-Romero, Daniel and Sell, Gregory and Povey, Daniel and Khudanpur, Sanjeev}", "booktitle": "icassp", "year": "{2018}"}}}
{"key": "wang2018additive", "entry_type": "article", "query_title": "{Additive margin softmax for face verification}", "normalized_title": "additive margin softmax for face verification", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Additive margin softmax for face verification}", "author": "{Wang, Feng and Cheng, Jian and Liu, Weiyang and Liu, Haijun}", "journal": "{IEEE Signal Processing Letters}", "volume": "{25}", "number": "{7}", "pages": "{926--930}", "year": "{2018}"}}}
{"key": "bastianelli2020slurp", "entry_type": "inproceedings", "query_title": "\"{SLURP}: A Spoken Language Understanding Resource Package\"", "normalized_title": "slurp a spoken language understanding resource package", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "\"{SLURP}: A Spoken Language Understanding Resource Package\"", "author": "\"Bastianelli, Emanuele  and\n      Vanzo, Andrea  and\n      Swietojanski, Pawel  and\n      Rieser, Verena\"", "booktitle": "emnlp", "year": "\"2020\""}}}
{"key": "warden2017speech", "entry_type": "article", "query_title": "{{Speech Commands}: A Dataset for Limited-Vocabulary Speech Recognition}", "normalized_title": "speech commands a dataset for limited vocabulary speech recognition", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Warden, Pete}", "title": "{{Speech Commands}: A Dataset for Limited-Vocabulary Speech Recognition}", "journal": "{arXiv preprint arXiv:1804.03209}", "year": "2018"}}}
{"key": "tacotron2", "entry_type": "inproceedings", "query_title": "{Natural {TTS} Synthesis by Conditioning {WaveNet} on {Mel} Spectrogram Predictions}", "normalized_title": "natural tts synthesis by conditioning wavenet on mel spectrogram predictions", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Shen, Jonathan and Pang, Ruoming and Weiss, Ron J. and Schuster, Mike and Jaitly, Navdeep and Yang, Zongheng and Chen, Zhifeng and Zhang, Yu and Wang, Yuxuan and Skerrv-Ryan, Rj and Saurous, Rif A. and Agiomvrgiannakis, Yannis and Wu, Yonghui}", "booktitle": "icassp", "title": "{Natural {TTS} Synthesis by Conditioning {WaveNet} on {Mel} Spectrogram Predictions}", "year": "{2018}"}}}
{"key": "guided-attention", "entry_type": "inproceedings", "query_title": "{Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention}", "normalized_title": "efficiently trainable text to speech system based on deep convolutional networks with guided attention", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Tachibana, Hideyuki and Uenoyama, Katsuya and Aihara, Shunsuke}", "booktitle": "icassp", "title": "{Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention}", "year": "{2018}"}}}
{"key": "levenshtein", "entry_type": "article", "query_title": "{Binary Codes Capable of Correcting Deletions, Insertions and Reversals}", "normalized_title": "binary codes capable of correcting deletions insertions and reversals", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Levenshtein, Vladimir I}", "journal": "{Soviet Physics Doklady}", "pages": "707", "title": "{Binary Codes Capable of Correcting Deletions, Insertions and Reversals}", "volume": "10", "year": "1966"}}}
{"key": "dwer", "entry_type": "article", "query_title": "{Alternating Between Spectral and Spatial Estimation for Speech Separation and Enhancement}", "normalized_title": "alternating between spectral and spatial estimation for speech separation and enhancement", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Wang, Zhong{-}Qiu and Wisdom, Scott and Wilson, Kevin W. and Hershey, John R.}", "title": "{Alternating Between Spectral and Spatial Estimation for Speech Separation and Enhancement}", "journal": "{arXiv preprint arXiv:1911.07953}", "year": "{2019}"}}}
{"key": "abouelenin2025phi", "entry_type": "article", "query_title": "{Phi-4-mini technical report: Compact yet powerful multimodal language models via mixture-of-loras}", "normalized_title": "phi 4 mini technical report compact yet powerful multimodal language models via mixture of loras", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Phi-4-mini technical report: Compact yet powerful multimodal language models via mixture-of-loras}", "author": "{Abouelenin, Abdelrahman and Ashfaq, Atabak and Atkinson, Adam and Awadalla, Hany and Bach, Nguyen and Bao, Jianmin and Benhaim, Alon and Cai, Martin and Chaudhary, Vishrav and Chen, Congcong and others}", "journal": "{arXiv preprint arXiv:2503.01743}", "year": "{2025}"}}}
{"key": "chang2024speechprompt", "entry_type": "article", "query_title": "{Speechprompt: Prompting speech language models for speech processing tasks}", "normalized_title": "speechprompt prompting speech language models for speech processing tasks", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Speechprompt: Prompting speech language models for speech processing tasks}", "author": "{Chang, Kai-Wei and Wu, Haibin and Wang, Yu-Kai and Wu, Yuan-Kuei and Shen, Hua and Tseng, Wei-Cheng and Kang, Iu-thing and Li, Shang-Wen and Lee, Hung-yi}", "journal": "{IEEE/ACM Transactions on Audio, Speech, and Language Processing}", "year": "{2024}", "publisher": "{IEEE}"}}}
{"key": "cp-decomposition", "entry_type": "article", "query_title": "{The Expression of a Tensor or a Polyadic as a Sum of Products}", "normalized_title": "the expression of a tensor or a polyadic as a sum of products", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{The Expression of a Tensor or a Polyadic as a Sum of Products}", "author": "{Hitchcock, Frank Lauren}", "journal": "{Journal of Mathematics and Physics}", "year": "{1927}", "volume": "{6}", "pages": "{164-189}"}}}
{"key": "dubey2024icassp", "entry_type": "article", "query_title": "{{ICASSP} 2023 deep noise suppression challenge}", "normalized_title": "icassp 2023 deep noise suppression challenge", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{ICASSP} 2023 deep noise suppression challenge}", "author": "{Dubey, Harishchandra and Aazami, Ashkan and Gopal, Vishak and Naderi, Babak and Braun, Sebastian and Cutler, Ross and Ju, Alex and Zohourian, Mehdi and Tang, Min and Golestaneh, Mehrsa and others}", "journal": "{IEEE Open Journal of Signal Processing}", "year": "{2024}"}}}
{"key": "gemmeke2017audio", "entry_type": "inproceedings", "query_title": "{{Audio Set}: An ontology and human-labeled dataset for audio events}", "normalized_title": "audio set an ontology and human labeled dataset for audio events", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{Audio Set}: An ontology and human-labeled dataset for audio events}", "author": "{Gemmeke, Jort F and Ellis, Daniel PW and Freedman, Dylan and Jansen, Aren and Lawrence, Wade and Moore, R Channing and Plakal, Manoj and Ritter, Marvin}", "booktitle": "icassp", "year": "{2017}"}}}
{"key": "fonseca2021fsd50k", "entry_type": "article", "query_title": "{{FSD50K}: an open dataset of human-labeled sound events}", "normalized_title": "fsd50k an open dataset of human labeled sound events", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{FSD50K}: an open dataset of human-labeled sound events}", "author": "{Fonseca, Eduardo and Favory, Xavier and Pons, Jordi and Font, Frederic and Serra, Xavier}", "journal": "{IEEE/ACM Transactions on Audio, Speech, and Language Processing}", "volume": "{30}", "pages": "{829--852}", "year": "{2021}"}}}
{"key": "bogdanov2019mtg", "entry_type": "inproceedings", "query_title": "{The {MTG-Jamendo} dataset for automatic music tagging}", "normalized_title": "the mtg jamendo dataset for automatic music tagging", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{The {MTG-Jamendo} dataset for automatic music tagging}", "author": "{Bogdanov, Dmitry and Won, Minz and Tovstogan, Philip and Porter, Alastair and Serra, Xavier}", "year": "{2019}", "booktitle": "icml"}}}
{"key": "mysore2014can", "entry_type": "article", "query_title": "{Can we automatically transform speech recorded on common consumer devices in real-world environments into professional production quality speech?\u2014{A} dataset, insights, and challenges}", "normalized_title": "can we automatically transform speech recorded on common consumer devices in real world environments into professional production quality speech a dataset insights and challenges", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Can we automatically transform speech recorded on common consumer devices in real-world environments into professional production quality speech?\u2014{A} dataset, insights, and challenges}", "author": "{Mysore, Gautham J}", "journal": "{IEEE Signal Processing Letters}", "volume": "{22}", "number": "{8}", "pages": "{1006--1010}", "year": "{2014}", "publisher": "{IEEE}"}}}
{"key": "vctk2017", "entry_type": "misc", "query_title": "{{CSTR VCTK Corpus}: English Multi-speaker Corpus for {CSTR} Voice Cloning Toolkit (version 0.92)}", "normalized_title": "cstr vctk corpus english multi speaker corpus for cstr voice cloning toolkit version 0 92", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Yamagishi, Junichi and Veaux, Christophe and MacDonald, Kirsten}", "title": "{{CSTR VCTK Corpus}: English Multi-speaker Corpus for {CSTR} Voice Cloning Toolkit (version 0.92)}", "publisher": "{University of Edinburgh. The Centre for Speech Technology Research (CSTR)}", "year": "2019", "doi": "{10.7488/ds/2645}"}}}
{"key": "reddy2022dnsmos", "entry_type": "inproceedings", "query_title": "{{DNSMOS P.835}: A non-intrusive perceptual objective speech quality metric to evaluate noise suppressors}", "normalized_title": "dnsmos p 835 a non intrusive perceptual objective speech quality metric to evaluate noise suppressors", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{DNSMOS P.835}: A non-intrusive perceptual objective speech quality metric to evaluate noise suppressors}", "author": "{Reddy, Chandan KA and Gopal, Vishak and Cutler, Ross}", "booktitle": "icassp", "year": "{2022}"}}}
{"key": "valentinibotinhao2016voicebank", "entry_type": "inproceedings", "query_title": "{Investigating {RNN}-based speech enhancement methods for noise-robust Text-to-Speech}", "normalized_title": "investigating rnn based speech enhancement methods for noise robust text to speech", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Investigating {RNN}-based speech enhancement methods for noise-robust Text-to-Speech}", "author": "{Cassia Valentini-Botinhao and Xin Wang and Shinji Takaki and Junichi Yamagishi}", "booktitle": "{Speech Synthesis Workshop}", "year": "{2016}", "pages": "{146--152}"}}}
{"key": "cosentino2020librimix", "entry_type": "article", "query_title": "{{LibriMix}: An Open-Source Dataset for Generalizable Speech Separation}", "normalized_title": "librimix an open source dataset for generalizable speech separation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{LibriMix}: An Open-Source Dataset for Generalizable Speech Separation}", "author": "{Joris Cosentino and Manuel Pariente and Samuele Cornell and Antoine Deleforge and Emmanuel Vincent}", "journal": "{arXiv preprint arXiv:2005.11262}", "year": "{2020}"}}}
{"key": "gulati_conformer", "entry_type": "inproceedings", "query_title": "{Conformer: Convolution-augmented Transformer for Speech Recognition}", "normalized_title": "conformer convolution augmented transformer for speech recognition", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Anmol Gulati and James Qin and Chung-Cheng Chiu and Niki Parmar and Yu Zhang and Jiahui Yu and Wei Han and Shibo Wang and Zhengdong Zhang and Yonghui Wu and Ruoming Pang}", "title": "{Conformer: Convolution-augmented Transformer for Speech Recognition}", "year": "2020", "booktitle": "interspeech"}}}
{"key": "zhan2024anygpt", "entry_type": "inproceedings", "query_title": "{AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling}", "normalized_title": "anygpt unified multimodal llm with discrete sequence modeling", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling}", "author": "{Zhan, Jun and Dai, Junqi and Ye, Jiasheng and Zhou, Yunhua and Zhang, Dong and Liu, Zhigeng and Zhang, Xin and Yuan, Ruibin and Zhang, Ge and Li, Linyang and others}", "booktitle": "acl", "year": "{2024}"}}}
{"key": "xin2024bigcodec", "entry_type": "article", "query_title": "{Bigcodec: Pushing the limits of low-bitrate neural speech codec}", "normalized_title": "bigcodec pushing the limits of low bitrate neural speech codec", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Bigcodec: Pushing the limits of low-bitrate neural speech codec}", "author": "{Xin, Detai and Tan, Xu and Takamichi, Shinnosuke and Saruwatari, Hiroshi}", "journal": "{arXiv preprint arXiv:2409.05377}", "year": "{2024}"}}}
{"key": "niu2024ndvq", "entry_type": "inproceedings", "query_title": "{{NDVQ}: Robust neural audio codec with normal distribution-based vector quantization}", "normalized_title": "ndvq robust neural audio codec with normal distribution based vector quantization", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{NDVQ}: Robust neural audio codec with normal distribution-based vector quantization}", "author": "{Niu, Zhikang and Chen, Sanyuan and Zhou, Long and Ma, Ziyang and Chen, Xie and Liu, Shujie}", "booktitle": "slt", "year": "{2024}"}}}
{"key": "siuzdak2024snac", "entry_type": "article", "query_title": "{{SNAC}: Multi-scale neural audio codec}", "normalized_title": "snac multi scale neural audio codec", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{SNAC}: Multi-scale neural audio codec}", "author": "{Siuzdak, Hubert and Gr{\\\"o}tschla, Florian and Lanzend{\\\"o}rfer, Luca A},\n  journal={arXiv preprint arXiv:2410.14411},\n  year={2024}"}}}
{"key": "chiu2022bestrq", "entry_type": "inproceedings", "query_title": "{Self-supervised learning with random-projection quantizer for speech recognition}", "normalized_title": "self supervised learning with random projection quantizer for speech recognition", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Self-supervised learning with random-projection quantizer for speech recognition}", "author": "{Chiu, Chung-Cheng and Qin, James and Zhang, Yu and Yu, Jiahui and Wu, Yonghui}", "booktitle": "icml", "year": "{2022}"}}}
{"key": "zhang2023googleusm", "entry_type": "article", "query_title": "{Google {USM}: Scaling automatic speech recognition beyond 100 languages}", "normalized_title": "google usm scaling automatic speech recognition beyond 100 languages", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Google {USM}: Scaling automatic speech recognition beyond 100 languages}", "author": "{Zhang, Yu and Han, Wei and Qin, James and Wang, Yongqiang and Bapna, Ankur and Chen, Zhehuai and Chen, Nanxin and Li, Bo and Axelrod, Vera and Wang, Gary and others}", "journal": "{arXiv preprint arXiv:2303.01037}", "year": "{2023}"}}}
{"key": "langman2024spectral", "entry_type": "article", "query_title": "{Spectral codecs: Spectrogram-based audio codecs for high quality speech synthesis}", "normalized_title": "spectral codecs spectrogram based audio codecs for high quality speech synthesis", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Spectral codecs: Spectrogram-based audio codecs for high quality speech synthesis}", "author": "{Langman, Ryan and Juki{\\'c}, Ante and Dhawan, Kunal and Koluguri, Nithin Rao and Ginsburg, Boris}", "journal": "{arXiv preprint arXiv:2406.05298}", "year": "{2024}"}}}
{"key": "gu2024esc", "entry_type": "inproceedings", "query_title": "{Esc: Efficient speech coding with cross-scale residual vector quantized transformers}", "normalized_title": "esc efficient speech coding with cross scale residual vector quantized transformers", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Esc: Efficient speech coding with cross-scale residual vector quantized transformers}", "author": "{Gu, Yuzhe and Diao, Enmao}", "booktitle": "emnlp", "year": "{2024}"}}}
{"key": "tang2024singomd", "entry_type": "inproceedings", "query_title": "{Sing{OMD}: Singing Oriented Multi-resolution Discrete Representation Construction from Speech Models}", "normalized_title": "singomd singing oriented multi resolution discrete representation construction from speech models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Sing{OMD}: Singing Oriented Multi-resolution Discrete Representation Construction from Speech Models}", "author": "{Tang, Yuxun and Wu, Yuning and Shi, Jiatong and Jin, Qin}", "booktitle": "interspeech", "year": "{2024}"}}}
{"key": "shi2024mmm", "entry_type": "inproceedings", "query_title": "{{MMM}: Multi-Layer Multi-Residual Multi-Stream Discrete Speech Representation from Self-supervised Learning Model}", "normalized_title": "mmm multi layer multi residual multi stream discrete speech representation from self supervised learning model", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{MMM}: Multi-Layer Multi-Residual Multi-Stream Discrete Speech Representation from Self-supervised Learning Model}", "author": "{Shi, Jiatong and Ma, Xutai and Inaguma, Hirofumi and Sun, Anna and Watanabe, Shinji}", "booktitle": "interspeech", "year": "{2024}"}}}
{"key": "messica2024nast", "entry_type": "inproceedings", "query_title": "{Nast: Noise aware speech tokenization for speech language models}", "normalized_title": "nast noise aware speech tokenization for speech language models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Nast: Noise aware speech tokenization for speech language models}", "author": "{Messica, Shoval and Adi, Yossi}", "booktitle": "interspeech", "year": "{2024}"}}}
{"key": "chen-etal-2024-towards-robust", "entry_type": "inproceedings", "query_title": "\"Towards Robust Speech Representation Learning for Thousands of Languages\"", "normalized_title": "towards robust speech representation learning for thousands of languages", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "\"Towards Robust Speech Representation Learning for Thousands of Languages\"", "author": "\"Chen, William  and\n      Zhang, Wangyou  and\n      Peng, Yifan  and\n      Li, Xinjian  and\n      Tian, Jinchuan  and\n      Shi, Jiatong  and\n      Chang, Xuankai  and\n      Maiti, Soumi  and\n      Livescu, Karen  and\n      Watanabe, Shinji\"", "booktitle": "emnlp", "year": "\"2024\""}}}
{"key": "zhang2023speechgpt", "entry_type": "inproceedings", "query_title": "{Speechgpt: Empowering large language models with intrinsic cross-modal conversational abilities}", "normalized_title": "speechgpt empowering large language models with intrinsic cross modal conversational abilities", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Speechgpt: Empowering large language models with intrinsic cross-modal conversational abilities}", "author": "{Zhang, Dong and Li, Shimin and Zhang, Xin and Zhan, Jun and Wang, Pengyu and Zhou, Yaqian and Qiu, Xipeng}", "booktitle": "emnlp", "year": "{2023}"}}}
{"key": "valin2012definition", "entry_type": "misc", "query_title": "{RFC 6716: Definition of the Opus audio codec}", "normalized_title": "rfc 6716 definition of the opus audio codec", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{RFC 6716: Definition of the Opus audio codec}", "author": "{Valin, Jean-Marc and Vos, Koen and Terriberry, T}", "year": "{2012}", "publisher": "{RFC Editor}"}}}
{"key": "dietz2015overview", "entry_type": "inproceedings", "query_title": "{Overview of the {EVS} codec architecture}", "normalized_title": "overview of the evs codec architecture", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Overview of the {EVS} codec architecture}", "author": "{Dietz, Martin and Multrus, Markus and Eksler, Vaclav and Malenovsky, Vladimir and Norvell, Erik and Pobloth, Harald and Miao, Lei and Wang, Zhe and Laaksonen, Lasse and Vasilache, Adriana and others}", "booktitle": "icassp", "year": "{2015}"}}}
{"key": "fma_dataset", "entry_type": "inproceedings", "query_title": "{{FMA}: A Dataset for Music Analysis}", "normalized_title": "fma a dataset for music analysis", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{FMA}: A Dataset for Music Analysis}", "author": "{Defferrard, Micha\\\"el and Benzi, Kirell and Vandergheynst, Pierre and Bresson, Xavier},\n  booktitle = ismir, \n  year = {2017},"}}}
{"key": "evans2025stable", "entry_type": "inproceedings", "query_title": "{Stable audio open}", "normalized_title": "stable audio open", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Stable audio open}", "author": "{Evans, Zach and Parker, Julian D and Carr, CJ and Zukowski, Zack and Taylor, Josiah and Pons, Jordi}", "booktitle": "icassp", "year": "{2025}"}}}
{"key": "van2022comparison", "entry_type": "inproceedings", "query_title": "{A comparison of discrete and soft speech units for improved voice conversion}", "normalized_title": "a comparison of discrete and soft speech units for improved voice conversion", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{A comparison of discrete and soft speech units for improved voice conversion}", "author": "{van Niekerk, Benjamin and Carbonneau, Marc-Andr{\\'e} and Za{\\\"\\i}di, Julian and Baas, Matthew and Seut{\\'e}, Hugo and Kamper, Herman},\n  booktitle=icassp,\n  year={2022},"}}}
{"key": "guo2024socodec", "entry_type": "inproceedings", "query_title": "{SoCodec: A Semantic-Ordered Multi-Stream Speech Codec For Efficient Language Model Based Text-to-Speech Synthesis}", "normalized_title": "socodec a semantic ordered multi stream speech codec for efficient language model based text to speech synthesis", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Guo, Haohan and Xie, Fenglong and Xie, Kun and Yang, Dongchao and Guo, Dake and Wu, Xixin and Meng, Helen}", "booktitle": "slt", "title": "{SoCodec: A Semantic-Ordered Multi-Stream Speech Codec For Efficient Language Model Based Text-to-Speech Synthesis}", "year": "{2024}"}}}
{"key": "casanova2024lfsc", "entry_type": "inproceedings", "query_title": "{Low frame-rate speech codec: a codec designed for fast high-quality speech {LLM} training and inference}", "normalized_title": "low frame rate speech codec a codec designed for fast high quality speech llm training and inference", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Low frame-rate speech codec: a codec designed for fast high-quality speech {LLM} training and inference}", "author": "{Casanova, Edresson and Langman, Ryan and Neekhara, Paarth and Hussain, Shehzeen and Li, Jason and Ghosh, Subhankar and Juki{\\'c}, Ante and Lee, Sang-gil}", "booktitle": "icassp", "year": "{2025}"}}}
{"key": "ren2024ticodec", "entry_type": "inproceedings", "query_title": "{Fewer-token neural speech codec with time-invariant codes}", "normalized_title": "fewer token neural speech codec with time invariant codes", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Fewer-token neural speech codec with time-invariant codes}", "author": "{Ren, Yong and Wang, Tao and Yi, Jiangyan and Xu, Le and Tao, Jianhua and Zhang, Chu Yuan and Zhou, Junzuo}", "booktitle": "icassp", "year": "{2024}"}}}
{"key": "parker2024scaling", "entry_type": "inproceedings", "query_title": "{Scaling Transformers for Low-Bitrate High-Quality Speech Coding}", "normalized_title": "scaling transformers for low bitrate high quality speech coding", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Scaling Transformers for Low-Bitrate High-Quality Speech Coding}", "author": "{Julian D Parker and Anton Smirnov and Jordi Pons and CJ Carr and Zack Zukowski and Zach Evans and Xubo Liu}", "booktitle": "icml", "year": "{2025}"}}}
{"key": "bai2024dmel", "entry_type": "article", "query_title": "{{D}mel: Speech tokenization made simple}", "normalized_title": "dmel speech tokenization made simple", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{D}mel: Speech tokenization made simple}", "author": "{Bai, He and Likhomanenko, Tatiana and Zhang, Ruixiang and Gu, Zijin and Aldeneh, Zakaria and Jaitly, Navdeep}", "journal": "{arXiv preprint arXiv:2407.15835}", "year": "{2024}"}}}
{"key": "ai2024apcodec", "entry_type": "article", "query_title": "{APCodec: A neural audio codec with parallel amplitude and phase spectrum encoding and decoding}", "normalized_title": "apcodec a neural audio codec with parallel amplitude and phase spectrum encoding and decoding", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{APCodec: A neural audio codec with parallel amplitude and phase spectrum encoding and decoding}", "author": "{Ai, Yang and Jiang, Xiao-Hang and Lu, Ye-Xin and Du, Hui-Peng and Ling, Zhen-Hua}", "journal": "{IEEE/ACM Transactions on Audio, Speech, and Language Processing}", "year": "{2024}", "publisher": "{IEEE}"}}}
{"key": "kolbaek2017multitalker", "entry_type": "article", "query_title": "{{M}ultitalker speech separation with utterance-level permutation invariant training of deep recurrent neural networks}", "normalized_title": "multitalker speech separation with utterance level permutation invariant training of deep recurrent neural networks", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{M}ultitalker speech separation with utterance-level permutation invariant training of deep recurrent neural networks}", "author": "{Kolb{\\ae}k, M. and Yu, D. and Tan, Z.-H. and Jensen, J.}", "journal": "{IEEE/ACM Transactions on Audio, Speech, and Language Processing}", "volume": "{25}", "pages": "{1901--1913}", "year": "{2017}"}}}
{"key": "piczak2015esc", "entry_type": "inproceedings", "query_title": "{ESC: Dataset for environmental sound classification}", "normalized_title": "esc dataset for environmental sound classification", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{ESC: Dataset for environmental sound classification}", "author": "{Piczak, Karol J}", "booktitle": "{Proc. ACM}", "year": "{2015}"}}}
{"key": "tzanetakis2002musical", "entry_type": "article", "query_title": "{Musical genre classification of audio signals}", "normalized_title": "musical genre classification of audio signals", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Musical genre classification of audio signals}", "author": "{Tzanetakis, George and Cook, Perry}", "journal": "{IEEE Transactions on speech and audio processing}", "volume": "{10}", "number": "{5}", "pages": "{293--302}", "year": "{2002}", "publisher": "{IEEE}"}}}
{"key": "li2023mert", "entry_type": "inproceedings", "query_title": "{{MERT}: Acoustic Music Understanding Model with Large-Scale Self-supervised Training}", "normalized_title": "mert acoustic music understanding model with large scale self supervised training", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{MERT}: Acoustic Music Understanding Model with Large-Scale Self-supervised Training}", "author": "{Yizhi LI and Ruibin Yuan and Ge Zhang and Yinghao Ma and Xingran Chen and Hanzhi Yin and Chenghao Xiao and Chenghua Lin and Anton Ragni and Emmanouil Benetos and Norbert Gyenge and Roger Dannenberg and Ruibo Liu and Wenhu Chen and Gus Xia and Yemin Shi and Wenhao Huang and Zili Wang and Yike Guo and Jie Fu}", "booktitle": "iclr", "year": "{2024}"}}}
{"key": "kong2020panns", "entry_type": "article", "query_title": "{Panns: Large-scale pretrained audio neural networks for audio pattern recognition}", "normalized_title": "panns large scale pretrained audio neural networks for audio pattern recognition", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Panns: Large-scale pretrained audio neural networks for audio pattern recognition}", "author": "{Kong, Qiuqiang and Cao, Yin and Iqbal, Turab and Wang, Yuxuan and Wang, Wenwu and Plumbley, Mark D}", "journal": "{IEEE/ACM Transactions on Audio, Speech, and Language Processing}", "volume": "{28}", "pages": "{2880--2894}", "year": "{2020}", "publisher": "{IEEE}"}}}
{"key": "wang2022usb", "entry_type": "article", "query_title": "{Usb: A unified semi-supervised learning benchmark for classification}", "normalized_title": "usb a unified semi supervised learning benchmark for classification", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Usb: A unified semi-supervised learning benchmark for classification}", "author": "{Wang, Yidong and Chen, Hao and Fan, Yue and Sun, Wang and Tao, Ran and Hou, Wenxin and Wang, Renjie and Yang, Linyi and Zhou, Zhi and Guo, Lan-Zhe and others}", "journal": "{neurips}", "year": "{2022}"}}}
{"key": "mousavi2024dasb", "entry_type": "article", "query_title": "{DASB--Discrete Audio and Speech Benchmark}", "normalized_title": "dasb discrete audio and speech benchmark", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{DASB--Discrete Audio and Speech Benchmark}", "author": "{Mousavi, Pooneh and Della Libera, Luca and Duret, Jarod and Ploujnikov, Artem and Subakan, Cem and Ravanelli, Mirco}", "journal": "{arXiv preprint arXiv:2406.14294}", "year": "{2024}"}}}
{"key": "wang2023lmvc", "entry_type": "article", "query_title": "{Lm-vc: Zero-shot voice conversion via speech generation based on language models}", "normalized_title": "lm vc zero shot voice conversion via speech generation based on language models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Lm-vc: Zero-shot voice conversion via speech generation based on language models}", "author": "{Wang, Zhichao and Chen, Yuanzhe and Xie, Lei and Tian, Qiao and Wang, Yuping}", "journal": "{IEEE Signal Processing Letters}", "volume": "{30}", "pages": "{1157--1161}", "year": "{2023}", "publisher": "{IEEE}"}}}
{"key": "maimon2023speaking", "entry_type": "inproceedings", "query_title": "{Speaking Style Conversion in the Waveform Domain Using Discrete Self-Supervised Units}", "normalized_title": "speaking style conversion in the waveform domain using discrete self supervised units", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Speaking Style Conversion in the Waveform Domain Using Discrete Self-Supervised Units}", "author": "{Maimon, Gallil and Adi, Yossi}", "booktitle": "emnlp", "year": "{2023}"}}}
{"key": "wang2024streamvoice", "entry_type": "inproceedings", "query_title": "{StreamVoice: Streamable Context-Aware Language Modeling for Real-time Zero-Shot Voice Conversion}", "normalized_title": "streamvoice streamable context aware language modeling for real time zero shot voice conversion", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{StreamVoice: Streamable Context-Aware Language Modeling for Real-time Zero-Shot Voice Conversion}", "author": "{Wang, Zhichao and Chen, Yuanzhe and Wang, Xinsheng and Xie, Lei and Wang, Yuping}", "booktitle": "acl", "year": "{2024}"}}}
{"key": "shi2024espnet", "entry_type": "inproceedings", "query_title": "{{ESPnet-Codec}: Comprehensive training and evaluation of neural codecs for audio, music, and speech}", "normalized_title": "espnet codec comprehensive training and evaluation of neural codecs for audio music and speech", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{ESPnet-Codec}: Comprehensive training and evaluation of neural codecs for audio, music, and speech}", "author": "{Shi, Jiatong and Tian, Jinchuan and Wu, Yihan and Jung, Jee-weon and Yip, Jia Qi and Masuyama, Yoshiki and Chen, William and Wu, Yuning and Tang, Yuxun and Baali, Massa and others}", "booktitle": "slt", "year": "{2024}"}}}
{"key": "vashishth2024stab", "entry_type": "article", "query_title": "{{STAB}: Speech Tokenizer Assessment Benchmark}", "normalized_title": "stab speech tokenizer assessment benchmark", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{STAB}: Speech Tokenizer Assessment Benchmark}", "author": "{Vashishth, Shikhar and Singh, Harman and Bharadwaj, Shikhar and Ganapathy, Sriram and Asawaroengchai, Chulayuth and Audhkhasi, Kartik and Rosenberg, Andrew and Bapna, Ankur and Ramabhadran, Bhuvana}", "journal": "{arXiv preprint arXiv:2409.02384}", "year": "{2024}"}}}
{"key": "zen2019libritts", "entry_type": "inproceedings", "query_title": "{Libri{TTS}: A Corpus Derived from LibriSpeech for Text-to-Speech}", "normalized_title": "libritts a corpus derived from librispeech for text to speech", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Libri{TTS}: A Corpus Derived from LibriSpeech for Text-to-Speech}", "author": "{Zen, Heiga and Dang, Viet and Clark, Rob and Zhang, Yu and Weiss, Ron J and Jia, Ye and Chen, Zhifeng and Wu, Yonghui}", "booktitle": "interspeech", "year": "{2019}"}}}
{"key": "7178964", "entry_type": "inproceedings", "query_title": "{Librispeech: An ASR corpus based on public domain audio books}", "normalized_title": "librispeech an asr corpus based on public domain audio books", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev}", "booktitle": "icassp", "title": "{Librispeech: An ASR corpus based on public domain audio books}", "year": "{2015}"}}}
{"key": "lam2023efficient", "entry_type": "inproceedings", "query_title": "{Efficient neural music generation}", "normalized_title": "efficient neural music generation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Efficient neural music generation}", "author": "{Lam, Max WY and Tian, Qiao and Li, Tang and Yin, Zongyu and Feng, Siyuan and Tu, Ming and Ji, Yuliang and Xia, Rui and Ma, Mingbo and Song, Xuchen and others}", "booktitle": "neurips", "year": "{2023}"}}}
{"key": "rouard2024audio", "entry_type": "inproceedings", "query_title": "{Audio conditioning for music generation via discrete bottleneck features}", "normalized_title": "audio conditioning for music generation via discrete bottleneck features", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Audio conditioning for music generation via discrete bottleneck features}", "author": "{Rouard, Simon and Adi, Yossi and Copet, Jade and Roebel, Axel and D{\\'e}fossez, Alexandre}", "booktitle": "ismir", "year": "{2024}"}}}
{"key": "chen2024musicldm", "entry_type": "inproceedings", "query_title": "{Musicldm: Enhancing novelty in text-to-music generation using beat-synchronous mixup strategies}", "normalized_title": "musicldm enhancing novelty in text to music generation using beat synchronous mixup strategies", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Musicldm: Enhancing novelty in text-to-music generation using beat-synchronous mixup strategies}", "author": "{Chen, Ke and Wu, Yusong and Liu, Haohe and Nezhurina, Marianna and Berg-Kirkpatrick, Taylor and Dubnov, Shlomo}", "booktitle": "icassp", "year": "{2024}"}}}
{"key": "yang2024generative", "entry_type": "inproceedings", "query_title": "{Generative de-quantization for neural speech codec via latent diffusion}", "normalized_title": "generative de quantization for neural speech codec via latent diffusion", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Generative de-quantization for neural speech codec via latent diffusion}", "author": "{Yang, Haici and Jang, Inseon and Kim, Minje}", "booktitle": "icassp", "year": "{2024}"}}}
{"key": "li2024single", "entry_type": "inproceedings", "query_title": "{Single-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation}", "normalized_title": "single codec single codebook speech codec towards high performance speech generation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Single-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation}", "author": "{Li, Hanzhao and Xue, Liumeng and Guo, Haohan and Zhu, Xinfa and Lv, Yuanjun and Xie, Lei and Chen, Yunlin and Yin, Hao and Li, Zhifei}", "booktitle": "interspeech", "year": "{2024}"}}}
{"key": "huang2023repcodec", "entry_type": "inproceedings", "query_title": "\"{R}ep{C}odec: A Speech Representation Codec for Speech Tokenization\"", "normalized_title": "repcodec a speech representation codec for speech tokenization", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "\"{R}ep{C}odec: A Speech Representation Codec for Speech Tokenization\"", "author": "\"Huang, Zhichao  and\n      Meng, Chutong  and\n      Ko, Tom\"", "booktitle": "acl", "year": "\"2024\""}}}
{"key": "siuzdak2023vocos", "entry_type": "inproceedings", "query_title": "{Vocos: Closing the gap between time-domain and Fourier-based neural vocoders for high-quality audio synthesis}", "normalized_title": "vocos closing the gap between time domain and fourier based neural vocoders for high quality audio synthesis", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Vocos: Closing the gap between time-domain and Fourier-based neural vocoders for high-quality audio synthesis}", "author": "{Hubert Siuzdak}", "booktitle": "iclr", "year": "{2024}"}}}
{"key": "kang2024libriheavy", "entry_type": "inproceedings", "query_title": "{Libriheavy: A 50,000 hours ASR corpus with punctuation casing and context}", "normalized_title": "libriheavy a 50 000 hours asr corpus with punctuation casing and context", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Libriheavy: A 50,000 hours ASR corpus with punctuation casing and context}", "author": "{Kang, Wei and Yang, Xiaoyu and Yao, Zengwei and Kuang, Fangjun and Yang, Yifan and Guo, Liyong and Lin, Long and Povey, Daniel}", "booktitle": "icassp", "year": "{2024}"}}}
{"key": "maimon2024suite", "entry_type": "inproceedings", "query_title": "{Salmon: A Suite for Acoustic Language Model Evaluation}", "normalized_title": "salmon a suite for acoustic language model evaluation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Maimon, Gallil and Roth, Amit and Adi, Yossi}", "booktitle": "icassp", "title": "{Salmon: A Suite for Acoustic Language Model Evaluation}", "year": "{2025}"}}}
{"key": "LMCodec", "entry_type": "inproceedings", "query_title": "\"Towards Codec-{LM} Co-design for Neural Codec Language Models\"", "normalized_title": "towards codec lm co design for neural codec language models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "\"Towards Codec-{LM} Co-design for Neural Codec Language Models\"", "author": "\"Wu, Shih-Lun  and\n      Lahoti, Aakash  and\n      Desai, Arjun D  and\n      Goel, Karan  and\n      Donahue, Chris  and\n      Gu, Albert\"", "booktitle": "naacl", "year": "\"2025\""}}}
{"key": "bie2024learning", "entry_type": "inproceedings", "query_title": "{Learning source disentanglement in neural audio codec}", "normalized_title": "learning source disentanglement in neural audio codec", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Learning source disentanglement in neural audio codec}", "author": "{Bie, Xiaoyu and Liu, Xubo and Richard, Ga{\\\"e}l},\n  booktitle=icassp,\n  year={2025}"}}}
{"key": "liu2024semanticodec", "entry_type": "article", "query_title": "{Semanticodec: An ultra low bitrate semantic audio codec for general sound}", "normalized_title": "semanticodec an ultra low bitrate semantic audio codec for general sound", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Semanticodec: An ultra low bitrate semantic audio codec for general sound}", "author": "{Liu, Haohe and Xu, Xuenan and Yuan, Yi and Wu, Mengyue and Wang, Wenwu and Plumbley, Mark D}", "journal": "{IEEE Journal of Selected Topics in Signal Processing}", "year": "{2024}", "publisher": "{IEEE}"}}}
{"key": "jiang22_interspeech", "entry_type": "inproceedings", "query_title": "{Cross-Scale Vector Quantization for Scalable Neural Speech Coding}", "normalized_title": "cross scale vector quantization for scalable neural speech coding", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Cross-Scale Vector Quantization for Scalable Neural Speech Coding}", "author": "{Xue Jiang and Xiulian Peng and Huaying Xue and Yuan Zhang and Yan Lu}", "year": "{2022}", "booktitle": "interspeech"}}}
{"key": "yang2024qwen2", "entry_type": "article", "query_title": "{Qwen2 technical report}", "normalized_title": "qwen2 technical report", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Qwen2 technical report}", "author": "{Yang, An and Yang, Baosong and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Zhou, Chang and Li, Chengpeng and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and others}", "journal": "{arXiv preprint arXiv:2407.10671}", "year": "{2024}"}}}
{"key": "huang2022mulan", "entry_type": "inproceedings", "query_title": "{MuLan: A Joint Embedding of Music Audio and Natural Language}", "normalized_title": "mulan a joint embedding of music audio and natural language", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{MuLan: A Joint Embedding of Music Audio and Natural Language}", "author": "{Huang, Qingqing and Jansen, Aren and Lee, Joonseok and Ganti, Ravi and Li, Judith Yue and Ellis, Daniel PW}", "booktitle": "ismir", "year": "{2022}"}}}
{"key": "turetzky_last_2024", "entry_type": "article", "query_title": "{{LAST}: {Language} {Model} {Aware} {Speech} {Tokenization}}", "normalized_title": "last language model aware speech tokenization", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{LAST}: {Language} {Model} {Aware} {Speech} {Tokenization}}", "author": "{Arnon Turetzky and Yossi Adi}", "journal": "{arXiv preprint arXiv:arXiv:2409.03701}", "year": "{2024}"}}}
{"key": "nguyen2024spiritlminterleavedspokenwritten", "entry_type": "article", "query_title": "\"{S}pi{R}it-{LM}: Interleaved Spoken and Written Language Model\"", "normalized_title": "spirit lm interleaved spoken and written language model", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "\"{S}pi{R}it-{LM}: Interleaved Spoken and Written Language Model\"", "author": "\"Nguyen, Tu Anh  and\n      Muller, Benjamin  and\n      Yu, Bokai  and\n      Costa-jussa, Marta R.  and\n      Elbayad, Maha  and\n      Popuri, Sravya  and\n      Ropers, Christophe  and\n      Duquenne, Paul-Ambroise  and\n      Algayres, Robin  and\n      Mavlyutov, Ruslan  and\n      Gat, Itai  and\n      Williamson, Mary  and\n      Synnaeve, Gabriel  and\n      Pino, Juan  and\n      Sagot, Beno{\\^i}t  and\n      Dupoux, Emmanuel\"", "journal": "\"Transactions of the Association for Computational Linguistics\"", "volume": "\"13\"", "year": "\"2025\"", "pages": "\"30--52\""}}}
{"key": "nguyen2020zeroresourcespeechbenchmark", "entry_type": "inproceedings", "query_title": "{The Zero Resource Speech Benchmark 2021: Metrics and baselines for unsupervised spoken language modeling}", "normalized_title": "the zero resource speech benchmark 2021 metrics and baselines for unsupervised spoken language modeling", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{The Zero Resource Speech Benchmark 2021: Metrics and baselines for unsupervised spoken language modeling}", "author": "{Nguyen, Tu Anh and de Seyssel, Maureen and Roz{\\'e}, Patricia and Rivi{\\`e}re, Morgane and Kharitonov, Evgeny and Baevski, Alexei and Dunbar, Ewan and Dupoux, Emmanuel}", "booktitle": "neurips", "year": "{2020}"}}}
{"key": "manilow2019cutting", "entry_type": "inproceedings", "query_title": "{Cutting music source separation some Slakh: A dataset to study the impact of training data quality and quantity}", "normalized_title": "cutting music source separation some slakh a dataset to study the impact of training data quality and quantity", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Cutting music source separation some Slakh: A dataset to study the impact of training data quality and quantity}", "author": "{Manilow, Ethan and Wichern, Gordon and Seetharaman, Prem and Le Roux, Jonathan}", "booktitle": "waspaa", "year": "{2019}", "organization": "{IEEE}"}}}
{"key": "arnault2020urban", "entry_type": "article", "query_title": "{Urban Sound Classification: striving towards a fair comparison}", "normalized_title": "urban sound classification striving towards a fair comparison", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Urban Sound Classification: striving towards a fair comparison}", "author": "{Arnault, Augustin and Hanssens, Baptiste and Riche, Nicolas}", "journal": "{arXiv preprint arXiv:2010.11805}", "year": "{2020}"}}}
{"key": "wisdom2021s", "entry_type": "inproceedings", "query_title": "{What\u2019s all the fuss about free universal sound separation data?}", "normalized_title": "whats all the fuss about free universal sound separation data", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{What\u2019s all the fuss about free universal sound separation data?}", "author": "{Wisdom, Scott and Erdogan, Hakan and Ellis, Daniel PW and Serizel, Romain and Turpault, Nicolas and Fonseca, Eduardo and Salamon, Justin and Seetharaman, Prem and Hershey, John R}", "booktitle": "icassp", "year": "{2021}"}}}
{"key": "hershey2016deep", "entry_type": "inproceedings", "query_title": "{Deep clustering: Discriminative embeddings for segmentation and separation}", "normalized_title": "deep clustering discriminative embeddings for segmentation and separation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Deep clustering: Discriminative embeddings for segmentation and separation}", "author": "{Hershey, John R and Chen, Zhuo and Le Roux, Jonathan and Watanabe, Shinji}", "booktitle": "icassp", "year": "{2016}"}}}
{"key": "liu2024revisiting", "entry_type": "inproceedings", "query_title": "{Revisiting Self-supervised Learning of Speech Representation from a Mutual Information Perspective}", "normalized_title": "revisiting self supervised learning of speech representation from a mutual information perspective", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Revisiting Self-supervised Learning of Speech Representation from a Mutual Information Perspective}", "author": "{Liu, Alexander H and Yeh, Sung-Lin and Glass, James R}", "booktitle": "icassp", "year": "{2024}"}}}
{"key": "chung2025kad", "entry_type": "article", "query_title": "{KAD: No More FAD! An Effective and Efficient Evaluation Metric for Audio Generation}", "normalized_title": "kad no more fad an effective and efficient evaluation metric for audio generation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{KAD: No More FAD! An Effective and Efficient Evaluation Metric for Audio Generation}", "author": "{Chung, Yoonjin and Eu, Pilsun and Lee, Junwon and Choi, Keunwoo and Nam, Juhan and Chon, Ben Sangbae}", "journal": "{arXiv preprint arXiv:2502.15602}", "year": "{2025}"}}}
{"key": "fadtk", "entry_type": "inproceedings", "query_title": "{Adapting frechet audio distance for generative music evaluation}", "normalized_title": "adapting frechet audio distance for generative music evaluation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Adapting frechet audio distance for generative music evaluation}", "author": "{Gui, Azalea and Gamper, Hannes and Braun, Sebastian and Emmanouilidou, Dimitra}", "booktitle": "icassp", "year": "{2024}"}}}
{"key": "koutini2021passt", "entry_type": "inproceedings", "query_title": "{Efficient Training of Audio Transformers with Patchout}", "normalized_title": "efficient training of audio transformers with patchout", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Efficient Training of Audio Transformers with Patchout}", "author": "{Khaled Koutini and Jan Schl\u00fcter and Hamid Eghbal-zadeh and Gerhard Widmer}", "year": "{2022}", "booktitle": "interspeech"}}}
{"key": "san2023discrete", "entry_type": "inproceedings", "query_title": "{From discrete tokens to high-fidelity audio using multi-band diffusion}", "normalized_title": "from discrete tokens to high fidelity audio using multi band diffusion", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{From discrete tokens to high-fidelity audio using multi-band diffusion}", "author": "{San Roman, Robin and Adi, Yossi and Deleforge, Antoine and Serizel, Romain and Synnaeve, Gabriel and D{\\'e}fossez, Alexandre}", "booktitle": "neurips", "year": "{2023}"}}}
{"key": "yang2023diffsound", "entry_type": "article", "query_title": "{Diffsound: Discrete diffusion model for text-to-sound generation}", "normalized_title": "diffsound discrete diffusion model for text to sound generation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Diffsound: Discrete diffusion model for text-to-sound generation}", "author": "{Yang, Dongchao and Yu, Jianwei and Wang, Helin and Wang, Wen and Weng, Chao and Zou, Yuexian and Yu, Dong}", "journal": "{IEEE/ACM Transactions on Audio, Speech, and Language Processing}", "volume": "{31}", "pages": "{1720--1733}", "year": "{2023}", "publisher": "{IEEE}"}}}
{"key": "wu2023large", "entry_type": "inproceedings", "query_title": "{Large-scale contrastive language-audio pretraining with feature fusion and keyword-to-caption augmentation}", "normalized_title": "large scale contrastive language audio pretraining with feature fusion and keyword to caption augmentation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Large-scale contrastive language-audio pretraining with feature fusion and keyword-to-caption augmentation}", "author": "{Wu, Yusong and Chen, Ke and Zhang, Tianyu and Hui, Yuchen and Berg-Kirkpatrick, Taylor and Dubnov, Shlomo}", "booktitle": "icassp", "year": "{2023}"}}}
{"key": "huang2023make", "entry_type": "inproceedings", "query_title": "{Make-an-audio: Text-to-audio generation with prompt-enhanced diffusion models}", "normalized_title": "make an audio text to audio generation with prompt enhanced diffusion models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Make-an-audio: Text-to-audio generation with prompt-enhanced diffusion models}", "author": "{Huang, Rongjie and Huang, Jiawei and Yang, Dongchao and Ren, Yi and Liu, Luping and Li, Mingze and Ye, Zhenhui and Liu, Jinglin and Yin, Xiang and Zhao, Zhou}", "booktitle": "icml", "year": "{2023}"}}}
{"key": "audiocaps", "entry_type": "inproceedings", "query_title": "{AudioCaps: Generating Captions for Audios in The Wild}", "normalized_title": "audiocaps generating captions for audios in the wild", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{AudioCaps: Generating Captions for Audios in The Wild}", "author": "{Kim, Chris Dongjoo and Kim, Byeongchang and Lee, Hyunmin and Kim, Gunhee}", "booktitle": "naacl", "year": "{2019}"}}}
{"key": "macs", "entry_type": "inproceedings", "query_title": "{Diversity and bias in audio captioning datasets}", "normalized_title": "diversity and bias in audio captioning datasets", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Diversity and bias in audio captioning datasets}", "author": "{Morato, Irene Martin and Mesaros, Annamaria}", "booktitle": "{Proc. DCASE}", "year": "{2021}"}}}
{"key": "liu2023audioldm", "entry_type": "inproceedings", "query_title": "{{A}udio{LDM}: Text-to-Audio Generation with Latent Diffusion Models}", "normalized_title": "audioldm text to audio generation with latent diffusion models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{A}udio{LDM}: Text-to-Audio Generation with Latent Diffusion Models}", "author": "{Liu, Haohe and Chen, Zehua and Yuan, Yi and Mei, Xinhao and Liu, Xubo and Mandic, Danilo and Wang, Wenwu and Plumbley, Mark D}", "booktitle": "icml", "year": "{2023}"}}}
{"key": "liu2024audioldm2", "entry_type": "article", "query_title": "{Audio{LDM} 2: Learning holistic audio generation with self-supervised pretraining}", "normalized_title": "audioldm 2 learning holistic audio generation with self supervised pretraining", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Audio{LDM} 2: Learning holistic audio generation with self-supervised pretraining}", "author": "{Liu, Haohe and Yuan, Yi and Liu, Xubo and Mei, Xinhao and Kong, Qiuqiang and Tian, Qiao and Wang, Yuping and Wang, Wenwu and Wang, Yuxuan and Plumbley, Mark D}", "journal": "{IEEE/ACM Transactions on Audio, Speech, and Language Processing}", "year": "{2024}", "publisher": "{IEEE}"}}}
{"key": "wang2024v2a", "entry_type": "inproceedings", "query_title": "{V2a-mapper: A lightweight solution for vision-to-audio generation by connecting foundation models}", "normalized_title": "v2a mapper a lightweight solution for vision to audio generation by connecting foundation models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{V2a-mapper: A lightweight solution for vision-to-audio generation by connecting foundation models}", "author": "{Wang, Heng and Ma, Jianbo and Pascual, Santiago and Cartwright, Richard and Cai, Weidong}", "booktitle": "aaai", "year": "{2024}"}}}
{"key": "pascual2024masked", "entry_type": "inproceedings", "query_title": "{Masked generative video-to-audio transformers with enhanced synchronicity}", "normalized_title": "masked generative video to audio transformers with enhanced synchronicity", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Masked generative video-to-audio transformers with enhanced synchronicity}", "author": "{Pascual, Santiago and Yeh, Chunghsin and Tsiamas, Ioannis and Serr{\\`a}, Joan}", "booktitle": "eccv", "year": "{2024}"}}}
{"key": "zhang2024foleycrafter", "entry_type": "article", "query_title": "{Foleycrafter: Bring silent videos to life with lifelike and synchronized sounds}", "normalized_title": "foleycrafter bring silent videos to life with lifelike and synchronized sounds", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Foleycrafter: Bring silent videos to life with lifelike and synchronized sounds}", "author": "{Zhang, Yiming and Gu, Yicheng and Zeng, Yanhong and Xing, Zhening and Wang, Yuancheng and Wu, Zhizheng and Chen, Kai}", "journal": "{arXiv preprint arXiv:2407.01494}", "year": "{2024}"}}}
{"key": "dong2023clipsonic", "entry_type": "inproceedings", "query_title": "{Clipsonic: Text-to-audio synthesis with unlabeled videos and pretrained language-vision models}", "normalized_title": "clipsonic text to audio synthesis with unlabeled videos and pretrained language vision models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Clipsonic: Text-to-audio synthesis with unlabeled videos and pretrained language-vision models}", "author": "{Dong, Hao-Wen and Liu, Xiaoyu and Pons, Jordi and Bhattacharya, Gautam and Pascual, Santiago and Serr{\\`a}, Joan and Berg-Kirkpatrick, Taylor and McAuley, Julian}", "booktitle": "waspaa", "year": "{2023}"}}}
{"key": "jeong2024read", "entry_type": "inproceedings", "query_title": "{Read, watch and scream! sound generation from text and video}", "normalized_title": "read watch and scream sound generation from text and video", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Read, watch and scream! sound generation from text and video}", "author": "{Jeong, Yujin and Kim, Yunji and Chun, Sanghyuk and Lee, Jiyoung}", "booktitle": "aaai", "year": "{2025}"}}}
{"key": "chen2024video", "entry_type": "article", "query_title": "{Video-guided foley sound generation with multimodal controls}", "normalized_title": "video guided foley sound generation with multimodal controls", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Video-guided foley sound generation with multimodal controls}", "author": "{Chen, Ziyang and Seetharaman, Prem and Russell, Bryan and Nieto, Oriol and Bourgin, David and Owens, Andrew and Salamon, Justin}", "journal": "{arXiv preprint arXiv:2411.17698}", "year": "{2024}"}}}
{"key": "saito2024soundctm", "entry_type": "inproceedings", "query_title": "{Sound{CTM}: Uniting Score-based and Consistency Models for Text-to-Sound Generation}", "normalized_title": "soundctm uniting score based and consistency models for text to sound generation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Sound{CTM}: Uniting Score-based and Consistency Models for Text-to-Sound Generation}", "author": "{Koichi Saito and Dongjun Kim and Takashi Shibuya and Chieh-Hsin Lai and Zhi Zhong and Yuhta Takida and Yuki Mitsufuji}", "booktitle": "{Proc. NeurIPS Workshops}", "year": "{2024}"}}}
{"key": "wang2025frieren", "entry_type": "inproceedings", "query_title": "{Frieren: Efficient Video-to-Audio Generation Network with Rectified Flow Matching}", "normalized_title": "frieren efficient video to audio generation network with rectified flow matching", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Frieren: Efficient Video-to-Audio Generation Network with Rectified Flow Matching}", "author": "{Wang, Yongqi and Guo, Wenxiang and Huang, Rongjie and Huang, Jiawei and Wang, Zehan and You, Fuming and Li, Ruiqi and Zhao, Zhou}", "booktitle": "neurips", "year": "{2025}"}}}
{"key": "luo2023diff", "entry_type": "inproceedings", "query_title": "{Diff-foley: Synchronized video-to-audio synthesis with latent diffusion models}", "normalized_title": "diff foley synchronized video to audio synthesis with latent diffusion models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Diff-foley: Synchronized video-to-audio synthesis with latent diffusion models}", "author": "{Luo, Simian and Yan, Chuanhao and Hu, Chenxu and Zhao, Hang}", "booktitle": "neurips", "year": "{2023}"}}}
{"key": "sheffer2023hear", "entry_type": "inproceedings", "query_title": "{I hear your true colors: Image guided audio generation}", "normalized_title": "i hear your true colors image guided audio generation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{I hear your true colors: Image guided audio generation}", "author": "{Sheffer, Roy and Adi, Yossi}", "booktitle": "icassp", "year": "{2023}"}}}
{"key": "raffel2020exploring", "entry_type": "article", "query_title": "{Exploring the limits of transfer learning with a unified text-to-text transformer}", "normalized_title": "exploring the limits of transfer learning with a unified text to text transformer", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Exploring the limits of transfer learning with a unified text-to-text transformer}", "author": "{Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J}", "journal": "{Journal of machine learning research}", "volume": "{21}", "number": "{140}", "pages": "{1--67}", "year": "{2020}"}}}
{"key": "peng2024survey", "entry_type": "article", "query_title": "{A survey on speech large language models}", "normalized_title": "a survey on speech large language models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{A survey on speech large language models}", "author": "{Peng, Jing and Wang, Yucheng and Xi, Yu and Li, Xu and Zhang, Xizhuo and Yu, Kai}", "journal": "{arXiv preprint arXiv:2410.18908}", "year": "{2024}"}}}
{"key": "cui2024recent", "entry_type": "article", "query_title": "{Recent advances in speech language models: A survey}", "normalized_title": "recent advances in speech language models a survey", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Recent advances in speech language models: A survey}", "author": "{Cui, Wenqian and Yu, Dianzhi and Jiao, Xiaoqi and Meng, Ziqiao and Zhang, Guangyan and Wang, Qichao and Guo, Yiwen and King, Irwin}", "journal": "{arXiv preprint arXiv:2410.03751}", "year": "{2024}"}}}
{"key": "ji2024wavchat", "entry_type": "article", "query_title": "{Wavchat: A survey of spoken dialogue models}", "normalized_title": "wavchat a survey of spoken dialogue models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Wavchat: A survey of spoken dialogue models}", "author": "{Ji, Shengpeng and Chen, Yifu and Fang, Minghui and Zuo, Jialong and Lu, Jingyu and Wang, Hanting and Jiang, Ziyue and Zhou, Long and Liu, Shujie and Cheng, Xize and others}", "journal": "{arXiv preprint arXiv:2411.13577}", "year": "{2024}"}}}
{"key": "latif2023sparks", "entry_type": "article", "query_title": "{Sparks of large audio models: A survey and outlook}", "normalized_title": "sparks of large audio models a survey and outlook", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Sparks of large audio models: A survey and outlook}", "author": "{Latif, Siddique and Shoukat, Moazzam and Shamshad, Fahad and Usama, Muhammad and Ren, Yi and Cuay{\\'a}huitl, Heriberto and Wang, Wenwu and Zhang, Xulong and Togneri, Roberto and Cambria, Erik and others}", "journal": "{arXiv preprint arXiv:2308.12792}", "year": "{2023}"}}}
{"key": "dunbar2021zero", "entry_type": "inproceedings", "query_title": "{The Zero Resource Speech Challenge 2021: Spoken Language Modelling}", "normalized_title": "the zero resource speech challenge 2021 spoken language modelling", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{The Zero Resource Speech Challenge 2021: Spoken Language Modelling}", "author": "{Ewan Dunbar and Mathieu Bernard and Nicolas Hamilakis and Tu Anh Nguyen and Maureen de Seyssel and Patricia Roz\u00e9 and Morgane Rivi\u00e8re and Eugene Kharitonov and Emmanuel Dupoux}", "year": "{2021}", "booktitle": "interspeech"}}}
{"key": "lin2024alignslm", "entry_type": "article", "query_title": "{Align-SLM: Textless Spoken Language Models with Reinforcement Learning from AI Feedback}", "normalized_title": "align slm textless spoken language models with reinforcement learning from ai feedback", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Align-SLM: Textless Spoken Language Models with Reinforcement Learning from AI Feedback}", "author": "{Lin, Guan-Ting and Shivakumar, Prashanth Gurunath and Gourav, Aditya and Gu, Yile and Gandhe, Ankur and Lee, Hung-yi and Bulyko, Ivan}", "journal": "{arXiv preprint arXiv:2411.01834}", "year": "{2024}"}}}
{"key": "radford2023robust", "entry_type": "inproceedings", "query_title": "{Robust speech recognition via large-scale weak supervision}", "normalized_title": "robust speech recognition via large scale weak supervision", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Robust speech recognition via large-scale weak supervision}", "author": "{Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya}", "booktitle": "icml", "year": "{2023}"}}}
{"key": "mostafazadeh2016corpus", "entry_type": "inproceedings", "query_title": "\"A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense Stories\"", "normalized_title": "a corpus and cloze evaluation for deeper understanding of commonsense stories", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "\"A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense Stories\"", "author": "\"Mostafazadeh, Nasrin  and\n      Chambers, Nathanael  and\n      He, Xiaodong  and\n      Parikh, Devi  and\n      Batra, Dhruv  and\n      Vanderwende, Lucy  and\n      Kohli, Pushmeet  and\n      Allen, James\"", "booktitle": "naacl", "year": "\"2016\""}}}
{"key": "yang2024uniaudio", "entry_type": "inproceedings", "query_title": "{Uni{A}udio 1.5: Large Language Model-Driven Audio Codec is A Few-Shot Audio Task Learner}", "normalized_title": "uniaudio 1 5 large language model driven audio codec is a few shot audio task learner", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Uni{A}udio 1.5: Large Language Model-Driven Audio Codec is A Few-Shot Audio Task Learner}", "author": "{Dongchao Yang and Haohan Guo and Yuanyuan Wang and Rongjie Huang and Xiang Li and Xu Tan and Xixin Wu and Helen M. Meng}", "booktitle": "neurips", "year": "{2024}"}}}
{"key": "park2024long", "entry_type": "article", "query_title": "{Long-Form Speech Generation with Spoken Language Models}", "normalized_title": "long form speech generation with spoken language models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Se Jin Park and\n                  Julian Salazar and\n                  Aren Jansen and\n                  Keisuke Kinoshita and\n                  Yong Man Ro and\n                  R. J. Skerry{-}Ryan}", "title": "{Long-Form Speech Generation with Spoken Language Models}", "journal": "{arXiv preprint arXiv:2412.18603}", "year": "{2024}"}}}
{"key": "dhariwal2020jukebox", "entry_type": "article", "query_title": "{Jukebox: A generative model for music}", "normalized_title": "jukebox a generative model for music", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Jukebox: A generative model for music}", "author": "{Dhariwal, Prafulla and Jun, Heewoo and Payne, Christine and Kim, Jong Wook and Radford, Alec and Sutskever, Ilya}", "journal": "{arXiv preprint arXiv:2005.00341}", "year": "{2020}"}}}
{"key": "ziv2024masked", "entry_type": "inproceedings", "query_title": "{Masked Audio Generation using a Single Non-Autoregressive Transformer}", "normalized_title": "masked audio generation using a single non autoregressive transformer", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Masked Audio Generation using a Single Non-Autoregressive Transformer}", "author": "{Ziv, Alon and Gat, Itai and Le Lan, Ga{\\\"e}l and Remez, Tal and Kreuk, Felix and Copet, Jade and D{\\'e}fossez, Alexandre and Synnaeve, Gabriel and Adi, Yossi},\n  booktitle=iclr,\n  year={2024}"}}}
{"key": "garcia2023vampnet", "entry_type": "inproceedings", "query_title": "{VampNet: Music Generation via Masked Acoustic Token Modeling}", "normalized_title": "vampnet music generation via masked acoustic token modeling", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{VampNet: Music Generation via Masked Acoustic Token Modeling}", "author": "{Garcia, Hugo F Flores and Seetharaman, Prem and Kumar, Rithesh and Pardo, Bryan}", "booktitle": "ismir", "year": "{2023}"}}}
{"key": "gu2021efficiently", "entry_type": "inproceedings", "query_title": "{Efficiently Modeling Long Sequences with Structured State Spaces}", "normalized_title": "efficiently modeling long sequences with structured state spaces", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Efficiently Modeling Long Sequences with Structured State Spaces}", "author": "{Albert Gu and Karan Goel and Christopher Re}", "booktitle": "iclr", "year": "{2022}"}}}
{"key": "elmakies2025unsupervised", "entry_type": "article", "query_title": "{Unsupervised Speech Segmentation: A General Approach Using Speech Language Models}", "normalized_title": "unsupervised speech segmentation a general approach using speech language models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Unsupervised Speech Segmentation: A General Approach Using Speech Language Models}", "author": "{Avishai Elmakies and Omri Abend and Yossi Adi}", "journal": "{arXiv preprint arXiv:2501.03711}", "year": "{2025}"}}}
{"key": "salmonn", "entry_type": "inproceedings", "query_title": "{{SALMONN}: Towards Generic Hearing Abilities for Large Language Models}", "normalized_title": "salmonn towards generic hearing abilities for large language models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{SALMONN}: Towards Generic Hearing Abilities for Large Language Models}", "author": "{Changli Tang and Wenyi Yu and Guangzhi Sun and Xianzhao Chen and Tian Tan and Wei Li and Lu Lu and Zejun MA and Chao Zhang}", "booktitle": "iclr", "year": "{2024}"}}}
{"key": "qwen_audio", "entry_type": "article", "query_title": "{Qwen-audio: Advancing universal audio understanding via unified large-scale audio-language models}", "normalized_title": "qwen audio advancing universal audio understanding via unified large scale audio language models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Qwen-audio: Advancing universal audio understanding via unified large-scale audio-language models}", "author": "{Chu, Yunfei and Xu, Jin and Zhou, Xiaohuan and Yang, Qian and Zhang, Shiliang and Yan, Zhijie and Zhou, Chang and Zhou, Jingren}", "journal": "{arXiv preprint arXiv:2311.07919}", "year": "{2023}"}}}
{"key": "maimon2025slamming", "entry_type": "article", "query_title": "{Slamming: Training a Speech Language Model on One GPU in a Day}", "normalized_title": "slamming training a speech language model on one gpu in a day", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Slamming: Training a Speech Language Model on One GPU in a Day}", "author": "{Maimon, Gallil and Elmakies, Avishai and Adi, Yossi}", "journal": "{arXiv preprint arXiv:2502.15814}", "year": "{2025}"}}}
{"key": "shi2021aishell", "entry_type": "inproceedings", "query_title": "{{AISHELL-3}: A Multi-Speaker Mandarin {TTS} Corpus}", "normalized_title": "aishell 3 a multi speaker mandarin tts corpus", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{AISHELL-3}: A Multi-Speaker Mandarin {TTS} Corpus}", "author": "{Shi, Yao and Bu, Hui and Xu, Xin and Zhang, Shaoji and Li, Ming}", "year": "{2021}", "booktitle": "interspeech"}}}
{"key": "shi2021highland", "entry_type": "inproceedings", "query_title": "{Highland {P}uebla {N}ahuatl speech translation corpus for endangered language documentation}", "normalized_title": "highland puebla nahuatl speech translation corpus for endangered language documentation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Highland {P}uebla {N}ahuatl speech translation corpus for endangered language documentation}", "author": "{Shi, Jiatong and Amith, Jonathan D and Chang, Xuankai and Dalmia, Siddharth and Yan, Brian and Watanabe, Shinji}", "booktitle": "{Proc. AmericasNLP}", "year": "{2021}"}}}
{"key": "shi2021leveraging", "entry_type": "inproceedings", "query_title": "{Leveraging End-to-End {ASR} for Endangered Language Documentation: An Empirical Study on {Y}ol{\\'o}xochitl {M}ixtec}", "normalized_title": "leveraging end to end asr for endangered language documentation an empirical study on yol oxochitl mixtec", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Leveraging End-to-End {ASR} for Endangered Language Documentation: An Empirical Study on {Y}ol{\\'o}xochitl {M}ixtec}", "author": "{Shi, Jiatong and Amith, Jonathan D and Garc{\\'\\i}a, Rey Castillo and Sierra, Esteban Guadalupe and Duh, Kevin and Watanabe, Shinji}", "booktitle": "{Proc. EACL}", "year": "{2021}"}}}
{"key": "huang2021multi", "entry_type": "inproceedings", "query_title": "{Multi-singer: Fast multi-singer singing voice vocoder with a large-scale corpus}", "normalized_title": "multi singer fast multi singer singing voice vocoder with a large scale corpus", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Multi-singer: Fast multi-singer singing voice vocoder with a large-scale corpus}", "author": "{Huang, Rongjie and Chen, Feiyang and Ren, Yi and Liu, Jinglin and Cui, Chenye and Zhao, Zhou}", "booktitle": "{Proc. ACMMM}", "year": "{2021}"}}}
{"key": "dai2023singstyle111", "entry_type": "inproceedings", "query_title": "{Singstyle111: A multilingual singing dataset with style transfer}", "normalized_title": "singstyle111 a multilingual singing dataset with style transfer", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Singstyle111: A multilingual singing dataset with style transfer}", "author": "{Dai, Shuqi and Chen, Siqi and Wu, Yuxuan and Diao, Ruxin and Huang, Roy and Dannenberg, Roger B}", "booktitle": "ismir", "year": "{2023}"}}}
{"key": "zhang2022m4singer", "entry_type": "inproceedings", "query_title": "{M4singer: A multi-style, multi-singer and musical score provided mandarin singing corpus}", "normalized_title": "m4singer a multi style multi singer and musical score provided mandarin singing corpus", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{M4singer: A multi-style, multi-singer and musical score provided mandarin singing corpus}", "author": "{Zhang, Lichao and Li, Ruiqi and Wang, Shoutong and Deng, Liqun and Liu, Jinglin and Ren, Yi and He, Jinzheng and Huang, Rongjie and Zhu, Jieming and Chen, Xiao and others}", "booktitle": "neurips", "year": "{2022}"}}}
{"key": "ogawa2021tohoku", "entry_type": "article", "query_title": "{Tohoku {K}iritan singing database: A singing database for statistical parametric singing synthesis using Japanese pop songs}", "normalized_title": "tohoku kiritan singing database a singing database for statistical parametric singing synthesis using japanese pop songs", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Tohoku {K}iritan singing database: A singing database for statistical parametric singing synthesis using Japanese pop songs}", "author": "{Ogawa, Itsuki and Morise, Masanori}", "journal": "{AST}", "volume": "{42}", "number": "{3}", "pages": "{140--145}", "year": "{2021}", "publisher": "{Acoustical Society of Japan}"}}}
{"key": "wang2022opencpop", "entry_type": "inproceedings", "query_title": "{Opencpop: A High-Quality Open Source Chinese Popular Song Corpus for Singing Voice Synthesis}", "normalized_title": "opencpop a high quality open source chinese popular song corpus for singing voice synthesis", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Opencpop: A High-Quality Open Source Chinese Popular Song Corpus for Singing Voice Synthesis}", "author": "{Wang, Yu and Wang, Xinsheng and Zhu, Pengcheng and Wu, Jie and Li, Hanzhao and Xue, Heyang and Zhang, Yongmao and Xie, Lei and Bi, Mengxiao}", "year": "{2022}", "booktitle": "interspeech"}}}
{"key": "shi2024singing", "entry_type": "inproceedings", "query_title": "{Singing Voice Data Scaling-up: An Introduction to {ACE-Opencpop and ACE-KiSing}}", "normalized_title": "singing voice data scaling up an introduction to ace opencpop and ace kising", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Singing Voice Data Scaling-up: An Introduction to {ACE-Opencpop and ACE-KiSing}}", "author": "{Shi, Jiatong and Lin, Yueqian and Bai, Xinyi and Zhang, Keyi and Wu, Yuning and Tang, Yuxun and Yu, Yifeng and Jin, Qin and Watanabe, Shinji}", "booktitle": "interspeech", "year": "{2024}"}}}
{"key": "koguchi2020pjs", "entry_type": "inproceedings", "query_title": "{{PJS}: Phoneme-balanced Japanese singing-voice corpus}", "normalized_title": "pjs phoneme balanced japanese singing voice corpus", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{PJS}: Phoneme-balanced Japanese singing-voice corpus}", "author": "{Koguchi, Junya and Takamichi, Shinnosuke and Morise, Masanori}", "booktitle": "{Proc. APSIPA ASC}", "year": "{2020}"}}}
{"key": "takamichi2020jsut", "entry_type": "article", "query_title": "{{JSUT and JVS}: Free Japanese voice corpora for accelerating speech synthesis research}", "normalized_title": "jsut and jvs free japanese voice corpora for accelerating speech synthesis research", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{JSUT and JVS}: Free Japanese voice corpora for accelerating speech synthesis research}", "author": "{Takamichi, Shinnosuke and Sonobe, Ryosuke and Mitsui, Kentaro and Saito, Yuki and Koriyama, Tomoki and Tanji, Naoko and Saruwatari, Hiroshi}", "journal": "{AST}", "volume": "{41}", "number": "{5}", "pages": "{761--768}", "year": "{2020}"}}}
{"key": "amith_yoloxochitl_mixtec", "entry_type": "misc", "query_title": "{Audio corpus of Yolox\u00f3chitl Mixtec with accompanying time-coded transcriptions in ELAN}", "normalized_title": "audio corpus of yoloxochitl mixtec with accompanying time coded transcriptions in elan", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Amith, Jonathan D. and Castillo Castillo, Rey}", "title": "{Audio corpus of Yolox\u00f3chitl Mixtec with accompanying time-coded transcriptions in ELAN}", "year": "2021", "url": "{https://www.openslr.org/89/}"}}}
{"key": "amith_audio_corpus_sierra", "entry_type": "misc", "query_title": "{Audio corpus of Sierra Nororiental and Sierra Norte de Puebla Nahuat(l) with accompanying time-code transcriptions in ELAN}", "normalized_title": "audio corpus of sierra nororiental and sierra norte de puebla nahuat l with accompanying time code transcriptions in elan", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Amith, Jonathan D. and Dom\u00ednguez Alc\u00e1ntara, Amelia and Salazar Osollo, Hermelindo and Salgado Casta\u00f1eda, Ceferino and Gorostiza Salazar, Eleuterio}", "title": "{Audio corpus of Sierra Nororiental and Sierra Norte de Puebla Nahuat(l) with accompanying time-code transcriptions in ELAN}", "year": "2021", "url": "{https://www.openslr.org/92/}"}}}
{"key": "amith_totonac", "entry_type": "misc", "query_title": "{Audio corpus of Totonac recordings from northern Puebla and adjacent areas of Veracruz}", "normalized_title": "audio corpus of totonac recordings from northern puebla and adjacent areas of veracruz", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Amith, Jonathan D. and L\u00f3pez Francisco, Osbel}", "title": "{Audio corpus of Totonac recordings from northern Puebla and adjacent areas of Veracruz}", "year": "2022", "url": "{https://www.openslr.org/107/}"}}}
{"key": "kuhn2014daps", "entry_type": "inproceedings", "query_title": "{{DAPS}: Intelligent delay-aware packet scheduling for multipath transport}", "normalized_title": "daps intelligent delay aware packet scheduling for multipath transport", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{DAPS}: Intelligent delay-aware packet scheduling for multipath transport}", "author": "{Kuhn, Nicolas and Lochin, Emmanuel and Mifdaoui, Ahlem and Sarwar, Golam and Mehani, Olivier and Boreli, Roksana}", "booktitle": "{Proc. ICC}", "year": "{2014}"}}}
{"key": "yamagishi2019cstr", "entry_type": "article", "query_title": "{{CSTR VCTK} Corpus: English multi-speaker corpus for {CSTR} voice cloning toolkit (version 0.92)}", "normalized_title": "cstr vctk corpus english multi speaker corpus for cstr voice cloning toolkit version 0 92", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{CSTR VCTK} Corpus: English multi-speaker corpus for {CSTR} voice cloning toolkit (version 0.92)}", "author": "{Yamagishi, Junichi and Veaux, Christophe and MacDonald, Kirsten and others}", "journal": "{University of Edinburgh. The Centre for Speech Technology Research (CSTR)}", "pages": "{271--350}", "year": "{2019}"}}}
{"key": "yan2023espnet", "entry_type": "inproceedings", "query_title": "{{ESPnet-ST-v2}: Multipurpose Spoken Language Translation Toolkit}", "normalized_title": "espnet st v2 multipurpose spoken language translation toolkit", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{ESPnet-ST-v2}: Multipurpose Spoken Language Translation Toolkit}", "author": "{Yan, Brian and Shi, Jiatong and Tang, Yun and Inaguma, Hirofumi and Peng, Yifan and Dalmia, Siddharth and Polak, Peter and Fernandes, Patrick and Berrebbi, Dan and Hayashi, Tomoki and others}", "booktitle": "acl", "year": "{2023}"}}}
{"key": "vincent2006bss", "entry_type": "article", "query_title": "{Performance measurement in blind audio source separation}", "normalized_title": "performance measurement in blind audio source separation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Vincent, E. and Gribonval, R. and Fevotte, C.}", "journal": "{IEEE Transactions on Audio, Speech, and Language Processing}", "title": "{Performance measurement in blind audio source separation}", "year": "{2006}", "volume": "{14}", "number": "{4}", "pages": "{1462-1469}"}}}
{"key": "allal2024SmolLM", "entry_type": "misc", "query_title": "{SmolLM - blazingly fast and remarkably powerful}", "normalized_title": "smollm blazingly fast and remarkably powerful", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{SmolLM - blazingly fast and remarkably powerful}", "author": "{Loubna Ben Allal and Anton Lozhkov and Elie Bakouch and Leandro von Werra and Thomas Wolf}", "year": "{2024}"}}}
{"key": "rouard2022hybrid", "entry_type": "inproceedings", "query_title": "{Hybrid transformers for music source separation}", "normalized_title": "hybrid transformers for music source separation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Hybrid transformers for music source separation}", "author": "{Rouard, Simon and Massa, Francisco and D{\\'e}fossez, Alexandre}", "booktitle": "icassp", "year": "{2023}"}}}
{"key": "LuoY2019conv-tasnet", "entry_type": "article", "query_title": "{Conv-tasnet: Surpassing ideal time--frequency magnitude masking for speech separation}", "normalized_title": "conv tasnet surpassing ideal time frequency magnitude masking for speech separation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Conv-tasnet: Surpassing ideal time--frequency magnitude masking for speech separation}", "author": "{Luo, Yi and Mesgarani, Nima}", "journal": "{IEEE/ACM Transactions on audio, speech, and language processing}", "volume": "{27}", "number": "{8}", "pages": "{1256--1266}", "year": "{2019}", "publisher": "{IEEE}"}}}
{"key": "Saijo2024_TFLoco", "entry_type": "inproceedings", "query_title": "{TF-Locoformer: Transformer with Local Modeling by Convolution for Speech Separation and Enhancement}", "normalized_title": "tf locoformer transformer with local modeling by convolution for speech separation and enhancement", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Saijo, Kohei and Wichern, Gordon and Germain, Fran\\c{c}ois G. and Pan, Zexu and {Le Roux}, Jonathan}", "title": "{TF-Locoformer: Transformer with Local Modeling by Convolution for Speech Separation and Enhancement}", "booktitle": "{Proc. IWAENC}", "year": "2024"}}}
{"key": "Kavalerov2019UniversalSS", "entry_type": "inproceedings", "query_title": "{Universal Sound Separation}", "normalized_title": "universal sound separation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Universal Sound Separation}", "author": "{Ilya Kavalerov and Scott Wisdom and Hakan Erdogan and Brian Patton and Kevin W. Wilson and Jonathan Le Roux and John R. Hershey}", "booktitle": "waspaa", "year": "{2019}"}}}
{"key": "espnet", "entry_type": "inproceedings", "query_title": "{{ESPnet}: End-to-End Speech Processing Toolkit}", "normalized_title": "espnet end to end speech processing toolkit", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{ESPnet}: End-to-End Speech Processing Toolkit}", "author": "{Shinji Watanabe and Takaaki Hori and Shigeki Karita and Tomoki Hayashi and Jiro Nishitoba and Yuya Unno and Nelson {Enrique Yalta Soplin} and Jahn Heymann and Matthew Wiesner and Nanxin Chen and Adithya Renduchintala and Tsubasa Ochiai}", "year": "{2018}", "booktitle": "interspeech"}}}
{"key": "mars6", "entry_type": "article", "query_title": "{MARS6: A Small and Robust Hierarchical-Codec Text-to-Speech Model}", "normalized_title": "mars6 a small and robust hierarchical codec text to speech model", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{MARS6: A Small and Robust Hierarchical-Codec Text-to-Speech Model}", "author": "{Matthew Baas and Pieter Scholtz and Arnav Mehta and Elliott Dyson and Akshat Prakash and Herman Kamper}", "year": "{2025}", "journal": "{arXiv preprint arXiv:2501.05787}"}}}
{"key": "simplespeech", "entry_type": "inproceedings", "query_title": "{SimpleSpeech: Towards Simple and Efficient Text-to-Speech with Scalar Latent Transformer Diffusion Models}", "normalized_title": "simplespeech towards simple and efficient text to speech with scalar latent transformer diffusion models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{SimpleSpeech: Towards Simple and Efficient Text-to-Speech with Scalar Latent Transformer Diffusion Models}", "author": "{Yang, Dongchao and Wang, Dingdong and Guo, Haohan and Chen, Xueyuan and Wu, Xixin and Meng, Helen}", "booktitle": "interspeech", "year": "{2024}"}}}
{"key": "cuervo2024scalingpropertiesspeechlanguag", "entry_type": "inproceedings", "query_title": "{{Scaling Properties of Speech Language Models}}", "normalized_title": "scaling properties of speech language models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{Scaling Properties of Speech Language Models}}", "author": "{Cuervo, Santiago and Marxer, Ricard}", "booktitle": "emnlp", "year": "{2024}"}}}
{"key": "hassid2023textually", "entry_type": "inproceedings", "query_title": "{Textually pretrained speech language models}", "normalized_title": "textually pretrained speech language models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Textually pretrained speech language models}", "author": "{Hassid, Michael and Remez, Tal and Nguyen, Tu Anh and Gat, Itai and Conneau, Alexis and Kreuk, Felix and Copet, Jade and Defossez, Alexandre and Synnaeve, Gabriel and Dupoux, Emmanuel and others}", "booktitle": "neurips", "year": "{2023}"}}}
{"key": "copet2024musicgen", "entry_type": "inproceedings", "query_title": "{Simple and controllable music generation}", "normalized_title": "simple and controllable music generation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Simple and controllable music generation}", "author": "{Copet, Jade and Kreuk, Felix and Gat, Itai and Remez, Tal and Kant, David and Synnaeve, Gabriel and Adi, Yossi and D{\\'e}fossez, Alexandre}", "booktitle": "neurips", "year": "{2023}"}}}
{"key": "wolf2020huggingfacestransformersstateoftheartnatural", "entry_type": "misc", "query_title": "{HuggingFace's Transformers: State-of-the-art Natural Language Processing}", "normalized_title": "huggingface s transformers state of the art natural language processing", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{HuggingFace's Transformers: State-of-the-art Natural Language Processing}", "author": "{Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R\u00e9mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush}", "year": "{2019}", "journal": "{arXiv preprint arXiv:1910.03771}"}}}
{"key": "ji2024wavtokenizer", "entry_type": "inproceedings", "query_title": "{WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling}", "normalized_title": "wavtokenizer an efficient acoustic discrete codec tokenizer for audio language modeling", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling}", "author": "{Ji, Shengpeng and Jiang, Ziyue and Cheng, Xize and Chen, Yifu and Fang, Minghui and Zuo, Jialong and Yang, Qian and Li, Ruiqi and Zhang, Ziang and Yang, Xiaoda and others}", "booktitle": "iclr", "year": "{2024}"}}}
{"key": "gpt", "entry_type": "article", "query_title": "{Language Models are Few-Shot Learners}", "normalized_title": "language models are few shot learners", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Tom B. Brown and\n                  Benjamin Mann and\n                  Nick Ryder and\n                  Melanie Subbiah and\n                  Jared Kaplan and\n                  Prafulla Dhariwal and\n                  Arvind Neelakantan and\n                  Pranav Shyam and\n                  Girish Sastry and\n                  Amanda Askell and\n                  Sandhini Agarwal and\n                  Ariel Herbert{-}Voss and\n                  Gretchen Krueger and\n                  Tom Henighan and\n                  Rewon Child and\n                  Aditya Ramesh and\n                  Daniel M. Ziegler and\n                  Jeffrey Wu and\n                  Clemens Winter and\n                  Christopher Hesse and\n                  Mark Chen and\n                  Eric Sigler and\n                  Mateusz Litwin and\n                  Scott Gray and\n                  Benjamin Chess and\n                  Jack Clark and\n                  Christopher Berner and\n                  Sam McCandlish and\n                  Alec Radford and\n                  Ilya Sutskever and\n                  Dario Amodei}", "title": "{Language Models are Few-Shot Learners}", "journal": "{arXiv preprint arXiv:2005.14165}", "year": "{2020}"}}}
{"key": "bark2023", "entry_type": "misc", "query_title": "{Bark: Text-Prompted Generative Audio Model}", "normalized_title": "bark text prompted generative audio model", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Suno AI}", "title": "{Bark: Text-Prompted Generative Audio Model}", "year": "{2023}", "howpublished": "{\\url{https://github.com/suno-ai/bark}}", "note": "{Accessed: 2025-03-21}"}}}
{"key": "guo2025recent", "entry_type": "article", "query_title": "{Recent Advances in Discrete Speech Tokens: A Review}", "normalized_title": "recent advances in discrete speech tokens a review", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Recent Advances in Discrete Speech Tokens: A Review}", "author": "{Guo, Yiwei and Li, Zhihan and Wang, Hankun and Li, Bohan and Shao, Chongtian and Zhang, Hanglei and Du, Chenpeng and Chen, Xie and Liu, Shujie and Yu, Kai}", "journal": "{arXiv preprint arXiv:2502.06490}", "year": "{2025}"}}}
{"key": "zaiem2023speech", "entry_type": "inproceedings", "query_title": "{Speech Self-Supervised Representation Benchmarking: Are We Doing it Right?}", "normalized_title": "speech self supervised representation benchmarking are we doing it right", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Speech Self-Supervised Representation Benchmarking: Are We Doing it Right?}", "author": "{Zaiem, Salah and Kemiche, Youcef and Parcollet, Titouan and Essid, Slim and Ravanelli, Mirco}", "booktitle": "interspeech", "year": "{2023}"}}}
{"key": "watanabe2023tree", "entry_type": "article", "query_title": "{Tree-structured parzen estimator: Understanding its algorithm components and their roles for better empirical performance}", "normalized_title": "tree structured parzen estimator understanding its algorithm components and their roles for better empirical performance", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Tree-structured parzen estimator: Understanding its algorithm components and their roles for better empirical performance}", "author": "{Watanabe, Shuhei}", "journal": "{arXiv preprint arXiv:2304.11127}", "year": "{2023}"}}}
{"key": "xavier_bouthillier_2022_0_2_6", "entry_type": "misc", "query_title": "{{Epistimio/orion: Asynchronous Distributed Hyperparameter Optimization}}", "normalized_title": "epistimio orion asynchronous distributed hyperparameter optimization", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Bouthillier, Xavier  and\n                  Tsirigotis, Christos and\n                  Corneau-Tremblay, Fran\u00e7ois and\n                  Schweizer, Thomas and\n                  Dong, Lin and\n                  Delaunay, Pierre and\n                  Normandin, Fabrice and\n                  Bronzi, Mirko and\n                  Suhubdy, Dendi and\n                  Askari, Reyhane and\n                  Noukhovitch, Michael and\n                  Xue, Chao and\n                  Ortiz-Gagn\u00e9, Satya and\n                  Breuleux, Olivier and\n                  Bergeron, Arnaud and\n                  Bilaniuk, Olexa and\n                  Bocco, Steven and\n                  Bertrand, Hadrien and\n                  Alain, Guillaume and\n                  Serdyuk, Dmitriy and\n                  Henderson, Peter and\n                  Lamblin, Pascal and\n                  Beckham, Christopher}", "title": "{{Epistimio/orion: Asynchronous Distributed Hyperparameter Optimization}}", "month": "\"Aug\"", "year": "2022", "publisher": "{Zenodo}", "version": "{v0.2.6}", "doi": "{10.5281/zenodo.3478592}", "url": "{https://doi.org/10.5281/zenodo.3478592}"}}}
{"key": "mentzer2023finite", "entry_type": "inproceedings", "query_title": "{Finite Scalar Quantization: VQ-VAE Made Simple}", "normalized_title": "finite scalar quantization vq vae made simple", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Finite Scalar Quantization: VQ-VAE Made Simple}", "author": "{Mentzer, Fabian and Minnen, David and Agustsson, Eirikur and Tschannen, Michael}", "booktitle": "iclr", "year": "2024"}}}
{"key": "du2024cosyvoiceAS", "entry_type": "article", "query_title": "{CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens}", "normalized_title": "cosyvoice a scalable multilingual zero shot text to speech synthesizer based on supervised semantic tokens", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens}", "author": "{Du, Zhihao and Chen, Qian and Zhang, Shiliang and Hu, Kai and Lu, Heng and Yang, Yexin and Hu, Hangrui and Zheng, Siqi and Gu, Yue and Ma, Ziyang and others}", "journal": "{arXiv preprint arXiv:2407.05407}", "year": "{2024}"}}}
{"key": "du2024cosyvoice", "entry_type": "article", "query_title": "{Cosyvoice 2: Scalable streaming speech synthesis with large language models}", "normalized_title": "cosyvoice 2 scalable streaming speech synthesis with large language models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Cosyvoice 2: Scalable streaming speech synthesis with large language models}", "author": "{Du, Zhihao and Wang, Yuxuan and Chen, Qian and Shi, Xian and Lv, Xiang and Zhao, Tianyu and Gao, Zhifu and Yang, Yexin and Gao, Changfeng and Wang, Hui and others}", "journal": "{arXiv preprint arXiv:2412.10117}", "year": "{2024}"}}}
{"key": "tong2023improving", "entry_type": "article", "query_title": "{Improving and Generalizing Flow-Based Generative Models with Minibatch Optimal Transport}", "normalized_title": "improving and generalizing flow based generative models with minibatch optimal transport", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Improving and Generalizing Flow-Based Generative Models with Minibatch Optimal Transport}", "author": "{Tong, Alexander and Malkin, Nikolay and Huguet, Guillaume and Zhang, Yanlei and Rector-Brooks, Jarrid and FATRAS, Kilian and Wolf, Guy and Bengio, Yoshua}", "journal": "{Transactions on Machine Learning Research}", "year": "{2024}"}}}
{"key": "ho2020denoising", "entry_type": "inproceedings", "query_title": "{Denoising diffusion probabilistic models}", "normalized_title": "denoising diffusion probabilistic models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Denoising diffusion probabilistic models}", "author": "{Ho, Jonathan and Jain, Ajay and Abbeel, Pieter}", "booktitle": "neurips", "year": "{2020}"}}}
{"key": "rombach2022high", "entry_type": "inproceedings", "query_title": "{High-resolution image synthesis with latent diffusion models}", "normalized_title": "high resolution image synthesis with latent diffusion models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{High-resolution image synthesis with latent diffusion models}", "author": "{Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\\\"o}rn},\n  booktitle=cvpr,\n  year={2022}"}}}
{"key": "kim2024neural", "entry_type": "article", "query_title": "{Neural speech and audio coding}", "normalized_title": "neural speech and audio coding", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Neural speech and audio coding}", "author": "{Kim, Minje and Skoglund, Jan}", "journal": "{arXiv preprint arXiv:2408.06954}", "year": "{2024}"}}}
{"key": "anees2024speech", "entry_type": "article", "query_title": "{Speech coding techniques and challenges: A comprehensive literature survey}", "normalized_title": "speech coding techniques and challenges a comprehensive literature survey", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Speech coding techniques and challenges: A comprehensive literature survey}", "author": "{Anees, Mohamed}", "journal": "{Multimedia Tools and Applications}", "volume": "{83}", "number": "{10}", "pages": "{29859--29879}", "year": "{2024}", "publisher": "{Springer}"}}}
{"key": "shannon1948mathematical", "entry_type": "article", "query_title": "{A mathematical theory of communication}", "normalized_title": "a mathematical theory of communication", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{A mathematical theory of communication}", "author": "{Shannon, Claude E}", "journal": "{The Bell system technical journal}", "volume": "{27}", "number": "{3}", "pages": "{379--423}", "year": "{1948}", "publisher": "{Nokia Bell Labs}"}}}
{"key": "nyquist1928certain", "entry_type": "article", "query_title": "{Certain topics in telegraph transmission theory}", "normalized_title": "certain topics in telegraph transmission theory", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Certain topics in telegraph transmission theory}", "author": "{Nyquist, Harry}", "journal": "{Transactions of the American Institute of Electrical Engineers}", "volume": "{47}", "pages": "{617-644}", "year": "{1928}"}}}
{"key": "o1988linear", "entry_type": "article", "query_title": "{Linear predictive coding}", "normalized_title": "linear predictive coding", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Linear predictive coding}", "author": "{O'Shaughnessy, Douglas}", "journal": "{IEEE potentials}", "volume": "{7}", "number": "{1}", "pages": "{29--32}", "year": "{1988}", "publisher": "{IEEE}"}}}
{"key": "wang2003modified", "entry_type": "article", "query_title": "{Modified discrete cosine transform: Its implications for audio coding and error concealment}", "normalized_title": "modified discrete cosine transform its implications for audio coding and error concealment", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Modified discrete cosine transform: Its implications for audio coding and error concealment}", "author": "{Wang, Ye and Vilermo, Mikka}", "journal": "{Journal of the Audio Engineering Society}", "volume": "{51}", "number": "{1/2}", "pages": "{52--61}", "year": "{2003}", "publisher": "{Audio Engineering Society}"}}}
{"key": "noll1997mpeg", "entry_type": "article", "query_title": "{MPEG digital audio coding}", "normalized_title": "mpeg digital audio coding", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{MPEG digital audio coding}", "author": "{Noll, Peter}", "journal": "{IEEE signal processing magazine}", "volume": "{14}", "number": "{5}", "pages": "{59--81}", "year": "{1997}", "publisher": "{IEEE}"}}}
{"key": "painter2000perceptual", "entry_type": "article", "query_title": "{Perceptual coding of digital audio}", "normalized_title": "perceptual coding of digital audio", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Perceptual coding of digital audio}", "author": "{Painter, Ted and Spanias, Andreas}", "journal": "{Proceedings of the IEEE}", "volume": "{88}", "number": "{4}", "pages": "{451--515}", "year": "{2000}", "publisher": "{IEEE}"}}}
{"key": "jage2016celp", "entry_type": "inproceedings", "query_title": "{CELP and MELP speech coding techniques}", "normalized_title": "celp and melp speech coding techniques", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{CELP and MELP speech coding techniques}", "author": "{Jage, Rhutuja and Upadhya, Savitha}", "booktitle": "{Proc. WiSPNET}", "year": "{2016}"}}}
{"key": "maimon2025scaling", "entry_type": "article", "query_title": "{Scaling Analysis of Interleaved Speech-Text Language Models}", "normalized_title": "scaling analysis of interleaved speech text language models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Scaling Analysis of Interleaved Speech-Text Language Models}", "author": "{Maimon, Gallil and Hassid, Michael and Roth, Amit and Adi, Yossi}", "journal": "{arXiv preprint arXiv:2504.02398}", "year": "{2025}"}}}
{"key": "qwen2025qwen25technicalreport", "entry_type": "article", "query_title": "{Qwen2.5 Technical Report}", "normalized_title": "qwen2 5 technical report", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Qwen2.5 Technical Report}", "author": "{An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tianyi Tang and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu}", "journal": "{arXiv preprint arXiv:2412.15115}", "year": "{2024}"}}}
{"key": "cuervo2025textspeechlanguagemodelsimproved", "entry_type": "article", "query_title": "{Text-Speech Language Models with Improved Cross-Modal Transfer by Aligning Abstraction Levels}", "normalized_title": "text speech language models with improved cross modal transfer by aligning abstraction levels", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Text-Speech Language Models with Improved Cross-Modal Transfer by Aligning Abstraction Levels}", "author": "{Santiago Cuervo and Adel Moumen and Yanis Labrak and Sameer Khurana and Antoine Laurent and Mickael Rouvier and Ricard Marxer}", "year": "{2025}", "journal": "{arXiv preprint arXiv:2503.06211}"}}}
{"key": "kharitonov2022textfreeprosodyawaregenerativespoken", "entry_type": "inproceedings", "query_title": "{Text-Free Prosody-Aware Generative Spoken Language Modeling}", "normalized_title": "text free prosody aware generative spoken language modeling", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Text-Free Prosody-Aware Generative Spoken Language Modeling}", "author": "{Kharitonov, Eugene and Lee, Ann and Polyak, Adam and Adi, Yossi and Copet, Jade and Lakhotia, Kushal and Nguyen, Tu-Anh and Rivi{\\`e}re, Morgane and Mohamed, Abdelrahman and Dupoux, Emmanuel and others}", "booktitle": "acl", "year": "{2022}", "organization": "{MIT Press}"}}}
{"key": "agustsson2017soft", "entry_type": "inproceedings", "query_title": "{Soft-to-hard vector quantization for end-to-end learning compressible representations}", "normalized_title": "soft to hard vector quantization for end to end learning compressible representations", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Soft-to-hard vector quantization for end-to-end learning compressible representations}", "author": "{Agustsson, Eirikur and Mentzer, Fabian and Tschannen, Michael and Cavigelli, Lukas and Timofte, Radu and Benini, Luca and Gool, Luc V}", "booktitle": "neurips", "year": "{2017}"}}}
{"key": "kankanahalli2018end", "entry_type": "inproceedings", "query_title": "{End-to-end optimized speech coding with deep neural networks}", "normalized_title": "end to end optimized speech coding with deep neural networks", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{End-to-end optimized speech coding with deep neural networks}", "author": "{Kankanahalli, Srihari}", "booktitle": "icassp", "year": "{2018}"}}}
{"key": "choi2024selfsupervisedspeechrepresentationsphonetic", "entry_type": "inproceedings", "query_title": "{Self-Supervised Speech Representations are More Phonetic than Semantic}", "normalized_title": "self supervised speech representations are more phonetic than semantic", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Self-Supervised Speech Representations are More Phonetic than Semantic}", "author": "{Choi, Kwanghee and Pasad, Ankita and Nakamura, Tomohiko and Fukayama, Satoru and Livescu, Karen and Watanabe, Shinji}", "booktitle": "interspeech", "year": "{2024}"}}}
{"key": "grattafiori2024llama3herdmodels", "entry_type": "article", "query_title": "{The llama 3 herd of models}", "normalized_title": "the llama 3 herd of models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{The llama 3 herd of models}", "author": "{Grattafiori, Aaron and Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Vaughan, Alex and others}", "journal": "{arXiv preprint arXiv:2407.21783}", "year": "{2024}"}}}
{"key": "radhakrishnan2023whispering", "entry_type": "inproceedings", "query_title": "{Whispering LLaMA: A Cross-Modal Generative Error Correction Framework for Speech Recognition}", "normalized_title": "whispering llama a cross modal generative error correction framework for speech recognition", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Whispering LLaMA: A Cross-Modal Generative Error Correction Framework for Speech Recognition}", "author": "{Radhakrishnan, Srijith and Yang, Chao-Han Huck and Khan, Sumeer Ahmad and Kumar, Rohit and Kiani, Narsis A. and Gomez-Cabrero, David and Tegner, Jesper N.}", "booktitle": "emnlp", "year": "{2023}"}}}
{"key": "libritts-alignments", "entry_type": "misc", "query_title": "{LibriTTS-Phones-and-Mel}", "normalized_title": "libritts phones and mel", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Christoph Minixhofer}", "title": "{LibriTTS-Phones-and-Mel}", "year": "{2023}", "publisher": "{Hugging Face}", "note": "{\\url{https://huggingface.co/datasets/cdminix/libritts-phones-and-mel}}", "howpublished": "{\\url{https://huggingface.co/datasets/cdminix/libritts-phones-and-mel}}"}}}
{"key": "ren2019fastspeech", "entry_type": "inproceedings", "query_title": "{Fastspeech: Fast, robust and controllable text to speech}", "normalized_title": "fastspeech fast robust and controllable text to speech", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Fastspeech: Fast, robust and controllable text to speech}", "author": "{Ren, Yi and Ruan, Yangjun and Tan, Xu and Qin, Tao and Zhao, Sheng and Zhao, Zhou and Liu, Tie-Yan}", "booktitle": "neurips", "year": "{2019}"}}}
{"key": "morise2016world", "entry_type": "article", "query_title": "{WORLD: a vocoder-based high-quality speech synthesis system for real-time applications}", "normalized_title": "world a vocoder based high quality speech synthesis system for real time applications", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{WORLD: a vocoder-based high-quality speech synthesis system for real-time applications}", "author": "{Morise, Masanori and Yokomori, Fumiya and Ozawa, Kenji}", "journal": "{IEICE TRANSACTIONS on Information and Systems}", "volume": "{99}", "number": "{7}", "pages": "{1877--1884}", "year": "{2016}", "publisher": "{The Institute of Electronics, Information and Communication Engineers}"}}}
{"key": "ren2020fastspeech", "entry_type": "inproceedings", "query_title": "{FastSpeech 2: Fast and High-Quality End-to-End Text to Speech}", "normalized_title": "fastspeech 2 fast and high quality end to end text to speech", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{FastSpeech 2: Fast and High-Quality End-to-End Text to Speech}", "author": "{Yi Ren and Chenxu Hu and Xu Tan and Tao Qin and Sheng Zhao and Zhou Zhao and Tie-Yan Liu}", "booktitle": "iclr", "year": "{2021}"}}}
{"key": "kim2021conditional", "entry_type": "inproceedings", "query_title": "{Conditional variational autoencoder with adversarial learning for end-to-end text-to-speech}", "normalized_title": "conditional variational autoencoder with adversarial learning for end to end text to speech", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Conditional variational autoencoder with adversarial learning for end-to-end text-to-speech}", "author": "{Kim, Jaehyeon and Kong, Jungil and Son, Juhee}", "booktitle": "icml", "year": "{2021}"}}}
{"key": "ju2024naturalspeech", "entry_type": "inproceedings", "query_title": "{NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models}", "normalized_title": "naturalspeech 3 zero shot speech synthesis with factorized codec and diffusion models", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models}", "author": "{Ju, Zeqian and Wang, Yuancheng and Shen, Kai and Tan, Xu and Xin, Detai and Yang, Dongchao and Liu, Eric and Leng, Yichong and Song, Kaitao and Tang, Siliang and others}", "booktitle": "icml", "year": "{2024}"}}}
{"key": "mcauliffe2017montreal", "entry_type": "inproceedings", "query_title": "{Montreal forced aligner: Trainable text-speech alignment using {k}aldi.}", "normalized_title": "montreal forced aligner trainable text speech alignment using kaldi", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Montreal forced aligner: Trainable text-speech alignment using {k}aldi.}", "author": "{McAuliffe, Michael and Socolof, Michaela and Mihuc, Sarah and Wagner, Michael and Sonderegger, Morgan}", "booktitle": "interspeech", "year": "{2017}"}}}
{"key": "har2025past", "entry_type": "article", "query_title": "{PAST: Phonetic-Acoustic Speech Tokenizer}", "normalized_title": "past phonetic acoustic speech tokenizer", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{PAST: Phonetic-Acoustic Speech Tokenizer}", "author": "{Har-Tuv, Nadav and Tal, Or and Adi, Yossi}", "journal": "{arXiv preprint arXiv:2505.14470}", "year": "{2025}"}}}
{"key": "10889092", "entry_type": "inproceedings", "query_title": "{What Are They Doing? Joint Audio-Speech Co-Reasoning}", "normalized_title": "what are they doing joint audio speech co reasoning", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Wang, Yingzhi and Mousavi, Pooneh and Ploujnikov, Artem and Ravanelli, Mirco}", "title": "{What Are They Doing? Joint Audio-Speech Co-Reasoning}", "year": "{2025}", "booktitle": "icassp"}}}
{"key": "zengscaling", "entry_type": "inproceedings", "query_title": "{Scaling Speech-Text Pre-training with Synthetic Interleaved Data}", "normalized_title": "scaling speech text pre training with synthetic interleaved data", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Scaling Speech-Text Pre-training with Synthetic Interleaved Data}", "author": "{Zeng, Aohan and Du, Zhengxiao and Liu, Mingdao and Zhang, Lei and Dong, Yuxiao and Tang, Jie and others}", "booktitle": "iclr", "year": "{2025}"}}}
{"key": "yosha2025stresstest", "entry_type": "article", "query_title": "{{StressTest}: Can YOUR Speech {LM} Handle the Stress?}", "normalized_title": "stresstest can your speech lm handle the stress", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{{StressTest}: Can YOUR Speech {LM} Handle the Stress?}", "author": "{Yosha, Iddo and Maimon, Gallil and Adi, Yossi}", "journal": "{arXiv preprint arXiv:2505.22765}", "year": "{2025}"}}}
{"key": "mousavi2025listen", "entry_type": "article", "query_title": "{LiSTEN: Learning Soft Token Embeddings for Neural Audio LLMs}", "normalized_title": "listen learning soft token embeddings for neural audio llms", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{LiSTEN: Learning Soft Token Embeddings for Neural Audio LLMs}", "author": "{Mousavi, Pooneh and Gupta, Shubham and Subakan, Cem and Ravanelli, Mirco}", "journal": "{arXiv preprint arXiv:2505.18517}", "year": "{2025}"}}}
{"key": "kumar2024sila", "entry_type": "article", "query_title": "{SILA: Signal-to-Language Augmentation for Enhanced Control in Text-to-Audio Generation}", "normalized_title": "sila signal to language augmentation for enhanced control in text to audio generation", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{SILA: Signal-to-Language Augmentation for Enhanced Control in Text-to-Audio Generation}", "author": "{Kumar, Sonal and Seetharaman, Prem and Salamon, Justin and Manocha, Dinesh and Nieto, Oriol}", "journal": "{arXiv preprint arXiv:2412.09789}", "year": "{2024}"}}}
{"key": "chen2025video", "entry_type": "inproceedings", "query_title": "{Video-guided foley sound generation with multimodal controls}", "normalized_title": "video guided foley sound generation with multimodal controls", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Video-guided foley sound generation with multimodal controls}", "author": "{Chen, Ziyang and Seetharaman, Prem and Russell, Bryan and Nieto, Oriol and Bourgin, David and Owens, Andrew and Salamon, Justin}", "booktitle": "cvpr", "year": "{2025}"}}}
{"key": "international1993coding", "entry_type": "article", "query_title": "{Coding of moving pictures and associated audio for digital storage media at up to about 1.5 Mbit/s}", "normalized_title": "coding of moving pictures and associated audio for digital storage media at up to about 1 5 mbit s", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Coding of moving pictures and associated audio for digital storage media at up to about 1.5 Mbit/s}", "author": "{ISO/IEC JTC1/SC29 and others}", "journal": "{ISO/IEC 11172}", "year": "{1993}"}}}
{"key": "6530580", "entry_type": "article", "query_title": "{MPEG Unified Speech and Audio Coding}", "normalized_title": "mpeg unified speech and audio coding", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"author": "{Quackenbush, Schuyler}", "journal": "{IEEE MultiMedia}", "title": "{MPEG Unified Speech and Audio Coding}", "year": "{2013}", "volume": "{20}", "number": "{2}", "pages": "{72-78}"}}}
{"key": "devlin2019bert", "entry_type": "inproceedings", "query_title": "{Bert: Pre-training of deep bidirectional transformers for language understanding}", "normalized_title": "bert pre training of deep bidirectional transformers for language understanding", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Bert: Pre-training of deep bidirectional transformers for language understanding}", "author": "{Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina}", "booktitle": "naacl", "year": "{2019}"}}}
{"key": "turetzky2024last", "entry_type": "article", "query_title": "{Last: Language model aware speech tokenization}", "normalized_title": "last language model aware speech tokenization", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Last: Language model aware speech tokenization}", "author": "{Turetzky, Arnon and Adi, Yossi}", "journal": "{arXiv preprint arXiv:2409.03701}", "year": "{2024}"}}}
{"key": "zheng2025ervq", "entry_type": "article", "query_title": "{ERVQ: Enhanced residual vector quantization with intra-and-inter-codebook optimization for neural audio codecs}", "normalized_title": "ervq enhanced residual vector quantization with intra and inter codebook optimization for neural audio codecs", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{ERVQ: Enhanced residual vector quantization with intra-and-inter-codebook optimization for neural audio codecs}", "author": "{Zheng, Rui-Chen and Du, Hui-Peng and Jiang, Xiao-Hang and Ai, Yang and Ling, Zhen-Hua}", "journal": "{IEEE Transactions on Audio, Speech and Language Processing}", "year": "{2025}", "booktitle": "{IEEE}"}}}
{"key": "esser2021taming", "entry_type": "inproceedings", "query_title": "{Taming transformers for high-resolution image synthesis}", "normalized_title": "taming transformers for high resolution image synthesis", "matched": false, "match_score": 0.0, "arxiv": null, "sources": {"query_title": "local"}, "raw": {"local": {"title": "{Taming transformers for high-resolution image synthesis}", "author": "{Esser, Patrick and Rombach, Robin and Ommer, Bjorn}", "booktitle": "cvpr", "year": "{2021}"}}}
