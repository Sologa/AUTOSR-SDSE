{
  "query_title": "{Codec does matter: Exploring the semantic shortcoming of codec for audio language model}",
  "response": "<?xml version='1.0' encoding='UTF-8'?>\n<feed xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\" xmlns:arxiv=\"http://arxiv.org/schemas/atom\" xmlns=\"http://www.w3.org/2005/Atom\">\n  <id>https://arxiv.org/api/dAeQaj7XquFFL0DPSXdhqgg6Itc</id>\n  <title>arXiv Query: search_query=ti:\"codec does matter exploring the semantic shortcoming of codec for audio language model\"&amp;id_list=&amp;start=0&amp;max_results=5</title>\n  <updated>2025-12-29T13:21:43Z</updated>\n  <link href=\"https://arxiv.org/api/query?search_query=ti:%22codec+does+matter+exploring+the+semantic+shortcoming+of+codec+for+audio+language+model%22&amp;start=0&amp;max_results=5&amp;id_list=\" type=\"application/atom+xml\"/>\n  <opensearch:itemsPerPage>5</opensearch:itemsPerPage>\n  <opensearch:totalResults>1</opensearch:totalResults>\n  <opensearch:startIndex>0</opensearch:startIndex>\n  <entry>\n    <id>http://arxiv.org/abs/2408.17175v3</id>\n    <title>Codec Does Matter: Exploring the Semantic Shortcoming of Codec for Audio Language Model</title>\n    <updated>2024-11-27T11:47:45Z</updated>\n    <link href=\"https://arxiv.org/abs/2408.17175v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2408.17175v3\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Recent advancements in audio generation have been significantly propelled by the capabilities of Large Language Models (LLMs). The existing research on audio LLM has primarily focused on enhancing the architecture and scale of audio language models, as well as leveraging larger datasets, and generally, acoustic codecs, such as EnCodec, are used for audio tokenization. However, these codecs were originally designed for audio compression, which may lead to suboptimal performance in the context of audio LLM. Our research aims to address the shortcomings of current audio LLM codecs, particularly their challenges in maintaining semantic integrity in generated audio. For instance, existing methods like VALL-E, which condition acoustic token generation on text transcriptions, often suffer from content inaccuracies and elevated word error rates (WER) due to semantic misinterpretations of acoustic tokens, resulting in word skipping and errors. To overcome these issues, we propose a straightforward yet effective approach called X-Codec. X-Codec incorporates semantic features from a pre-trained semantic encoder before the Residual Vector Quantization (RVQ) stage and introduces a semantic reconstruction loss after RVQ. By enhancing the semantic ability of the codec, X-Codec significantly reduces WER in speech synthesis tasks and extends these benefits to non-speech applications, including music and sound generation. Our experiments in text-to-speech, music continuation, and text-to-sound tasks demonstrate that integrating semantic information substantially improves the overall performance of language models in audio generation. Our code and demo are available (Demo: https://x-codec-audio.github.io Code: https://github.com/zhenye234/xcodec)</summary>\n    <category term=\"eess.AS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SD\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2024-08-30T10:24:07Z</published>\n    <arxiv:primary_category term=\"eess.AS\"/>\n    <author>\n      <name>Zhen Ye</name>\n    </author>\n    <author>\n      <name>Peiwen Sun</name>\n    </author>\n    <author>\n      <name>Jiahe Lei</name>\n    </author>\n    <author>\n      <name>Hongzhan Lin</name>\n    </author>\n    <author>\n      <name>Xu Tan</name>\n    </author>\n    <author>\n      <name>Zheqi Dai</name>\n    </author>\n    <author>\n      <name>Qiuqiang Kong</name>\n    </author>\n    <author>\n      <name>Jianyi Chen</name>\n    </author>\n    <author>\n      <name>Jiahao Pan</name>\n    </author>\n    <author>\n      <name>Qifeng Liu</name>\n    </author>\n    <author>\n      <name>Yike Guo</name>\n    </author>\n    <author>\n      <name>Wei Xue</name>\n    </author>\n  </entry>\n</feed>\n"
}