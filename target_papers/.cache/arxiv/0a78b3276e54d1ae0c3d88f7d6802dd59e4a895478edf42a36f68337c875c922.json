{
  "query_title": "{Towards General-Purpose Text-Instruction-Guided Voice Conversion}",
  "response": "<?xml version='1.0' encoding='UTF-8'?>\n<feed xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\" xmlns:arxiv=\"http://arxiv.org/schemas/atom\" xmlns=\"http://www.w3.org/2005/Atom\">\n  <id>https://arxiv.org/api/sD+ZW6aZgmgC+zYW52sFK9qz09Y</id>\n  <title>arXiv Query: search_query=ti:\"towards general purpose text instruction guided voice conversion\"&amp;id_list=&amp;start=0&amp;max_results=5</title>\n  <updated>2025-12-29T13:24:23Z</updated>\n  <link href=\"https://arxiv.org/api/query?search_query=ti:%22towards+general+purpose+text+instruction+guided+voice+conversion%22&amp;start=0&amp;max_results=5&amp;id_list=\" type=\"application/atom+xml\"/>\n  <opensearch:itemsPerPage>5</opensearch:itemsPerPage>\n  <opensearch:totalResults>1</opensearch:totalResults>\n  <opensearch:startIndex>0</opensearch:startIndex>\n  <entry>\n    <id>http://arxiv.org/abs/2309.14324v2</id>\n    <title>Towards General-Purpose Text-Instruction-Guided Voice Conversion</title>\n    <updated>2024-01-16T13:53:56Z</updated>\n    <link href=\"https://arxiv.org/abs/2309.14324v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2309.14324v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>This paper introduces a novel voice conversion (VC) model, guided by text instructions such as \"articulate slowly with a deep tone\" or \"speak in a cheerful boyish voice\". Unlike traditional methods that rely on reference utterances to determine the attributes of the converted speech, our model adds versatility and specificity to voice conversion. The proposed VC model is a neural codec language model which processes a sequence of discrete codes, resulting in the code sequence of converted speech. It utilizes text instructions as style prompts to modify the prosody and emotional information of the given speech. In contrast to previous approaches, which often rely on employing separate encoders like prosody and content encoders to handle different aspects of the source speech, our model handles various information of speech in an end-to-end manner. Experiments have demonstrated the impressive capabilities of our model in comprehending instructions and delivering reasonable results.</summary>\n    <category term=\"eess.AS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SD\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2023-09-25T17:52:09Z</published>\n    <arxiv:comment>Accepted to ASRU 2023</arxiv:comment>\n    <arxiv:primary_category term=\"eess.AS\"/>\n    <author>\n      <name>Chun-Yi Kuan</name>\n    </author>\n    <author>\n      <name>Chen An Li</name>\n    </author>\n    <author>\n      <name>Tsu-Yuan Hsu</name>\n    </author>\n    <author>\n      <name>Tse-Yang Lin</name>\n    </author>\n    <author>\n      <name>Ho-Lam Chung</name>\n    </author>\n    <author>\n      <name>Kai-Wei Chang</name>\n    </author>\n    <author>\n      <name>Shuo-yiin Chang</name>\n    </author>\n    <author>\n      <name>Hung-yi Lee</name>\n    </author>\n  </entry>\n</feed>\n"
}