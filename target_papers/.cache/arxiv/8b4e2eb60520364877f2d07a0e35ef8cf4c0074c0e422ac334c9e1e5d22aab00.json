{
  "query_title": "{Dynamic-{SUPERB}: Towards a dynamic, collaborative, and comprehensive instruction-tuning benchmark for speech}",
  "response": "<?xml version='1.0' encoding='UTF-8'?>\n<feed xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\" xmlns:arxiv=\"http://arxiv.org/schemas/atom\" xmlns=\"http://www.w3.org/2005/Atom\">\n  <id>https://arxiv.org/api/8Ccp5hY+HMDO9DjL6DbQNY+sCy0</id>\n  <title>arXiv Query: search_query=ti:\"dynamic superb towards a dynamic collaborative and comprehensive instruction tuning benchmark for speech\"&amp;id_list=&amp;start=0&amp;max_results=5</title>\n  <updated>2025-12-29T13:24:27Z</updated>\n  <link href=\"https://arxiv.org/api/query?search_query=ti:%22dynamic+superb+towards+a+dynamic+collaborative+and+comprehensive+instruction+tuning+benchmark+for+speech%22&amp;start=0&amp;max_results=5&amp;id_list=\" type=\"application/atom+xml\"/>\n  <opensearch:itemsPerPage>5</opensearch:itemsPerPage>\n  <opensearch:totalResults>1</opensearch:totalResults>\n  <opensearch:startIndex>0</opensearch:startIndex>\n  <entry>\n    <id>http://arxiv.org/abs/2309.09510v2</id>\n    <title>Dynamic-SUPERB: Towards A Dynamic, Collaborative, and Comprehensive Instruction-Tuning Benchmark for Speech</title>\n    <updated>2024-03-22T15:25:04Z</updated>\n    <link href=\"https://arxiv.org/abs/2309.09510v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2309.09510v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Text language models have shown remarkable zero-shot capability in generalizing to unseen tasks when provided with well-formulated instructions. However, existing studies in speech processing primarily focus on limited or specific tasks. Moreover, the lack of standardized benchmarks hinders a fair comparison across different approaches. Thus, we present Dynamic-SUPERB, a benchmark designed for building universal speech models capable of leveraging instruction tuning to perform multiple tasks in a zero-shot fashion. To achieve comprehensive coverage of diverse speech tasks and harness instruction tuning, we invite the community to collaborate and contribute, facilitating the dynamic growth of the benchmark. To initiate, Dynamic-SUPERB features 55 evaluation instances by combining 33 tasks and 22 datasets. This spans a broad spectrum of dimensions, providing a comprehensive platform for evaluation. Additionally, we propose several approaches to establish benchmark baselines. These include the utilization of speech models, text language models, and the multimodal encoder. Evaluation results indicate that while these baselines perform reasonably on seen tasks, they struggle with unseen ones. We release all materials to the public and welcome researchers to collaborate on the project, advancing technologies in the field together.</summary>\n    <category term=\"eess.AS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SD\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2023-09-18T06:43:30Z</published>\n    <arxiv:comment>To appear in the proceedings of ICASSP 2024</arxiv:comment>\n    <arxiv:primary_category term=\"eess.AS\"/>\n    <author>\n      <name>Chien-yu Huang</name>\n    </author>\n    <author>\n      <name>Ke-Han Lu</name>\n    </author>\n    <author>\n      <name>Shih-Heng Wang</name>\n    </author>\n    <author>\n      <name>Chi-Yuan Hsiao</name>\n    </author>\n    <author>\n      <name>Chun-Yi Kuan</name>\n    </author>\n    <author>\n      <name>Haibin Wu</name>\n    </author>\n    <author>\n      <name>Siddhant Arora</name>\n    </author>\n    <author>\n      <name>Kai-Wei Chang</name>\n    </author>\n    <author>\n      <name>Jiatong Shi</name>\n    </author>\n    <author>\n      <name>Yifan Peng</name>\n    </author>\n    <author>\n      <name>Roshan Sharma</name>\n    </author>\n    <author>\n      <name>Shinji Watanabe</name>\n    </author>\n    <author>\n      <name>Bhiksha Ramakrishnan</name>\n    </author>\n    <author>\n      <name>Shady Shehata</name>\n    </author>\n    <author>\n      <name>Hung-yi Lee</name>\n    </author>\n  </entry>\n</feed>\n"
}