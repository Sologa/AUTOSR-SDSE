{
  "query_title": "{Enhanced Direct Speech-to-Speech Translation Using Self-supervised Pre-training and Data Augmentation}",
  "response": "<?xml version='1.0' encoding='UTF-8'?>\n<feed xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\" xmlns:arxiv=\"http://arxiv.org/schemas/atom\" xmlns=\"http://www.w3.org/2005/Atom\">\n  <id>https://arxiv.org/api/1/dsHeca5t/EW+eg7+cWr9Q7d0k</id>\n  <title>arXiv Query: search_query=ti:\"enhanced direct speech to speech translation using self supervised pre training and data augmentation\"&amp;id_list=&amp;start=0&amp;max_results=5</title>\n  <updated>2025-12-29T13:23:53Z</updated>\n  <link href=\"https://arxiv.org/api/query?search_query=ti:%22enhanced+direct+speech+to+speech+translation+using+self+supervised+pre+training+and+data+augmentation%22&amp;start=0&amp;max_results=5&amp;id_list=\" type=\"application/atom+xml\"/>\n  <opensearch:itemsPerPage>5</opensearch:itemsPerPage>\n  <opensearch:totalResults>1</opensearch:totalResults>\n  <opensearch:startIndex>0</opensearch:startIndex>\n  <entry>\n    <id>http://arxiv.org/abs/2204.02967v3</id>\n    <title>Enhanced Direct Speech-to-Speech Translation Using Self-supervised Pre-training and Data Augmentation</title>\n    <updated>2022-09-13T17:00:55Z</updated>\n    <link href=\"https://arxiv.org/abs/2204.02967v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2204.02967v3\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Direct speech-to-speech translation (S2ST) models suffer from data scarcity issues as there exists little parallel S2ST data, compared to the amount of data available for conventional cascaded systems that consist of automatic speech recognition (ASR), machine translation (MT), and text-to-speech (TTS) synthesis. In this work, we explore self-supervised pre-training with unlabeled speech data and data augmentation to tackle this issue. We take advantage of a recently proposed speech-to-unit translation (S2UT) framework that encodes target speech into discrete representations, and transfer pre-training and efficient partial finetuning techniques that work well for speech-to-text translation (S2T) to the S2UT domain by studying both speech encoder and discrete unit decoder pre-training. Our experiments on Spanish-English translation show that self-supervised pre-training consistently improves model performance compared with multitask learning with an average 6.6-12.1 BLEU gain, and it can be further combined with data augmentation techniques that apply MT to create weakly supervised training data. Audio samples are available at: https://facebookresearch.github.io/speech_translation/enhanced_direct_s2st_units/index.html .</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SD\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"eess.AS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2022-04-06T17:59:22Z</published>\n    <arxiv:comment>Accepted to be published in the Proceedings of Interspeech 2022</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Sravya Popuri</name>\n    </author>\n    <author>\n      <name>Peng-Jen Chen</name>\n    </author>\n    <author>\n      <name>Changhan Wang</name>\n    </author>\n    <author>\n      <name>Juan Pino</name>\n    </author>\n    <author>\n      <name>Yossi Adi</name>\n    </author>\n    <author>\n      <name>Jiatao Gu</name>\n    </author>\n    <author>\n      <name>Wei-Ning Hsu</name>\n    </author>\n    <author>\n      <name>Ann Lee</name>\n    </author>\n  </entry>\n</feed>\n"
}