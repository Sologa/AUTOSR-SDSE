{
  "query_title": "{Low bit-rate speech coding with VQ-VAE and a WaveNet decoder}",
  "response": "<?xml version='1.0' encoding='UTF-8'?>\n<feed xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\" xmlns:arxiv=\"http://arxiv.org/schemas/atom\" xmlns=\"http://www.w3.org/2005/Atom\">\n  <id>https://arxiv.org/api/ug5G3CYjYHrJHnwLmOHdhXK3urM</id>\n  <title>arXiv Query: search_query=ti:\"low bit rate speech coding with vq vae and a wavenet decoder\"&amp;id_list=&amp;start=0&amp;max_results=5</title>\n  <updated>2025-12-29T13:20:10Z</updated>\n  <link href=\"https://arxiv.org/api/query?search_query=ti:%22low+bit+rate+speech+coding+with+vq+vae+and+a+wavenet+decoder%22&amp;start=0&amp;max_results=5&amp;id_list=\" type=\"application/atom+xml\"/>\n  <opensearch:itemsPerPage>5</opensearch:itemsPerPage>\n  <opensearch:totalResults>1</opensearch:totalResults>\n  <opensearch:startIndex>0</opensearch:startIndex>\n  <entry>\n    <id>http://arxiv.org/abs/1910.06464v1</id>\n    <title>Low Bit-Rate Speech Coding with VQ-VAE and a WaveNet Decoder</title>\n    <updated>2019-10-14T23:54:08Z</updated>\n    <link href=\"https://arxiv.org/abs/1910.06464v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/1910.06464v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>In order to efficiently transmit and store speech signals, speech codecs create a minimally redundant representation of the input signal which is then decoded at the receiver with the best possible perceptual quality. In this work we demonstrate that a neural network architecture based on VQ-VAE with a WaveNet decoder can be used to perform very low bit-rate speech coding with high reconstruction quality. A prosody-transparent and speaker-independent model trained on the LibriSpeech corpus coding audio at 1.6 kbps exhibits perceptual quality which is around halfway between the MELP codec at 2.4 kbps and AMR-WB codec at 23.05 kbps. In addition, when training on high-quality recorded speech with the test speaker included in the training set, a model coding speech at 1.6 kbps produces output of similar perceptual quality to that generated by AMR-WB at 23.05 kbps.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SD\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"eess.AS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2019-10-14T23:54:08Z</published>\n    <arxiv:comment>ICASSP 2019</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <arxiv:journal_ref>ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 735-739. IEEE, 2019</arxiv:journal_ref>\n    <author>\n      <name>Cristina G\u00e2rbacea</name>\n    </author>\n    <author>\n      <name>A\u00e4ron van den Oord</name>\n    </author>\n    <author>\n      <name>Yazhe Li</name>\n    </author>\n    <author>\n      <name>Felicia S C Lim</name>\n    </author>\n    <author>\n      <name>Alejandro Luebs</name>\n    </author>\n    <author>\n      <name>Oriol Vinyals</name>\n    </author>\n    <author>\n      <name>Thomas C Walters</name>\n    </author>\n    <arxiv:doi>10.1109/ICASSP.2019.8683277</arxiv:doi>\n    <link rel=\"related\" href=\"https://doi.org/10.1109/ICASSP.2019.8683277\" title=\"doi\"/>\n  </entry>\n</feed>\n"
}