{
  "query_title": "{{SELM}: Speech Enhancement Using Discrete Tokens and Language Models}",
  "response": "<?xml version='1.0' encoding='UTF-8'?>\n<feed xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\" xmlns:arxiv=\"http://arxiv.org/schemas/atom\" xmlns=\"http://www.w3.org/2005/Atom\">\n  <id>https://arxiv.org/api/XpioarXaXU6IPpyA6H34S/eVVkg</id>\n  <title>arXiv Query: search_query=ti:\"selm speech enhancement using discrete tokens and language models\"&amp;id_list=&amp;start=0&amp;max_results=5</title>\n  <updated>2025-12-29T13:24:41Z</updated>\n  <link href=\"https://arxiv.org/api/query?search_query=ti:%22selm+speech+enhancement+using+discrete+tokens+and+language+models%22&amp;start=0&amp;max_results=5&amp;id_list=\" type=\"application/atom+xml\"/>\n  <opensearch:itemsPerPage>5</opensearch:itemsPerPage>\n  <opensearch:totalResults>1</opensearch:totalResults>\n  <opensearch:startIndex>0</opensearch:startIndex>\n  <entry>\n    <id>http://arxiv.org/abs/2312.09747v2</id>\n    <title>SELM: Speech Enhancement Using Discrete Tokens and Language Models</title>\n    <updated>2024-01-07T09:02:52Z</updated>\n    <link href=\"https://arxiv.org/abs/2312.09747v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2312.09747v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Language models (LMs) have shown superior performances in various speech generation tasks recently, demonstrating their powerful ability for semantic context modeling. Given the intrinsic similarity between speech generation and speech enhancement, harnessing semantic information holds potential advantages for speech enhancement tasks. In light of this, we propose SELM, a novel paradigm for speech enhancement, which integrates discrete tokens and leverages language models. SELM comprises three stages: encoding, modeling, and decoding. We transform continuous waveform signals into discrete tokens using pre-trained self-supervised learning (SSL) models and a k-means tokenizer. Language models then capture comprehensive contextual information within these tokens. Finally, a detokenizer and HiFi-GAN restore them into enhanced speech. Experimental results demonstrate that SELM achieves comparable performance in objective metrics alongside superior results in subjective perception. Our demos are available https://honee-w.github.io/SELM/.</summary>\n    <category term=\"eess.AS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"eess.SP\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2023-12-15T12:36:05Z</published>\n    <arxiv:comment>Accepted by ICASSP 2024</arxiv:comment>\n    <arxiv:primary_category term=\"eess.AS\"/>\n    <author>\n      <name>Ziqian Wang</name>\n    </author>\n    <author>\n      <name>Xinfa Zhu</name>\n    </author>\n    <author>\n      <name>Zihan Zhang</name>\n    </author>\n    <author>\n      <name>YuanJun Lv</name>\n    </author>\n    <author>\n      <name>Ning Jiang</name>\n    </author>\n    <author>\n      <name>Guoqing Zhao</name>\n    </author>\n    <author>\n      <name>Lei Xie</name>\n    </author>\n  </entry>\n</feed>\n"
}