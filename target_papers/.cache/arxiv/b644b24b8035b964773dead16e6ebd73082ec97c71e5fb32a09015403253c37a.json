{
  "query_title": "{SpeechX: Neural Codec Language Model as a Versatile Speech Transformer}",
  "response": "<?xml version='1.0' encoding='UTF-8'?>\n<feed xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\" xmlns:arxiv=\"http://arxiv.org/schemas/atom\" xmlns=\"http://www.w3.org/2005/Atom\">\n  <id>https://arxiv.org/api/DVg0Os2K/NjcrnBIgksWowQrSCg</id>\n  <title>arXiv Query: search_query=ti:\"speechx neural codec language model as a versatile speech transformer\"&amp;id_list=&amp;start=0&amp;max_results=5</title>\n  <updated>2025-12-29T13:23:01Z</updated>\n  <link href=\"https://arxiv.org/api/query?search_query=ti:%22speechx+neural+codec+language+model+as+a+versatile+speech+transformer%22&amp;start=0&amp;max_results=5&amp;id_list=\" type=\"application/atom+xml\"/>\n  <opensearch:itemsPerPage>5</opensearch:itemsPerPage>\n  <opensearch:totalResults>1</opensearch:totalResults>\n  <opensearch:startIndex>0</opensearch:startIndex>\n  <entry>\n    <id>http://arxiv.org/abs/2308.06873v2</id>\n    <title>SpeechX: Neural Codec Language Model as a Versatile Speech Transformer</title>\n    <updated>2024-06-25T18:38:28Z</updated>\n    <link href=\"https://arxiv.org/abs/2308.06873v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2308.06873v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Recent advancements in generative speech models based on audio-text prompts have enabled remarkable innovations like high-quality zero-shot text-to-speech. However, existing models still face limitations in handling diverse audio-text speech generation tasks involving transforming input speech and processing audio captured in adverse acoustic conditions. This paper introduces SpeechX, a versatile speech generation model capable of zero-shot TTS and various speech transformation tasks, dealing with both clean and noisy signals. SpeechX combines neural codec language modeling with multi-task learning using task-dependent prompting, enabling unified and extensible modeling and providing a consistent way for leveraging textual input in speech enhancement and transformation tasks. Experimental results show SpeechX's efficacy in various tasks, including zero-shot TTS, noise suppression, target speaker extraction, speech removal, and speech editing with or without background noise, achieving comparable or superior performance to specialized models across tasks. See https://aka.ms/speechx for demo samples.</summary>\n    <category term=\"eess.AS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SD\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2023-08-14T01:01:19Z</published>\n    <arxiv:comment>To appear in TASLP. See https://aka.ms/speechx for demo samples</arxiv:comment>\n    <arxiv:primary_category term=\"eess.AS\"/>\n    <author>\n      <name>Xiaofei Wang</name>\n    </author>\n    <author>\n      <name>Manthan Thakker</name>\n    </author>\n    <author>\n      <name>Zhuo Chen</name>\n    </author>\n    <author>\n      <name>Naoyuki Kanda</name>\n    </author>\n    <author>\n      <name>Sefik Emre Eskimez</name>\n    </author>\n    <author>\n      <name>Sanyuan Chen</name>\n    </author>\n    <author>\n      <name>Min Tang</name>\n    </author>\n    <author>\n      <name>Shujie Liu</name>\n    </author>\n    <author>\n      <name>Jinyu Li</name>\n    </author>\n    <author>\n      <name>Takuya Yoshioka</name>\n    </author>\n  </entry>\n</feed>\n"
}