{
  "query_title": "{Disentangled feature learning for real-time neural speech coding}",
  "response": "<?xml version='1.0' encoding='UTF-8'?>\n<feed xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\" xmlns:arxiv=\"http://arxiv.org/schemas/atom\" xmlns=\"http://www.w3.org/2005/Atom\">\n  <id>https://arxiv.org/api/oxVxY9IXudxhGqUpZUlPgbqeGkU</id>\n  <title>arXiv Query: search_query=ti:\"disentangled feature learning for real time neural speech coding\"&amp;id_list=&amp;start=0&amp;max_results=5</title>\n  <updated>2025-12-29T13:19:40Z</updated>\n  <link href=\"https://arxiv.org/api/query?search_query=ti:%22disentangled+feature+learning+for+real+time+neural+speech+coding%22&amp;start=0&amp;max_results=5&amp;id_list=\" type=\"application/atom+xml\"/>\n  <opensearch:itemsPerPage>5</opensearch:itemsPerPage>\n  <opensearch:totalResults>1</opensearch:totalResults>\n  <opensearch:startIndex>0</opensearch:startIndex>\n  <entry>\n    <id>http://arxiv.org/abs/2211.11960v2</id>\n    <title>Disentangled Feature Learning for Real-Time Neural Speech Coding</title>\n    <updated>2023-02-25T02:30:23Z</updated>\n    <link href=\"https://arxiv.org/abs/2211.11960v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2211.11960v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Recently end-to-end neural audio/speech coding has shown its great potential to outperform traditional signal analysis based audio codecs. This is mostly achieved by following the VQ-VAE paradigm where blind features are learned, vector-quantized and coded. In this paper, instead of blind end-to-end learning, we propose to learn disentangled features for real-time neural speech coding. Specifically, more global-like speaker identity and local content features are learned with disentanglement to represent speech. Such a compact feature decomposition not only achieves better coding efficiency by exploiting bit allocation among different features but also provides the flexibility to do audio editing in embedding space, such as voice conversion in real-time communications. Both subjective and objective results demonstrate its coding efficiency and we find that the learned disentangled features show comparable performance on any-to-any voice conversion with modern self-supervised speech representation learning models with far less parameters and low latency, showing the potential of our neural coding framework.</summary>\n    <category term=\"cs.SD\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"eess.AS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2022-11-22T02:50:12Z</published>\n    <arxiv:comment>ICASSP 2023 (Accepted)</arxiv:comment>\n    <arxiv:primary_category term=\"cs.SD\"/>\n    <author>\n      <name>Xue Jiang</name>\n    </author>\n    <author>\n      <name>Xiulian Peng</name>\n    </author>\n    <author>\n      <name>Yuan Zhang</name>\n    </author>\n    <author>\n      <name>Yan Lu</name>\n    </author>\n  </entry>\n</feed>\n"
}