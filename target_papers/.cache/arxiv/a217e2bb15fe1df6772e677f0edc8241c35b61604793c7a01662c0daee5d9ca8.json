{
  "query_title": "{Harp-net: Hyper-autoencoded reconstruction propagation for scalable neural audio coding}",
  "response": "<?xml version='1.0' encoding='UTF-8'?>\n<feed xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\" xmlns:arxiv=\"http://arxiv.org/schemas/atom\" xmlns=\"http://www.w3.org/2005/Atom\">\n  <id>https://arxiv.org/api/vcUL01Y6XzbWjMY7cZJGTDdSsbQ</id>\n  <title>arXiv Query: search_query=ti:\"harp net hyper autoencoded reconstruction propagation for scalable neural audio coding\"&amp;id_list=&amp;start=0&amp;max_results=5</title>\n  <updated>2025-12-29T13:20:32Z</updated>\n  <link href=\"https://arxiv.org/api/query?search_query=ti:%22harp+net+hyper+autoencoded+reconstruction+propagation+for+scalable+neural+audio+coding%22&amp;start=0&amp;max_results=5&amp;id_list=\" type=\"application/atom+xml\"/>\n  <opensearch:itemsPerPage>5</opensearch:itemsPerPage>\n  <opensearch:totalResults>1</opensearch:totalResults>\n  <opensearch:startIndex>0</opensearch:startIndex>\n  <entry>\n    <id>http://arxiv.org/abs/2107.10843v2</id>\n    <title>HARP-Net: Hyper-Autoencoded Reconstruction Propagation for Scalable Neural Audio Coding</title>\n    <updated>2021-07-23T14:33:04Z</updated>\n    <link href=\"https://arxiv.org/abs/2107.10843v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2107.10843v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>An autoencoder-based codec employs quantization to turn its bottleneck layer activation into bitstrings, a process that hinders information flow between the encoder and decoder parts. To circumvent this issue, we employ additional skip connections between the corresponding pair of encoder-decoder layers. The assumption is that, in a mirrored autoencoder topology, a decoder layer reconstructs the intermediate feature representation of its corresponding encoder layer. Hence, any additional information directly propagated from the corresponding encoder layer helps the reconstruction. We implement this kind of skip connections in the form of additional autoencoders, each of which is a small codec that compresses the massive data transfer between the paired encoder-decoder layers. We empirically verify that the proposed hyper-autoencoded architecture improves perceptual audio quality compared to an ordinary autoencoder baseline.</summary>\n    <category term=\"eess.AS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SD\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2021-07-22T17:57:53Z</published>\n    <arxiv:comment>Accepted to the IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) 2021, Mohonk Mountain House, New Paltz, NY</arxiv:comment>\n    <arxiv:primary_category term=\"eess.AS\"/>\n    <author>\n      <name>Darius Petermann</name>\n    </author>\n    <author>\n      <name>Seungkwon Beack</name>\n    </author>\n    <author>\n      <name>Minje Kim</name>\n    </author>\n  </entry>\n</feed>\n"
}