{
  "query_title": "{{ECAPA-TDNN}: Emphasized channel attention, propagation and aggregation in {TDNN} based speaker verification}",
  "response": "<?xml version='1.0' encoding='UTF-8'?>\n<feed xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\" xmlns:arxiv=\"http://arxiv.org/schemas/atom\" xmlns=\"http://www.w3.org/2005/Atom\">\n  <id>https://arxiv.org/api/lPVQxFrK5d7nAYbk4Ok1FolpkFQ</id>\n  <title>arXiv Query: search_query=ti:\"ecapa tdnn emphasized channel attention propagation and aggregation in tdnn based speaker verification\"&amp;id_list=&amp;start=0&amp;max_results=5</title>\n  <updated>2025-12-29T13:23:25Z</updated>\n  <link href=\"https://arxiv.org/api/query?search_query=ti:%22ecapa+tdnn+emphasized+channel+attention+propagation+and+aggregation+in+tdnn+based+speaker+verification%22&amp;start=0&amp;max_results=5&amp;id_list=\" type=\"application/atom+xml\"/>\n  <opensearch:itemsPerPage>5</opensearch:itemsPerPage>\n  <opensearch:totalResults>1</opensearch:totalResults>\n  <opensearch:startIndex>0</opensearch:startIndex>\n  <entry>\n    <id>http://arxiv.org/abs/2005.07143v3</id>\n    <title>ECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation in TDNN Based Speaker Verification</title>\n    <updated>2020-08-10T13:50:24Z</updated>\n    <link href=\"https://arxiv.org/abs/2005.07143v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2005.07143v3\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Current speaker verification techniques rely on a neural network to extract speaker representations. The successful x-vector architecture is a Time Delay Neural Network (TDNN) that applies statistics pooling to project variable-length utterances into fixed-length speaker characterizing embeddings. In this paper, we propose multiple enhancements to this architecture based on recent trends in the related fields of face verification and computer vision. Firstly, the initial frame layers can be restructured into 1-dimensional Res2Net modules with impactful skip connections. Similarly to SE-ResNet, we introduce Squeeze-and-Excitation blocks in these modules to explicitly model channel interdependencies. The SE block expands the temporal context of the frame layer by rescaling the channels according to global properties of the recording. Secondly, neural networks are known to learn hierarchical features, with each layer operating on a different level of complexity. To leverage this complementary information, we aggregate and propagate features of different hierarchical levels. Finally, we improve the statistics pooling module with channel-dependent frame attention. This enables the network to focus on different subsets of frames during each of the channel's statistics estimation. The proposed ECAPA-TDNN architecture significantly outperforms state-of-the-art TDNN based systems on the VoxCeleb test sets and the 2019 VoxCeleb Speaker Recognition Challenge.</summary>\n    <category term=\"eess.AS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SD\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2020-05-14T17:02:15Z</published>\n    <arxiv:comment>proceedings of INTERSPEECH 2020</arxiv:comment>\n    <arxiv:primary_category term=\"eess.AS\"/>\n    <author>\n      <name>Brecht Desplanques</name>\n    </author>\n    <author>\n      <name>Jenthe Thienpondt</name>\n    </author>\n    <author>\n      <name>Kris Demuynck</name>\n    </author>\n    <arxiv:doi>10.21437/Interspeech.2020-2650</arxiv:doi>\n    <link rel=\"related\" href=\"https://doi.org/10.21437/Interspeech.2020-2650\" title=\"doi\"/>\n  </entry>\n</feed>\n"
}