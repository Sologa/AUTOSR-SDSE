{
  "query_title": "{LSCodec: Low-Bitrate and Speaker-Decoupled Discrete Speech Codec}",
  "response": "<?xml version='1.0' encoding='UTF-8'?>\n<feed xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\" xmlns:arxiv=\"http://arxiv.org/schemas/atom\" xmlns=\"http://www.w3.org/2005/Atom\">\n  <id>https://arxiv.org/api/lZ6n/pe4cI+qSkzQznbnG71lWpc</id>\n  <title>arXiv Query: search_query=ti:\"lscodec low bitrate and speaker decoupled discrete speech codec\"&amp;id_list=&amp;start=0&amp;max_results=5</title>\n  <updated>2025-12-29T13:21:56Z</updated>\n  <link href=\"https://arxiv.org/api/query?search_query=ti:%22lscodec+low+bitrate+and+speaker+decoupled+discrete+speech+codec%22&amp;start=0&amp;max_results=5&amp;id_list=\" type=\"application/atom+xml\"/>\n  <opensearch:itemsPerPage>5</opensearch:itemsPerPage>\n  <opensearch:totalResults>1</opensearch:totalResults>\n  <opensearch:startIndex>0</opensearch:startIndex>\n  <entry>\n    <id>http://arxiv.org/abs/2410.15764v3</id>\n    <title>LSCodec: Low-Bitrate and Speaker-Decoupled Discrete Speech Codec</title>\n    <updated>2025-05-21T16:46:32Z</updated>\n    <link href=\"https://arxiv.org/abs/2410.15764v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2410.15764v3\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Although discrete speech tokens have exhibited strong potential for language model-based speech generation, their high bitrates and redundant timbre information restrict the development of such models. In this work, we propose LSCodec, a discrete speech codec that has both low bitrate and speaker decoupling ability. LSCodec adopts a multi-stage unsupervised training framework with a speaker perturbation technique. A continuous information bottleneck is first established, followed by vector quantization that produces a discrete speaker-decoupled space. A discrete token vocoder finally refines acoustic details from LSCodec. By reconstruction evaluations, LSCodec demonstrates superior intelligibility and audio quality with only a single codebook and smaller vocabulary size than baselines. Voice conversion and speaker probing experiments prove the excellent speaker disentanglement of LSCodec, and ablation study verifies the effectiveness of the proposed training framework.</summary>\n    <category term=\"eess.AS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SD\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2024-10-21T08:23:31Z</published>\n    <arxiv:comment>5 pages, 2 figures, 3 tables. Demo page: https://cantabile-kwok.github.io/LSCodec/. Accepted to Interspeech 2025</arxiv:comment>\n    <arxiv:primary_category term=\"eess.AS\"/>\n    <author>\n      <name>Yiwei Guo</name>\n    </author>\n    <author>\n      <name>Zhihan Li</name>\n    </author>\n    <author>\n      <name>Chenpeng Du</name>\n    </author>\n    <author>\n      <name>Hankun Wang</name>\n    </author>\n    <author>\n      <name>Xie Chen</name>\n    </author>\n    <author>\n      <name>Kai Yu</name>\n    </author>\n  </entry>\n</feed>\n"
}