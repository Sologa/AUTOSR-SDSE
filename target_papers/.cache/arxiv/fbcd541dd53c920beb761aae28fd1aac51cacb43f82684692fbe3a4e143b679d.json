{
  "query_title": "{Fine-tuning Strategies for Faster Inference using Speech Self-Supervised Models: A Comparative Study}",
  "response": "<?xml version='1.0' encoding='UTF-8'?>\n<feed xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\" xmlns:arxiv=\"http://arxiv.org/schemas/atom\" xmlns=\"http://www.w3.org/2005/Atom\">\n  <id>https://arxiv.org/api/A4mHSwZrJpXmLEBLqj8CA/ow0CE</id>\n  <title>arXiv Query: search_query=ti:\"fine tuning strategies for faster inference using speech self supervised models a comparative study\"&amp;id_list=&amp;start=0&amp;max_results=5</title>\n  <updated>2025-12-29T13:21:58Z</updated>\n  <link href=\"https://arxiv.org/api/query?search_query=ti:%22fine+tuning+strategies+for+faster+inference+using+speech+self+supervised+models+a+comparative+study%22&amp;start=0&amp;max_results=5&amp;id_list=\" type=\"application/atom+xml\"/>\n  <opensearch:itemsPerPage>5</opensearch:itemsPerPage>\n  <opensearch:totalResults>1</opensearch:totalResults>\n  <opensearch:startIndex>0</opensearch:startIndex>\n  <entry>\n    <id>http://arxiv.org/abs/2303.06740v1</id>\n    <title>Fine-tuning Strategies for Faster Inference using Speech Self-Supervised Models: A Comparative Study</title>\n    <updated>2023-03-12T19:52:34Z</updated>\n    <link href=\"https://arxiv.org/abs/2303.06740v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2303.06740v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Self-supervised learning (SSL) has allowed substantial progress in Automatic Speech Recognition (ASR) performance in low-resource settings. In this context, it has been demonstrated that larger self-supervised feature extractors are crucial for achieving lower downstream ASR error rates. Thus, better performance might be sanctioned with longer inferences. This article explores different approaches that may be deployed during the fine-tuning to reduce the computations needed in the SSL encoder, leading to faster inferences. We adapt a number of existing techniques to common ASR settings and benchmark them, displaying performance drops and gains in inference times. Interestingly, we found that given enough downstream data, a simple downsampling of the input sequences outperforms the other methods with both low performance drops and high computational savings, reducing computations by 61.3% with an WER increase of only 0.81. Finally, we analyze the robustness of the comparison to changes in dataset conditions, revealing sensitivity to dataset size.</summary>\n    <category term=\"eess.AS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2023-03-12T19:52:34Z</published>\n    <arxiv:comment>Submitted to ICASSP \"Self-supervision in Audio, Speech and Beyond\" workshop</arxiv:comment>\n    <arxiv:primary_category term=\"eess.AS\"/>\n    <author>\n      <name>Salah Zaiem</name>\n    </author>\n    <author>\n      <name>Robin Algayres</name>\n    </author>\n    <author>\n      <name>Titouan Parcollet</name>\n    </author>\n    <author>\n      <name>Slim Essid</name>\n    </author>\n    <author>\n      <name>Mirco Ravanelli</name>\n    </author>\n  </entry>\n</feed>\n"
}