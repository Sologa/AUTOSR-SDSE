{
  "query_title": "{Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study}",
  "response": "<?xml version='1.0' encoding='UTF-8'?>\n<feed xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\" xmlns:arxiv=\"http://arxiv.org/schemas/atom\" xmlns=\"http://www.w3.org/2005/Atom\">\n  <id>https://arxiv.org/api/2bvdYw7MsJTHFq0at1Z7nK+L5Xs</id>\n  <title>arXiv Query: search_query=ti:\"exploring speech recognition translation and understanding with discrete speech units a comparative study\"&amp;id_list=&amp;start=0&amp;max_results=5</title>\n  <updated>2025-12-29T13:24:37Z</updated>\n  <link href=\"https://arxiv.org/api/query?search_query=ti:%22exploring+speech+recognition+translation+and+understanding+with+discrete+speech+units+a+comparative+study%22&amp;start=0&amp;max_results=5&amp;id_list=\" type=\"application/atom+xml\"/>\n  <opensearch:itemsPerPage>5</opensearch:itemsPerPage>\n  <opensearch:totalResults>1</opensearch:totalResults>\n  <opensearch:startIndex>0</opensearch:startIndex>\n  <entry>\n    <id>http://arxiv.org/abs/2309.15800v1</id>\n    <title>Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study</title>\n    <updated>2023-09-27T17:21:13Z</updated>\n    <link href=\"https://arxiv.org/abs/2309.15800v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2309.15800v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Speech signals, typically sampled at rates in the tens of thousands per second, contain redundancies, evoking inefficiencies in sequence modeling. High-dimensional speech features such as spectrograms are often used as the input for the subsequent model. However, they can still be redundant. Recent investigations proposed the use of discrete speech units derived from self-supervised learning representations, which significantly compresses the size of speech data. Applying various methods, such as de-duplication and subword modeling, can further compress the speech sequence length. Hence, training time is significantly reduced while retaining notable performance. In this study, we undertake a comprehensive and systematic exploration into the application of discrete units within end-to-end speech processing models. Experiments on 12 automatic speech recognition, 3 speech translation, and 1 spoken language understanding corpora demonstrate that discrete units achieve reasonably good results in almost all the settings. We intend to release our configurations and trained models to foster future research efforts.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SD\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"eess.AS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2023-09-27T17:21:13Z</published>\n    <arxiv:comment>Submitted to IEEE ICASSP 2024</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Xuankai Chang</name>\n    </author>\n    <author>\n      <name>Brian Yan</name>\n    </author>\n    <author>\n      <name>Kwanghee Choi</name>\n    </author>\n    <author>\n      <name>Jeeweon Jung</name>\n    </author>\n    <author>\n      <name>Yichen Lu</name>\n    </author>\n    <author>\n      <name>Soumi Maiti</name>\n    </author>\n    <author>\n      <name>Roshan Sharma</name>\n    </author>\n    <author>\n      <name>Jiatong Shi</name>\n    </author>\n    <author>\n      <name>Jinchuan Tian</name>\n    </author>\n    <author>\n      <name>Shinji Watanabe</name>\n    </author>\n    <author>\n      <name>Yuya Fujita</name>\n    </author>\n    <author>\n      <name>Takashi Maekaku</name>\n    </author>\n    <author>\n      <name>Pengcheng Guo</name>\n    </author>\n    <author>\n      <name>Yao-Fei Cheng</name>\n    </author>\n    <author>\n      <name>Pavel Denisov</name>\n    </author>\n    <author>\n      <name>Kohei Saijo</name>\n    </author>\n    <author>\n      <name>Hsiu-Hsuan Wang</name>\n    </author>\n  </entry>\n</feed>\n"
}