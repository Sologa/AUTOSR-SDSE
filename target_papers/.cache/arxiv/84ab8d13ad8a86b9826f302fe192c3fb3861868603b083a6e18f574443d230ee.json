{
  "query_title": "{{FunCodec}: A Fundamental, Reproducible and Integrable Open-source Toolkit for Neural Speech Codec}",
  "response": "<?xml version='1.0' encoding='UTF-8'?>\n<feed xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\" xmlns:arxiv=\"http://arxiv.org/schemas/atom\" xmlns=\"http://www.w3.org/2005/Atom\">\n  <id>https://arxiv.org/api/Jb747y8sItuOvu7Ep+PUHyMImLY</id>\n  <title>arXiv Query: search_query=ti:\"funcodec a fundamental reproducible and integrable open source toolkit for neural speech codec\"&amp;id_list=&amp;start=0&amp;max_results=5</title>\n  <updated>2025-12-29T13:22:42Z</updated>\n  <link href=\"https://arxiv.org/api/query?search_query=ti:%22funcodec+a+fundamental+reproducible+and+integrable+open+source+toolkit+for+neural+speech+codec%22&amp;start=0&amp;max_results=5&amp;id_list=\" type=\"application/atom+xml\"/>\n  <opensearch:itemsPerPage>5</opensearch:itemsPerPage>\n  <opensearch:totalResults>1</opensearch:totalResults>\n  <opensearch:startIndex>0</opensearch:startIndex>\n  <entry>\n    <id>http://arxiv.org/abs/2309.07405v2</id>\n    <title>FunCodec: A Fundamental, Reproducible and Integrable Open-source Toolkit for Neural Speech Codec</title>\n    <updated>2023-10-07T02:56:00Z</updated>\n    <link href=\"https://arxiv.org/abs/2309.07405v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2309.07405v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>This paper presents FunCodec, a fundamental neural speech codec toolkit, which is an extension of the open-source speech processing toolkit FunASR. FunCodec provides reproducible training recipes and inference scripts for the latest neural speech codec models, such as SoundStream and Encodec. Thanks to the unified design with FunASR, FunCodec can be easily integrated into downstream tasks, such as speech recognition. Along with FunCodec, pre-trained models are also provided, which can be used for academic or generalized purposes. Based on the toolkit, we further propose the frequency-domain codec models, FreqCodec, which can achieve comparable speech quality with much lower computation and parameter complexity. Experimental results show that, under the same compression ratio, FunCodec can achieve better reconstruction quality compared with other toolkits and released models. We also demonstrate that the pre-trained models are suitable for downstream tasks, including automatic speech recognition and personalized text-to-speech synthesis. This toolkit is publicly available at https://github.com/alibaba-damo-academy/FunCodec.</summary>\n    <category term=\"cs.SD\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"eess.AS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2023-09-14T03:18:24Z</published>\n    <arxiv:comment>5 pages, 3 figures, submitted to ICASSP 2024</arxiv:comment>\n    <arxiv:primary_category term=\"cs.SD\"/>\n    <author>\n      <name>Zhihao Du</name>\n    </author>\n    <author>\n      <name>Shiliang Zhang</name>\n    </author>\n    <author>\n      <name>Kai Hu</name>\n    </author>\n    <author>\n      <name>Siqi Zheng</name>\n    </author>\n  </entry>\n</feed>\n"
}