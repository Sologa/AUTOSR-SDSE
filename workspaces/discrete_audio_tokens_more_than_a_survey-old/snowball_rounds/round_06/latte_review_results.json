[
  {
    "title": "An Unsupervised Approach to Speech Segmentation using Auto Resonance Networks",
    "abstract": "Automatic speech segmentation finds application in speech recognition, speaker diarization etc. However, it is challenging as it demands huge labelled data. Unsupervised approach can overcome the laborious labeling task. Auto resonance networks are one choice for unsupervised approach. Recently auto resonance networks have been used in classification problems. This work proposes an unsupervised approach for speech segmentation using auto resonance networks. The system is tested using the standard TIMIT database and a few pathological speech utterances. Results show that the speech frames belonging to the same broad class are assigned to the same cluster. The results are compared with another neural network approach, namely, self organizing maps.",
    "metadata": {
      "title": "An Unsupervised Approach to Speech Segmentation using Auto Resonance Networks",
      "summary": "Automatic speech segmentation finds application in speech recognition, speaker diarization etc. However, it is challenging as it demands huge labelled data. Unsupervised approach can overcome the laborious labeling task. Auto resonance networks are one choice for unsupervised approach. Recently auto resonance networks have been used in classification problems. This work proposes an unsupervised approach for speech segmentation using auto resonance networks. The system is tested using the standard TIMIT database and a few pathological speech utterances. Results show that the speech frames belonging to the same broad class are assigned to the same cluster. The results are compared with another neural network approach, namely, self organizing maps.",
      "abstract": "Automatic speech segmentation finds application in speech recognition, speaker diarization etc. However, it is challenging as it demands huge labelled data. Unsupervised approach can overcome the laborious labeling task. Auto resonance networks are one choice for unsupervised approach. Recently auto resonance networks have been used in classification problems. This work proposes an unsupervised approach for speech segmentation using auto resonance networks. The system is tested using the standard TIMIT database and a few pathological speech utterances. Results show that the speech frames belonging to the same broad class are assigned to the same cluster. The results are compared with another neural network approach, namely, self organizing maps.",
      "doi": "https://doi.org/10.1109/mysurucon59703.2023.10396940",
      "openalex_id": "https://openalex.org/W4391182775",
      "arxiv_id": "",
      "publication_date": "2023-12-01",
      "published": "2023-12-01",
      "source": "openalex_snowball"
    },
    "round-A_JuniorNano_output": {
      "reasoning": "The title/abstract describe unsupervised speech segmentation with Auto Resonance Networks and clustering, but there is no discussion of discrete audio token design/quantization (VQ/RVQ) or token-based representations required by the inclusion criteria.",
      "evaluation": 1
    },
    "round-A_JuniorNano_reasoning": "The title/abstract describe unsupervised speech segmentation with Auto Resonance Networks and clustering, but there is no discussion of discrete audio token design/quantization (VQ/RVQ) or token-based representations required by the inclusion criteria.",
    "round-A_JuniorNano_evaluation": 1,
    "round-A_JuniorMini_output": {
      "reasoning": "The paper proposes an unsupervised approach for speech segmentation using auto resonance networks, focusing on clustering speech frames, but it does not describe generating discrete audio tokens, quantization methods, or token utilization for sequence or language models, which are critical inclusion criteria.",
      "evaluation": 1
    },
    "round-A_JuniorMini_reasoning": "The paper proposes an unsupervised approach for speech segmentation using auto resonance networks, focusing on clustering speech frames, but it does not describe generating discrete audio tokens, quantization methods, or token utilization for sequence or language models, which are critical inclusion criteria.",
    "round-A_JuniorMini_evaluation": 1,
    "final_verdict": "exclude (junior:1)",
    "review_skipped": false,
    "discard_reason": "exclude (junior:1)"
  },
  {
    "title": "Truly Unsupervised Acoustic Word Embeddings Using Weak Top-down Constraints in Encoder-decoder Models",
    "abstract": "We investigate unsupervised models that can map a variable-duration speech segment to a fixed-dimensional representation. In settings where unlabelled speech is the only available resource, such acoustic word embeddings can form the basis for \"zero-resource\" speech search, discovery and indexing systems. Most existing unsupervised embedding methods still use some supervision, such as word or phoneme boundaries. Here we propose the encoder-decoder correspondence autoencoder (EncDec-CAE), which, instead of true word segments, uses automatically discovered segments: an unsupervised term discovery system finds pairs of words of the same unknown type, and the EncDec-CAE is trained to reconstruct one word given the other as input. We compare it to a standard encoder-decoder autoencoder (AE), a variational AE with a prior over its latent embedding, and downsampling. EncDec-CAE outperforms its closest competitor by 24% relative in average precision on two languages in a word discrimination task.",
    "metadata": {
      "title": "Truly Unsupervised Acoustic Word Embeddings Using Weak Top-down Constraints in Encoder-decoder Models",
      "summary": "We investigate unsupervised models that can map a variable-duration speech segment to a fixed-dimensional representation. In settings where unlabelled speech is the only available resource, such acoustic word embeddings can form the basis for \"zero-resource\" speech search, discovery and indexing systems. Most existing unsupervised embedding methods still use some supervision, such as word or phoneme boundaries. Here we propose the encoder-decoder correspondence autoencoder (EncDec-CAE), which, instead of true word segments, uses automatically discovered segments: an unsupervised term discovery system finds pairs of words of the same unknown type, and the EncDec-CAE is trained to reconstruct one word given the other as input. We compare it to a standard encoder-decoder autoencoder (AE), a variational AE with a prior over its latent embedding, and downsampling. EncDec-CAE outperforms its closest competitor by 24% relative in average precision on two languages in a word discrimination task.",
      "abstract": "We investigate unsupervised models that can map a variable-duration speech segment to a fixed-dimensional representation. In settings where unlabelled speech is the only available resource, such acoustic word embeddings can form the basis for \"zero-resource\" speech search, discovery and indexing systems. Most existing unsupervised embedding methods still use some supervision, such as word or phoneme boundaries. Here we propose the encoder-decoder correspondence autoencoder (EncDec-CAE), which, instead of true word segments, uses automatically discovered segments: an unsupervised term discovery system finds pairs of words of the same unknown type, and the EncDec-CAE is trained to reconstruct one word given the other as input. We compare it to a standard encoder-decoder autoencoder (AE), a variational AE with a prior over its latent embedding, and downsampling. EncDec-CAE outperforms its closest competitor by 24% relative in average precision on two languages in a word discrimination task.",
      "doi": "https://doi.org/10.1109/icassp.2019.8683639",
      "openalex_id": "https://openalex.org/W2899069432",
      "arxiv_id": "",
      "publication_date": "2019-04-17",
      "published": "2019-04-17",
      "source": "openalex_snowball"
    },
    "round-A_JuniorNano_output": {
      "reasoning": "The study focuses on unsupervised acoustic word embeddings using autoencoder-based reconstruction with automatically discovered word segments, but it does not present a discrete audio token generation/quantization framework (e.g., VQ/RVQ, token corpora, or semantic-disentangled discrete tokens) required by the inclusion criteria.",
      "evaluation": 1
    },
    "round-A_JuniorNano_reasoning": "The study focuses on unsupervised acoustic word embeddings using autoencoder-based reconstruction with automatically discovered word segments, but it does not present a discrete audio token generation/quantization framework (e.g., VQ/RVQ, token corpora, or semantic-disentangled discrete tokens) required by the inclusion criteria.",
    "round-A_JuniorNano_evaluation": 1,
    "round-A_JuniorMini_output": {
      "reasoning": "The study focuses on unsupervised acoustic word embeddings using encoder-decoder models to map speech segments to fixed-dimensional representations; however, it does not describe or emphasize the generation of discrete audio tokens (e.g., via vector quantization or similar) as a core method or contribution, nor does it clarify the token generation process for use in language or sequence models, which is a key inclusion criterion. Therefore, it does not meet the main criteria requiring discrete audio token design or production for downstream modeling.",
      "evaluation": 1
    },
    "round-A_JuniorMini_reasoning": "The study focuses on unsupervised acoustic word embeddings using encoder-decoder models to map speech segments to fixed-dimensional representations; however, it does not describe or emphasize the generation of discrete audio tokens (e.g., via vector quantization or similar) as a core method or contribution, nor does it clarify the token generation process for use in language or sequence models, which is a key inclusion criterion. Therefore, it does not meet the main criteria requiring discrete audio token design or production for downstream modeling.",
    "round-A_JuniorMini_evaluation": 1,
    "final_verdict": "exclude (junior:1)",
    "review_skipped": false,
    "discard_reason": "exclude (junior:1)"
  },
  {
    "title": "Evaluating speech features with the minimal-pair ABX task (II): resistance to noise",
    "abstract": "The Minimal-Pair ABX (MP-ABX) paradigm has been proposed as a method for evaluating speech features for zeroresource/unsupervised speech technologies. We apply it in a phoneme discrimination task on the Articulation Index corpus to evaluate the resistance to noise of various speech features. In Experiment 1, we evaluate the robustness to additive noise at different signal-to-noise ratios, using car and babble noise from the Aurora-4 database and white noise. In Experiment 2, we examine the robustness to different kinds of convolutional noise. In both experiments we consider two classes of techniques to induce noise resistance: smoothing of the time-frequency representation and short-term adaptation in the time-domain. We consider smoothing along the spectral axis (as in PLP) and along the time axis (as in FDLP). For short-term adaptation in the time-domain, we compare the use of a static compressive non-linearity followed by RASTA filtering to an adaptive compression scheme.",
    "metadata": {
      "title": "Evaluating speech features with the minimal-pair ABX task (II): resistance to noise",
      "summary": "The Minimal-Pair ABX (MP-ABX) paradigm has been proposed as a method for evaluating speech features for zeroresource/unsupervised speech technologies. We apply it in a phoneme discrimination task on the Articulation Index corpus to evaluate the resistance to noise of various speech features. In Experiment 1, we evaluate the robustness to additive noise at different signal-to-noise ratios, using car and babble noise from the Aurora-4 database and white noise. In Experiment 2, we examine the robustness to different kinds of convolutional noise. In both experiments we consider two classes of techniques to induce noise resistance: smoothing of the time-frequency representation and short-term adaptation in the time-domain. We consider smoothing along the spectral axis (as in PLP) and along the time axis (as in FDLP). For short-term adaptation in the time-domain, we compare the use of a static compressive non-linearity followed by RASTA filtering to an adaptive compression scheme.",
      "abstract": "The Minimal-Pair ABX (MP-ABX) paradigm has been proposed as a method for evaluating speech features for zeroresource/unsupervised speech technologies. We apply it in a phoneme discrimination task on the Articulation Index corpus to evaluate the resistance to noise of various speech features. In Experiment 1, we evaluate the robustness to additive noise at different signal-to-noise ratios, using car and babble noise from the Aurora-4 database and white noise. In Experiment 2, we examine the robustness to different kinds of convolutional noise. In both experiments we consider two classes of techniques to induce noise resistance: smoothing of the time-frequency representation and short-term adaptation in the time-domain. We consider smoothing along the spectral axis (as in PLP) and along the time axis (as in FDLP). For short-term adaptation in the time-domain, we compare the use of a static compressive non-linearity followed by RASTA filtering to an adaptive compression scheme.",
      "doi": "https://doi.org/10.21437/interspeech.2014-228",
      "openalex_id": "https://openalex.org/W2406349064",
      "arxiv_id": "",
      "publication_date": "2014-09-14",
      "published": "2014-09-14",
      "source": "openalex_snowball"
    },
    "round-A_JuniorNano_output": {
      "reasoning": "The abstract describes evaluating speech features for noise resistance using MP-ABX and smoothing/adaptation techniques, none of which centers on discrete audio tokens or tokenization as the core research contribution, thus it does not meet the inclusion criteria.",
      "evaluation": 1
    },
    "round-A_JuniorNano_reasoning": "The abstract describes evaluating speech features for noise resistance using MP-ABX and smoothing/adaptation techniques, none of which centers on discrete audio tokens or tokenization as the core research contribution, thus it does not meet the inclusion criteria.",
    "round-A_JuniorNano_evaluation": 1,
    "round-A_JuniorMini_output": {
      "reasoning": "The title and abstract focus on evaluating speech features for noise robustness using the Minimal-Pair ABX task, specifically examining signal processing techniques for noise resistance. However, there is no mention or indication that the study involves the generation or design of discrete audio tokens, vector quantization, or any tokenization mechanisms that are central to the inclusion criteria. The work seems to concentrate on acoustic feature evaluation rather than discrete token-based representation or modeling for language models. Therefore, it does not meet the inclusion criteria related to discrete audio token design and usage, nor does it address token generation processes or their application in sequence modeling.",
      "evaluation": 1
    },
    "round-A_JuniorMini_reasoning": "The title and abstract focus on evaluating speech features for noise robustness using the Minimal-Pair ABX task, specifically examining signal processing techniques for noise resistance. However, there is no mention or indication that the study involves the generation or design of discrete audio tokens, vector quantization, or any tokenization mechanisms that are central to the inclusion criteria. The work seems to concentrate on acoustic feature evaluation rather than discrete token-based representation or modeling for language models. Therefore, it does not meet the inclusion criteria related to discrete audio token design and usage, nor does it address token generation processes or their application in sequence modeling.",
    "round-A_JuniorMini_evaluation": 1,
    "final_verdict": "exclude (junior:1)",
    "review_skipped": false,
    "discard_reason": "exclude (junior:1)"
  },
  {
    "title": "Bayesian unsupervised word segmentation with nested Pitman-Yor language modeling",
    "abstract": "In this paper, we propose a new Bayesian model for fully unsupervised word segmentation and an efficient blocked Gibbs sampler combined with dynamic programming for inference. Our model is a nested hierarchical Pitman-Yor language model, where Pitman-Yor spelling model is embedded in the word model. We confirmed that it significantly outperforms previous reported results in both phonetic transcripts and standard datasets for Chinese and Japanese word segmentation. Our model is also considered as a way to construct an accurate word n-gram language model directly from characters of arbitrary language, without any \"word\" indications.",
    "metadata": {
      "title": "Bayesian unsupervised word segmentation with nested Pitman-Yor language modeling",
      "summary": "In this paper, we propose a new Bayesian model for fully unsupervised word segmentation and an efficient blocked Gibbs sampler combined with dynamic programming for inference. Our model is a nested hierarchical Pitman-Yor language model, where Pitman-Yor spelling model is embedded in the word model. We confirmed that it significantly outperforms previous reported results in both phonetic transcripts and standard datasets for Chinese and Japanese word segmentation. Our model is also considered as a way to construct an accurate word n-gram language model directly from characters of arbitrary language, without any \"word\" indications.",
      "abstract": "In this paper, we propose a new Bayesian model for fully unsupervised word segmentation and an efficient blocked Gibbs sampler combined with dynamic programming for inference. Our model is a nested hierarchical Pitman-Yor language model, where Pitman-Yor spelling model is embedded in the word model. We confirmed that it significantly outperforms previous reported results in both phonetic transcripts and standard datasets for Chinese and Japanese word segmentation. Our model is also considered as a way to construct an accurate word n-gram language model directly from characters of arbitrary language, without any \"word\" indications.",
      "doi": "https://doi.org/10.3115/1687878.1687894",
      "openalex_id": "https://openalex.org/W2140991203",
      "arxiv_id": "",
      "publication_date": "2009-01-01",
      "published": "2009-01-01",
      "source": "openalex_snowball"
    },
    "round-A_JuniorNano_output": {
      "reasoning": "The item focuses on unsupervised word segmentation in text using Pitman-Yor language modeling; it does not discuss discrete audio tokens, token generation, or audio-language modeling as defined by the criteria, so it should be excluded.",
      "evaluation": 1
    },
    "round-A_JuniorNano_reasoning": "The item focuses on unsupervised word segmentation in text using Pitman-Yor language modeling; it does not discuss discrete audio tokens, token generation, or audio-language modeling as defined by the criteria, so it should be excluded.",
    "round-A_JuniorNano_evaluation": 1,
    "round-A_JuniorMini_output": {
      "reasoning": "The study focuses on Bayesian unsupervised word segmentation using a nested hierarchical Pitman-Yor language model and does not address the generation or design of discrete audio tokens from continuous audio signals, nor does it describe any quantization or tokenization process related to audio data for use in language or sequence models. Therefore, it does not meet the main inclusion criteria focused on discrete audio tokens and their production or utilization as defined.",
      "evaluation": 1
    },
    "round-A_JuniorMini_reasoning": "The study focuses on Bayesian unsupervised word segmentation using a nested hierarchical Pitman-Yor language model and does not address the generation or design of discrete audio tokens from continuous audio signals, nor does it describe any quantization or tokenization process related to audio data for use in language or sequence models. Therefore, it does not meet the main inclusion criteria focused on discrete audio tokens and their production or utilization as defined.",
    "round-A_JuniorMini_evaluation": 1,
    "final_verdict": "exclude (junior:1)",
    "review_skipped": false,
    "discard_reason": "exclude (junior:1)"
  },
  {
    "title": "A density-based algorithm for discovering clusters in large spatial Databases with Noise",
    "abstract": "Clustering algorithms are attractive for the task of class identification in spatial databases. However, the application to large spatial databases rises the following requirements for clustering algorithms: minimal requirements of domain knowledge to determine the input parameters, discovery of clusters with arbitrary shape and good efficiency on large databases. The well-known clustering algorithms offer no solution to the combination of these requirements. In this paper, we present the new clustering algorithm DBSCAN relying on a density-based notion of clusters which is designed to discover clusters of arbitrary shape. DBSCAN requires only one input parameter and supports the user in determining an appropriate value for it. We performed an experimental evaluation of the effectiveness and efficiency of DBSCAN using synthetic data and real data of the SEQUOIA 2000 benchmark. The results of our experiments demonstrate that (1) DBSCAN is significantly more effective in discovering clusters of arbitrary shape than the well-known algorithm CLAR-ANS, and that (2) DBSCAN outperforms CLARANS by a factor of more than 100 in terms of efficiency.",
    "metadata": {
      "title": "A density-based algorithm for discovering clusters in large spatial Databases with Noise",
      "summary": "Clustering algorithms are attractive for the task of class identification in spatial databases. However, the application to large spatial databases rises the following requirements for clustering algorithms: minimal requirements of domain knowledge to determine the input parameters, discovery of clusters with arbitrary shape and good efficiency on large databases. The well-known clustering algorithms offer no solution to the combination of these requirements. In this paper, we present the new clustering algorithm DBSCAN relying on a density-based notion of clusters which is designed to discover clusters of arbitrary shape. DBSCAN requires only one input parameter and supports the user in determining an appropriate value for it. We performed an experimental evaluation of the effectiveness and efficiency of DBSCAN using synthetic data and real data of the SEQUOIA 2000 benchmark. The results of our experiments demonstrate that (1) DBSCAN is significantly more effective in discovering clusters of arbitrary shape than the well-known algorithm CLAR-ANS, and that (2) DBSCAN outperforms CLARANS by a factor of more than 100 in terms of efficiency.",
      "abstract": "Clustering algorithms are attractive for the task of class identification in spatial databases. However, the application to large spatial databases rises the following requirements for clustering algorithms: minimal requirements of domain knowledge to determine the input parameters, discovery of clusters with arbitrary shape and good efficiency on large databases. The well-known clustering algorithms offer no solution to the combination of these requirements. In this paper, we present the new clustering algorithm DBSCAN relying on a density-based notion of clusters which is designed to discover clusters of arbitrary shape. DBSCAN requires only one input parameter and supports the user in determining an appropriate value for it. We performed an experimental evaluation of the effectiveness and efficiency of DBSCAN using synthetic data and real data of the SEQUOIA 2000 benchmark. The results of our experiments demonstrate that (1) DBSCAN is significantly more effective in discovering clusters of arbitrary shape than the well-known algorithm CLAR-ANS, and that (2) DBSCAN outperforms CLARANS by a factor of more than 100 in terms of efficiency.",
      "doi": "",
      "openalex_id": "https://openalex.org/W1673310716",
      "arxiv_id": "",
      "publication_date": "1996-01-01",
      "published": "1996-01-01",
      "source": "openalex_snowball"
    },
    "round-A_JuniorNano_output": {
      "reasoning": "本題與主題離散音訊 token 完全無關，該論文為 DBSCAN 的密度基聚類演算法，與離散音訊 token 的設計、量化與語言模型應用無關，因此不符合納入條件。",
      "evaluation": 1
    },
    "round-A_JuniorNano_reasoning": "本題與主題離散音訊 token 完全無關，該論文為 DBSCAN 的密度基聚類演算法，與離散音訊 token 的設計、量化與語言模型應用無關，因此不符合納入條件。",
    "round-A_JuniorNano_evaluation": 1,
    "round-A_JuniorMini_output": {
      "reasoning": "The title and abstract describe a clustering algorithm for spatial databases that focuses on discovering clusters in data, which is unrelated to the discrete audio token domain defined in the inclusion criteria. There is no mention of audio signals, vector quantization related to audio, or tokenization processes suitable for language or sequence models based on audio. Thus, the study does not meet the inclusion criteria and conflicts with the exclusion criteria as it does not relate to discrete audio tokens or their generation.",
      "evaluation": 1
    },
    "round-A_JuniorMini_reasoning": "The title and abstract describe a clustering algorithm for spatial databases that focuses on discovering clusters in data, which is unrelated to the discrete audio token domain defined in the inclusion criteria. There is no mention of audio signals, vector quantization related to audio, or tokenization processes suitable for language or sequence models based on audio. Thus, the study does not meet the inclusion criteria and conflicts with the exclusion criteria as it does not relate to discrete audio tokens or their generation.",
    "round-A_JuniorMini_evaluation": 1,
    "final_verdict": "exclude (junior:1)",
    "review_skipped": false,
    "discard_reason": "exclude (junior:1)"
  },
  {
    "title": "Statistical mechanics of community detection",
    "abstract": "Starting from a general ansatz, we show how community detection can be interpreted as finding the ground state of an infinite range spin glass. Our approach applies to weighted and directed networks alike. It contains the ad hoc introduced quality function from [J. Reichardt and S. Bornholdt, Phys. Rev. Lett. 93, 218701 (2004)] and the modularity Q as defined by Newman and Girvan [Phys. Rev. E 69, 026113 (2004)] as special cases. The community structure of the network is interpreted as the spin configuration that minimizes the energy of the spin glass with the spin states being the community indices. We elucidate the properties of the ground state configuration to give a concise definition of communities as cohesive subgroups in networks that is adaptive to the specific class of network under study. Further, we show how hierarchies and overlap in the community structure can be detected. Computationally efficient local update rules for optimization procedures to find the ground state are given. We show how the ansatz may be used to discover the community around a given node without detecting all communities in the full network and we give benchmarks for the performance of this extension. Finally, we give expectation values for the modularity of random graphs, which can be used in the assessment of statistical significance of community structure.",
    "metadata": {
      "title": "Statistical mechanics of community detection",
      "summary": "Starting from a general ansatz, we show how community detection can be interpreted as finding the ground state of an infinite range spin glass. Our approach applies to weighted and directed networks alike. It contains the ad hoc introduced quality function from [J. Reichardt and S. Bornholdt, Phys. Rev. Lett. 93, 218701 (2004)] and the modularity Q as defined by Newman and Girvan [Phys. Rev. E 69, 026113 (2004)] as special cases. The community structure of the network is interpreted as the spin configuration that minimizes the energy of the spin glass with the spin states being the community indices. We elucidate the properties of the ground state configuration to give a concise definition of communities as cohesive subgroups in networks that is adaptive to the specific class of network under study. Further, we show how hierarchies and overlap in the community structure can be detected. Computationally efficient local update rules for optimization procedures to find the ground state are given. We show how the ansatz may be used to discover the community around a given node without detecting all communities in the full network and we give benchmarks for the performance of this extension. Finally, we give expectation values for the modularity of random graphs, which can be used in the assessment of statistical significance of community structure.",
      "abstract": "Starting from a general ansatz, we show how community detection can be interpreted as finding the ground state of an infinite range spin glass. Our approach applies to weighted and directed networks alike. It contains the ad hoc introduced quality function from [J. Reichardt and S. Bornholdt, Phys. Rev. Lett. 93, 218701 (2004)] and the modularity Q as defined by Newman and Girvan [Phys. Rev. E 69, 026113 (2004)] as special cases. The community structure of the network is interpreted as the spin configuration that minimizes the energy of the spin glass with the spin states being the community indices. We elucidate the properties of the ground state configuration to give a concise definition of communities as cohesive subgroups in networks that is adaptive to the specific class of network under study. Further, we show how hierarchies and overlap in the community structure can be detected. Computationally efficient local update rules for optimization procedures to find the ground state are given. We show how the ansatz may be used to discover the community around a given node without detecting all communities in the full network and we give benchmarks for the performance of this extension. Finally, we give expectation values for the modularity of random graphs, which can be used in the assessment of statistical significance of community structure.",
      "doi": "https://doi.org/10.1103/physreve.74.016110",
      "openalex_id": "https://openalex.org/W2025543856",
      "arxiv_id": "",
      "publication_date": "2006-07-18",
      "published": "2006-07-18",
      "source": "openalex_snowball"
    },
    "round-A_JuniorNano_output": {
      "reasoning": "此项为网络社区检测的统计力学论文，与离散音频 token 的研究方向不符，且未给出可评估的离散音频表征/量化方法，因此应排除。",
      "evaluation": 1
    },
    "round-A_JuniorNano_reasoning": "此项为网络社区检测的统计力学论文，与离散音频 token 的研究方向不符，且未给出可评估的离散音频表征/量化方法，因此应排除。",
    "round-A_JuniorNano_evaluation": 1,
    "round-A_JuniorMini_output": {
      "reasoning": "The title and abstract discuss community detection in networks through statistical mechanics concepts like spin glass models, without any mention of discrete audio tokens, audio signal processing, vector quantization, or related audio language modeling techniques. The content is unrelated to the inclusion criteria focused on discrete audio token design and usage for audio sequence modeling and thus does not meet the inclusion requirements.",
      "evaluation": 1
    },
    "round-A_JuniorMini_reasoning": "The title and abstract discuss community detection in networks through statistical mechanics concepts like spin glass models, without any mention of discrete audio tokens, audio signal processing, vector quantization, or related audio language modeling techniques. The content is unrelated to the inclusion criteria focused on discrete audio token design and usage for audio sequence modeling and thus does not meet the inclusion requirements.",
    "round-A_JuniorMini_evaluation": 1,
    "final_verdict": "exclude (junior:1)",
    "review_skipped": false,
    "discard_reason": "exclude (junior:1)"
  },
  {
    "title": "Robust word boundary detection in spontaneous speech using acoustic and lexical cues",
    "abstract": "We consider the problem of word boundary detection in spontaneous speech utterances. Acoustic features have been well explored in the literature in the context of word boundary detection; however, in spontaneous speech of Switchboard-I corpus, we found that the accuracy of word boundary detection using acoustic features is poor (F-score ~ 0.63). We propose a new feature - that captures lexical cues in the context of the word boundary detection problem. We show that including proposed lexical feature along with the usual acoustic features, the accuracy of the word boundary detection improves considerably (F-score ~ 0.81). We also demonstrate the robustness of our proposed feature in presence of different noise levels for additive white and pink noise.",
    "metadata": {
      "title": "Robust word boundary detection in spontaneous speech using acoustic and lexical cues",
      "summary": "We consider the problem of word boundary detection in spontaneous speech utterances. Acoustic features have been well explored in the literature in the context of word boundary detection; however, in spontaneous speech of Switchboard-I corpus, we found that the accuracy of word boundary detection using acoustic features is poor (F-score ~ 0.63). We propose a new feature - that captures lexical cues in the context of the word boundary detection problem. We show that including proposed lexical feature along with the usual acoustic features, the accuracy of the word boundary detection improves considerably (F-score ~ 0.81). We also demonstrate the robustness of our proposed feature in presence of different noise levels for additive white and pink noise.",
      "abstract": "We consider the problem of word boundary detection in spontaneous speech utterances. Acoustic features have been well explored in the literature in the context of word boundary detection; however, in spontaneous speech of Switchboard-I corpus, we found that the accuracy of word boundary detection using acoustic features is poor (F-score ~ 0.63). We propose a new feature - that captures lexical cues in the context of the word boundary detection problem. We show that including proposed lexical feature along with the usual acoustic features, the accuracy of the word boundary detection improves considerably (F-score ~ 0.81). We also demonstrate the robustness of our proposed feature in presence of different noise levels for additive white and pink noise.",
      "doi": "https://doi.org/10.1109/icassp.2009.4960701",
      "openalex_id": "https://openalex.org/W2100308344",
      "arxiv_id": "",
      "publication_date": "2009-04-01",
      "published": "2009-04-01",
      "source": "openalex_snowball"
    },
    "round-A_JuniorNano_output": {
      "reasoning": "The paper addresses word boundary detection using acoustic and lexical cues and does not present any discrete audio token representations or tokenization/quantization methods (e.g., VQ/RVQ, SSL-based discrete tokens), so it does not satisfy the 'Discrete Audio Tokens' inclusion criteria and should be excluded.",
      "evaluation": 1
    },
    "round-A_JuniorNano_reasoning": "The paper addresses word boundary detection using acoustic and lexical cues and does not present any discrete audio token representations or tokenization/quantization methods (e.g., VQ/RVQ, SSL-based discrete tokens), so it does not satisfy the 'Discrete Audio Tokens' inclusion criteria and should be excluded.",
    "round-A_JuniorNano_evaluation": 1,
    "round-A_JuniorMini_output": {
      "reasoning": "The paper focuses on word boundary detection using acoustic and lexical cues, which is related to speech processing but does not involve the creation or use of discrete audio tokens derived by vector quantization or similar discrete representation methods critical to the inclusion criteria; it lacks description of token generation processes or usage for sequence/language modeling, thus does not meet the core requirements for inclusion.",
      "evaluation": 1
    },
    "round-A_JuniorMini_reasoning": "The paper focuses on word boundary detection using acoustic and lexical cues, which is related to speech processing but does not involve the creation or use of discrete audio tokens derived by vector quantization or similar discrete representation methods critical to the inclusion criteria; it lacks description of token generation processes or usage for sequence/language modeling, thus does not meet the core requirements for inclusion.",
    "round-A_JuniorMini_evaluation": 1,
    "final_verdict": "exclude (junior:1)",
    "review_skipped": false,
    "discard_reason": "exclude (junior:1)"
  },
  {
    "title": "Unsupervised optimal phoneme segmentation: Objectives, algorithm and comparisons",
    "abstract": "Phoneme segmentation is a fundamental problem in many speech recognition and synthesis studies. Unsupervised phoneme segmentation assumes no knowledge on linguistic contents and acoustic models, and thus poses a challenging problem. The essential question here is what is the optimal segmentation. This paper formulates the optimal segmentation problem into a probabilistic framework. Using statistics and information theory analysis, we develop three different objective functions, namely, summation of square error (SSE), log determinant (LD) and rate distortion (RD). Specially, RD function is derived from information rate distortion theory and can be related to human signal perception mechanism. We introduce a time-constrained agglomerative clustering algorithm to find the optimal segmentations. We also propose an efficient method to implement the algorithm by using integration functions. We carry out experiments on TIMIT database to compare the above three objective functions. The results show that rate distortion achieves the best performance and indicate that our method outperforms the recently published unsupervised segmentation methods.",
    "metadata": {
      "title": "Unsupervised optimal phoneme segmentation: Objectives, algorithm and comparisons",
      "summary": "Phoneme segmentation is a fundamental problem in many speech recognition and synthesis studies. Unsupervised phoneme segmentation assumes no knowledge on linguistic contents and acoustic models, and thus poses a challenging problem. The essential question here is what is the optimal segmentation. This paper formulates the optimal segmentation problem into a probabilistic framework. Using statistics and information theory analysis, we develop three different objective functions, namely, summation of square error (SSE), log determinant (LD) and rate distortion (RD). Specially, RD function is derived from information rate distortion theory and can be related to human signal perception mechanism. We introduce a time-constrained agglomerative clustering algorithm to find the optimal segmentations. We also propose an efficient method to implement the algorithm by using integration functions. We carry out experiments on TIMIT database to compare the above three objective functions. The results show that rate distortion achieves the best performance and indicate that our method outperforms the recently published unsupervised segmentation methods.",
      "abstract": "Phoneme segmentation is a fundamental problem in many speech recognition and synthesis studies. Unsupervised phoneme segmentation assumes no knowledge on linguistic contents and acoustic models, and thus poses a challenging problem. The essential question here is what is the optimal segmentation. This paper formulates the optimal segmentation problem into a probabilistic framework. Using statistics and information theory analysis, we develop three different objective functions, namely, summation of square error (SSE), log determinant (LD) and rate distortion (RD). Specially, RD function is derived from information rate distortion theory and can be related to human signal perception mechanism. We introduce a time-constrained agglomerative clustering algorithm to find the optimal segmentations. We also propose an efficient method to implement the algorithm by using integration functions. We carry out experiments on TIMIT database to compare the above three objective functions. The results show that rate distortion achieves the best performance and indicate that our method outperforms the recently published unsupervised segmentation methods.",
      "doi": "https://doi.org/10.1109/icassp.2008.4518528",
      "openalex_id": "https://openalex.org/W2121997342",
      "arxiv_id": "",
      "publication_date": "2008-03-01",
      "published": "2008-03-01",
      "source": "openalex_snowball"
    },
    "round-A_JuniorNano_output": {
      "reasoning": "The item centers on unsupervised phoneme segmentation without describing discrete audio token generation/quantization or token-centric downstream tasks, so it does not meet the required discrete audio token criteria (VQ/RVQ, hierarchical quantization, etc.).",
      "evaluation": 2
    },
    "round-A_JuniorNano_reasoning": "The item centers on unsupervised phoneme segmentation without describing discrete audio token generation/quantization or token-centric downstream tasks, so it does not meet the required discrete audio token criteria (VQ/RVQ, hierarchical quantization, etc.).",
    "round-A_JuniorNano_evaluation": 2,
    "round-A_JuniorMini_output": {
      "reasoning": "The study focuses on unsupervised phoneme segmentation using clustering algorithms and information theory, but does not describe producing discrete audio tokens through vector quantization or similar methods for use in sequence or language models; token generation processes, quantization, or structured discrete representations are not mentioned, thus it does not meet the inclusion criteria related to discrete audio token design.",
      "evaluation": 2
    },
    "round-A_JuniorMini_reasoning": "The study focuses on unsupervised phoneme segmentation using clustering algorithms and information theory, but does not describe producing discrete audio tokens through vector quantization or similar methods for use in sequence or language models; token generation processes, quantization, or structured discrete representations are not mentioned, thus it does not meet the inclusion criteria related to discrete audio token design.",
    "round-A_JuniorMini_evaluation": 2,
    "final_verdict": "exclude (junior:2)",
    "review_skipped": false,
    "discard_reason": "exclude (junior:2)"
  }
]