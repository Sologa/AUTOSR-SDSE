openalex_id,doi,title,abstract,referenced_works,publication_date
https://openalex.org/W4389266910,https://doi.org/10.1002/aisy.202300359,Multimodal Human–Robot Interaction for Human‐Centric Smart Manufacturing: A Survey,"Human–robot interaction (HRI) has escalated in notability in recent years, and multimodal communication and control strategies are necessitated to guarantee a secure, efficient, and intelligent HRI experience. In spite of the considerable focus on multimodal HRI, comprehensive disquisitions delineating various modalities and intricately analyzing their combinations remain elusive, consequently limiting holistic understanding and future advancements. This article aspires to bridge this inadequacy by conducting a profound exploration of multimodal HRI, predominantly concentrating on four principal modalities: vision, auditory and language, haptics, and physiological sensing. An extensive review encapsulating algorithmic dissection, interface devices, and applicative dimensions forms part of this discourse. This manuscript distinctively combines multimodal HRI with cognitive science, deeply probing into the three dimensions, perception, cognition, and action, thereby demystifying algorithms intrinsic to multimodal HRI. Finally, it accentuates the empirical challenges and contours preemptive trajectories for multimodal HRI in human‐centric smart manufacturing.","['https://openalex.org/W4280567426', 'https://openalex.org/W4300817754', 'https://openalex.org/W4295745363', 'https://openalex.org/W3189348291', 'https://openalex.org/W4220687285', 'https://openalex.org/W3185473887', 'https://openalex.org/W3194303810', 'https://openalex.org/W4385417070', 'https://openalex.org/W2751092903', 'https://openalex.org/W3094186510', 'https://openalex.org/W4323536725', 'https://openalex.org/W4385400355', 'https://openalex.org/W2955808192', 'https://openalex.org/W4211188394', 'https://openalex.org/W3002681205', 'https://openalex.org/W4206654130', 'https://openalex.org/W3022845750', 'https://openalex.org/W3120983578', 'https://openalex.org/W3205405951', 'https://openalex.org/W3174760112', 'https://openalex.org/W3008552394', 'https://openalex.org/W3198559682', 'https://openalex.org/W3022796439', 'https://openalex.org/W3024166792', 'https://openalex.org/W3115959388', 'https://openalex.org/W3083244126', 'https://openalex.org/W3117415653', 'https://openalex.org/W3192262009', 'https://openalex.org/W3045775887', 'https://openalex.org/W3205840220', 'https://openalex.org/W3170208249', 'https://openalex.org/W3094187366', 'https://openalex.org/W3027351386', 'https://openalex.org/W3016943329', 'https://openalex.org/W3112335585', 'https://openalex.org/W3128683505', 'https://openalex.org/W4282926942', 'https://openalex.org/W3175630806', 'https://openalex.org/W3173398710', 'https://openalex.org/W3014212548', 'https://openalex.org/W4226378723', 'https://openalex.org/W3046216614', 'https://openalex.org/W2999400313', 'https://openalex.org/W2986189201', 'https://openalex.org/W3097791751', 'https://openalex.org/W2921151905', 'https://openalex.org/W3107892667', 'https://openalex.org/W3137522674', 'https://openalex.org/W3133946207', 'https://openalex.org/W3176315233', 'https://openalex.org/W3119221111', 'https://openalex.org/W4200234870', 'https://openalex.org/W4288770705', 'https://openalex.org/W3082497237', 'https://openalex.org/W4295751932', 'https://openalex.org/W4210603465', 'https://openalex.org/W4282030117', 'https://openalex.org/W3183866186', 'https://openalex.org/W3184986255', 'https://openalex.org/W3020491491', 'https://openalex.org/W3138965819', 'https://openalex.org/W4225012776', 'https://openalex.org/W3212741141', 'https://openalex.org/W4297338453', 'https://openalex.org/W2980410359', 'https://openalex.org/W4295066885', 'https://openalex.org/W3125882366', 'https://openalex.org/W4212796129', 'https://openalex.org/W3204090911', 'https://openalex.org/W4223499953', 'https://openalex.org/W3128650182', 'https://openalex.org/W4313397676', 'https://openalex.org/W4288032956', 'https://openalex.org/W3184877567', 'https://openalex.org/W3188422869', 'https://openalex.org/W3205513966', 'https://openalex.org/W3216205210', 'https://openalex.org/W4285102375', 'https://openalex.org/W3129416290', 'https://openalex.org/W2965040423', 'https://openalex.org/W4285102195', 'https://openalex.org/W4210866977', 'https://openalex.org/W4293002984', 'https://openalex.org/W4226140731', 'https://openalex.org/W3089931253', 'https://openalex.org/W2912997088', 'https://openalex.org/W2966649515', 'https://openalex.org/W3188183700', 'https://openalex.org/W2962975726', 'https://openalex.org/W3049106855', 'https://openalex.org/W3160827875', 'https://openalex.org/W3190168772', 'https://openalex.org/W4296871415', 'https://openalex.org/W2911918145', 'https://openalex.org/W3130589561', 'https://openalex.org/W3198947878', 'https://openalex.org/W3098287426', 'https://openalex.org/W4281635836', 'https://openalex.org/W3090733808', 'https://openalex.org/W3199423927', 'https://openalex.org/W4281900509', 'https://openalex.org/W3182689414', 'https://openalex.org/W4200444375', 'https://openalex.org/W3207726767', 'https://openalex.org/W4281289356', 'https://openalex.org/W2989803300', 'https://openalex.org/W4200341868', 'https://openalex.org/W2945462057', 'https://openalex.org/W3042160505', 'https://openalex.org/W2958740673', 'https://openalex.org/W3034035730', 'https://openalex.org/W3007508877', 'https://openalex.org/W2947434510', 'https://openalex.org/W3129838052', 'https://openalex.org/W3190530720', 'https://openalex.org/W3131283877', 'https://openalex.org/W3164196935', 'https://openalex.org/W2999666348', 'https://openalex.org/W2786768213', 'https://openalex.org/W2965382638', 'https://openalex.org/W4226261823', 'https://openalex.org/W2809506543', 'https://openalex.org/W1901658528', 'https://openalex.org/W3198470685', 'https://openalex.org/W3091331558', 'https://openalex.org/W3035378577', 'https://openalex.org/W2904195888', 'https://openalex.org/W4299879782', 'https://openalex.org/W2999224157', 'https://openalex.org/W2999262712', 'https://openalex.org/W3033578652', 'https://openalex.org/W3117080414', 'https://openalex.org/W3109719334', 'https://openalex.org/W3182595211', 'https://openalex.org/W2944753626', 'https://openalex.org/W3017605837', 'https://openalex.org/W3014982919', 'https://openalex.org/W2966949208', 'https://openalex.org/W3102407952', 'https://openalex.org/W3015032324', 'https://openalex.org/W2913036154', 'https://openalex.org/W2767290858', 'https://openalex.org/W2053101950', 'https://openalex.org/W3129435223', 'https://openalex.org/W3130174139', 'https://openalex.org/W2898242330', 'https://openalex.org/W2997288337', 'https://openalex.org/W4285606617', 'https://openalex.org/W3094524767', 'https://openalex.org/W3009350896', 'https://openalex.org/W3025630664', 'https://openalex.org/W3193171560', 'https://openalex.org/W2747623286', 'https://openalex.org/W2976187852', 'https://openalex.org/W3134294468', 'https://openalex.org/W3130473386', 'https://openalex.org/W3207626483', 'https://openalex.org/W3091198826', 'https://openalex.org/W3173541058', 'https://openalex.org/W4223627534', 'https://openalex.org/W3130337384', 'https://openalex.org/W3029652091', 'https://openalex.org/W3164012715', 'https://openalex.org/W4313453017', 'https://openalex.org/W4296552195', 'https://openalex.org/W3217370814', 'https://openalex.org/W4285102314', 'https://openalex.org/W4386071707', 'https://openalex.org/W3199955095', 'https://openalex.org/W3096481046', 'https://openalex.org/W4295517390', 'https://openalex.org/W3023818716', 'https://openalex.org/W3040932193', 'https://openalex.org/W4302292846', 'https://openalex.org/W3007790139', 'https://openalex.org/W3137249133', 'https://openalex.org/W3098457050', 'https://openalex.org/W4206965993', 'https://openalex.org/W3001517505', 'https://openalex.org/W2765445970', 'https://openalex.org/W3151500663', 'https://openalex.org/W3047759098', 'https://openalex.org/W4285102362']",2023-12-01
https://openalex.org/W4385571111,https://doi.org/10.18653/v1/2023.acl-long.438,Speech-Text Pre-training for Spoken Dialog Understanding with Explicit Cross-Modal Alignment,"Tianshu Yu, Haoyu Gao, Ting-En Lin, Min Yang, Yuchuan Wu, Wentao Ma, Chao Wang, Fei Huang, Yongbin Li. Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2023.","['https://openalex.org/W2899663614', 'https://openalex.org/W4304080418', 'https://openalex.org/W3148001440', 'https://openalex.org/W3034266838', 'https://openalex.org/W3113822960', 'https://openalex.org/W2883409523', 'https://openalex.org/W3035451444', 'https://openalex.org/W4223622550', 'https://openalex.org/W4372278801', 'https://openalex.org/W3166396011', 'https://openalex.org/W4281701185', 'https://openalex.org/W2465534249', 'https://openalex.org/W3096109555', 'https://openalex.org/W3212743544', 'https://openalex.org/W3036601975', 'https://openalex.org/W2954492830', 'https://openalex.org/W4297833904', 'https://openalex.org/W4372260047', 'https://openalex.org/W4282030117', 'https://openalex.org/W4285149123', 'https://openalex.org/W3021096583', 'https://openalex.org/W2897182555', 'https://openalex.org/W2966715458', 'https://openalex.org/W4297783677', 'https://openalex.org/W4221141243', 'https://openalex.org/W2768282280', 'https://openalex.org/W3094502228', 'https://openalex.org/W3209984917', 'https://openalex.org/W4224903019', 'https://openalex.org/W3169320628', 'https://openalex.org/W2973049979', 'https://openalex.org/W2896457183', 'https://openalex.org/W4287065249', 'https://openalex.org/W2982223350', 'https://openalex.org/W2146334809', 'https://openalex.org/W2956125353', 'https://openalex.org/W3207222250', 'https://openalex.org/W4226315417', 'https://openalex.org/W4385573166', 'https://openalex.org/W2965373594', 'https://openalex.org/W2952409498', 'https://openalex.org/W4221142780', 'https://openalex.org/W3161302809', 'https://openalex.org/W3107826490', 'https://openalex.org/W4372266552', 'https://openalex.org/W2899377381', 'https://openalex.org/W4385573848']",2023-01-01
https://openalex.org/W4387969507,https://doi.org/10.1145/3581783.3612336,UniSA: Unified Generative Framework for Sentiment Analysis,"Sentiment analysis is a crucial task that aims to understand people's emotional states and predict emotional categories based on multimodal information. It consists of several subtasks, such as emotion recognition in conversation (ERC), aspect-based sentiment analysis (ABSA), and multimodal sentiment analysis (MSA). However, unifying all subtasks in sentiment analysis presents numerous challenges, including modality alignment, unified input/output forms, and dataset bias. To address these challenges, we propose a Task-Specific Prompt method to jointly model subtasks and introduce a multimodal generative framework called UniSA. Additionally, we organize the benchmark datasets of main subtasks into a new Sentiment Analysis Evaluation benchmark, SAEval. We design novel pre-training tasks and training methods to enable the model to learn generic sentiment knowledge among subtasks to improve the model's multimodal sentiment perception ability. Our experimental results show that UniSA performs comparably to the state-of-the-art on all subtasks and generalizes well to various subtasks in sentiment analysis.","['https://openalex.org/W2806198715', 'https://openalex.org/W2954226438', 'https://openalex.org/W2146334809', 'https://openalex.org/W4384890868', 'https://openalex.org/W3098556456', 'https://openalex.org/W2985882473', 'https://openalex.org/W2891359673', 'https://openalex.org/W6602117066', 'https://openalex.org/W4284683546', 'https://openalex.org/W3216055172', 'https://openalex.org/W3176399185', 'https://openalex.org/W4385573848', 'https://openalex.org/W3173396651', 'https://openalex.org/W4379259169', 'https://openalex.org/W3034999214', 'https://openalex.org/W4226470037', 'https://openalex.org/W3034336785', 'https://openalex.org/W4226025958', 'https://openalex.org/W3177224328', 'https://openalex.org/W4221147459', 'https://openalex.org/W4282030117', 'https://openalex.org/W2998721586', 'https://openalex.org/W2740567223', 'https://openalex.org/W2950601686', 'https://openalex.org/W2964164368', 'https://openalex.org/W2997573100', 'https://openalex.org/W2964300796', 'https://openalex.org/W2191779130', 'https://openalex.org/W2805744755', 'https://openalex.org/W2971196067', 'https://openalex.org/W4304092645', 'https://openalex.org/W2251648804', 'https://openalex.org/W2740550900', 'https://openalex.org/W2963686995', 'https://openalex.org/W3155230099', 'https://openalex.org/W3035507081', 'https://openalex.org/W2916132663', 'https://openalex.org/W2905107686', 'https://openalex.org/W3173751215', 'https://openalex.org/W3175552668', 'https://openalex.org/W2251939518', 'https://openalex.org/W4385573172', 'https://openalex.org/W2964051877', 'https://openalex.org/W2562607067', 'https://openalex.org/W3173233571', 'https://openalex.org/W3176038554', 'https://openalex.org/W3175225269', 'https://openalex.org/W4385571111', 'https://openalex.org/W3128412859', 'https://openalex.org/W2964010806', 'https://openalex.org/W2787581402', 'https://openalex.org/W2883409523', 'https://openalex.org/W4221141243', 'https://openalex.org/W3200369555', 'https://openalex.org/W3103900065', 'https://openalex.org/W1516184288', 'https://openalex.org/W2740887992', 'https://openalex.org/W2612690371', 'https://openalex.org/W2999905431']",2023-10-26
https://openalex.org/W4372260047,https://doi.org/10.1109/icassp49357.2023.10095652,Empathetic Response Generation via Emotion Cause Transition Graph,"Empathetic dialogue is a human-like behavior that requires the perception of both affective factors (e.g., emotion status) and cognitive factors (e.g., cause of the emotion). Besides concerning emotion status in early work, the latest approaches study emotion causes in empathetic dialogue. These approaches focus on understanding and duplicating emotion causes in the context to show empathy for the speaker. However, instead of only repeating the contextual causes, the real empathic response often demonstrate a logical and emotion-centered transition from the causes in the context to those in the responses. In this work, we propose an emotion cause transition graph to explicitly model the natural transition of emotion causes between two adjacent turns in empathetic dialogue. With this graph, the concept words of the emotion causes in the next turn can be predicted and used by a specifically designed concept-aware decoder to generate the empathic response. Automatic and human experimental results on the benchmark dataset demonstrate that our method produces more empathetic, coherent, informative, and specific responses than existing models.","['https://openalex.org/W4283798957', 'https://openalex.org/W3200833038', 'https://openalex.org/W4385573848', 'https://openalex.org/W1567569044', 'https://openalex.org/W6730084236', 'https://openalex.org/W2988937804', 'https://openalex.org/W3213635351', 'https://openalex.org/W3201162576', 'https://openalex.org/W3155584966', 'https://openalex.org/W2034951011', 'https://openalex.org/W2998563994', 'https://openalex.org/W4385573166', 'https://openalex.org/W4221141243', 'https://openalex.org/W3034569646', 'https://openalex.org/W3173691672', 'https://openalex.org/W6763562071', 'https://openalex.org/W6725207838', 'https://openalex.org/W6843144967', 'https://openalex.org/W6843658558', 'https://openalex.org/W3197754599', 'https://openalex.org/W3011411500', 'https://openalex.org/W3173176471', 'https://openalex.org/W2951583236', 'https://openalex.org/W6760017253', 'https://openalex.org/W6761205521', 'https://openalex.org/W3105906861', 'https://openalex.org/W2970303069', 'https://openalex.org/W3116376974', 'https://openalex.org/W3216055172', 'https://openalex.org/W4282030117', 'https://openalex.org/W2805738666', 'https://openalex.org/W2741866274', 'https://openalex.org/W4297833904', 'https://openalex.org/W4322614756', 'https://openalex.org/W2950299257', 'https://openalex.org/W2949644922', 'https://openalex.org/W2936695845', 'https://openalex.org/W4297834299']",2023-05-05
https://openalex.org/W4384890868,https://doi.org/10.1145/3539618.3592081,Unsupervised Dialogue Topic Segmentation with Topic-aware Contrastive Learning,"Dialogue Topic Segmentation (DTS) plays an essential role in a variety of dialogue modeling tasks. Previous DTS methods either focus on semantic similarity or dialogue coherence to assess topic similarity for unsupervised dialogue segmentation. However, the topic similarity cannot be fully identified via semantic similarity or dialogue coherence. In addition, the unlabeled dialogue data, which contains useful clues of utterance relationships, remains underexploited. In this paper, we propose a novel unsupervised DTS framework, which learns topic-aware utterance representations from unlabeled dialogue data through neighboring utterance matching and pseudo-segmentation. Extensive experiments on two benchmark datasets (i.e., DialSeg711 and Doc2Dial) demonstrate that our method significantly outperforms the strong baseline methods. For reproducibility, we provide our code and data at: https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/dial-start.","['https://openalex.org/W1557074680', 'https://openalex.org/W2964006684', 'https://openalex.org/W3104257895', 'https://openalex.org/W2963640662', 'https://openalex.org/W2027823133', 'https://openalex.org/W2963491014', 'https://openalex.org/W3099590177', 'https://openalex.org/W3216055172', 'https://openalex.org/W4282030117', 'https://openalex.org/W2998721586', 'https://openalex.org/W2952890017', 'https://openalex.org/W2159083595', 'https://openalex.org/W3212923188', 'https://openalex.org/W2970641574', 'https://openalex.org/W2509596028', 'https://openalex.org/W4284683576', 'https://openalex.org/W3172351783', 'https://openalex.org/W3173758804', 'https://openalex.org/W3176113532', 'https://openalex.org/W2963838657', 'https://openalex.org/W3198147814', 'https://openalex.org/W3110659220', 'https://openalex.org/W2904336621', 'https://openalex.org/W2595551253']",2023-07-18
https://openalex.org/W4409749042,https://doi.org/10.1145/3706598.3714228,Toward Enabling Natural Conversation with Older Adults via the Design of LLM-Powered Voice Agents that Support Interruptions and Backchannels,,"['https://openalex.org/W2396661804', 'https://openalex.org/W2154267140', 'https://openalex.org/W4224311623', 'https://openalex.org/W4221051163', 'https://openalex.org/W4384520820', 'https://openalex.org/W2003380544', 'https://openalex.org/W3094610014', 'https://openalex.org/W3081819086', 'https://openalex.org/W3115465968', 'https://openalex.org/W4224327103', 'https://openalex.org/W4288359812', 'https://openalex.org/W2751379218', 'https://openalex.org/W4384406040', 'https://openalex.org/W4221163951', 'https://openalex.org/W4318066536', 'https://openalex.org/W2969653753', 'https://openalex.org/W2810225641', 'https://openalex.org/W4313701988', 'https://openalex.org/W3161683830', 'https://openalex.org/W3210386143', 'https://openalex.org/W2068090989', 'https://openalex.org/W2081386522', 'https://openalex.org/W2808440803', 'https://openalex.org/W2088269687', 'https://openalex.org/W2142422296', 'https://openalex.org/W2984578905', 'https://openalex.org/W4395686545', 'https://openalex.org/W3047517294', 'https://openalex.org/W3014901735', 'https://openalex.org/W2897115307', 'https://openalex.org/W4368755241', 'https://openalex.org/W3198219962', 'https://openalex.org/W4200032706', 'https://openalex.org/W2155504372', 'https://openalex.org/W2069113683', 'https://openalex.org/W4390722831', 'https://openalex.org/W3118958215', 'https://openalex.org/W3168715003', 'https://openalex.org/W3095328365', 'https://openalex.org/W4388623927', 'https://openalex.org/W2787693967', 'https://openalex.org/W2017011121', 'https://openalex.org/W1832790333', 'https://openalex.org/W4282030117', 'https://openalex.org/W4200510736', 'https://openalex.org/W2099386544', 'https://openalex.org/W2763552934', 'https://openalex.org/W2405187948', 'https://openalex.org/W3117824238', 'https://openalex.org/W3007163346', 'https://openalex.org/W2889231094', 'https://openalex.org/W188676301', 'https://openalex.org/W4200512533', 'https://openalex.org/W2059497297', 'https://openalex.org/W2525988787', 'https://openalex.org/W4312004183', 'https://openalex.org/W2022378030', 'https://openalex.org/W2015037772', 'https://openalex.org/W2980987013', 'https://openalex.org/W4384520878', 'https://openalex.org/W2064304524', 'https://openalex.org/W2782898451', 'https://openalex.org/W4394591929', 'https://openalex.org/W2902121421', 'https://openalex.org/W3006162966', 'https://openalex.org/W2787712888', 'https://openalex.org/W2004513044', 'https://openalex.org/W3084929246', 'https://openalex.org/W1976399205', 'https://openalex.org/W2127813287', 'https://openalex.org/W2145916567', 'https://openalex.org/W3094018806', 'https://openalex.org/W2967859656', 'https://openalex.org/W2205411208', 'https://openalex.org/W2130490182', 'https://openalex.org/W1998659155', 'https://openalex.org/W1558276682', 'https://openalex.org/W4295955091', 'https://openalex.org/W3186089682', 'https://openalex.org/W4387901698', 'https://openalex.org/W3112188842', 'https://openalex.org/W2164569586', 'https://openalex.org/W1964198739', 'https://openalex.org/W4213305518', 'https://openalex.org/W2798066193', 'https://openalex.org/W3095385635', 'https://openalex.org/W2077433730', 'https://openalex.org/W4366549110', 'https://openalex.org/W4400142383', 'https://openalex.org/W4396919238', 'https://openalex.org/W4386413998', 'https://openalex.org/W2990191718', 'https://openalex.org/W4407100023', 'https://openalex.org/W2798746331', 'https://openalex.org/W4403334712']",2025-04-24
https://openalex.org/W4411046783,https://doi.org/10.1016/j.cosrev.2025.100768,Transformers in speech processing: Overcoming challenges and paving the future,,"['https://openalex.org/W6768009688', 'https://openalex.org/W3085139254', 'https://openalex.org/W6773475747', 'https://openalex.org/W2979826702', 'https://openalex.org/W6769243733', 'https://openalex.org/W2963542740', 'https://openalex.org/W6754299077', 'https://openalex.org/W4223499953', 'https://openalex.org/W6786554360', 'https://openalex.org/W6794544138', 'https://openalex.org/W4361994820', 'https://openalex.org/W6784764134', 'https://openalex.org/W6739901393', 'https://openalex.org/W2946794439', 'https://openalex.org/W4403343940', 'https://openalex.org/W4402592280', 'https://openalex.org/W6849071563', 'https://openalex.org/W3038342317', 'https://openalex.org/W4312905724', 'https://openalex.org/W3198544313', 'https://openalex.org/W2339271353', 'https://openalex.org/W4401059461', 'https://openalex.org/W4400877473', 'https://openalex.org/W6600459194', 'https://openalex.org/W3120390034', 'https://openalex.org/W2618099328', 'https://openalex.org/W2912581782', 'https://openalex.org/W2969889150', 'https://openalex.org/W3199964822', 'https://openalex.org/W2606977969', 'https://openalex.org/W3045086295', 'https://openalex.org/W3138794547', 'https://openalex.org/W6607786901', 'https://openalex.org/W3200318528', 'https://openalex.org/W3100732527', 'https://openalex.org/W6600424091', 'https://openalex.org/W6727693337', 'https://openalex.org/W4362603432', 'https://openalex.org/W3128513378', 'https://openalex.org/W4206706211', 'https://openalex.org/W4362519158', 'https://openalex.org/W4221094122', 'https://openalex.org/W6601065604', 'https://openalex.org/W1995562189', 'https://openalex.org/W2963403664', 'https://openalex.org/W6702248584', 'https://openalex.org/W6763701032', 'https://openalex.org/W6769627184', 'https://openalex.org/W2970641574', 'https://openalex.org/W6769196770', 'https://openalex.org/W6780218876', 'https://openalex.org/W3197642003', 'https://openalex.org/W3213029956', 'https://openalex.org/W6810007534', 'https://openalex.org/W6679775712', 'https://openalex.org/W6818723395', 'https://openalex.org/W6736996214', 'https://openalex.org/W6746700228', 'https://openalex.org/W6757079273', 'https://openalex.org/W6600310816', 'https://openalex.org/W3196523535', 'https://openalex.org/W6632668414', 'https://openalex.org/W2982223350', 'https://openalex.org/W2973049979', 'https://openalex.org/W4221162874', 'https://openalex.org/W3034949308', 'https://openalex.org/W3097777922', 'https://openalex.org/W3209059054', 'https://openalex.org/W6788335241', 'https://openalex.org/W6600351811', 'https://openalex.org/W3204696009', 'https://openalex.org/W6600062020', 'https://openalex.org/W6762050013', 'https://openalex.org/W3205644108', 'https://openalex.org/W6600005967', 'https://openalex.org/W4408345930', 'https://openalex.org/W6600195515', 'https://openalex.org/W4283704748', 'https://openalex.org/W6803394801', 'https://openalex.org/W6803396120', 'https://openalex.org/W3209984917', 'https://openalex.org/W6761629969', 'https://openalex.org/W3205475937', 'https://openalex.org/W6846849257', 'https://openalex.org/W2064675550', 'https://openalex.org/W6757998062', 'https://openalex.org/W6749669830', 'https://openalex.org/W2150355110', 'https://openalex.org/W6774223107', 'https://openalex.org/W6779264309', 'https://openalex.org/W3161768215', 'https://openalex.org/W6752048366', 'https://openalex.org/W6777615951', 'https://openalex.org/W6751306699', 'https://openalex.org/W6769729509', 'https://openalex.org/W6771291481', 'https://openalex.org/W3097973766', 'https://openalex.org/W3161873870', 'https://openalex.org/W2144499799', 'https://openalex.org/W2936078256', 'https://openalex.org/W2591927543', 'https://openalex.org/W6745697700', 'https://openalex.org/W6753855596', 'https://openalex.org/W2120847449', 'https://openalex.org/W6755592152', 'https://openalex.org/W3150572638', 'https://openalex.org/W6603795164', 'https://openalex.org/W6791196930', 'https://openalex.org/W6785102216', 'https://openalex.org/W3198039885', 'https://openalex.org/W6768848920', 'https://openalex.org/W6785153917', 'https://openalex.org/W6603527449', 'https://openalex.org/W6737778391', 'https://openalex.org/W6754693226', 'https://openalex.org/W3097538987', 'https://openalex.org/W6772340256', 'https://openalex.org/W6600577311', 'https://openalex.org/W6775580082', 'https://openalex.org/W6803967953', 'https://openalex.org/W6778825219', 'https://openalex.org/W6777614773', 'https://openalex.org/W6771070734', 'https://openalex.org/W6775145810', 'https://openalex.org/W6803104305', 'https://openalex.org/W6784342092', 'https://openalex.org/W6795055674', 'https://openalex.org/W6792694458', 'https://openalex.org/W6764278823', 'https://openalex.org/W6676738204', 'https://openalex.org/W6632017195', 'https://openalex.org/W2747920239', 'https://openalex.org/W2582956876', 'https://openalex.org/W2786891429', 'https://openalex.org/W6736180185', 'https://openalex.org/W6756627502', 'https://openalex.org/W2973048981', 'https://openalex.org/W6602488901', 'https://openalex.org/W6607666538', 'https://openalex.org/W3173767661', 'https://openalex.org/W3092424727', 'https://openalex.org/W3174501695', 'https://openalex.org/W4296068413', 'https://openalex.org/W6803022836', 'https://openalex.org/W6784012970', 'https://openalex.org/W4283067311', 'https://openalex.org/W4313887688', 'https://openalex.org/W3197580070', 'https://openalex.org/W3006926732', 'https://openalex.org/W3129077738', 'https://openalex.org/W6769412140', 'https://openalex.org/W6791833598', 'https://openalex.org/W6600388300', 'https://openalex.org/W6779609050', 'https://openalex.org/W6850690076', 'https://openalex.org/W2973062255', 'https://openalex.org/W3096090308', 'https://openalex.org/W7055657227', 'https://openalex.org/W6784775991', 'https://openalex.org/W3193846000', 'https://openalex.org/W4283727958', 'https://openalex.org/W6777337586', 'https://openalex.org/W6755207826', 'https://openalex.org/W6770208550', 'https://openalex.org/W3034999214', 'https://openalex.org/W6778883912', 'https://openalex.org/W6799722865', 'https://openalex.org/W6637031373', 'https://openalex.org/W6764961387', 'https://openalex.org/W6770864467', 'https://openalex.org/W6769690604', 'https://openalex.org/W6783681928', 'https://openalex.org/W6796118626', 'https://openalex.org/W6800976701', 'https://openalex.org/W6793332429', 'https://openalex.org/W3156287428', 'https://openalex.org/W3155584966', 'https://openalex.org/W6843498491', 'https://openalex.org/W3135638847', 'https://openalex.org/W6607643177', 'https://openalex.org/W4367047335', 'https://openalex.org/W6767723188', 'https://openalex.org/W2972892266', 'https://openalex.org/W6775877123', 'https://openalex.org/W6768302716', 'https://openalex.org/W6769093554', 'https://openalex.org/W6785599655', 'https://openalex.org/W6784795729', 'https://openalex.org/W3094393093', 'https://openalex.org/W6782072778', 'https://openalex.org/W3016128928', 'https://openalex.org/W6785033428', 'https://openalex.org/W6788659840', 'https://openalex.org/W6805572337', 'https://openalex.org/W3103181422', 'https://openalex.org/W3162646066', 'https://openalex.org/W4210609201', 'https://openalex.org/W3208820060', 'https://openalex.org/W4385574421', 'https://openalex.org/W4297841632', 'https://openalex.org/W4282030117', 'https://openalex.org/W4297841597', 'https://openalex.org/W6842387725', 'https://openalex.org/W6846281274', 'https://openalex.org/W4224903891', 'https://openalex.org/W4226315417', 'https://openalex.org/W4312892334', 'https://openalex.org/W4307009360', 'https://openalex.org/W4320008876', 'https://openalex.org/W6810738896', 'https://openalex.org/W6750615492', 'https://openalex.org/W3096109555', 'https://openalex.org/W3096485810', 'https://openalex.org/W4287888406', 'https://openalex.org/W2963425185', 'https://openalex.org/W2619383789', 'https://openalex.org/W2964010806', 'https://openalex.org/W6600402904', 'https://openalex.org/W6797613833', 'https://openalex.org/W6795103355', 'https://openalex.org/W6763650382', 'https://openalex.org/W6761197245', 'https://openalex.org/W6803194594', 'https://openalex.org/W6797109355', 'https://openalex.org/W6780924892', 'https://openalex.org/W6776721752', 'https://openalex.org/W6793736971', 'https://openalex.org/W6600617704', 'https://openalex.org/W6685518012', 'https://openalex.org/W3184369217', 'https://openalex.org/W6776747255', 'https://openalex.org/W6751183075', 'https://openalex.org/W6750121898', 'https://openalex.org/W6758423016', 'https://openalex.org/W6758732453', 'https://openalex.org/W6797264745', 'https://openalex.org/W4319586927', 'https://openalex.org/W6805745850', 'https://openalex.org/W6770008262', 'https://openalex.org/W3131922516', 'https://openalex.org/W6802926664', 'https://openalex.org/W4307977693', 'https://openalex.org/W2965046076', 'https://openalex.org/W6610877984', 'https://openalex.org/W6800034559', 'https://openalex.org/W6768248613', 'https://openalex.org/W6784418856', 'https://openalex.org/W6784916438', 'https://openalex.org/W6764409202', 'https://openalex.org/W6600349396', 'https://openalex.org/W4296499650', 'https://openalex.org/W6855668210', 'https://openalex.org/W6795904598', 'https://openalex.org/W3035251378', 'https://openalex.org/W6792391316', 'https://openalex.org/W6788135285', 'https://openalex.org/W3176824248', 'https://openalex.org/W6801390177', 'https://openalex.org/W6600175266', 'https://openalex.org/W3158375352', 'https://openalex.org/W6810371925', 'https://openalex.org/W6601548533', 'https://openalex.org/W2936774411', 'https://openalex.org/W4403826603', 'https://openalex.org/W4396640474', 'https://openalex.org/W6789881344', 'https://openalex.org/W6603999813', 'https://openalex.org/W6779473860', 'https://openalex.org/W6796481600', 'https://openalex.org/W6799858907', 'https://openalex.org/W6779373063', 'https://openalex.org/W6774131351', 'https://openalex.org/W6792983607', 'https://openalex.org/W6779412326', 'https://openalex.org/W2002591263', 'https://openalex.org/W3039263585', 'https://openalex.org/W6766272978', 'https://openalex.org/W3135526844', 'https://openalex.org/W6794166682', 'https://openalex.org/W2998356391', 'https://openalex.org/W6775970589', 'https://openalex.org/W6600654476', 'https://openalex.org/W6779705445', 'https://openalex.org/W6603832454', 'https://openalex.org/W6792501387', 'https://openalex.org/W2962960500', 'https://openalex.org/W6785011006', 'https://openalex.org/W6790019176', 'https://openalex.org/W3203711169', 'https://openalex.org/W6789729544', 'https://openalex.org/W6600553734', 'https://openalex.org/W6805750369', 'https://openalex.org/W4285606530', 'https://openalex.org/W6604094065', 'https://openalex.org/W6797265648', 'https://openalex.org/W2963499153', 'https://openalex.org/W6602474744', 'https://openalex.org/W6766632297', 'https://openalex.org/W6601258443', 'https://openalex.org/W3182937942', 'https://openalex.org/W3102342027', 'https://openalex.org/W6848673773', 'https://openalex.org/W3102393842', 'https://openalex.org/W3154596443', 'https://openalex.org/W4324092848', 'https://openalex.org/W2489487449', 'https://openalex.org/W4287124724', 'https://openalex.org/W4287125738', 'https://openalex.org/W626291199', 'https://openalex.org/W4309793872', 'https://openalex.org/W2952902402', 'https://openalex.org/W3036601975', 'https://openalex.org/W4213069590', 'https://openalex.org/W3096888553', 'https://openalex.org/W3174906557', 'https://openalex.org/W4239019441', 'https://openalex.org/W2599674900', 'https://openalex.org/W4205807230', 'https://openalex.org/W4292779060', 'https://openalex.org/W4288089799', 'https://openalex.org/W4226278401', 'https://openalex.org/W2766812927', 'https://openalex.org/W3035688398', 'https://openalex.org/W2912083425', 'https://openalex.org/W4205185581', 'https://openalex.org/W4287608901', 'https://openalex.org/W3095311338', 'https://openalex.org/W4287107550', 'https://openalex.org/W3166163487', 'https://openalex.org/W4214540501', 'https://openalex.org/W3143835353', 'https://openalex.org/W2970597249', 'https://openalex.org/W2915722758', 'https://openalex.org/W2963609956', 'https://openalex.org/W4206281850', 'https://openalex.org/W4252531498', 'https://openalex.org/W2963975282', 'https://openalex.org/W2962778134', 'https://openalex.org/W4200253303', 'https://openalex.org/W4253694105', 'https://openalex.org/W3120680448', 'https://openalex.org/W2186222003']",2025-06-05
https://openalex.org/W4403918885,https://doi.org/10.1109/ro-man60168.2024.10731285,A Humanoid Robot Dialogue System Architecture Targeting Patient Interview Tasks,"Humanoid robots are promising approach to automating patient interviews routinely conducted by medical staff. Their human-like appearance enables them to use the full gamut of verbal and behavioral cues that are critical to a successful interview. On the other hand, anthropomorphism can induce expectations of human-level performance by the robot. Not meeting such expectations degrades the quality of interaction. Specifically, humans expect rich real-time interactions during speech exchange, such as backchanneling and barge-ins. The nature of the patient interview task differs from most other scenarios where task oriented dialogue systems have been used, as there is increased potential of engagement breakdown during interaction. We describe a dialogue system architecture that improves the performance of humanoid robots on the patient interview task. Our architecture adds a nested inner real-time control loop to improve the timeliness of the robot's responses based on the notion of ""stance"", an elaboration of the concept of a ""turn"", common in most existing dialogue systems. It also expands the dialogue state to monitor not only task progress, but also human engagement. Experiments using a humanoid robot running our proposed architecture reveal improved performance on interview tasks in terms of the perceived timeliness of responses and users' impressions of the system.","['https://openalex.org/W2135934847', 'https://openalex.org/W4210634796', 'https://openalex.org/W2118238333', 'https://openalex.org/W4391213551', 'https://openalex.org/W1974294498', 'https://openalex.org/W6774543847', 'https://openalex.org/W4250914428', 'https://openalex.org/W2527766749', 'https://openalex.org/W2787693967', 'https://openalex.org/W3136389354', 'https://openalex.org/W2765447327', 'https://openalex.org/W2111151330', 'https://openalex.org/W6694251273', 'https://openalex.org/W2081703679', 'https://openalex.org/W2184673397', 'https://openalex.org/W2984864729', 'https://openalex.org/W3000596306', 'https://openalex.org/W3169860338', 'https://openalex.org/W2097501252', 'https://openalex.org/W4389009448', 'https://openalex.org/W3112188842', 'https://openalex.org/W2161345458', 'https://openalex.org/W2161296357', 'https://openalex.org/W1964725106', 'https://openalex.org/W1992506508', 'https://openalex.org/W2293392332', 'https://openalex.org/W4282030117', 'https://openalex.org/W28861688', 'https://openalex.org/W6752022697', 'https://openalex.org/W2980823180', 'https://openalex.org/W4296068615', 'https://openalex.org/W2067348796', 'https://openalex.org/W4285138657', 'https://openalex.org/W2886305736', 'https://openalex.org/W82840137', 'https://openalex.org/W2066816720', 'https://openalex.org/W2595229763']",2024-08-26
https://openalex.org/W4405710078,https://doi.org/10.1109/iscslp63861.2024.10800061,FCTalker: Fine and Coarse Grained Context Modeling for Expressive Conversational Speech Synthesis,,"['https://openalex.org/W3151309757', 'https://openalex.org/W3198152857', 'https://openalex.org/W4285553096', 'https://openalex.org/W4282030117', 'https://openalex.org/W2963609956', 'https://openalex.org/W2964243274', 'https://openalex.org/W6763832098', 'https://openalex.org/W6778823374', 'https://openalex.org/W2129142580', 'https://openalex.org/W2102003408', 'https://openalex.org/W2074042974', 'https://openalex.org/W4390926710', 'https://openalex.org/W157389678', 'https://openalex.org/W2395956841', 'https://openalex.org/W4283662594', 'https://openalex.org/W4225275170', 'https://openalex.org/W4285301431', 'https://openalex.org/W2998432370', 'https://openalex.org/W2946085385', 'https://openalex.org/W6755207826', 'https://openalex.org/W4385822427', 'https://openalex.org/W6765987481', 'https://openalex.org/W6749489859', 'https://openalex.org/W3196001064', 'https://openalex.org/W6783867762', 'https://openalex.org/W4385245566', 'https://openalex.org/W3100110884', 'https://openalex.org/W4304013787', 'https://openalex.org/W4372260474', 'https://openalex.org/W6745297980', 'https://openalex.org/W6762339780', 'https://openalex.org/W2997771882', 'https://openalex.org/W3048768961', 'https://openalex.org/W1975163393']",2024-11-07
https://openalex.org/W4402134537,https://doi.org/10.3390/data9090104,Interruption Audio &amp; Transcript: Derived from Group Affect and Performance Dataset,"Despite the widespread development and use of chatbots, there is a lack of audio-based interruption datasets. This study provides a dataset of 200 manually annotated interruptions from a broader set of 355 data points of overlapping utterances. The dataset is derived from the Group Affect and Performance dataset managed by the University of the Fraser Valley, Canada. It includes both audio files and transcripts, allowing for multi-modal analysis. Given the extensive literature and the varied definitions of interruptions, it was necessary to establish precise definitions. The study aims to provide a comprehensive dataset for researchers to build and improve interruption prediction models. The findings demonstrate that classification models can generalize well to identify interruptions based on this dataset’s audio. This opens up research avenues with respect to interruption-related topics, ranging from multi-modal interruption classification using text and audio modalities to the analysis of group dynamics.","['https://openalex.org/W28861688', 'https://openalex.org/W3209059054', 'https://openalex.org/W2069207217', 'https://openalex.org/W2906410507', 'https://openalex.org/W4248634141', 'https://openalex.org/W4282030117', 'https://openalex.org/W160869212', 'https://openalex.org/W2048008777', 'https://openalex.org/W1010839910']",2024-08-31
https://openalex.org/W4415065054,https://doi.org/10.1145/3716553.3750799,When Words Fall Short: The Case for Conversational Interfaces that Don’t Listen,,"['https://openalex.org/W4411119815', 'https://openalex.org/W3186407077', 'https://openalex.org/W4390117436', 'https://openalex.org/W3197523558', 'https://openalex.org/W3029538415', 'https://openalex.org/W4385822549', 'https://openalex.org/W4290742115', 'https://openalex.org/W192728001', 'https://openalex.org/W2538667019', 'https://openalex.org/W2963341956', 'https://openalex.org/W2967826320', 'https://openalex.org/W2765982206', 'https://openalex.org/W2151905266', 'https://openalex.org/W2157289187', 'https://openalex.org/W4366547574', 'https://openalex.org/W3135347383', 'https://openalex.org/W2968682416', 'https://openalex.org/W1969152782', 'https://openalex.org/W2919115771', 'https://openalex.org/W4282030117', 'https://openalex.org/W3196075737', 'https://openalex.org/W2405187948', 'https://openalex.org/W2945401141', 'https://openalex.org/W4291138481', 'https://openalex.org/W3186527222', 'https://openalex.org/W2605353781', 'https://openalex.org/W4306412289', 'https://openalex.org/W2950801649', 'https://openalex.org/W4387446263', 'https://openalex.org/W2015003921', 'https://openalex.org/W2007465845', 'https://openalex.org/W2979372603', 'https://openalex.org/W3043303013', 'https://openalex.org/W2967462851', 'https://openalex.org/W2131799829', 'https://openalex.org/W4205119860', 'https://openalex.org/W3042239274', 'https://openalex.org/W4308104623', 'https://openalex.org/W3209042988', 'https://openalex.org/W4412046224', 'https://openalex.org/W2003187229', 'https://openalex.org/W4361274151', 'https://openalex.org/W4393147219', 'https://openalex.org/W2612690371', 'https://openalex.org/W4214717370', 'https://openalex.org/W4205807230', 'https://openalex.org/W2990138404']",2025-10-11
https://openalex.org/W4415821687,https://doi.org/10.1109/ro-man63969.2025.11217726,Dynamic Prompting Improves Turn-taking in Embodied Spoken Dialogue Systems,,"['https://openalex.org/W4391213551', 'https://openalex.org/W3009894005', 'https://openalex.org/W2202997319', 'https://openalex.org/W4403918885', 'https://openalex.org/W2765447327', 'https://openalex.org/W2081703679', 'https://openalex.org/W3169860338', 'https://openalex.org/W3000596306', 'https://openalex.org/W3112188842', 'https://openalex.org/W4301357669', 'https://openalex.org/W4297841817', 'https://openalex.org/W3094393093', 'https://openalex.org/W4385992525', 'https://openalex.org/W4412945230', 'https://openalex.org/W2067097374', 'https://openalex.org/W1964725106', 'https://openalex.org/W2161296357', 'https://openalex.org/W2293392332', 'https://openalex.org/W4282030117', 'https://openalex.org/W2067348796', 'https://openalex.org/W4410297768', 'https://openalex.org/W4403918898', 'https://openalex.org/W4412023051', 'https://openalex.org/W2502840125']",2025-08-25
https://openalex.org/W4415822139,https://doi.org/10.1109/ro-man63969.2025.11217629,Integrating LLM into a Socially Assistive Robot for Social Dialogue: An Exploratory Study in a Nursing Home*,,"['https://openalex.org/W4312130054', 'https://openalex.org/W4409766522', 'https://openalex.org/W4404141408', 'https://openalex.org/W4285307790', 'https://openalex.org/W4408267896', 'https://openalex.org/W4323537006', 'https://openalex.org/W4406431634', 'https://openalex.org/W4410297116', 'https://openalex.org/W4392719612', 'https://openalex.org/W4403442768', 'https://openalex.org/W3131757125', 'https://openalex.org/W3199541953', 'https://openalex.org/W4399053129', 'https://openalex.org/W2178392627', 'https://openalex.org/W3157200701', 'https://openalex.org/W2586081748', 'https://openalex.org/W4323536841', 'https://openalex.org/W4387372812', 'https://openalex.org/W2871950322', 'https://openalex.org/W4390722831', 'https://openalex.org/W4282959077', 'https://openalex.org/W2901462046', 'https://openalex.org/W2967859656', 'https://openalex.org/W2060981264', 'https://openalex.org/W4251166405', 'https://openalex.org/W2491176990', 'https://openalex.org/W4390617354', 'https://openalex.org/W4400396839', 'https://openalex.org/W2617211984', 'https://openalex.org/W4403331636', 'https://openalex.org/W3112188842', 'https://openalex.org/W4282030117', 'https://openalex.org/W4410297768', 'https://openalex.org/W4414051101', 'https://openalex.org/W4404434403', 'https://openalex.org/W3158984017', 'https://openalex.org/W2926095828', 'https://openalex.org/W4407841405', 'https://openalex.org/W4412945298', 'https://openalex.org/W4403919187']",2025-08-25
https://openalex.org/W4385570943,https://doi.org/10.18653/v1/2023.findings-acl.508,Prosody-TTS: Improving Prosody with Masked Autoencoder and Conditional Diffusion Model For Expressive Text-to-Speech,"Expressive text-to-speech aims to generate high-quality samples with rich and diverse prosody, which is hampered by dual challenges: 1) prosodic attributes in highly dynamic voices are difficult to capture and model without intonation; and 2) highly multimodal prosodic representations cannot be well learned by simple regression (e.g., MSE) objectives, which causes blurry and over-smoothing predictions. This paper proposes Prosody-TTS, a two-stage pipeline that enhances prosody modeling and sampling by introducing several components: 1) a self-supervised masked autoencoder to model the prosodic representation without relying on text transcriptions or local prosody attributes, which ensures to cover diverse speaking voices with superior generalization; and 2) a diffusion model to sample diverse prosodic patterns within the latent space, which prevents TTS models from generating samples with dull prosodic performance. Experimental results show that Prosody-TTS achieves new state-of-the-art in text-to-speech with natural and expressive synthesis. Both subjective and objective evaluation demonstrate that it exhibits superior audio quality and prosody naturalness with rich and diverse prosodic attributes. Audio samples are available at https://improved_prosody.github.io","['https://openalex.org/W4306175879', 'https://openalex.org/W4283659485', 'https://openalex.org/W4221159457', 'https://openalex.org/W4367061106', 'https://openalex.org/W2952269766', 'https://openalex.org/W3206191467', 'https://openalex.org/W3169320628', 'https://openalex.org/W4312933868', 'https://openalex.org/W4225680573', 'https://openalex.org/W4296068785', 'https://openalex.org/W3140429000', 'https://openalex.org/W4287184558', 'https://openalex.org/W3162926177', 'https://openalex.org/W3026874504', 'https://openalex.org/W4287236468', 'https://openalex.org/W3168527213', 'https://openalex.org/W2798658180', 'https://openalex.org/W4285483538', 'https://openalex.org/W3197580070', 'https://openalex.org/W2933138175', 'https://openalex.org/W4285483774', 'https://openalex.org/W2107860279', 'https://openalex.org/W3128910262', 'https://openalex.org/W3180196270', 'https://openalex.org/W3172148458', 'https://openalex.org/W3036601975', 'https://openalex.org/W4303519914', 'https://openalex.org/W2982602185', 'https://openalex.org/W4308352263', 'https://openalex.org/W2146334809', 'https://openalex.org/W2794490148', 'https://openalex.org/W4287111234', 'https://openalex.org/W3206996142', 'https://openalex.org/W4300980462', 'https://openalex.org/W4289785095', 'https://openalex.org/W3016021263', 'https://openalex.org/W3034794073', 'https://openalex.org/W3168292814', 'https://openalex.org/W3092028330', 'https://openalex.org/W4287121924', 'https://openalex.org/W2940703732', 'https://openalex.org/W4301371414', 'https://openalex.org/W4297808394', 'https://openalex.org/W2963609956', 'https://openalex.org/W3033411150', 'https://openalex.org/W2946200149', 'https://openalex.org/W3121370741', 'https://openalex.org/W4285345683', 'https://openalex.org/W1494198834', 'https://openalex.org/W4285483692', 'https://openalex.org/W4297841853', 'https://openalex.org/W4313156423', 'https://openalex.org/W2963799213', 'https://openalex.org/W3110257065', 'https://openalex.org/W2972677740']",2023-01-01
https://openalex.org/W4389524060,https://doi.org/10.18653/v1/2023.findings-emnlp.541,Speaking Style Conversion in the Waveform Domain Using Discrete Self-Supervised Units,"We introduce DISSC, a novel, lightweight method that converts the rhythm, pitch contour and timbre of a recording to a target speaker in a textless manner. Unlike DISSC, most voice conversion (VC) methods focus primarily on timbre, and ignore people’s unique speaking style (prosody). The proposed approach uses a pretrained, self-supervised model for encoding speech to discrete units, which makes it simple, effective, and fast to train. All conversion modules are only trained on reconstruction like tasks, thus suitable for any-to-many VC with no paired data. We introduce a suite of quantitative and qualitative evaluation metrics for this setup, and empirically demonstrate that DISSC significantly outperforms the evaluated baselines. Code and samples are available at https://pages.cs.huji.ac.il/adiyoss-lab/dissc/.","['https://openalex.org/W2963539064', 'https://openalex.org/W4311000453', 'https://openalex.org/W4287854499', 'https://openalex.org/W2774848319', 'https://openalex.org/W4381786045', 'https://openalex.org/W4394671563', 'https://openalex.org/W4307680525', 'https://openalex.org/W3092028330', 'https://openalex.org/W2589664214', 'https://openalex.org/W4206711328', 'https://openalex.org/W3214606349', 'https://openalex.org/W3141523618', 'https://openalex.org/W4300980117', 'https://openalex.org/W4287887366', 'https://openalex.org/W2294351487', 'https://openalex.org/W2747874407', 'https://openalex.org/W3169739675', 'https://openalex.org/W4225892118', 'https://openalex.org/W4283659485', 'https://openalex.org/W4372266960', 'https://openalex.org/W4303494982', 'https://openalex.org/W4300980462', 'https://openalex.org/W4297412183', 'https://openalex.org/W3126283728', 'https://openalex.org/W2972659941', 'https://openalex.org/W4296070387', 'https://openalex.org/W3169320628', 'https://openalex.org/W2156142001', 'https://openalex.org/W3161695192', 'https://openalex.org/W3163475957', 'https://openalex.org/W2123003832', 'https://openalex.org/W4297841435', 'https://openalex.org/W3034794073', 'https://openalex.org/W3180374548', 'https://openalex.org/W4387247604', 'https://openalex.org/W1494198834', 'https://openalex.org/W3213873715', 'https://openalex.org/W2527729766', 'https://openalex.org/W4378105483', 'https://openalex.org/W3198217962', 'https://openalex.org/W2125101937', 'https://openalex.org/W3140429000', 'https://openalex.org/W3167533889', 'https://openalex.org/W2945478979', 'https://openalex.org/W4308161937', 'https://openalex.org/W4306169273', 'https://openalex.org/W3150271208', 'https://openalex.org/W3024869864']",2023-01-01
https://openalex.org/W4286716540,https://doi.org/10.4274/balkanmedj.galenos.2022.2022-4-7,The Clinicopathological Characteristics of Pure and Mixed Invasive Micropapillary Breast Carcinomas: A Single Center Experience,"Compared to the mixed IMPC, pure IMPC appears to have a more aggressive behavior with lower locoregional recurrence-free survival and more locoregional recurrences. This may be due to the low progesterone receptor positivity rate.","['https://openalex.org/W4295308567', 'https://openalex.org/W3197259906', 'https://openalex.org/W78556948', 'https://openalex.org/W3156153946', 'https://openalex.org/W3095437272', 'https://openalex.org/W3104432410', 'https://openalex.org/W3093096176', 'https://openalex.org/W108089327', 'https://openalex.org/W2940544976', 'https://openalex.org/W2470706628', 'https://openalex.org/W2035897039', 'https://openalex.org/W2973026522', 'https://openalex.org/W1967236754', 'https://openalex.org/W1980187804', 'https://openalex.org/W1981726950', 'https://openalex.org/W2141769811', 'https://openalex.org/W2104929631', 'https://openalex.org/W2082551530', 'https://openalex.org/W2044551314', 'https://openalex.org/W2058337001', 'https://openalex.org/W2914524714', 'https://openalex.org/W1805507973', 'https://openalex.org/W2005773329', 'https://openalex.org/W2806779042', 'https://openalex.org/W85474131', 'https://openalex.org/W2081046050', 'https://openalex.org/W2765095764', 'https://openalex.org/W2601348099', 'https://openalex.org/W2057506657', 'https://openalex.org/W3004307370', 'https://openalex.org/W2328364787', 'https://openalex.org/W4251467484', 'https://openalex.org/W2134663318', 'https://openalex.org/W3138795314', 'https://openalex.org/W2053752630', 'https://openalex.org/W2119811732', 'https://openalex.org/W4287633059', 'https://openalex.org/W2775172917', 'https://openalex.org/W2141528269']",2022-07-22
https://openalex.org/W4391021726,https://doi.org/10.1109/asru57964.2023.10389719,Salt: Distinguishable Speaker Anonymization Through Latent Space Transformation,"Speaker anonymization aims to conceal a speaker's identity without degrading speech quality and intelligibility. Most speaker anonymization systems disentangle the speaker representation from the original speech and achieve anonymization by averaging or modifying the speaker representation. However, the anonymized speech is subject to reduction in pseudo speaker distinctiveness, speech quality and intelligibility for out-of-distribution speaker. To solve this issue, we propose SALT, a Speaker Anonymization system based on Latent space Transformation. Specifically, we extract latent features by a self-supervised feature extractor and randomly sample multiple speakers and their weights, and then interpolate the latent vectors to achieve speaker anonymization. Meanwhile, we explore the extrapolation method to further extend the diversity of pseudo speakers. Experiments on Voice Privacy Challenge dataset show our system achieves a state-of-the-art distinctiveness metric while preserving speech quality and intelligibility. Our code and demo is availible at github <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">1</sup> . <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">1</sup> https://github.com/BakerBunker/SALT","['https://openalex.org/W2790046776', 'https://openalex.org/W6810404315', 'https://openalex.org/W4306867200', 'https://openalex.org/W4296069300', 'https://openalex.org/W2972848589', 'https://openalex.org/W6791179763', 'https://openalex.org/W3096424617', 'https://openalex.org/W6788095198', 'https://openalex.org/W6784635364', 'https://openalex.org/W4385823432', 'https://openalex.org/W3209984917', 'https://openalex.org/W6765696844', 'https://openalex.org/W6783867762', 'https://openalex.org/W6843253040', 'https://openalex.org/W4295308567', 'https://openalex.org/W1494198834', 'https://openalex.org/W3081871358', 'https://openalex.org/W3201497420', 'https://openalex.org/W6847363464', 'https://openalex.org/W6797037654', 'https://openalex.org/W3197478142', 'https://openalex.org/W3198694222', 'https://openalex.org/W2888867175', 'https://openalex.org/W3024869864', 'https://openalex.org/W3167533889', 'https://openalex.org/W2998572311', 'https://openalex.org/W3170405627', 'https://openalex.org/W4225585117', 'https://openalex.org/W4311000453', 'https://openalex.org/W4245692952', 'https://openalex.org/W3122079819', 'https://openalex.org/W139084513', 'https://openalex.org/W3094544164', 'https://openalex.org/W4297437784']",2023-12-16
https://openalex.org/W4401246677,https://doi.org/10.1109/taslp.2024.3436618,SpeechPrompt: Prompting Speech Language Models for Speech Processing Tasks,"Prompting has become a practical method for utilizing pre-trained language\nmodels (LMs). This approach offers several advantages. It allows an LM to adapt\nto new tasks with minimal training and parameter updates, thus achieving\nefficiency in both storage and computation. Additionally, prompting modifies\nonly the LM's inputs and harnesses the generative capabilities of language\nmodels to address various downstream tasks in a unified manner. This\nsignificantly reduces the need for human labor in designing task-specific\nmodels. These advantages become even more evident as the number of tasks served\nby the LM scales up. Motivated by the strengths of prompting, we are the first\nto explore the potential of prompting speech LMs in the domain of speech\nprocessing. Recently, there has been a growing interest in converting speech\ninto discrete units for language modeling. Our pioneer research demonstrates\nthat these quantized speech units are highly versatile within our unified\nprompting framework. Not only can they serve as class labels, but they also\ncontain rich phonetic information that can be re-synthesized back into speech\nsignals for speech generation tasks. Specifically, we reformulate speech\nprocessing tasks into speech-to-unit generation tasks. As a result, we can\nseamlessly integrate tasks such as speech classification, sequence generation,\nand speech generation within a single, unified prompting framework. The\nexperiment results show that the prompting method can achieve competitive\nperformance compared to the strong fine-tuning method based on self-supervised\nlearning models with a similar number of trainable parameters. The prompting\nmethod also shows promising results in the few-shot setting. Moreover, with the\nadvanced speech LMs coming into the stage, the proposed prompting framework\nattains great potential.\n","['https://openalex.org/W4281492411', 'https://openalex.org/W3197580070', 'https://openalex.org/W3189296823', 'https://openalex.org/W4285250921', 'https://openalex.org/W3185341429', 'https://openalex.org/W3098267758', 'https://openalex.org/W6769627184', 'https://openalex.org/W3172642864', 'https://openalex.org/W3153427360', 'https://openalex.org/W3188542058', 'https://openalex.org/W4322766882', 'https://openalex.org/W4386187806', 'https://openalex.org/W4205991051', 'https://openalex.org/W4312651322', 'https://openalex.org/W4226162428', 'https://openalex.org/W6810313920', 'https://openalex.org/W6790356757', 'https://openalex.org/W3198217962', 'https://openalex.org/W4296070387', 'https://openalex.org/W3140429000', 'https://openalex.org/W4385822683', 'https://openalex.org/W2951082691', 'https://openalex.org/W3034999214', 'https://openalex.org/W4295308567', 'https://openalex.org/W4292825791', 'https://openalex.org/W4287887366', 'https://openalex.org/W3209059054', 'https://openalex.org/W6810673746', 'https://openalex.org/W3016181583', 'https://openalex.org/W6780218876', 'https://openalex.org/W3198608154', 'https://openalex.org/W3016011332', 'https://openalex.org/W3015265920', 'https://openalex.org/W3041561163', 'https://openalex.org/W4392909068', 'https://openalex.org/W4392909760', 'https://openalex.org/W2964243274', 'https://openalex.org/W6783867762', 'https://openalex.org/W4381786045', 'https://openalex.org/W6852781825', 'https://openalex.org/W6853530687', 'https://openalex.org/W4297841687', 'https://openalex.org/W4385822890', 'https://openalex.org/W6847363464', 'https://openalex.org/W6752946794', 'https://openalex.org/W4393157525', 'https://openalex.org/W6796456916', 'https://openalex.org/W4385823335', 'https://openalex.org/W4385245566', 'https://openalex.org/W4385567149', 'https://openalex.org/W4285286749', 'https://openalex.org/W6750665317', 'https://openalex.org/W3096251052', 'https://openalex.org/W3108231750', 'https://openalex.org/W3134187040', 'https://openalex.org/W6788231366', 'https://openalex.org/W2972584841', 'https://openalex.org/W6838356808', 'https://openalex.org/W6777335856', 'https://openalex.org/W3160747466', 'https://openalex.org/W6746278845', 'https://openalex.org/W1494198834', 'https://openalex.org/W3161223924', 'https://openalex.org/W3196509775', 'https://openalex.org/W4372260337', 'https://openalex.org/W6917585676', 'https://openalex.org/W2995181338', 'https://openalex.org/W2972495969', 'https://openalex.org/W3180374548', 'https://openalex.org/W4297841405', 'https://openalex.org/W4391021530', 'https://openalex.org/W4372270126', 'https://openalex.org/W4392902623', 'https://openalex.org/W4391021627', 'https://openalex.org/W6857054612', 'https://openalex.org/W4394671563', 'https://openalex.org/W4288089799', 'https://openalex.org/W2797583228']",2024-01-01
https://openalex.org/W4407748379,https://doi.org/10.3390/electronics14040802,End-to-End Speech Recognition with Deep Fusion: Leveraging External Language Models for Low-Resource Scenarios,"With the rapid development of Automatic Speech Recognition (ASR) technology, end-to-end speech recognition systems have gained significant attention due to their ability to directly convert raw speech signals into text. However, such systems heavily rely on large amounts of labeled speech data, which severely limits model training performance and generalization, especially in low-resource language environments. To address this issue, this paper proposes an end-to-end speech recognition approach based on deep fusion, which tightly integrates an external language model (LM) with the end-to-end model during the training phase, effectively compensating for the lack of linguistic prior knowledge. Unlike traditional shallow fusion methods, deep fusion enables the model and the external LM to share representations and jointly optimize during training, thereby enhancing recognition performance under low-resource conditions. Experiments conducted on the Common Voice dataset show that, in a 10 h extremely low-resource scenario, the deep fusion method reduces the character error rate (CER) from 51.1% to 17.65%. In a 100 h scenario, it achieves a relative reduction of approximately 2.8%. Furthermore, ablation studies on model layers demonstrate that even with a reduced number of encoder and decoder layers to decrease model complexity, deep fusion continues to effectively leverage external linguistic priors, significantly improving performance in low-resource speech recognition tasks.","['https://openalex.org/W4385799550', 'https://openalex.org/W4392903288', 'https://openalex.org/W3198694222', 'https://openalex.org/W4392903704', 'https://openalex.org/W2184343439', 'https://openalex.org/W2973034126', 'https://openalex.org/W4200475319', 'https://openalex.org/W4281296901', 'https://openalex.org/W4403826739', 'https://openalex.org/W4292596092', 'https://openalex.org/W4225534571', 'https://openalex.org/W4385823064', 'https://openalex.org/W4295308567', 'https://openalex.org/W4386591026', 'https://openalex.org/W6780218876', 'https://openalex.org/W3209059054', 'https://openalex.org/W3201363102', 'https://openalex.org/W4319779560', 'https://openalex.org/W4385572536', 'https://openalex.org/W4402111995', 'https://openalex.org/W2963362078', 'https://openalex.org/W2577366047', 'https://openalex.org/W4387799863', 'https://openalex.org/W2144499799', 'https://openalex.org/W2127141656', 'https://openalex.org/W3036601975', 'https://openalex.org/W4385245566']",2025-02-19
https://openalex.org/W4408832887,https://doi.org/10.3390/fi17040143,EmoSDS: Unified Emotionally Adaptive Spoken Dialogue System Using Self-Supervised Speech Representations,"In recent years, advancements in artificial intelligence, speech, and natural language processing technology have enhanced spoken dialogue systems (SDSs), enabling natural, voice-based human–computer interaction. However, discrete, token-based LLMs in emotionally adaptive SDSs focus on lexical content while overlooking essential paralinguistic cues for emotion expression. Existing methods use external emotion predictors to compensate for this but introduce computational overhead and fail to fully integrate paralinguistic features with linguistic context. Moreover, the lack of high-quality emotional speech datasets limits models’ ability to learn expressive emotional cues. To address these challenges, we propose EmoSDS, a unified SDS framework that integrates speech and emotion recognition by leveraging self-supervised learning (SSL) features. Our three-stage training pipeline enables the LLM to learn both discrete linguistic content and continuous paralinguistic features, improving emotional expressiveness and response naturalness. Additionally, we construct EmoSC, a dataset combining GPT-generated dialogues with emotional voice conversion data, ensuring greater emotional diversity and a balanced sample distribution across emotion categories. The experimental results show that EmoSDS outperforms existing models in emotional alignment and response generation, achieving a minimum 2.9% increase in text generation metrics, enhancing the LLM’s ability to interpret emotional and textual cues for more expressive and contextually appropriate responses.","['https://openalex.org/W4389524500', 'https://openalex.org/W3174716116', 'https://openalex.org/W3153025627', 'https://openalex.org/W4392931281', 'https://openalex.org/W4402683976', 'https://openalex.org/W4372260474', 'https://openalex.org/W4205742757', 'https://openalex.org/W4391021623', 'https://openalex.org/W4405709862', 'https://openalex.org/W3209059054', 'https://openalex.org/W3209984917', 'https://openalex.org/W4226380987', 'https://openalex.org/W4385823432', 'https://openalex.org/W4295308567', 'https://openalex.org/W4372260053', 'https://openalex.org/W3140429000', 'https://openalex.org/W4392902857', 'https://openalex.org/W3198429080', 'https://openalex.org/W1494198834', 'https://openalex.org/W2101105183', 'https://openalex.org/W6682631176', 'https://openalex.org/W6761205521', 'https://openalex.org/W3193377986']",2025-03-25
https://openalex.org/W4405528881,https://doi.org/10.1016/j.specom.2024.103169,A model of early word acquisition based on realistic-scale audiovisual naming events,,"['https://openalex.org/W6730310116', 'https://openalex.org/W2625455707', 'https://openalex.org/W6780218876', 'https://openalex.org/W2768701474', 'https://openalex.org/W2063303346', 'https://openalex.org/W3130041921', 'https://openalex.org/W3159481202', 'https://openalex.org/W3157861865', 'https://openalex.org/W2586148577', 'https://openalex.org/W2978289988', 'https://openalex.org/W4225014367', 'https://openalex.org/W4378619943', 'https://openalex.org/W4295308567', 'https://openalex.org/W2483390977', 'https://openalex.org/W2396361046', 'https://openalex.org/W2148764920', 'https://openalex.org/W2113363891', 'https://openalex.org/W2963902314', 'https://openalex.org/W2989358187', 'https://openalex.org/W68733909', 'https://openalex.org/W3174311593', 'https://openalex.org/W2988907666', 'https://openalex.org/W2154396137', 'https://openalex.org/W2038056950', 'https://openalex.org/W2059824090', 'https://openalex.org/W2896457183', 'https://openalex.org/W4376140088', 'https://openalex.org/W4388118108', 'https://openalex.org/W6796162435', 'https://openalex.org/W6800532498', 'https://openalex.org/W2020944885', 'https://openalex.org/W2161673253', 'https://openalex.org/W3161374022', 'https://openalex.org/W4391669171', 'https://openalex.org/W4385822936', 'https://openalex.org/W1861492603', 'https://openalex.org/W2104752510', 'https://openalex.org/W4306317873', 'https://openalex.org/W2790695690', 'https://openalex.org/W4391503780', 'https://openalex.org/W4294955557', 'https://openalex.org/W6629717138', 'https://openalex.org/W6801926475', 'https://openalex.org/W4221161768', 'https://openalex.org/W4224875474', 'https://openalex.org/W4385823277', 'https://openalex.org/W1980044217', 'https://openalex.org/W2398490608', 'https://openalex.org/W2973180715', 'https://openalex.org/W2415378728', 'https://openalex.org/W2138410680', 'https://openalex.org/W2117539524', 'https://openalex.org/W2169578671', 'https://openalex.org/W1980862600', 'https://openalex.org/W3125087428', 'https://openalex.org/W2395899413', 'https://openalex.org/W2059168261', 'https://openalex.org/W6607376919', 'https://openalex.org/W3084747096', 'https://openalex.org/W2136549906', 'https://openalex.org/W2115099665', 'https://openalex.org/W1897242287', 'https://openalex.org/W4391428296', 'https://openalex.org/W2103280972', 'https://openalex.org/W2129168188', 'https://openalex.org/W4297808394', 'https://openalex.org/W4230640548', 'https://openalex.org/W2558086882', 'https://openalex.org/W2625477228', 'https://openalex.org/W3099142230', 'https://openalex.org/W4220770602', 'https://openalex.org/W3036601975', 'https://openalex.org/W3105148948', 'https://openalex.org/W4230776473', 'https://openalex.org/W2995680346', 'https://openalex.org/W3149547182', 'https://openalex.org/W4238433653']",2024-12-18
https://openalex.org/W4389524018,https://doi.org/10.18653/v1/2023.emnlp-main.182,Generative Spoken Language Model based on continuous word-sized audio tokens,"In NLP, text language models based on words or subwords are known to outperform their character-based counterparts. Yet, in the speech community, the standard input of spoken LMs are 20ms or 40ms-long discrete units (shorter than a phoneme). Taking inspiration from word-based LM, we introduce a Generative Spoken Language Model (GSLM) based on word-size continuous-valued audio tokens that can generate diverse and expressive language output. This is obtained by replacing lookup table for lexical types with a Lexical Embedding function, the cross entropy loss by a contrastive loss, and multinomial sampling by k-NN sampling. The resulting model is the first generative language model based on word-size continuous tokens. Its performance is on par with discrete unit GSLMs regarding generation quality as measured by automatic metrics and subjective human judgements. Moreover, it is five times more memory efficient thanks to its large 200ms units. In addition, the embeddings before and after the Lexical Embedder are phonetically and semantically interpretable.","['https://openalex.org/W2979476256', 'https://openalex.org/W4221164184', 'https://openalex.org/W4299585995', 'https://openalex.org/W2121227244', 'https://openalex.org/W4385245566', 'https://openalex.org/W4292825791', 'https://openalex.org/W2145410271', 'https://openalex.org/W2963456134', 'https://openalex.org/W4286984129', 'https://openalex.org/W2519091744', 'https://openalex.org/W3092028330', 'https://openalex.org/W2079656678', 'https://openalex.org/W2970006822', 'https://openalex.org/W3148101939', 'https://openalex.org/W4295308567', 'https://openalex.org/W2972374322', 'https://openalex.org/W1614298861', 'https://openalex.org/W3096656254', 'https://openalex.org/W4313182775', 'https://openalex.org/W101045393', 'https://openalex.org/W2346964103', 'https://openalex.org/W2785896739', 'https://openalex.org/W4224875474', 'https://openalex.org/W4381786045', 'https://openalex.org/W2766812927', 'https://openalex.org/W4224308101', 'https://openalex.org/W2913062184', 'https://openalex.org/W4372260156', 'https://openalex.org/W3133702157', 'https://openalex.org/W2777302760', 'https://openalex.org/W4303649106', 'https://openalex.org/W2768381684', 'https://openalex.org/W3140429000', 'https://openalex.org/W2131738223', 'https://openalex.org/W2947445680', 'https://openalex.org/W4214633470', 'https://openalex.org/W3146777637', 'https://openalex.org/W3036601975', 'https://openalex.org/W2126377586', 'https://openalex.org/W4286902103', 'https://openalex.org/W3110761489', 'https://openalex.org/W3197580070', 'https://openalex.org/W1810943226', 'https://openalex.org/W1494198834', 'https://openalex.org/W3215615641', 'https://openalex.org/W2963720603', 'https://openalex.org/W2963425185', 'https://openalex.org/W3097692357', 'https://openalex.org/W46679369', 'https://openalex.org/W4223486244', 'https://openalex.org/W3213873715', 'https://openalex.org/W4303519914', 'https://openalex.org/W2160473997', 'https://openalex.org/W2152790380', 'https://openalex.org/W2950414763', 'https://openalex.org/W4287887366', 'https://openalex.org/W2964243274', 'https://openalex.org/W2963979492']",2023-01-01
https://openalex.org/W4391021513,https://doi.org/10.1109/asru57964.2023.10389619,Audio-Visual Neural Syntax Acquisition,"We study phrase structure induction from visually-grounded speech. The core idea is to first segment the speech waveform into sequences of word segments, and subsequently induce phrase structure using the inferred segment-level continuous representations. We present the Audio-Visual Neural Syntax Learner (AV-NSL) that learns phrase structure by listening to audio and looking at images, without ever being exposed to text. By training on paired images and spoken captions, AV-NSL exhibits the capability to infer meaningful phrase structures that are comparable to those derived by naturally-supervised text parsers, for both English and German. Our findings extend prior work in unsupervised language acquisition from speech and grounded grammar induction, and present one approach to bridge the gap between the two topics.","['https://openalex.org/W2483390977', 'https://openalex.org/W2025482506', 'https://openalex.org/W2129882630', 'https://openalex.org/W2153568660', 'https://openalex.org/W2477749706', 'https://openalex.org/W2962753610', 'https://openalex.org/W6770596778', 'https://openalex.org/W2949579048', 'https://openalex.org/W4224875474', 'https://openalex.org/W2949399644', 'https://openalex.org/W3100776995', 'https://openalex.org/W3171691518', 'https://openalex.org/W7062406522', 'https://openalex.org/W2114347655', 'https://openalex.org/W2057007397', 'https://openalex.org/W6632788291', 'https://openalex.org/W1778492285', 'https://openalex.org/W2468716020', 'https://openalex.org/W3197974236', 'https://openalex.org/W3198782837', 'https://openalex.org/W4295308567', 'https://openalex.org/W6744839764', 'https://openalex.org/W2069859485', 'https://openalex.org/W2963521945', 'https://openalex.org/W2796738181', 'https://openalex.org/W2973230496', 'https://openalex.org/W3198702270', 'https://openalex.org/W2937176889', 'https://openalex.org/W2963084773', 'https://openalex.org/W4285064783', 'https://openalex.org/W4372259823', 'https://openalex.org/W2932376173', 'https://openalex.org/W2972885185', 'https://openalex.org/W2990883660', 'https://openalex.org/W4206003764', 'https://openalex.org/W2119717200', 'https://openalex.org/W6755977528', 'https://openalex.org/W2954930777', 'https://openalex.org/W3103427938', 'https://openalex.org/W2080090262', 'https://openalex.org/W3174311593', 'https://openalex.org/W1861492603', 'https://openalex.org/W2963909453', 'https://openalex.org/W2747874407', 'https://openalex.org/W4313182775', 'https://openalex.org/W3209059054', 'https://openalex.org/W2087165009', 'https://openalex.org/W4385823277', 'https://openalex.org/W3106150792', 'https://openalex.org/W2995680346', 'https://openalex.org/W1548450879', 'https://openalex.org/W2188924248', 'https://openalex.org/W3098643042', 'https://openalex.org/W2899663614']",2023-12-16
https://openalex.org/W4389524126,https://doi.org/10.18653/v1/2023.findings-emnlp.810,XLS-R fine-tuning on noisy word boundaries for unsupervised speech segmentation into words,"Due to the absence of explicit word boundaries in the speech stream, the task of segmenting spoken sentences into word units without text supervision is particularly challenging. In this work, we leverage the most recent self-supervised speech models that have proved to quickly adapt to new tasks through fine-tuning, even in low resource conditions. Taking inspiration from semi-supervised learning, we fine-tune an XLS-R model to predict word boundaries themselves produced by top-tier speech segmentation systems: DPDP, VG-HuBERT and DP-Parse. Once XLS-R is fine-tuned, it is used to infer new word boundary labels that are used in turn for another fine-tuning step. Our method consistently improves the performance of each system and set a new state-of-the-art that is, on average 130% higher than the previous one as measured by the F1 score on correctly discovered word tokens on five corpora featuring different languages. Finally, our system can segment speech from languages unseen during fine-tuning in a zero-shot fashion.","['https://openalex.org/W2985913104', 'https://openalex.org/W3036601975', 'https://openalex.org/W2126377586', 'https://openalex.org/W1821462560', 'https://openalex.org/W4296710617', 'https://openalex.org/W2117126688', 'https://openalex.org/W4300047444', 'https://openalex.org/W4287592659', 'https://openalex.org/W4297808394', 'https://openalex.org/W3213029956', 'https://openalex.org/W1494198834', 'https://openalex.org/W4319862440', 'https://openalex.org/W3144810982', 'https://openalex.org/W3094502228', 'https://openalex.org/W2995181338', 'https://openalex.org/W3015783745', 'https://openalex.org/W4372346125', 'https://openalex.org/W3169320628', 'https://openalex.org/W4295308567', 'https://openalex.org/W3198429080', 'https://openalex.org/W2057007397', 'https://openalex.org/W4224875474', 'https://openalex.org/W2550241133', 'https://openalex.org/W4313182775', 'https://openalex.org/W2943152387', 'https://openalex.org/W2111316763', 'https://openalex.org/W3110761489', 'https://openalex.org/W4389524018', 'https://openalex.org/W1778492285', 'https://openalex.org/W2963720603', 'https://openalex.org/W4226033575', 'https://openalex.org/W1522301498', 'https://openalex.org/W4378105483', 'https://openalex.org/W3209984917', 'https://openalex.org/W3035060554', 'https://openalex.org/W3197580070', 'https://openalex.org/W3198782837', 'https://openalex.org/W2100768664', 'https://openalex.org/W3035160371', 'https://openalex.org/W4297205890']",2023-01-01
https://openalex.org/W4308480316,https://doi.org/10.1109/jstsp.2022.3205434,Editorial Editorial of Special Issue on Self-Supervised Learning for Speech and Audio Processing,"The papers in this special section focus on self-supervised learning for speech and audio processing. A current trend in the machine learning community is the adoption of self-supervised approaches to pretrain deep networks. Self-supervised learning utilizes proxy-supervised learning tasks (or pretext tasks)—for example, distinguishing parts of the input signal from distractors or reconstructing masked input segments conditioned on unmasked segments—to obtain training data from unlabeled corpora. These approaches make it possible to use the tremendous amount of unlabeled data available on the web to train large neural models. Recent self-supervised approaches for speech and audio processing are also gaining attention.","['https://openalex.org/W4281492411', 'https://openalex.org/W4295308567', 'https://openalex.org/W4285144981', 'https://openalex.org/W4293793697', 'https://openalex.org/W4292976050', 'https://openalex.org/W4289792473', 'https://openalex.org/W4290995108', 'https://openalex.org/W4290712827', 'https://openalex.org/W4292968575', 'https://openalex.org/W4285069952', 'https://openalex.org/W4285412695', 'https://openalex.org/W4221160587', 'https://openalex.org/W4285258106', 'https://openalex.org/W4221141236', 'https://openalex.org/W4285821318', 'https://openalex.org/W4294068504', 'https://openalex.org/W4221161753', 'https://openalex.org/W4293370787', 'https://openalex.org/W4221140961', 'https://openalex.org/W4289824098', 'https://openalex.org/W4289821214', 'https://openalex.org/W4221152601', 'https://openalex.org/W4281663607', 'https://openalex.org/W4285225028', 'https://openalex.org/W4280619727', 'https://openalex.org/W3209984917', 'https://openalex.org/W3204696009', 'https://openalex.org/W3157923770', 'https://openalex.org/W3144173820', 'https://openalex.org/W3160397447', 'https://openalex.org/W3136810184', 'https://openalex.org/W3159481202', 'https://openalex.org/W3134652006', 'https://openalex.org/W4402490925', 'https://openalex.org/W3213029956', 'https://openalex.org/W6779941907', 'https://openalex.org/W4285192675', 'https://openalex.org/W4292825791', 'https://openalex.org/W4285110637', 'https://openalex.org/W4287889585', 'https://openalex.org/W3197580070', 'https://openalex.org/W4292969786', 'https://openalex.org/W3198771897', 'https://openalex.org/W4286359908', 'https://openalex.org/W4285414370', 'https://openalex.org/W3039695075']",2022-10-01
https://openalex.org/W4388118108,https://doi.org/10.23919/eusipco58844.2023.10290051,Simultaneous or Sequential Training? How Speech Representations Cooperate in a Multi-Task Self-Supervised Learning System*,"Speech representation learning with self-supervised algorithms has resulted in notable performance boosts in many downstream tasks. Recent work combined self-supervised learning (SSL) and visually grounded speech (VGS) processing mechanisms for representation learning. The joint training with SSL and VGS mechanisms provides the opportunity to utilize both unlabeled speech and speech-related visual information based on data availability. This has shown to enhance the quality of learned representations, especially at encoding semantic- and lexical-level knowledge. In this work, we further study the joint optimization of wav2vec 2.0-based SSL and transformer-based VGS as a multitask learning system. We explore a set of training scenarios to understand how speech representations are shared or transferred between the two tasks, and what is the optimal training strategy for cross-modal semantic retrieval and phoneme discrimination performance. As a result, we find that sequential training with wav2vec 2.0 first and VGS next provides higher performance on audio-visual retrieval compared to simultaneous optimization of both learning mechanisms. However, the parallel SSL-VGS training reduces the effects of catastrophic forgetting when switching between optimization criteria. Moreover, the results suggest that phonemic representations learned through the VGS mechanism may generalize better across datasets compared to those learned with SSL.","['https://openalex.org/W6809593508', 'https://openalex.org/W3198771897', 'https://openalex.org/W3197580070', 'https://openalex.org/W68733909', 'https://openalex.org/W4295308567', 'https://openalex.org/W4224875474', 'https://openalex.org/W2988907666', 'https://openalex.org/W4296068833', 'https://openalex.org/W2395899413', 'https://openalex.org/W2896457183', 'https://openalex.org/W3174311593', 'https://openalex.org/W6796162435', 'https://openalex.org/W3157861865', 'https://openalex.org/W1494198834', 'https://openalex.org/W4312210066', 'https://openalex.org/W2972892814', 'https://openalex.org/W3200287550', 'https://openalex.org/W3209059054', 'https://openalex.org/W6780218876', 'https://openalex.org/W6844194202', 'https://openalex.org/W2586148577', 'https://openalex.org/W3175593095', 'https://openalex.org/W2962753610', 'https://openalex.org/W2625455707', 'https://openalex.org/W3105148948', 'https://openalex.org/W3099142230', 'https://openalex.org/W4297808394', 'https://openalex.org/W3036601975', 'https://openalex.org/W3217290931', 'https://openalex.org/W4221161768']",2023-09-04
https://openalex.org/W4308412965,https://doi.org/10.1109/jstsp.2022.3219225,2022 Index IEEE Journal of Selected Topics in Signal Processing Vol. 16,,"['https://openalex.org/W6632923821', 'https://openalex.org/W6600828087', 'https://openalex.org/W6600360367', 'https://openalex.org/W6609364235', 'https://openalex.org/W6603584515', 'https://openalex.org/W6600788304', 'https://openalex.org/W6600856892', 'https://openalex.org/W6829103926', 'https://openalex.org/W6820348148', 'https://openalex.org/W6820460620', 'https://openalex.org/W6603944243', 'https://openalex.org/W6613768600', 'https://openalex.org/W6813651811', 'https://openalex.org/W6635869851', 'https://openalex.org/W6836200399', 'https://openalex.org/W6600627465', 'https://openalex.org/W6757545513', 'https://openalex.org/W6602226494', 'https://openalex.org/W6606275768', 'https://openalex.org/W6824273738', 'https://openalex.org/W6664736204', 'https://openalex.org/W6611603001', 'https://openalex.org/W6600200453', 'https://openalex.org/W6600033991', 'https://openalex.org/W6601010799', 'https://openalex.org/W6602142529', 'https://openalex.org/W6600446476', 'https://openalex.org/W6600822972', 'https://openalex.org/W6600246634', 'https://openalex.org/W6611882503', 'https://openalex.org/W6622500724', 'https://openalex.org/W6603435670', 'https://openalex.org/W6690408517', 'https://openalex.org/W6601579809', 'https://openalex.org/W6725572748', 'https://openalex.org/W6633560276', 'https://openalex.org/W6600741150', 'https://openalex.org/W6600238479', 'https://openalex.org/W6600137863', 'https://openalex.org/W6600003358', 'https://openalex.org/W6601676141', 'https://openalex.org/W6600109629', 'https://openalex.org/W6600339457', 'https://openalex.org/W6600577311', 'https://openalex.org/W6600339963', 'https://openalex.org/W6604862461', 'https://openalex.org/W6635000440', 'https://openalex.org/W6601022194', 'https://openalex.org/W6630513739', 'https://openalex.org/W6636946117', 'https://openalex.org/W6603460390', 'https://openalex.org/W6603930812', 'https://openalex.org/W6600248585', 'https://openalex.org/W6606191167', 'https://openalex.org/W6602855854', 'https://openalex.org/W6601641200', 'https://openalex.org/W6601211009', 'https://openalex.org/W6838370665', 'https://openalex.org/W6654051854', 'https://openalex.org/W6629264894', 'https://openalex.org/W6606931513', 'https://openalex.org/W6608782863', 'https://openalex.org/W6607167723', 'https://openalex.org/W6600708310', 'https://openalex.org/W6602646189', 'https://openalex.org/W6600751047', 'https://openalex.org/W6600868736', 'https://openalex.org/W6602780416', 'https://openalex.org/W6601215536', 'https://openalex.org/W6606648750', 'https://openalex.org/W6600903635', 'https://openalex.org/W6601141708', 'https://openalex.org/W6713663749', 'https://openalex.org/W6632164465', 'https://openalex.org/W6600204758', 'https://openalex.org/W6604721813', 'https://openalex.org/W6684367560', 'https://openalex.org/W6602127427', 'https://openalex.org/W6603527449', 'https://openalex.org/W6600902652', 'https://openalex.org/W6601846001', 'https://openalex.org/W6603957568', 'https://openalex.org/W6601626606', 'https://openalex.org/W6690597933', 'https://openalex.org/W6600874529', 'https://openalex.org/W6600503824', 'https://openalex.org/W6600168703', 'https://openalex.org/W6604801084', 'https://openalex.org/W6600009415', 'https://openalex.org/W6600020652', 'https://openalex.org/W6600195515', 'https://openalex.org/W6600005967', 'https://openalex.org/W6600041127', 'https://openalex.org/W6600140940', 'https://openalex.org/W6600558321', 'https://openalex.org/W6602120790', 'https://openalex.org/W6600336842', 'https://openalex.org/W6601313673', 'https://openalex.org/W6600291286', 'https://openalex.org/W6600319451', 'https://openalex.org/W6602841023', 'https://openalex.org/W4280579907', 'https://openalex.org/W4308480316', 'https://openalex.org/W4285258106', 'https://openalex.org/W4221160587', 'https://openalex.org/W4293370787', 'https://openalex.org/W4292968575', 'https://openalex.org/W4290712827', 'https://openalex.org/W6601680507', 'https://openalex.org/W4289821214', 'https://openalex.org/W4295308567', 'https://openalex.org/W4285821318', 'https://openalex.org/W4281492411', 'https://openalex.org/W4285225028', 'https://openalex.org/W4285144981', 'https://openalex.org/W4289792473', 'https://openalex.org/W4293793697', 'https://openalex.org/W4293195522', 'https://openalex.org/W3217211636', 'https://openalex.org/W3184562487', 'https://openalex.org/W4226232786', 'https://openalex.org/W3167748842', 'https://openalex.org/W4205819770', 'https://openalex.org/W4226061238', 'https://openalex.org/W4213443911', 'https://openalex.org/W4200634239', 'https://openalex.org/W4293179847', 'https://openalex.org/W4225747069', 'https://openalex.org/W4311212748', 'https://openalex.org/W4225759418', 'https://openalex.org/W4285306712', 'https://openalex.org/W4281663607', 'https://openalex.org/W4294068913', 'https://openalex.org/W3204696009', 'https://openalex.org/W4221153184', 'https://openalex.org/W3209064532', 'https://openalex.org/W4229003827', 'https://openalex.org/W4293195406', 'https://openalex.org/W3172644050', 'https://openalex.org/W4294068504', 'https://openalex.org/W4205224983', 'https://openalex.org/W4224281594', 'https://openalex.org/W4220722339', 'https://openalex.org/W3212443247', 'https://openalex.org/W4281940254', 'https://openalex.org/W4290995108', 'https://openalex.org/W4226154801', 'https://openalex.org/W4226216909', 'https://openalex.org/W4285414370', 'https://openalex.org/W4285205872', 'https://openalex.org/W4205443919', 'https://openalex.org/W3216940241', 'https://openalex.org/W4224942989', 'https://openalex.org/W4200632697', 'https://openalex.org/W4280571452', 'https://openalex.org/W4205782924', 'https://openalex.org/W4205224043', 'https://openalex.org/W4220914518', 'https://openalex.org/W4285412695', 'https://openalex.org/W4285213236', 'https://openalex.org/W4213055267', 'https://openalex.org/W4285121428', 'https://openalex.org/W4285534449', 'https://openalex.org/W4285408284', 'https://openalex.org/W4292969786', 'https://openalex.org/W4226406172']",2022-10-01
https://openalex.org/W4379540254,https://doi.org/10.48550/arxiv.2306.02972,Simultaneous or Sequential Training? How Speech Representations Cooperate in a Multi-Task Self-Supervised Learning System,"Speech representation learning with self-supervised algorithms has resulted in notable performance boosts in many downstream tasks. Recent work combined self-supervised learning (SSL) and visually grounded speech (VGS) processing mechanisms for representation learning. The joint training with SSL and VGS mechanisms provides the opportunity to utilize both unlabeled speech and speech-related visual information based on data availability. This has shown to enhance the quality of learned representations, especially at encoding semantic- and lexical-level knowledge. In this work, we further study the joint optimization of wav2vec 2.0-based SSL and transformer-based VGS as a multi-task learning system. We explore a set of training scenarios to understand how speech representations are shared or transferred between the two tasks, and what is the optimal training strategy for cross-modal semantic retrieval and phoneme discrimination performance. As a result, we find that sequential training with wav2vec 2.0 first and VGS next provides higher performance on audio-visual retrieval compared to simultaneous optimization of both learning mechanisms. However, the parallel SSL-VGS training reduces the effects of catastrophic forgetting when switching between optimization criteria. Moreover, the results suggest that phonemic representations learned through the VGS mechanism may generalize better across datasets compared to those learned with SSL.","['https://openalex.org/W3157861865', 'https://openalex.org/W4287552504', 'https://openalex.org/W2972892814', 'https://openalex.org/W3105148948', 'https://openalex.org/W4312210066', 'https://openalex.org/W4297808394', 'https://openalex.org/W4296068833', 'https://openalex.org/W2395899413', 'https://openalex.org/W3169320628', 'https://openalex.org/W4230640548', 'https://openalex.org/W2586148577', 'https://openalex.org/W3198771897', 'https://openalex.org/W4221161768', 'https://openalex.org/W4224875474', 'https://openalex.org/W1494198834', 'https://openalex.org/W3197580070', 'https://openalex.org/W2988907666', 'https://openalex.org/W68733909', 'https://openalex.org/W3036601975', 'https://openalex.org/W3174311593', 'https://openalex.org/W4295308567', 'https://openalex.org/W2896457183', 'https://openalex.org/W2962753610', 'https://openalex.org/W4286973758']",2023-06-05
https://openalex.org/W4386623759,https://doi.org/10.1017/s0305000923000491,Word segmentation from transcriptions of child-directed speech using lexical and sub-lexical cues,"Abstract We compare two frameworks for the segmentation of words in child-directed speech, PHOCUS and MULTICUE. PHOCUS is driven by lexical recognition, whereas MULTICUE combines sub-lexical properties to make boundary decisions, representing differing views of speech processing. We replicate these frameworks, perform novel benchmarking and confirm that both achieve competitive results. We develop a new framework for segmentation, the DYnamic Programming MULTIple-cue framework (DYMULTI), which combines the strengths of PHOCUS and MULTICUE by considering both sub-lexical and lexical cues when making boundary decisions. DYMULTI achieves state-of-the-art results and outperforms PHOCUS and MULTICUE on 15 of 26 languages in a cross-lingual experiment. As a model built on psycholinguistic principles, this validates DYMULTI as a robust model for speech segmentation and a contribution to the understanding of language acquisition.","['https://openalex.org/W2134237567', 'https://openalex.org/W2990106622', 'https://openalex.org/W2071402670', 'https://openalex.org/W2487316081', 'https://openalex.org/W2059824090', 'https://openalex.org/W2141622386', 'https://openalex.org/W1995982951', 'https://openalex.org/W2022564164', 'https://openalex.org/W2063303346', 'https://openalex.org/W6772289264', 'https://openalex.org/W2064699871', 'https://openalex.org/W2061863127', 'https://openalex.org/W2115197214', 'https://openalex.org/W2145410271', 'https://openalex.org/W2093825590', 'https://openalex.org/W4393452965', 'https://openalex.org/W4295308567', 'https://openalex.org/W2154756108', 'https://openalex.org/W2509645706', 'https://openalex.org/W6675354045', 'https://openalex.org/W2165965469', 'https://openalex.org/W2011110202', 'https://openalex.org/W1597739853', 'https://openalex.org/W2144800021', 'https://openalex.org/W3001772156', 'https://openalex.org/W2343593471', 'https://openalex.org/W2295297373', 'https://openalex.org/W2117325844', 'https://openalex.org/W4313182775', 'https://openalex.org/W2166061736', 'https://openalex.org/W2731975404', 'https://openalex.org/W2161952424', 'https://openalex.org/W2166391802', 'https://openalex.org/W2165348108', 'https://openalex.org/W3097485645', 'https://openalex.org/W1602670218', 'https://openalex.org/W4244663558', 'https://openalex.org/W6677975208', 'https://openalex.org/W4296710617', 'https://openalex.org/W1993768374', 'https://openalex.org/W2167834252', 'https://openalex.org/W2036572838', 'https://openalex.org/W1980862600', 'https://openalex.org/W2988511669', 'https://openalex.org/W4239549861', 'https://openalex.org/W2296328843', 'https://openalex.org/W1991133427', 'https://openalex.org/W2131785404', 'https://openalex.org/W2758697525', 'https://openalex.org/W2037752261', 'https://openalex.org/W2045343524', 'https://openalex.org/W2250818747', 'https://openalex.org/W2043013057', 'https://openalex.org/W2157149948', 'https://openalex.org/W2768381684', 'https://openalex.org/W2074546930', 'https://openalex.org/W6677207036', 'https://openalex.org/W2605959375', 'https://openalex.org/W2113641473', 'https://openalex.org/W2909509056', 'https://openalex.org/W1995991622', 'https://openalex.org/W2158324645', 'https://openalex.org/W4393849379', 'https://openalex.org/W2126377586', 'https://openalex.org/W3097159218', 'https://openalex.org/W2135704565', 'https://openalex.org/W2556510664', 'https://openalex.org/W6602469692', 'https://openalex.org/W2115867364', 'https://openalex.org/W2468716020', 'https://openalex.org/W2121975023', 'https://openalex.org/W2110485445', 'https://openalex.org/W2345913943', 'https://openalex.org/W2980252091', 'https://openalex.org/W4251556668', 'https://openalex.org/W7062273727', 'https://openalex.org/W2142111485', 'https://openalex.org/W2096112399', 'https://openalex.org/W2157427027', 'https://openalex.org/W3125087428', 'https://openalex.org/W6725770309', 'https://openalex.org/W6683724119', 'https://openalex.org/W4313255477', 'https://openalex.org/W2029948425', 'https://openalex.org/W3199093330', 'https://openalex.org/W2510020695', 'https://openalex.org/W3098643042', 'https://openalex.org/W62109652', 'https://openalex.org/W2101234009', 'https://openalex.org/W2996160789', 'https://openalex.org/W635149649']",2023-09-12
https://openalex.org/W4402605100,https://doi.org/10.1007/978-3-031-72350-6_2,Developmental Predictive Coding Model for Early Infancy Mono and Bilingual Vocal Continual Learning,,"['https://openalex.org/W2061248998', 'https://openalex.org/W4380182373', 'https://openalex.org/W2153791616', 'https://openalex.org/W4295308567', 'https://openalex.org/W2989728284', 'https://openalex.org/W2131352719', 'https://openalex.org/W1977628053', 'https://openalex.org/W4224920297', 'https://openalex.org/W2068838877', 'https://openalex.org/W1998550070', 'https://openalex.org/W2132960888', 'https://openalex.org/W2123940254', 'https://openalex.org/W65738273', 'https://openalex.org/W2046079134', 'https://openalex.org/W4248527740', 'https://openalex.org/W1984717236', 'https://openalex.org/W1972159947', 'https://openalex.org/W2155721440', 'https://openalex.org/W2005311247', 'https://openalex.org/W1545077353', 'https://openalex.org/W1879556487', 'https://openalex.org/W112736981', 'https://openalex.org/W1494198834', 'https://openalex.org/W2975606147', 'https://openalex.org/W2149970916', 'https://openalex.org/W2146670093', 'https://openalex.org/W3125087428', 'https://openalex.org/W2098731045', 'https://openalex.org/W2157469922', 'https://openalex.org/W2101509422', 'https://openalex.org/W4225391041']",2024-01-01
https://openalex.org/W4406132022,https://doi.org/10.1111/desc.13606,Simulating Early Phonetic and Word Learning Without Linguistic Categories,"ABSTRACT Before they even talk, infants become sensitive to the speech sounds of their native language and recognize the auditory form of an increasing number of words. Traditionally, these early perceptual changes are attributed to an emerging knowledge of linguistic categories such as phonemes or words. However, there is growing skepticism surrounding this interpretation due to limited evidence of category knowledge in infants. Previous modeling work has shown that a distributional learning algorithm could reproduce perceptual changes in infants' early phonetic learning without acquiring phonetic categories. Taking this inquiry further, we propose that linguistic categories may not be needed for early word learning. We introduce STELA, a predictive coding algorithm designed to extract statistical patterns from continuous raw speech data. Our findings demonstrate that STELA can reproduce some developmental patterns of phonetic and word form learning without relying on linguistic categories such as phonemes or words nor requiring explicit word segmentation. Through an analysis of the learned representations, we show evidence that linguistic categories may emerge as an end product of learning rather than being prerequisites during early language acquisition.","['https://openalex.org/W2529194139', 'https://openalex.org/W4283453659', 'https://openalex.org/W4296710617', 'https://openalex.org/W2099164611', 'https://openalex.org/W2995929068', 'https://openalex.org/W3193068792', 'https://openalex.org/W3202070718', 'https://openalex.org/W2063303346', 'https://openalex.org/W122673323', 'https://openalex.org/W3130041921', 'https://openalex.org/W4229781645', 'https://openalex.org/W6811685372', 'https://openalex.org/W2032442824', 'https://openalex.org/W4221038855', 'https://openalex.org/W4225815933', 'https://openalex.org/W1532704504', 'https://openalex.org/W4256675988', 'https://openalex.org/W4225726571', 'https://openalex.org/W4295308567', 'https://openalex.org/W2483390977', 'https://openalex.org/W2037662195', 'https://openalex.org/W2110485445', 'https://openalex.org/W6676391964', 'https://openalex.org/W2107038463', 'https://openalex.org/W3199093330', 'https://openalex.org/W6800775014', 'https://openalex.org/W2396361046', 'https://openalex.org/W2148764920', 'https://openalex.org/W6682122378', 'https://openalex.org/W4401117643', 'https://openalex.org/W2126377586', 'https://openalex.org/W2160727679', 'https://openalex.org/W2037525070', 'https://openalex.org/W2991557631', 'https://openalex.org/W1995422333', 'https://openalex.org/W1579929927', 'https://openalex.org/W3140196993', 'https://openalex.org/W1989914796', 'https://openalex.org/W2149784807', 'https://openalex.org/W2038056950', 'https://openalex.org/W2037752261', 'https://openalex.org/W4206039057', 'https://openalex.org/W1597121597', 'https://openalex.org/W6635894473', 'https://openalex.org/W2014307400', 'https://openalex.org/W6653853028', 'https://openalex.org/W2103091632', 'https://openalex.org/W1984717236', 'https://openalex.org/W7037316554', 'https://openalex.org/W2063525438', 'https://openalex.org/W3129009457', 'https://openalex.org/W4366994024', 'https://openalex.org/W4391669171', 'https://openalex.org/W4379474370', 'https://openalex.org/W4385822936', 'https://openalex.org/W2741692265', 'https://openalex.org/W4232693094', 'https://openalex.org/W6651343493', 'https://openalex.org/W2068247585', 'https://openalex.org/W6667887468', 'https://openalex.org/W2026992087', 'https://openalex.org/W2251025892', 'https://openalex.org/W2074488330', 'https://openalex.org/W2136653392', 'https://openalex.org/W4313255477', 'https://openalex.org/W6808618455', 'https://openalex.org/W2776941264', 'https://openalex.org/W2167834252', 'https://openalex.org/W3110458199', 'https://openalex.org/W4221140961', 'https://openalex.org/W4292825791', 'https://openalex.org/W2842511635', 'https://openalex.org/W4297808394', 'https://openalex.org/W2113332115', 'https://openalex.org/W2078828996', 'https://openalex.org/W6670256387', 'https://openalex.org/W4395036961', 'https://openalex.org/W6631362777', 'https://openalex.org/W2119885245', 'https://openalex.org/W3005511757', 'https://openalex.org/W3016181583', 'https://openalex.org/W1993984071', 'https://openalex.org/W1980862600', 'https://openalex.org/W6645640999', 'https://openalex.org/W2029008609', 'https://openalex.org/W3125087428', 'https://openalex.org/W2395899413', 'https://openalex.org/W1944583518', 'https://openalex.org/W6640915429', 'https://openalex.org/W2163097816', 'https://openalex.org/W2119165475', 'https://openalex.org/W6632622110', 'https://openalex.org/W2108582985', 'https://openalex.org/W2003341094', 'https://openalex.org/W1925965306', 'https://openalex.org/W6640227979', 'https://openalex.org/W4391428296', 'https://openalex.org/W2101509422', 'https://openalex.org/W3146245645', 'https://openalex.org/W4235199064', 'https://openalex.org/W1974052916', 'https://openalex.org/W2082256905', 'https://openalex.org/W593365102', 'https://openalex.org/W4394671563', 'https://openalex.org/W2468383091']",2025-01-06
https://openalex.org/W4406264212,https://doi.org/10.1109/icce-asia63397.2024.10773691,Impact of Target Speech Length on Performance in Voice Conversion Modeling,,"['https://openalex.org/W6762533536', 'https://openalex.org/W3083423753', 'https://openalex.org/W4385823432', 'https://openalex.org/W6856253845', 'https://openalex.org/W3098557217', 'https://openalex.org/W3209984917', 'https://openalex.org/W3209059054', 'https://openalex.org/W4372260053', 'https://openalex.org/W3096524539', 'https://openalex.org/W3015434413', 'https://openalex.org/W2963411216', 'https://openalex.org/W6640963894', 'https://openalex.org/W6610566761', 'https://openalex.org/W4238049007', 'https://openalex.org/W4295308567', 'https://openalex.org/W6783867762', 'https://openalex.org/W6797772099', 'https://openalex.org/W6805710207', 'https://openalex.org/W3024869864', 'https://openalex.org/W3197659778', 'https://openalex.org/W3165478005', 'https://openalex.org/W3092028330', 'https://openalex.org/W4386555999', 'https://openalex.org/W1959608418']",2024-11-03
https://openalex.org/W4406858552,https://doi.org/10.1109/apsipaasc63619.2025.10848766,Analytic Study of Text-Free Speech Synthesis for Raw Audio using a Self-Supervised Learning Model,,"['https://openalex.org/W6811170316', 'https://openalex.org/W2964243274', 'https://openalex.org/W6778823374', 'https://openalex.org/W6796464841', 'https://openalex.org/W6790356757', 'https://openalex.org/W2842511635', 'https://openalex.org/W6780218876', 'https://openalex.org/W3209059054', 'https://openalex.org/W4385245566', 'https://openalex.org/W3093096176', 'https://openalex.org/W3197259906', 'https://openalex.org/W4295308567', 'https://openalex.org/W3210530853', 'https://openalex.org/W4372349107', 'https://openalex.org/W4385822372', 'https://openalex.org/W1494198834', 'https://openalex.org/W6745289305', 'https://openalex.org/W6767245602', 'https://openalex.org/W3196027980', 'https://openalex.org/W4296068791', 'https://openalex.org/W4224932952', 'https://openalex.org/W6839738141', 'https://openalex.org/W6783726357', 'https://openalex.org/W3015877095', 'https://openalex.org/W4292264739']",2024-12-03
https://openalex.org/W4408354333,https://doi.org/10.1109/icassp49660.2025.10890008,Zero-resource Speech Translation and Recognition with LLMs,,"['https://openalex.org/W4295308567', 'https://openalex.org/W4297841687', 'https://openalex.org/W4392903956', 'https://openalex.org/W4391021623', 'https://openalex.org/W6859099255', 'https://openalex.org/W4390041933', 'https://openalex.org/W6780218876', 'https://openalex.org/W6838865847', 'https://openalex.org/W4402670519', 'https://openalex.org/W6853998256', 'https://openalex.org/W4385572710', 'https://openalex.org/W3214697273', 'https://openalex.org/W3097777922', 'https://openalex.org/W6810673746', 'https://openalex.org/W6757817989', 'https://openalex.org/W4385571124', 'https://openalex.org/W6769627184', 'https://openalex.org/W3169483174', 'https://openalex.org/W2979826702', 'https://openalex.org/W6866575372', 'https://openalex.org/W6796581206', 'https://openalex.org/W6853249747', 'https://openalex.org/W3196509775', 'https://openalex.org/W3015698636', 'https://openalex.org/W2963532001', 'https://openalex.org/W4392902792', 'https://openalex.org/W6771467084', 'https://openalex.org/W3119308075', 'https://openalex.org/W4319862635', 'https://openalex.org/W3095410713']",2025-03-12
https://openalex.org/W4412195314,https://doi.org/10.3390/s25144288,Phoneme-Aware Hierarchical Augmentation and Semantic-Aware SpecAugment for Low-Resource Cantonese Speech Recognition,"Cantonese Automatic Speech Recognition (ASR) is hindered by tonal complexity, acoustic diversity, and a lack of labelled data. This study proposes a phoneme-aware hierarchical augmentation framework that enhances performance without additional annotation. A Phoneme Substitution Matrix (PSM), built from Montreal Forced Aligner alignments and Tacotron-2 synthesis, injects adversarial phoneme variants into both transcripts and their aligned audio segments, enlarging pronunciation diversity. Concurrently, a semantic-aware SpecAugment scheme exploits wav2vec 2.0 attention heat maps and keyword boundaries to adaptively mask informative time–frequency regions; a reinforcement-learning controller tunes the masking schedule online, forcing the model to rely on a wider context. On the Common Voice Cantonese 50 h subset, the combined strategy reduces the character error rate (CER) from 26.17% to 16.88% with wav2vec 2.0 and from 38.83% to 23.55% with Zipformer. At 100 h, the CER further drops to 4.27% and 2.32%, yielding relative gains of 32–44%. Ablation studies confirm that phoneme-level and masking components provide complementary benefits. The framework offers a practical, model-independent path toward accurate ASR for Cantonese and other low-resource tonal languages. This paper presents an intelligent sensing-oriented modeling framework for speech signals, which is suitable for deployment on edge or embedded systems to process input from audio sensors (e.g., microphones) and shows promising potential for voice-interactive terminal applications.","['https://openalex.org/W4385799550', 'https://openalex.org/W3198694222', 'https://openalex.org/W4392903704', 'https://openalex.org/W3097777922', 'https://openalex.org/W3202419788', 'https://openalex.org/W4389519232', 'https://openalex.org/W3209059054', 'https://openalex.org/W4295308567', 'https://openalex.org/W6780218876', 'https://openalex.org/W4401043990', 'https://openalex.org/W4312120835', 'https://openalex.org/W2184343439', 'https://openalex.org/W2936774411', 'https://openalex.org/W3015995734', 'https://openalex.org/W4392903288', 'https://openalex.org/W2127141656', 'https://openalex.org/W2144499799', 'https://openalex.org/W2395416438', 'https://openalex.org/W3036601975']",2025-07-09
https://openalex.org/W4413930132,https://doi.org/10.3390/s25175404,LoRA-INT8 Whisper: A Low-Cost Cantonese Speech Recognition Framework for Edge Devices,"To address the triple bottlenecks of data scarcity, oversized models, and slow inference that hinder Cantonese automatic speech recognition (ASR) in low-resource and edge-deployment settings, this study proposes a cost-effective Cantonese ASR system based on LoRA fine-tuning and INT8 quantization. First, Whisper-tiny is parameter-efficiently fine-tuned on the Common Voice zh-HK training set using LoRA with rank = 8. Only 1.6% of the original weights are updated, reducing the character error rate (CER) from 49.5% to 11.1%, a performance close to full fine-tuning (10.3%), while cutting the training memory footprint and computational cost by approximately one order of magnitude. Next, the fine-tuned model is compressed into a 60 MB INT8 checkpoint via dynamic quantization in ONNX Runtime. On a MacBook Pro M1 Max CPU, the quantized model achieves an RTF = 0.20 (offline inference 5 × real-time) and 43% lower latency than the FP16 baseline; on an NVIDIA A10 GPU, it reaches RTF = 0.06, meeting the requirements of high-concurrency cloud services. Ablation studies confirm that the LoRA-INT8 configuration offers the best trade-off among accuracy, speed, and model size. Limitations include the absence of spontaneous-speech noise data, extreme-hardware validation, and adaptive LoRA structure optimization. Future work will incorporate large-scale self-supervised pre-training, tone-aware loss functions, AdaLoRA architecture search, and INT4/NPU quantization, and will establish an mJ/char energy–accuracy curve. The ultimate goal is to achieve CER ≤ 8%, RTF &lt; 0.1, and mJ/char &lt; 1 for low-power real-time Cantonese ASR in practical IoT scenarios.","['https://openalex.org/W4385799550', 'https://openalex.org/W3198694222', 'https://openalex.org/W4392903704', 'https://openalex.org/W3210365128', 'https://openalex.org/W4297841771', 'https://openalex.org/W4224918069', 'https://openalex.org/W4402112032', 'https://openalex.org/W4402115918', 'https://openalex.org/W3209059054', 'https://openalex.org/W4295308567', 'https://openalex.org/W4385245566', 'https://openalex.org/W2130942839', 'https://openalex.org/W3036601975']",2025-09-01
https://openalex.org/W4413974959,https://doi.org/10.3758/s13428-025-02772-6,A pipeline for stochastic and controlled generation of realistic language input for simulating infant language acquisition,"Abstract Computational models of early language development involve implementing theories of learning as functional learning algorithms, exposing these models to realistic language input, and comparing learning outcomes to those in infants. While recent research has made major strides in developing more powerful learning models and evaluation protocols grounded in infant data, models are still predominantly trained with non-naturalistic input data, such as crowd-sourced read speech or text transcripts. This is due to the lack of suitable child-directed speech (CDS) corpora in terms of scale and quality. In parallel, the question of how properties and individual variability in language input affect learning outcomes is an active area of empirical research, underlining the need for realistic yet controllable data for modeling such phenomena. This paper presents a solution to the training data problem through stochastic generation of naturalistic CDS data using statistical models, thereby enabling controlled computational simulations with naturalistic input. We provide a proof-of-concept demonstration of the approach by showing how naturalistic CDS transcripts can be generated with a language model conditioned on recipient information (here, infant age), and how text-to-speech systems can be used to convert the transcripts to high-quality speech with a controllable speaking style. We also conduct modeling experiments with generated speech corpora by varying different aspects of the data, showing how this maps into different learning outcomes, thereby demonstrating the feasibility of the approach for controlled language learning simulations. Finally, we discuss the limitations of using synthetic data in general, and of the present proof-of-concept pipeline in particular.","['https://openalex.org/W2007498854', 'https://openalex.org/W2885156775', 'https://openalex.org/W2044707576', 'https://openalex.org/W4402112533', 'https://openalex.org/W3157861865', 'https://openalex.org/W4402111712', 'https://openalex.org/W3045733287', 'https://openalex.org/W4382918397', 'https://openalex.org/W3005165546', 'https://openalex.org/W4378619943', 'https://openalex.org/W2125814841', 'https://openalex.org/W3197259906', 'https://openalex.org/W4295308567', 'https://openalex.org/W2483390977', 'https://openalex.org/W4392935650', 'https://openalex.org/W1993755070', 'https://openalex.org/W2130518563', 'https://openalex.org/W2396361046', 'https://openalex.org/W2148764920', 'https://openalex.org/W2147008239', 'https://openalex.org/W2605959375', 'https://openalex.org/W1969005071', 'https://openalex.org/W2085654611', 'https://openalex.org/W2736876693', 'https://openalex.org/W2989358187', 'https://openalex.org/W3211156350', 'https://openalex.org/W3213014097', 'https://openalex.org/W1990743660', 'https://openalex.org/W135984148', 'https://openalex.org/W4405528881', 'https://openalex.org/W4376140088', 'https://openalex.org/W2105899777', 'https://openalex.org/W1974714315', 'https://openalex.org/W2074011760', 'https://openalex.org/W2086880169', 'https://openalex.org/W2103091632', 'https://openalex.org/W3161374022', 'https://openalex.org/W4385822936', 'https://openalex.org/W1861492603', 'https://openalex.org/W3018827121', 'https://openalex.org/W4386347008', 'https://openalex.org/W2747874407', 'https://openalex.org/W4290673677', 'https://openalex.org/W2035983922', 'https://openalex.org/W2619115632', 'https://openalex.org/W2790695690', 'https://openalex.org/W4385823130', 'https://openalex.org/W2923426270', 'https://openalex.org/W3105478389', 'https://openalex.org/W4385823277', 'https://openalex.org/W3037109418', 'https://openalex.org/W1991274470', 'https://openalex.org/W2415378728', 'https://openalex.org/W2969145661', 'https://openalex.org/W2546861836', 'https://openalex.org/W3016181583', 'https://openalex.org/W1980862600', 'https://openalex.org/W2910821810', 'https://openalex.org/W2109606373', 'https://openalex.org/W170586818', 'https://openalex.org/W2395899413', 'https://openalex.org/W3125087428', 'https://openalex.org/W2059168261', 'https://openalex.org/W2154600605', 'https://openalex.org/W4323896824', 'https://openalex.org/W4391428296', 'https://openalex.org/W4389519222', 'https://openalex.org/W2089883580', 'https://openalex.org/W2101509422', 'https://openalex.org/W4399862058', 'https://openalex.org/W4385570848', 'https://openalex.org/W1997854624', 'https://openalex.org/W4392051461', 'https://openalex.org/W3103536442', 'https://openalex.org/W4300870773', 'https://openalex.org/W2612690371', 'https://openalex.org/W2990138404', 'https://openalex.org/W3143835353', 'https://openalex.org/W2962832640', 'https://openalex.org/W2750779823', 'https://openalex.org/W3112702808', 'https://openalex.org/W2559655401', 'https://openalex.org/W2542909410']",2025-09-04
https://openalex.org/W4414069553,https://doi.org/10.3390/sym17091478,Phoneme-Aware Augmentation for Robust Cantonese ASR Under Low-Resource Conditions,"Cantonese automatic speech recognition (ASR) faces persistent challenges due to its nine lexical tones, extensive phonological variation, and the scarcity of professionally transcribed corpora. To address these issues, we propose a lightweight and data-efficient framework that leverages weak phonetic supervision (WPS) in conjunction with two pho-neme-aware augmentation strategies. (1) Dynamic Boundary-Aligned Phoneme Dropout progressively removes entire IPA segments according to a curriculum schedule, simulating real-world phenomena such as elision, lenition, and tonal drift while ensuring training stability. (2) Phoneme-Aware SpecAugment confines all time- and frequency-masking operations within phoneme boundaries and prioritizes high-attention regions, thereby preserving intra-phonemic contours and formant integrity. Built on the Whistle encoder—which integrates a Conformer backbone, Connectionist Temporal Classification–Conditional Random Field (CTC-CRF) alignment, and a multi-lingual phonetic space—the approach requires only a grapheme-to-phoneme lexicon and Montreal Forced Aligner outputs, without any additional manual labeling. Experiments on the Cantonese subset of Common Voice demonstrate consistent gains: Dynamic Dropout alone reduces phoneme error rate (PER) from 17.8% to 16.7% with 50 h of speech and 16.4% to 15.1% with 100 h, while the combination of the two augmentations further lowers PER to 15.9%/14.4%. These results confirm that structure-aware phoneme-level perturbations provide an effective and low-cost solution for building robust Cantonese ASR systems under low-resource conditions.","['https://openalex.org/W4385799550', 'https://openalex.org/W3198694222', 'https://openalex.org/W4392903704', 'https://openalex.org/W4296068827', 'https://openalex.org/W3209059054', 'https://openalex.org/W4295308567', 'https://openalex.org/W2963194026', 'https://openalex.org/W4372270126', 'https://openalex.org/W4322714819', 'https://openalex.org/W4385822995', 'https://openalex.org/W4385823436', 'https://openalex.org/W4385822337', 'https://openalex.org/W4408358622', 'https://openalex.org/W2936774411', 'https://openalex.org/W2747874407', 'https://openalex.org/W3036601975']",2025-09-08
https://openalex.org/W4417052196,https://doi.org/10.23919/eusipco63237.2025.11226445,QR-VC: Leveraging Quantization Residuals for Linear Disentanglement in Zero-Shot Voice Conversion,,"['https://openalex.org/W3209059054', 'https://openalex.org/W3209984917', 'https://openalex.org/W4226380987', 'https://openalex.org/W4319862652', 'https://openalex.org/W4393156644', 'https://openalex.org/W4392902857', 'https://openalex.org/W4372260053', 'https://openalex.org/W3140429000', 'https://openalex.org/W4385823432', 'https://openalex.org/W4295308567', 'https://openalex.org/W4408017609', 'https://openalex.org/W4393156634', 'https://openalex.org/W1494198834', 'https://openalex.org/W4250024550', 'https://openalex.org/W1574447377', 'https://openalex.org/W3083423753']",2025-09-08
https://openalex.org/W4379193822,https://doi.org/10.1016/j.inffus.2023.101869,A review of deep learning techniques for speech processing,,"['https://openalex.org/W2912581782', 'https://openalex.org/W3137249133', 'https://openalex.org/W2976159681', 'https://openalex.org/W4205130185', 'https://openalex.org/W2125838338', 'https://openalex.org/W2160815625', 'https://openalex.org/W1995562189', 'https://openalex.org/W6681513673', 'https://openalex.org/W6623517193', 'https://openalex.org/W6739901393', 'https://openalex.org/W2088632109', 'https://openalex.org/W4313178214', 'https://openalex.org/W2110164509', 'https://openalex.org/W6775102986', 'https://openalex.org/W6779480587', 'https://openalex.org/W2099124598', 'https://openalex.org/W6675661078', 'https://openalex.org/W6680522077', 'https://openalex.org/W6640010188', 'https://openalex.org/W6600721324', 'https://openalex.org/W6682354605', 'https://openalex.org/W6682859417', 'https://openalex.org/W6712389868', 'https://openalex.org/W2131774270', 'https://openalex.org/W2064675550', 'https://openalex.org/W6604396178', 'https://openalex.org/W6807617354', 'https://openalex.org/W6810597000', 'https://openalex.org/W6772959282', 'https://openalex.org/W6744661987', 'https://openalex.org/W6738686518', 'https://openalex.org/W6775998690', 'https://openalex.org/W6803217577', 'https://openalex.org/W6786748378', 'https://openalex.org/W2965002127', 'https://openalex.org/W6759942353', 'https://openalex.org/W2945057891', 'https://openalex.org/W6696843773', 'https://openalex.org/W3100777112', 'https://openalex.org/W6688985767', 'https://openalex.org/W6768288844', 'https://openalex.org/W2556345765', 'https://openalex.org/W4318200341', 'https://openalex.org/W6757555829', 'https://openalex.org/W6683129133', 'https://openalex.org/W4220705102', 'https://openalex.org/W6769971416', 'https://openalex.org/W6752581720', 'https://openalex.org/W4292969786', 'https://openalex.org/W6746700228', 'https://openalex.org/W4312611743', 'https://openalex.org/W2974308384', 'https://openalex.org/W3199024477', 'https://openalex.org/W2989622482', 'https://openalex.org/W6731370813', 'https://openalex.org/W6761206160', 'https://openalex.org/W4294406066', 'https://openalex.org/W6770389661', 'https://openalex.org/W3211408542', 'https://openalex.org/W6785003639', 'https://openalex.org/W6773702976', 'https://openalex.org/W6778883912', 'https://openalex.org/W4213019189', 'https://openalex.org/W3031696893', 'https://openalex.org/W1923211482', 'https://openalex.org/W3208624098', 'https://openalex.org/W6768009688', 'https://openalex.org/W6757079273', 'https://openalex.org/W2972389417', 'https://openalex.org/W6763701032', 'https://openalex.org/W6769627184', 'https://openalex.org/W6810007534', 'https://openalex.org/W6788335241', 'https://openalex.org/W2974390546', 'https://openalex.org/W6784470492', 'https://openalex.org/W4283364647', 'https://openalex.org/W6848673773', 'https://openalex.org/W6743440867', 'https://openalex.org/W6754299077', 'https://openalex.org/W6755930846', 'https://openalex.org/W6768003404', 'https://openalex.org/W6774280737', 'https://openalex.org/W6675365184', 'https://openalex.org/W2972837679', 'https://openalex.org/W6754456516', 'https://openalex.org/W6755879856', 'https://openalex.org/W6776305863', 'https://openalex.org/W6784657998', 'https://openalex.org/W6770506093', 'https://openalex.org/W2897353073', 'https://openalex.org/W6791631845', 'https://openalex.org/W3083423753', 'https://openalex.org/W3038342317', 'https://openalex.org/W6766665032', 'https://openalex.org/W6745628346', 'https://openalex.org/W6783872503', 'https://openalex.org/W2936055714', 'https://openalex.org/W6750691924', 'https://openalex.org/W6787822403', 'https://openalex.org/W2996906606', 'https://openalex.org/W2985331920', 'https://openalex.org/W6745537798', 'https://openalex.org/W6767098714', 'https://openalex.org/W6784342092', 'https://openalex.org/W6784455497', 'https://openalex.org/W6802368550', 'https://openalex.org/W6776488176', 'https://openalex.org/W6801630172', 'https://openalex.org/W6810367489', 'https://openalex.org/W6774849813', 'https://openalex.org/W6787396906', 'https://openalex.org/W4319663835', 'https://openalex.org/W6790799587', 'https://openalex.org/W4312982325', 'https://openalex.org/W6779823529', 'https://openalex.org/W6679045638', 'https://openalex.org/W6795261426', 'https://openalex.org/W6798721538', 'https://openalex.org/W6810499433', 'https://openalex.org/W6748257384', 'https://openalex.org/W6748010250', 'https://openalex.org/W6785269020', 'https://openalex.org/W6743234192', 'https://openalex.org/W6735236233', 'https://openalex.org/W6745415975', 'https://openalex.org/W6767878346', 'https://openalex.org/W6744765397', 'https://openalex.org/W6755054534', 'https://openalex.org/W6795170356', 'https://openalex.org/W6775421620', 'https://openalex.org/W3131643166', 'https://openalex.org/W6810185288', 'https://openalex.org/W3100270690', 'https://openalex.org/W6753968785', 'https://openalex.org/W6754496211', 'https://openalex.org/W6784435678', 'https://openalex.org/W6767815451', 'https://openalex.org/W6662018943', 'https://openalex.org/W6742911084', 'https://openalex.org/W6850090677', 'https://openalex.org/W6787699154', 'https://openalex.org/W3204696009', 'https://openalex.org/W6775452034', 'https://openalex.org/W6784637704', 'https://openalex.org/W6600443243', 'https://openalex.org/W2914913933', 'https://openalex.org/W3090098535', 'https://openalex.org/W6779092977', 'https://openalex.org/W3207924272', 'https://openalex.org/W6840776798', 'https://openalex.org/W6769593479', 'https://openalex.org/W3041561163', 'https://openalex.org/W6773243159', 'https://openalex.org/W2752796333', 'https://openalex.org/W2423557781', 'https://openalex.org/W6780218876', 'https://openalex.org/W6773553514', 'https://openalex.org/W6799935246', 'https://openalex.org/W6761522202', 'https://openalex.org/W3209059054', 'https://openalex.org/W6810673746', 'https://openalex.org/W3209984917', 'https://openalex.org/W6803394801', 'https://openalex.org/W6791978275', 'https://openalex.org/W6767771057', 'https://openalex.org/W3211278025', 'https://openalex.org/W6849880362', 'https://openalex.org/W3132072393', 'https://openalex.org/W6802483191', 'https://openalex.org/W6629717138', 'https://openalex.org/W6789826613', 'https://openalex.org/W6691509046', 'https://openalex.org/W6773909944', 'https://openalex.org/W6756319913', 'https://openalex.org/W6773475747', 'https://openalex.org/W6756426640', 'https://openalex.org/W6726109732', 'https://openalex.org/W6785229415', 'https://openalex.org/W6768848920', 'https://openalex.org/W6687566353', 'https://openalex.org/W6783867762', 'https://openalex.org/W6803547063', 'https://openalex.org/W2966441164', 'https://openalex.org/W2591927543', 'https://openalex.org/W6765987481', 'https://openalex.org/W6603838645', 'https://openalex.org/W6754224190', 'https://openalex.org/W6763832098', 'https://openalex.org/W6779337556', 'https://openalex.org/W6772340256', 'https://openalex.org/W6786041167', 'https://openalex.org/W6801738251', 'https://openalex.org/W6748409065', 'https://openalex.org/W3155441579', 'https://openalex.org/W6755811826', 'https://openalex.org/W6810319272', 'https://openalex.org/W6779871621', 'https://openalex.org/W3034949308', 'https://openalex.org/W6777694618', 'https://openalex.org/W6775324216', 'https://openalex.org/W6784809985', 'https://openalex.org/W6789577077', 'https://openalex.org/W6796464841', 'https://openalex.org/W6800393981', 'https://openalex.org/W6802142237', 'https://openalex.org/W6843673214', 'https://openalex.org/W6755592152', 'https://openalex.org/W6769767169', 'https://openalex.org/W6767111847', 'https://openalex.org/W6776594914', 'https://openalex.org/W6784902658', 'https://openalex.org/W6809981015', 'https://openalex.org/W6749555683', 'https://openalex.org/W6750489868', 'https://openalex.org/W6755300632', 'https://openalex.org/W6794864843', 'https://openalex.org/W6849953009', 'https://openalex.org/W6810772336', 'https://openalex.org/W6839301689', 'https://openalex.org/W6790356757', 'https://openalex.org/W6842794329', 'https://openalex.org/W6787300339', 'https://openalex.org/W6801211481', 'https://openalex.org/W6800389019', 'https://openalex.org/W6804171790', 'https://openalex.org/W6754171061', 'https://openalex.org/W6769754352', 'https://openalex.org/W6774618169', 'https://openalex.org/W6735706088', 'https://openalex.org/W2991361823', 'https://openalex.org/W6771029501', 'https://openalex.org/W6839738141', 'https://openalex.org/W6798741528', 'https://openalex.org/W6790639658', 'https://openalex.org/W2996414377', 'https://openalex.org/W6761382815', 'https://openalex.org/W6791184523', 'https://openalex.org/W2946555236', 'https://openalex.org/W2975414524', 'https://openalex.org/W6782760101', 'https://openalex.org/W6840257003', 'https://openalex.org/W6771024825', 'https://openalex.org/W6779711495', 'https://openalex.org/W6790317203', 'https://openalex.org/W6769050887', 'https://openalex.org/W3216941316', 'https://openalex.org/W6774467145', 'https://openalex.org/W6770189186', 'https://openalex.org/W2966387353', 'https://openalex.org/W6760752336', 'https://openalex.org/W6771238005', 'https://openalex.org/W3168542456', 'https://openalex.org/W6777078688', 'https://openalex.org/W6785089734', 'https://openalex.org/W4319985616', 'https://openalex.org/W3203313352', 'https://openalex.org/W6846143095', 'https://openalex.org/W6762643587', 'https://openalex.org/W6840281264', 'https://openalex.org/W6757422803', 'https://openalex.org/W6757660528', 'https://openalex.org/W6776390925', 'https://openalex.org/W6788032840', 'https://openalex.org/W6810445039', 'https://openalex.org/W6775580082', 'https://openalex.org/W4225304461', 'https://openalex.org/W6781140794', 'https://openalex.org/W6854823327', 'https://openalex.org/W6774785168', 'https://openalex.org/W6726424462', 'https://openalex.org/W6686645966', 'https://openalex.org/W6712618806', 'https://openalex.org/W6769935359', 'https://openalex.org/W6776309249', 'https://openalex.org/W6770919351', 'https://openalex.org/W3123941558', 'https://openalex.org/W6788533573', 'https://openalex.org/W6784351597', 'https://openalex.org/W3156052130', 'https://openalex.org/W6687483927', 'https://openalex.org/W6776308974', 'https://openalex.org/W6759487677', 'https://openalex.org/W4205234379', 'https://openalex.org/W2081074144', 'https://openalex.org/W2159591770', 'https://openalex.org/W6801168043', 'https://openalex.org/W6810138040', 'https://openalex.org/W2997419692', 'https://openalex.org/W3178462146', 'https://openalex.org/W6775646649', 'https://openalex.org/W6678809451', 'https://openalex.org/W6767725219', 'https://openalex.org/W4289656378', 'https://openalex.org/W6802610516', 'https://openalex.org/W6769168142', 'https://openalex.org/W6784693623', 'https://openalex.org/W6802926664', 'https://openalex.org/W6761124745', 'https://openalex.org/W6789693907', 'https://openalex.org/W6780418161', 'https://openalex.org/W6800972147', 'https://openalex.org/W3092085609', 'https://openalex.org/W6781586211', 'https://openalex.org/W6770340004', 'https://openalex.org/W6841035593', 'https://openalex.org/W2973048981', 'https://openalex.org/W6839510803', 'https://openalex.org/W6713729801', 'https://openalex.org/W2128653836', 'https://openalex.org/W1995536493', 'https://openalex.org/W6682371319', 'https://openalex.org/W2016254085', 'https://openalex.org/W2121294245', 'https://openalex.org/W2070126272', 'https://openalex.org/W6790790445', 'https://openalex.org/W6785195226', 'https://openalex.org/W6791183285', 'https://openalex.org/W6802025286', 'https://openalex.org/W6787607767', 'https://openalex.org/W2788241093', 'https://openalex.org/W2969437910', 'https://openalex.org/W6767580577', 'https://openalex.org/W3190196596', 'https://openalex.org/W6762114000', 'https://openalex.org/W3032514799', 'https://openalex.org/W6773286268', 'https://openalex.org/W2044893557', 'https://openalex.org/W6713658392', 'https://openalex.org/W6726607834', 'https://openalex.org/W6744261651', 'https://openalex.org/W6773419339', 'https://openalex.org/W6751200590', 'https://openalex.org/W6800075084', 'https://openalex.org/W6767367760', 'https://openalex.org/W6802891684', 'https://openalex.org/W6803488396', 'https://openalex.org/W4210381452', 'https://openalex.org/W6795249795', 'https://openalex.org/W2144404214', 'https://openalex.org/W6630687167', 'https://openalex.org/W4205689591', 'https://openalex.org/W6633117090', 'https://openalex.org/W6675521023', 'https://openalex.org/W6731171211', 'https://openalex.org/W6776251105', 'https://openalex.org/W6775804823', 'https://openalex.org/W2944426940', 'https://openalex.org/W6801588699', 'https://openalex.org/W2143169494', 'https://openalex.org/W1653463454', 'https://openalex.org/W6688843265', 'https://openalex.org/W6754999120', 'https://openalex.org/W6754528422', 'https://openalex.org/W2734774145', 'https://openalex.org/W2952218014', 'https://openalex.org/W6784764134', 'https://openalex.org/W6791167661', 'https://openalex.org/W6774995033', 'https://openalex.org/W6768815455', 'https://openalex.org/W3185109982', 'https://openalex.org/W6756383738', 'https://openalex.org/W6755691404', 'https://openalex.org/W6669997747', 'https://openalex.org/W6672346363', 'https://openalex.org/W4283010118', 'https://openalex.org/W3163571828', 'https://openalex.org/W6788809509', 'https://openalex.org/W2582895315', 'https://openalex.org/W6753084572', 'https://openalex.org/W6762306309', 'https://openalex.org/W6776533818', 'https://openalex.org/W3186700381', 'https://openalex.org/W2029199293', 'https://openalex.org/W6734491695', 'https://openalex.org/W6755759972', 'https://openalex.org/W2015143272', 'https://openalex.org/W6743392952', 'https://openalex.org/W6732945439', 'https://openalex.org/W6775393185', 'https://openalex.org/W6769705265', 'https://openalex.org/W6781840038', 'https://openalex.org/W6752246543', 'https://openalex.org/W6788484017', 'https://openalex.org/W3136499730', 'https://openalex.org/W6767522477', 'https://openalex.org/W6761832646', 'https://openalex.org/W6757723671', 'https://openalex.org/W6810268148', 'https://openalex.org/W6810693232', 'https://openalex.org/W6761403421', 'https://openalex.org/W6795356967', 'https://openalex.org/W6767278437', 'https://openalex.org/W4321780088', 'https://openalex.org/W2946977471', 'https://openalex.org/W6785108712', 'https://openalex.org/W6810728751', 'https://openalex.org/W6721237847', 'https://openalex.org/W6801798994', 'https://openalex.org/W6838716384', 'https://openalex.org/W6751084923', 'https://openalex.org/W6810748662', 'https://openalex.org/W6784756737', 'https://openalex.org/W4285231507', 'https://openalex.org/W6775281820', 'https://openalex.org/W6801625237', 'https://openalex.org/W6810422493', 'https://openalex.org/W6845831171', 'https://openalex.org/W6810653126', 'https://openalex.org/W6793783828', 'https://openalex.org/W6769355297', 'https://openalex.org/W6775467270', 'https://openalex.org/W6795069909', 'https://openalex.org/W3213544594', 'https://openalex.org/W6810360497', 'https://openalex.org/W6759579507', 'https://openalex.org/W6788701349', 'https://openalex.org/W6796581206', 'https://openalex.org/W6777497023', 'https://openalex.org/W6780585982', 'https://openalex.org/W6794805428', 'https://openalex.org/W6770008262', 'https://openalex.org/W6792304734', 'https://openalex.org/W6846678071', 'https://openalex.org/W4372346804', 'https://openalex.org/W3102451458', 'https://openalex.org/W3099884890', 'https://openalex.org/W1828163288', 'https://openalex.org/W3196468212', 'https://openalex.org/W4301371414', 'https://openalex.org/W2884797218', 'https://openalex.org/W2752782242', 'https://openalex.org/W3165478005', 'https://openalex.org/W4283809320', 'https://openalex.org/W4384080510', 'https://openalex.org/W4285189120', 'https://openalex.org/W4205605040', 'https://openalex.org/W3030437843', 'https://openalex.org/W4372341629', 'https://openalex.org/W2996286887', 'https://openalex.org/W3123318516', 'https://openalex.org/W3195577433', 'https://openalex.org/W2584032004', 'https://openalex.org/W4283008665', 'https://openalex.org/W4318242507', 'https://openalex.org/W3025260599', 'https://openalex.org/W2915722758', 'https://openalex.org/W2914911817', 'https://openalex.org/W2972449503', 'https://openalex.org/W3097777922', 'https://openalex.org/W4238846128', 'https://openalex.org/W2144499799', 'https://openalex.org/W3197823486', 'https://openalex.org/W4281739498', 'https://openalex.org/W4296068589', 'https://openalex.org/W4289305009', 'https://openalex.org/W3198234802', 'https://openalex.org/W3196833881', 'https://openalex.org/W3197580070', 'https://openalex.org/W3176455679', 'https://openalex.org/W3152218910', 'https://openalex.org/W2988736778', 'https://openalex.org/W3175809709', 'https://openalex.org/W4297841818', 'https://openalex.org/W2962896155', 'https://openalex.org/W4367365521', 'https://openalex.org/W2963452667', 'https://openalex.org/W2730845691', 'https://openalex.org/W4382202681', 'https://openalex.org/W2972584841', 'https://openalex.org/W3097075707', 'https://openalex.org/W2600643276', 'https://openalex.org/W2970006822', 'https://openalex.org/W4285605725', 'https://openalex.org/W4300980117', 'https://openalex.org/W4320451749', 'https://openalex.org/W3197567540', 'https://openalex.org/W2972745527', 'https://openalex.org/W4318752004', 'https://openalex.org/W3140429000', 'https://openalex.org/W4327520938', 'https://openalex.org/W4312121834', 'https://openalex.org/W2973034126', 'https://openalex.org/W3196117288', 'https://openalex.org/W4395957972', 'https://openalex.org/W4372342420', 'https://openalex.org/W4285483692', 'https://openalex.org/W4372260139', 'https://openalex.org/W4287121455', 'https://openalex.org/W4375869120', 'https://openalex.org/W3197334236', 'https://openalex.org/W4372347392', 'https://openalex.org/W3035289074', 'https://openalex.org/W3096567388', 'https://openalex.org/W4296068781', 'https://openalex.org/W3141854550', 'https://openalex.org/W4245692952', 'https://openalex.org/W4253752031', 'https://openalex.org/W2919448963', 'https://openalex.org/W4323066695', 'https://openalex.org/W3101689408', 'https://openalex.org/W4297778191', 'https://openalex.org/W3097034112', 'https://openalex.org/W3036601975', 'https://openalex.org/W4281820413', 'https://openalex.org/W4281779489', 'https://openalex.org/W647272629', 'https://openalex.org/W4296068817', 'https://openalex.org/W2963082324', 'https://openalex.org/W3176382501', 'https://openalex.org/W4294619417', 'https://openalex.org/W4386434937', 'https://openalex.org/W3097892637', 'https://openalex.org/W4225566824', 'https://openalex.org/W3095936335', 'https://openalex.org/W599380687', 'https://openalex.org/W4324031729', 'https://openalex.org/W3197507772', 'https://openalex.org/W4323651091', 'https://openalex.org/W2918296821', 'https://openalex.org/W3095057960', 'https://openalex.org/W4287761884', 'https://openalex.org/W3033411150', 'https://openalex.org/W4286950013', 'https://openalex.org/W3092028330', 'https://openalex.org/W4313484599', 'https://openalex.org/W3091928890', 'https://openalex.org/W4236965008', 'https://openalex.org/W4205285111', 'https://openalex.org/W4320086272', 'https://openalex.org/W3159740474', 'https://openalex.org/W4297841766', 'https://openalex.org/W3198769980', 'https://openalex.org/W4300978696', 'https://openalex.org/W3013020904', 'https://openalex.org/W2804945011', 'https://openalex.org/W3027637851', 'https://openalex.org/W2963840672', 'https://openalex.org/W4375869348', 'https://openalex.org/W1902237438', 'https://openalex.org/W4322718191', 'https://openalex.org/W4309395027', 'https://openalex.org/W1539670134', 'https://openalex.org/W2140409019', 'https://openalex.org/W3204602440', 'https://openalex.org/W4224000641', 'https://openalex.org/W4313679638', 'https://openalex.org/W3094665028', 'https://openalex.org/W3193590960', 'https://openalex.org/W3198213150', 'https://openalex.org/W4385573646', 'https://openalex.org/W2896457183', 'https://openalex.org/W4283215837', 'https://openalex.org/W4296070453', 'https://openalex.org/W3123097577', 'https://openalex.org/W2619368999', 'https://openalex.org/W4301368689', 'https://openalex.org/W3198777143', 'https://openalex.org/W4305038462', 'https://openalex.org/W2970066309', 'https://openalex.org/W3081565196', 'https://openalex.org/W2964559396', 'https://openalex.org/W4226162428', 'https://openalex.org/W4288089799', 'https://openalex.org/W4372262687', 'https://openalex.org/W3121150787', 'https://openalex.org/W4320013820', 'https://openalex.org/W3102342027', 'https://openalex.org/W4297733535', 'https://openalex.org/W2921052634', 'https://openalex.org/W3037469336', 'https://openalex.org/W3037217258', 'https://openalex.org/W4286795976', 'https://openalex.org/W3096408984', 'https://openalex.org/W4297808394', 'https://openalex.org/W3028017480', 'https://openalex.org/W4375868953', 'https://openalex.org/W3213029956', 'https://openalex.org/W3187990717', 'https://openalex.org/W3099330747', 'https://openalex.org/W2529559718', 'https://openalex.org/W4245804068', 'https://openalex.org/W3139918052', 'https://openalex.org/W4300539257', 'https://openalex.org/W2970597249', 'https://openalex.org/W4297817572', 'https://openalex.org/W2973143779', 'https://openalex.org/W3112034174', 'https://openalex.org/W3197331597', 'https://openalex.org/W3200245256', 'https://openalex.org/W3025528898', 'https://openalex.org/W3197343310', 'https://openalex.org/W2972659941', 'https://openalex.org/W2963033987', 'https://openalex.org/W3034625919', 'https://openalex.org/W2899901795', 'https://openalex.org/W4226063663', 'https://openalex.org/W3213604094', 'https://openalex.org/W3093579165', 'https://openalex.org/W2972943112', 'https://openalex.org/W4306175879', 'https://openalex.org/W3095883095', 'https://openalex.org/W4236097098', 'https://openalex.org/W3096323553', 'https://openalex.org/W4287888298', 'https://openalex.org/W2963609956', 'https://openalex.org/W3097906045', 'https://openalex.org/W4225746985', 'https://openalex.org/W3025581723', 'https://openalex.org/W3104216863', 'https://openalex.org/W4292779060', 'https://openalex.org/W2963066655', 'https://openalex.org/W2973157397', 'https://openalex.org/W3026041220', 'https://openalex.org/W2964171275', 'https://openalex.org/W3153675281', 'https://openalex.org/W2262249176', 'https://openalex.org/W3093933225', 'https://openalex.org/W4367359628', 'https://openalex.org/W3024869864', 'https://openalex.org/W1583837637', 'https://openalex.org/W3198608154', 'https://openalex.org/W2979476256', 'https://openalex.org/W2133564696', 'https://openalex.org/W4385567350', 'https://openalex.org/W4286905216', 'https://openalex.org/W3198257150', 'https://openalex.org/W2963040451', 'https://openalex.org/W2519091744', 'https://openalex.org/W2972889948', 'https://openalex.org/W4375868863', 'https://openalex.org/W3096442195', 'https://openalex.org/W2792764867', 'https://openalex.org/W4287641946', 'https://openalex.org/W4394658530', 'https://openalex.org/W4255556797', 'https://openalex.org/W3197842028', 'https://openalex.org/W4296959082', 'https://openalex.org/W4297683418', 'https://openalex.org/W3095790275', 'https://openalex.org/W2972909277', 'https://openalex.org/W2963975282', 'https://openalex.org/W4307079201', 'https://openalex.org/W4376490867', 'https://openalex.org/W3092424727', 'https://openalex.org/W4283704748', 'https://openalex.org/W2792760996', 'https://openalex.org/W3200287816', 'https://openalex.org/W2946200149', 'https://openalex.org/W3017465475', 'https://openalex.org/W2120615054', 'https://openalex.org/W3205644108', 'https://openalex.org/W3095999419', 'https://openalex.org/W3197763626', 'https://openalex.org/W2941814890', 'https://openalex.org/W4320459320', 'https://openalex.org/W3198035615', 'https://openalex.org/W4311000453', 'https://openalex.org/W2797583228', 'https://openalex.org/W4301606627', 'https://openalex.org/W3129651364', 'https://openalex.org/W3128910262', 'https://openalex.org/W2153849757', 'https://openalex.org/W3171689473', 'https://openalex.org/W4226278401', 'https://openalex.org/W3025498998', 'https://openalex.org/W2954386831', 'https://openalex.org/W3204679573', 'https://openalex.org/W3157070662', 'https://openalex.org/W854541894', 'https://openalex.org/W2963691546', 'https://openalex.org/W2103934944', 'https://openalex.org/W4288091954', 'https://openalex.org/W4394671563', 'https://openalex.org/W2952167535', 'https://openalex.org/W4224612669', 'https://openalex.org/W4312437435', 'https://openalex.org/W3024147341', 'https://openalex.org/W3097787598', 'https://openalex.org/W4226098957', 'https://openalex.org/W2963799213', 'https://openalex.org/W3105669983', 'https://openalex.org/W2973049979', 'https://openalex.org/W4296068981', 'https://openalex.org/W3036167779', 'https://openalex.org/W2963317665', 'https://openalex.org/W4255113413', 'https://openalex.org/W3197411683', 'https://openalex.org/W2917128112', 'https://openalex.org/W3097828251', 'https://openalex.org/W3096235116', 'https://openalex.org/W4362598673', 'https://openalex.org/W189595333', 'https://openalex.org/W4297841714', 'https://openalex.org/W4301062550', 'https://openalex.org/W3126648213', 'https://openalex.org/W3099078140', 'https://openalex.org/W3095173472', 'https://openalex.org/W3054645415', 'https://openalex.org/W2985287635', 'https://openalex.org/W4385822534', 'https://openalex.org/W2601450892', 'https://openalex.org/W4322718246', 'https://openalex.org/W3198836239', 'https://openalex.org/W3026874504', 'https://openalex.org/W2186373062', 'https://openalex.org/W2781626870', 'https://openalex.org/W3105031100', 'https://openalex.org/W2919752630', 'https://openalex.org/W4297841774', 'https://openalex.org/W4385245566', 'https://openalex.org/W2971753973', 'https://openalex.org/W4297841480']",2023-06-03
https://openalex.org/W4401607735,https://doi.org/10.1109/taslp.2024.3444470,Textless Unit-to-Unit Training for Many-to-Many Multilingual Speech-to-Speech Translation,,"['https://openalex.org/W6640090968', 'https://openalex.org/W6687566353', 'https://openalex.org/W2526425061', 'https://openalex.org/W2766219058', 'https://openalex.org/W2962780374', 'https://openalex.org/W3205193540', 'https://openalex.org/W6810168380', 'https://openalex.org/W4224319127', 'https://openalex.org/W4386071467', 'https://openalex.org/W2105482032', 'https://openalex.org/W6727690538', 'https://openalex.org/W2964045208', 'https://openalex.org/W6778883912', 'https://openalex.org/W3001434439', 'https://openalex.org/W2963609956', 'https://openalex.org/W6752888775', 'https://openalex.org/W6778083308', 'https://openalex.org/W6790220310', 'https://openalex.org/W6805710207', 'https://openalex.org/W6848735303', 'https://openalex.org/W6811129797', 'https://openalex.org/W6850625674', 'https://openalex.org/W2972473628', 'https://openalex.org/W3095012670', 'https://openalex.org/W6850334629', 'https://openalex.org/W4385764360', 'https://openalex.org/W2962784628', 'https://openalex.org/W2963979492', 'https://openalex.org/W2963250244', 'https://openalex.org/W4200300291', 'https://openalex.org/W6790356757', 'https://openalex.org/W3140429000', 'https://openalex.org/W4385823403', 'https://openalex.org/W3209059054', 'https://openalex.org/W4385822683', 'https://openalex.org/W6780218876', 'https://openalex.org/W3213029956', 'https://openalex.org/W4381786045', 'https://openalex.org/W2033436836', 'https://openalex.org/W2106440210', 'https://openalex.org/W6776472420', 'https://openalex.org/W4287854499', 'https://openalex.org/W3209984917', 'https://openalex.org/W3205644108', 'https://openalex.org/W2551572271', 'https://openalex.org/W3213322812', 'https://openalex.org/W6849622896', 'https://openalex.org/W4372260478', 'https://openalex.org/W4392909068', 'https://openalex.org/W4307680525', 'https://openalex.org/W4385574033', 'https://openalex.org/W2242221029', 'https://openalex.org/W1992475611', 'https://openalex.org/W1995562189', 'https://openalex.org/W3017474798', 'https://openalex.org/W2781918655', 'https://openalex.org/W4309041555', 'https://openalex.org/W3213544594', 'https://openalex.org/W4386133927', 'https://openalex.org/W2972495969', 'https://openalex.org/W3017535695', 'https://openalex.org/W6841035593', 'https://openalex.org/W3142316150', 'https://openalex.org/W4385245566', 'https://openalex.org/W6838789019', 'https://openalex.org/W4385570550', 'https://openalex.org/W3180374548', 'https://openalex.org/W4221153524', 'https://openalex.org/W4226033575', 'https://openalex.org/W4296070387', 'https://openalex.org/W2963216553', 'https://openalex.org/W6763832098', 'https://openalex.org/W6734815144', 'https://openalex.org/W3015826515', 'https://openalex.org/W3090474612', 'https://openalex.org/W3081416955', 'https://openalex.org/W6798575157', 'https://openalex.org/W6846288075', 'https://openalex.org/W4307323391', 'https://openalex.org/W4375868953', 'https://openalex.org/W4385573012', 'https://openalex.org/W4372349107', 'https://openalex.org/W3119308075', 'https://openalex.org/W3034999214', 'https://openalex.org/W2896457183', 'https://openalex.org/W2933138175', 'https://openalex.org/W6783867762', 'https://openalex.org/W3197771105', 'https://openalex.org/W4385822729', 'https://openalex.org/W6796464841', 'https://openalex.org/W6917585676', 'https://openalex.org/W6750200984', 'https://openalex.org/W4385572318', 'https://openalex.org/W2972802841', 'https://openalex.org/W3015698636', 'https://openalex.org/W6810701745', 'https://openalex.org/W3196509775', 'https://openalex.org/W6810259195', 'https://openalex.org/W3197324626', 'https://openalex.org/W6754420807', 'https://openalex.org/W4322718191', 'https://openalex.org/W4403635980', 'https://openalex.org/W4323651091', 'https://openalex.org/W2891205112', 'https://openalex.org/W4226399820', 'https://openalex.org/W3181257032', 'https://openalex.org/W4221155340', 'https://openalex.org/W4313679638', 'https://openalex.org/W2525778437', 'https://openalex.org/W4394671563', 'https://openalex.org/W1922655562']",2024-01-01
https://openalex.org/W4392909911,https://doi.org/10.1109/icassp48485.2024.10446921,UNIT-DSR: Dysarthric Speech Reconstruction System Using Speech Unit Normalization,"Dysarthric speech reconstruction (DSR) systems aim to automatically convert dysarthric speech into normal-sounding speech. The technology eases communication with speakers affected by the neuromotor disorder and enhances their social inclusion. NED-based (Neural Encoder-Decoder) systems have significantly improved the intelligibility of the reconstructed speech as compared with GAN-based (Generative Adversarial Network) approaches, but the approach is still limited by training inefficiency caused by the cascaded pipeline and auxiliary tasks of the content encoder, which may in turn affect the quality of reconstruction. Inspired by self-supervised speech representation learning and discrete speech units, we propose a Unit-DSR system, which harnesses the powerful domain-adaptation capacity of HuBERT for training efficiency improvement and utilizes speech units to constrain the dysarthric content restoration in a discrete linguistic space. Compared with NED approaches, the Unit-DSR system only consists of a speech unit normalizer and a Unit HiFi-GAN vocoder, which is considerably simpler without cascaded sub-modules or auxiliary tasks. Results on the UASpeech corpus indicate that Unit-DSR outperforms competitive baselines in terms of content restoration, reaching a 28.2% relative average word error rate reduction when compared to original dysarthric speech, and shows robustness against speed perturbation and noise <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">1</sup> .","['https://openalex.org/W2152637773', 'https://openalex.org/W3117682035', 'https://openalex.org/W4296068414', 'https://openalex.org/W3082218567', 'https://openalex.org/W3015707856', 'https://openalex.org/W4225289116', 'https://openalex.org/W2972970915', 'https://openalex.org/W3194248215', 'https://openalex.org/W3161018648', 'https://openalex.org/W3140429000', 'https://openalex.org/W4285250921', 'https://openalex.org/W4287854499', 'https://openalex.org/W4372260139', 'https://openalex.org/W3209059054', 'https://openalex.org/W6780218876', 'https://openalex.org/W3197580070', 'https://openalex.org/W4372263660', 'https://openalex.org/W4375868953', 'https://openalex.org/W3119308075', 'https://openalex.org/W6917585676', 'https://openalex.org/W180052447', 'https://openalex.org/W2964243274', 'https://openalex.org/W2973215447', 'https://openalex.org/W3036601975']",2024-03-18
https://openalex.org/W4378619943,https://doi.org/10.1017/s0305000923000272,Realistic and broad-scope learning simulations: first results and challenges,"Abstract There is a current ‘theory crisis’ in language acquisition research, resulting from fragmentation both at the level of the approaches and the linguistic level studied. We identify a need for integrative approaches that go beyond these limitations, and propose to analyse the strengths and weaknesses of current theoretical approaches of language acquisition. In particular, we advocate that language learning simulations, if they integrate realistic input and multiple levels of language, have the potential to contribute significantly to our understanding of language acquisition. We then review recent results obtained through such language learning simulations. Finally, we propose some guidelines for the community to build better simulations.","['https://openalex.org/W2913939165', 'https://openalex.org/W4232516125', 'https://openalex.org/W2064135025', 'https://openalex.org/W2059168261', 'https://openalex.org/W3134108900', 'https://openalex.org/W1532494781', 'https://openalex.org/W2973180715', 'https://openalex.org/W6825992397', 'https://openalex.org/W3161374022', 'https://openalex.org/W2089883580', 'https://openalex.org/W2303872361', 'https://openalex.org/W4206039057', 'https://openalex.org/W2896342372', 'https://openalex.org/W2141038596', 'https://openalex.org/W2917235195', 'https://openalex.org/W1969005071', 'https://openalex.org/W2585893098', 'https://openalex.org/W2483390977', 'https://openalex.org/W4225726571', 'https://openalex.org/W2937297214', 'https://openalex.org/W2125566341', 'https://openalex.org/W833103999', 'https://openalex.org/W2765364385', 'https://openalex.org/W2153897911', 'https://openalex.org/W1968225092', 'https://openalex.org/W2078828996', 'https://openalex.org/W2595479191', 'https://openalex.org/W6800751262', 'https://openalex.org/W1530250655', 'https://openalex.org/W3199093330', 'https://openalex.org/W2060204180', 'https://openalex.org/W135984148', 'https://openalex.org/W6712444837', 'https://openalex.org/W2162505970', 'https://openalex.org/W4242738990', 'https://openalex.org/W2784570041', 'https://openalex.org/W1984586950', 'https://openalex.org/W2759573091', 'https://openalex.org/W4200598898', 'https://openalex.org/W4220770602', 'https://openalex.org/W6809594290', 'https://openalex.org/W3110458199', 'https://openalex.org/W2615444509', 'https://openalex.org/W4292825791', 'https://openalex.org/W4297677272', 'https://openalex.org/W4375868953', 'https://openalex.org/W2435103813', 'https://openalex.org/W2996556191', 'https://openalex.org/W6790356757', 'https://openalex.org/W1997015862', 'https://openalex.org/W4309419356', 'https://openalex.org/W2110221456', 'https://openalex.org/W2163999179', 'https://openalex.org/W2005592929', 'https://openalex.org/W4205897400', 'https://openalex.org/W6648830005', 'https://openalex.org/W2110485445', 'https://openalex.org/W2149932965', 'https://openalex.org/W3197259906', 'https://openalex.org/W3166292821', 'https://openalex.org/W6676025551', 'https://openalex.org/W1540332606', 'https://openalex.org/W1995403064', 'https://openalex.org/W1597121597', 'https://openalex.org/W3023172065', 'https://openalex.org/W2016292361', 'https://openalex.org/W2000977437', 'https://openalex.org/W4311481261', 'https://openalex.org/W2138641981', 'https://openalex.org/W3125087428', 'https://openalex.org/W4253682481', 'https://openalex.org/W2935067899', 'https://openalex.org/W4237938692', 'https://openalex.org/W3005081886', 'https://openalex.org/W2153767712', 'https://openalex.org/W4230725619', 'https://openalex.org/W2103091632', 'https://openalex.org/W2001771035', 'https://openalex.org/W2118373646', 'https://openalex.org/W3171477941', 'https://openalex.org/W2005311247', 'https://openalex.org/W4250883074', 'https://openalex.org/W2343593471', 'https://openalex.org/W4300721020', 'https://openalex.org/W6778883912', 'https://openalex.org/W1980862600', 'https://openalex.org/W3198815374', 'https://openalex.org/W2089358714', 'https://openalex.org/W4394671563', 'https://openalex.org/W2980877534', 'https://openalex.org/W2333023345', 'https://openalex.org/W4210307751', 'https://openalex.org/W593365102', 'https://openalex.org/W2950416202', 'https://openalex.org/W4221038855', 'https://openalex.org/W2107959623', 'https://openalex.org/W2395899413', 'https://openalex.org/W4298742451', 'https://openalex.org/W4292779060', 'https://openalex.org/W2132387635', 'https://openalex.org/W2612271891']",2023-05-29
https://openalex.org/W4392904292,https://doi.org/10.1109/icassp48485.2024.10446888,Towards Practical and Efficient Image-to-Speech Captioning with Vision-Language Pre-Training and Multi-Modal Tokens,"In this paper, we propose methods to build a powerful and efficient Image-to-Speech captioning (Im2Sp) model. To this end, we start with importing the rich knowledge related to image comprehension and language modeling from a large-scale pre-trained vision-language model into Im2Sp. We set the output of the proposed Im2Sp as discretized speech units, i.e., the quantized speech features of a self-supervised speech model. The speech units mainly contain linguistic information while suppressing other characteristics of speech. This allows us to incorporate the language modeling capability of the pre-trained vision-language model into the spoken language modeling of Im2Sp. With the vision-language pre-training strategy, we set new state-of-the-art Im2Sp performances on two widely used benchmark databases, COCO and Flickr8k. Then, we further improve the efficiency of the Im2Sp model. Similar to the speech unit case, we convert the original image into image units, which are derived through vector quantization of the raw image. With these image units, we can drastically reduce the required data storage for saving image data to just 0.8% when compared to the original image data in terms of bits. Demo page: bit.ly/3Z9T6LJ.","['https://openalex.org/W6807079506', 'https://openalex.org/W6630875275', 'https://openalex.org/W2752796333', 'https://openalex.org/W4375868850', 'https://openalex.org/W3206387123', 'https://openalex.org/W6790356757', 'https://openalex.org/W4385570550', 'https://openalex.org/W4296070387', 'https://openalex.org/W6855650468', 'https://openalex.org/W4375868953', 'https://openalex.org/W4307680525', 'https://openalex.org/W6777028661', 'https://openalex.org/W4385823403', 'https://openalex.org/W3209059054', 'https://openalex.org/W4385822683', 'https://openalex.org/W4390874021', 'https://openalex.org/W2586148577', 'https://openalex.org/W4319862477', 'https://openalex.org/W4386071467', 'https://openalex.org/W6791353385', 'https://openalex.org/W6850204008', 'https://openalex.org/W3180355996', 'https://openalex.org/W6802517614', 'https://openalex.org/W1861492603', 'https://openalex.org/W68733909', 'https://openalex.org/W2972394484', 'https://openalex.org/W4372260534', 'https://openalex.org/W3174311593', 'https://openalex.org/W3155217823', 'https://openalex.org/W3140429000', 'https://openalex.org/W6783867762', 'https://openalex.org/W3094502228', 'https://openalex.org/W4213019189', 'https://openalex.org/W6677929280', 'https://openalex.org/W4390871839', 'https://openalex.org/W2962862718', 'https://openalex.org/W1905882502', 'https://openalex.org/W6780218876', 'https://openalex.org/W6898505805', 'https://openalex.org/W2133459682', 'https://openalex.org/W6682631176', 'https://openalex.org/W1956340063', 'https://openalex.org/W2506483933', 'https://openalex.org/W6796464841', 'https://openalex.org/W4385245566', 'https://openalex.org/W2886641317', 'https://openalex.org/W6676497082', 'https://openalex.org/W4287854499', 'https://openalex.org/W3037465386', 'https://openalex.org/W4206865574', 'https://openalex.org/W3024605872', 'https://openalex.org/W3036601975', 'https://openalex.org/W4385970143', 'https://openalex.org/W2154652894', 'https://openalex.org/W2109586012', 'https://openalex.org/W4394671563', 'https://openalex.org/W4320458302', 'https://openalex.org/W3099142230']",2024-03-18
https://openalex.org/W4392902939,https://doi.org/10.1109/icassp48485.2024.10447345,Self-Supervised Models of Speech Infer Universal Articulatory Kinematics,"Self-Supervised Learning (SSL) based models of speech have shown remarkable performance on a range of downstream tasks. These state-of-the-art models have remained blackboxes, but many recent studies have begun ""probing"" models like HuBERT, to correlate their internal representations to different aspects of speech. In this paper, we show ""inference of articulatory kinematics"" as fundamental property of SSL models, i.e., the ability of these models to transform acoustics into the causal articulatory dynamics underlying the speech signal. We also show that this abstraction is largely overlapping across the language of the data used to train the model, with preference to the language with similar phonological system. Furthermore, we show that with simple affine transformations, Acoustic-to-Articulatory inversion (AAI) is transferrable across speakers, even across genders, languages, and dialects, showing the generalizability of this property. Together, these results shed new light on the internals of SSL models that are critical to their superior performance, and open up new avenues into language-agnostic universal models for speech engineering, that are interpretable and grounded in speech science.","['https://openalex.org/W3197580070', 'https://openalex.org/W4226380987', 'https://openalex.org/W6788328058', 'https://openalex.org/W4375869259', 'https://openalex.org/W4372348980', 'https://openalex.org/W4372340876', 'https://openalex.org/W2068447135', 'https://openalex.org/W2046681189', 'https://openalex.org/W4223430326', 'https://openalex.org/W4297841848', 'https://openalex.org/W3133449202', 'https://openalex.org/W6780218876', 'https://openalex.org/W3209059054', 'https://openalex.org/W3213029956', 'https://openalex.org/W6852909395', 'https://openalex.org/W4375868953', 'https://openalex.org/W4385823003', 'https://openalex.org/W2231075402', 'https://openalex.org/W2622158094', 'https://openalex.org/W2159693968', 'https://openalex.org/W2943899479', 'https://openalex.org/W2407043376', 'https://openalex.org/W4388034436', 'https://openalex.org/W3036601975', 'https://openalex.org/W4378105483', 'https://openalex.org/W3121914243']",2024-03-18
https://openalex.org/W4392904409,https://doi.org/10.1109/icassp48485.2024.10446062,SD-HuBERT: Sentence-Level Self-Distillation Induces Syllabic Organization in Hubert,"Data-driven unit discovery in self-supervised learning (SSL) of speech has embarked on a new era of spoken language processing. Yet, the discovered units often remain in phonetic space and speech units beyond phonemes are largely underexplored. Here, we demonstrate that a syllabic organization emerges in learning sentence-level representation of speech. In particular, we adopt ""self-distillation"" objective to fine-tune the pretrained HuBERT with an aggregator token that summarizes the entire sentence. Without any supervision, the resulting model draws definite boundaries in speech, and the representations across frames exhibit salient syllabic structures. We demonstrate that this emergent structure largely corresponds to the ground truth syllables. Furthermore, we propose a new benchmark task, Spoken Speech ABX, for evaluating sentence-level representation of speech. When compared to previous models, our model outperforms in both unsupervised syllable discovery and learning sentence-level representation. Together, we demonstrate that the self-distillation of HuBERT gives rise to syllabic organization without relying on external labels or modalities, and potentially provides novel data-driven units for spoken language modeling.","['https://openalex.org/W3197580070', 'https://openalex.org/W4281492411', 'https://openalex.org/W6790356757', 'https://openalex.org/W3198217962', 'https://openalex.org/W4381786045', 'https://openalex.org/W6848735303', 'https://openalex.org/W3140429000', 'https://openalex.org/W4372348980', 'https://openalex.org/W4375868953', 'https://openalex.org/W4385823003', 'https://openalex.org/W3159481202', 'https://openalex.org/W2114347655', 'https://openalex.org/W1778492285', 'https://openalex.org/W2964169922', 'https://openalex.org/W2963720603', 'https://openalex.org/W3209059054', 'https://openalex.org/W3095361818', 'https://openalex.org/W2963902314', 'https://openalex.org/W6770596778', 'https://openalex.org/W4224875474', 'https://openalex.org/W4385823277', 'https://openalex.org/W6803675045', 'https://openalex.org/W2936774411', 'https://openalex.org/W1494198834', 'https://openalex.org/W6757817989', 'https://openalex.org/W2747874407', 'https://openalex.org/W2462305634', 'https://openalex.org/W3156636935', 'https://openalex.org/W6780218876', 'https://openalex.org/W3209984917', 'https://openalex.org/W2250539671', 'https://openalex.org/W3036601975', 'https://openalex.org/W3213018012', 'https://openalex.org/W2908510526', 'https://openalex.org/W2995680346', 'https://openalex.org/W4394671563', 'https://openalex.org/W4313679638']",2024-03-18
https://openalex.org/W4403780768,https://doi.org/10.1145/3664647.3681221,Efficient Training for Multilingual Visual Speech Recognition: Pre-training with Discretized Visual Speech Representation,,"['https://openalex.org/W2963431393', 'https://openalex.org/W3015830103', 'https://openalex.org/W4385822683', 'https://openalex.org/W3209984917', 'https://openalex.org/W4385823403', 'https://openalex.org/W2808631503', 'https://openalex.org/W3034552680', 'https://openalex.org/W3024869864', 'https://openalex.org/W4289665794', 'https://openalex.org/W3163793923', 'https://openalex.org/W2194775991', 'https://openalex.org/W4386071467', 'https://openalex.org/W3209059054', 'https://openalex.org/W3008549139', 'https://openalex.org/W3205193540', 'https://openalex.org/W4390874021', 'https://openalex.org/W4224319127', 'https://openalex.org/W3129009457', 'https://openalex.org/W4287854499', 'https://openalex.org/W4372346152', 'https://openalex.org/W3162707322', 'https://openalex.org/W3162293946', 'https://openalex.org/W4307286264', 'https://openalex.org/W4225299282', 'https://openalex.org/W4307680525', 'https://openalex.org/W4390871839', 'https://openalex.org/W2963192365', 'https://openalex.org/W2404704342', 'https://openalex.org/W2963654155', 'https://openalex.org/W2963785710', 'https://openalex.org/W3140429000', 'https://openalex.org/W4296070387', 'https://openalex.org/W4312638101', 'https://openalex.org/W3095410713', 'https://openalex.org/W3167917117', 'https://openalex.org/W4375868953', 'https://openalex.org/W2963528589', 'https://openalex.org/W2964309797', 'https://openalex.org/W2766219058', 'https://openalex.org/W4225746985', 'https://openalex.org/W4390691978', 'https://openalex.org/W2996970093', 'https://openalex.org/W4376481237', 'https://openalex.org/W2042718506', 'https://openalex.org/W4394671563']",2024-10-26
https://openalex.org/W4408355663,https://doi.org/10.1109/icassp49660.2025.10887678,Causal Speech Enhancement with Predicting Semantics based on Quantized Self-supervised Learning Features,,"['https://openalex.org/W2405774341', 'https://openalex.org/W2078528584', 'https://openalex.org/W2605589342', 'https://openalex.org/W2889442120', 'https://openalex.org/W6757632829', 'https://openalex.org/W1901129140', 'https://openalex.org/W3096408984', 'https://openalex.org/W3097906045', 'https://openalex.org/W4385807442', 'https://openalex.org/W2952218014', 'https://openalex.org/W3088775906', 'https://openalex.org/W3095248373', 'https://openalex.org/W3198680319', 'https://openalex.org/W4296068619', 'https://openalex.org/W3211944253', 'https://openalex.org/W3209984917', 'https://openalex.org/W6779216093', 'https://openalex.org/W3015337486', 'https://openalex.org/W4226403810', 'https://openalex.org/W6790356757', 'https://openalex.org/W4375868953', 'https://openalex.org/W4392909571', 'https://openalex.org/W6856434366', 'https://openalex.org/W4400111385', 'https://openalex.org/W4226021270', 'https://openalex.org/W4402111617', 'https://openalex.org/W2094721231', 'https://openalex.org/W4232282348', 'https://openalex.org/W2603567530', 'https://openalex.org/W6790758941', 'https://openalex.org/W4224917166', 'https://openalex.org/W6739901393', 'https://openalex.org/W2760103357', 'https://openalex.org/W4402672068', 'https://openalex.org/W6762931180', 'https://openalex.org/W6869968026', 'https://openalex.org/W2144404214', 'https://openalex.org/W6777701575']",2025-03-12
https://openalex.org/W4391021372,https://doi.org/10.1109/asru57964.2023.10389757,Towards Matching Phones and Speech Representations,"Learning phone types from phone instances has been a long-standing problem, while still being open. In this work, we revisit this problem in the context of self-supervised learning, and pose it as the problem of matching cluster centroids to phone embeddings. We study two key properties that enable matching, namely, whether cluster centroids of self-supervised representations reduce the variability of phone instances and respect the relationship among phones. We then use the matching result to produce pseudo-labels and introduce a new loss function for improving self-supervised representations. Our experiments show that the matching result captures the relationship among phones. Training the new loss function jointly with the regular self-supervised losses, such as APC and CPC, significantly improves the downstream phone classification.","['https://openalex.org/W2842511635', 'https://openalex.org/W2972943112', 'https://openalex.org/W4294068504', 'https://openalex.org/W3197580070', 'https://openalex.org/W3197974236', 'https://openalex.org/W3204915839', 'https://openalex.org/W6838949706', 'https://openalex.org/W3209059054', 'https://openalex.org/W4297841405', 'https://openalex.org/W2114347655', 'https://openalex.org/W2786608204', 'https://openalex.org/W2963620343', 'https://openalex.org/W2962799225', 'https://openalex.org/W2972706021', 'https://openalex.org/W4205706554', 'https://openalex.org/W6795952400', 'https://openalex.org/W6849880362', 'https://openalex.org/W6757699909', 'https://openalex.org/W3096656254', 'https://openalex.org/W2468716020', 'https://openalex.org/W6675022971', 'https://openalex.org/W4375868953', 'https://openalex.org/W4385823426', 'https://openalex.org/W6765510844', 'https://openalex.org/W6755496592', 'https://openalex.org/W6755759118', 'https://openalex.org/W2027842533', 'https://openalex.org/W2417433140', 'https://openalex.org/W6810673746', 'https://openalex.org/W6636510571', 'https://openalex.org/W6682691769', 'https://openalex.org/W6780218876', 'https://openalex.org/W6631943919', 'https://openalex.org/W6788335241', 'https://openalex.org/W3212799896', 'https://openalex.org/W4297808394', 'https://openalex.org/W1533861849', 'https://openalex.org/W2963472233', 'https://openalex.org/W3098643042', 'https://openalex.org/W4319862670', 'https://openalex.org/W1614298861', 'https://openalex.org/W3036601975', 'https://openalex.org/W4294170691', 'https://openalex.org/W4221161761', 'https://openalex.org/W3167207712', 'https://openalex.org/W4287173589', 'https://openalex.org/W2100768664', 'https://openalex.org/W4299579390', 'https://openalex.org/W2899486018', 'https://openalex.org/W2964079874', 'https://openalex.org/W4281771945']",2023-12-16
https://openalex.org/W4387877468,https://doi.org/10.31234/osf.io/5p8ge,Artificial neural networks to analyze and simulate language acquisition in children,"Lightweight child-worn recorders that collect audio across an entire day allow for a big-data approach to the study of language development. By collecting the child's production and linguistic environment, these recordings offer us a uniquely naturalistic view of everyday language uses. However, such recordings quickly accumulate thousands of hours of audio and require the use of automatic speech processing algorithms. Besides providing ecologically-valid measures of what children hear and say, these recordings can fuel computational models of early language acquisition with what infants truly hear. This opens up new opportunities for running realistic language learning simulations.A first aspect of my doctoral work is dedicated to developing automatic speech processing algorithms for child-centered long-form recordings. In this manuscript, I first show that current state-of-the-art automatic speech recognition systems fail to capture the complexity of naturalistic speech as found in long-forms. I then present our attempt to propose a free, open-source, and more accurate alternative to the LENA proprietary software, which is currently the standard tool for obtaining automatic analyses of long-forms. Using supervised learning methods, my collaborators and I built a suite of speech processing tools to detect voice activity, identify voice signal sources (child vocalizations, female or male speech), count the number of linguistic units (phonemes, syllables, or words), and estimate the quantity of background noise and reverberation. A second aspect of my doctoral work is dedicated to computational models of early language acquisition. I present a first modeling study showing that self-supervised learning algorithms trained on audiobooks can learn phonetic and lexical aspects of their training language. I then show that the same algorithm trained on ecological long-forms needs inductive biases to learn phonetic aspects of its training language reliably and reflect on whether similar inductive biases may guide language learning in infants. Interestingly, there is no evidence for lexical learning on long-forms, contrary to what has been shown in the literature on more curated data. This series of studies illustrates the importance of considering ecologically-valid input data when modeling language acquisition.","['https://openalex.org/W2885156775', 'https://openalex.org/W4407276585', 'https://openalex.org/W2888800758', 'https://openalex.org/W2989863749', 'https://openalex.org/W2406262283', 'https://openalex.org/W6632323398', 'https://openalex.org/W2919849250', 'https://openalex.org/W2887814324', 'https://openalex.org/W2187280882', 'https://openalex.org/W2561127898', 'https://openalex.org/W2048632248', 'https://openalex.org/W3004481867', 'https://openalex.org/W2131168675', 'https://openalex.org/W3045733287', 'https://openalex.org/W1269382222', 'https://openalex.org/W2070218750', 'https://openalex.org/W2010604004', 'https://openalex.org/W4394142399', 'https://openalex.org/W2115857751', 'https://openalex.org/W2750259098', 'https://openalex.org/W6688816777', 'https://openalex.org/W2544860310', 'https://openalex.org/W2985913104', 'https://openalex.org/W1499999342', 'https://openalex.org/W6769833506', 'https://openalex.org/W1982599741', 'https://openalex.org/W6786127183', 'https://openalex.org/W2611943505', 'https://openalex.org/W2696967604', 'https://openalex.org/W2768416973', 'https://openalex.org/W4319862721', 'https://openalex.org/W2296434735', 'https://openalex.org/W2805466703', 'https://openalex.org/W2982059757', 'https://openalex.org/W3099610051', 'https://openalex.org/W2410879554', 'https://openalex.org/W3015235644', 'https://openalex.org/W4311000453', 'https://openalex.org/W1494198834', 'https://openalex.org/W2593116425', 'https://openalex.org/W2555915854', 'https://openalex.org/W3031133340', 'https://openalex.org/W3161374022', 'https://openalex.org/W2901243971', 'https://openalex.org/W3038871978', 'https://openalex.org/W2895356663', 'https://openalex.org/W2516342150', 'https://openalex.org/W2063525438', 'https://openalex.org/W4220770602', 'https://openalex.org/W2103091632', 'https://openalex.org/W122673323', 'https://openalex.org/W6600387335', 'https://openalex.org/W3129009457', 'https://openalex.org/W2809193001', 'https://openalex.org/W2759573091', 'https://openalex.org/W1592295210', 'https://openalex.org/W6789725041', 'https://openalex.org/W2063303346', 'https://openalex.org/W6665016202', 'https://openalex.org/W6790730029', 'https://openalex.org/W2944539396', 'https://openalex.org/W2586148577', 'https://openalex.org/W4213306813', 'https://openalex.org/W3135377987', 'https://openalex.org/W2483390977', 'https://openalex.org/W2774051897', 'https://openalex.org/W3084297320', 'https://openalex.org/W2991557631', 'https://openalex.org/W2112883467', 'https://openalex.org/W2071591642', 'https://openalex.org/W2889102505', 'https://openalex.org/W1485633403', 'https://openalex.org/W6641916425', 'https://openalex.org/W2085478996', 'https://openalex.org/W2972476505', 'https://openalex.org/W3025683731', 'https://openalex.org/W3125043549', 'https://openalex.org/W6729411815', 'https://openalex.org/W3125087428', 'https://openalex.org/W2141994663', 'https://openalex.org/W2135563147', 'https://openalex.org/W3192452456', 'https://openalex.org/W2610616322', 'https://openalex.org/W3128683352', 'https://openalex.org/W2012125774', 'https://openalex.org/W6945130725', 'https://openalex.org/W2022042240', 'https://openalex.org/W7054993619', 'https://openalex.org/W3129048159', 'https://openalex.org/W1981826156', 'https://openalex.org/W3034612657', 'https://openalex.org/W2095458199', 'https://openalex.org/W1988747931', 'https://openalex.org/W2101048305', 'https://openalex.org/W2340774970', 'https://openalex.org/W2046338384', 'https://openalex.org/W2890174796', 'https://openalex.org/W4295309037', 'https://openalex.org/W6812385817', 'https://openalex.org/W1990351858', 'https://openalex.org/W6655910177', 'https://openalex.org/W1968703923', 'https://openalex.org/W2912762364', 'https://openalex.org/W2104752510', 'https://openalex.org/W4206953441', 'https://openalex.org/W6808618455', 'https://openalex.org/W2776941264', 'https://openalex.org/W6678463487', 'https://openalex.org/W2062956221', 'https://openalex.org/W2138930657', 'https://openalex.org/W2051676521', 'https://openalex.org/W3136507086', 'https://openalex.org/W2125766564', 'https://openalex.org/W6600721412', 'https://openalex.org/W2090314151', 'https://openalex.org/W4303629135', 'https://openalex.org/W2802302202', 'https://openalex.org/W6640227979', 'https://openalex.org/W2153767712', 'https://openalex.org/W2066213611', 'https://openalex.org/W6778883912', 'https://openalex.org/W3110458199', 'https://openalex.org/W3198217962', 'https://openalex.org/W4300021539', 'https://openalex.org/W3213014097', 'https://openalex.org/W2765364385', 'https://openalex.org/W3215376969', 'https://openalex.org/W4318621130', 'https://openalex.org/W2155042697', 'https://openalex.org/W2995181338', 'https://openalex.org/W4281492411', 'https://openalex.org/W2741692265', 'https://openalex.org/W305655093', 'https://openalex.org/W4394150413', 'https://openalex.org/W2014307400', 'https://openalex.org/W4200300291', 'https://openalex.org/W4390854704', 'https://openalex.org/W6810610419', 'https://openalex.org/W3135131435', 'https://openalex.org/W4225079082', 'https://openalex.org/W6718447644', 'https://openalex.org/W2137181162', 'https://openalex.org/W2980577029', 'https://openalex.org/W2767826640', 'https://openalex.org/W2169471344', 'https://openalex.org/W2118611915', 'https://openalex.org/W3011583491', 'https://openalex.org/W2995929068', 'https://openalex.org/W2098192529', 'https://openalex.org/W241613093', 'https://openalex.org/W2747060779', 'https://openalex.org/W2508684615', 'https://openalex.org/W2935067899', 'https://openalex.org/W2091746061', 'https://openalex.org/W4291746033', 'https://openalex.org/W3112495382', 'https://openalex.org/W1984586950', 'https://openalex.org/W3046659789', 'https://openalex.org/W6684012063', 'https://openalex.org/W2805407818', 'https://openalex.org/W2088377333', 'https://openalex.org/W2997253105', 'https://openalex.org/W6781919819', 'https://openalex.org/W4322766928', 'https://openalex.org/W2162693531', 'https://openalex.org/W6811685372', 'https://openalex.org/W7014979702', 'https://openalex.org/W4213430915', 'https://openalex.org/W3157861865', 'https://openalex.org/W2553608650', 'https://openalex.org/W153534061', 'https://openalex.org/W4281621399', 'https://openalex.org/W3016398799', 'https://openalex.org/W2767354245', 'https://openalex.org/W3005165546', 'https://openalex.org/W3036367741', 'https://openalex.org/W1530250655', 'https://openalex.org/W4378619943', 'https://openalex.org/W4321854743', 'https://openalex.org/W3090329631', 'https://openalex.org/W3187244867', 'https://openalex.org/W2026484633', 'https://openalex.org/W6676391964', 'https://openalex.org/W2107959623', 'https://openalex.org/W2762841950', 'https://openalex.org/W52412328', 'https://openalex.org/W4404957577', 'https://openalex.org/W2605959375', 'https://openalex.org/W6663865628', 'https://openalex.org/W2176118107', 'https://openalex.org/W2129705892', 'https://openalex.org/W2019922577', 'https://openalex.org/W122498424', 'https://openalex.org/W1740027839', 'https://openalex.org/W4318686658', 'https://openalex.org/W6983383401', 'https://openalex.org/W2118599126', 'https://openalex.org/W2160815625', 'https://openalex.org/W6661090959', 'https://openalex.org/W6644252350', 'https://openalex.org/W2999130843', 'https://openalex.org/W6779451415', 'https://openalex.org/W3162021500', 'https://openalex.org/W2133189729', 'https://openalex.org/W1989914796', 'https://openalex.org/W2149784807', 'https://openalex.org/W2742950837', 'https://openalex.org/W2038056950', 'https://openalex.org/W2045343524', 'https://openalex.org/W2068116204', 'https://openalex.org/W6659778137', 'https://openalex.org/W2059824090', 'https://openalex.org/W1975418600', 'https://openalex.org/W2898208057', 'https://openalex.org/W2780264041', 'https://openalex.org/W2132573777', 'https://openalex.org/W2488199425', 'https://openalex.org/W2005311247', 'https://openalex.org/W2140661818', 'https://openalex.org/W2989321827', 'https://openalex.org/W4311481261', 'https://openalex.org/W4379474370', 'https://openalex.org/W3211278025', 'https://openalex.org/W3008675085', 'https://openalex.org/W2114156501', 'https://openalex.org/W6673731931', 'https://openalex.org/W6610742289', 'https://openalex.org/W2074488330', 'https://openalex.org/W6664716616', 'https://openalex.org/W2136653392', 'https://openalex.org/W2165627680', 'https://openalex.org/W6643209160', 'https://openalex.org/W4304465621', 'https://openalex.org/W3093121832', 'https://openalex.org/W2978027383', 'https://openalex.org/W2102870983', 'https://openalex.org/W281094599', 'https://openalex.org/W7043347943', 'https://openalex.org/W4292997377', 'https://openalex.org/W2167834252', 'https://openalex.org/W3092318106', 'https://openalex.org/W2132566726', 'https://openalex.org/W2089720224', 'https://openalex.org/W4288360843', 'https://openalex.org/W6670256387', 'https://openalex.org/W2398490608', 'https://openalex.org/W2768381684', 'https://openalex.org/W2951943862', 'https://openalex.org/W2969145661', 'https://openalex.org/W3082004699', 'https://openalex.org/W4224979832', 'https://openalex.org/W6610556715', 'https://openalex.org/W2010980346', 'https://openalex.org/W6616763113', 'https://openalex.org/W6632820619', 'https://openalex.org/W2136412480', 'https://openalex.org/W6645640999', 'https://openalex.org/W6738652494', 'https://openalex.org/W2395225233', 'https://openalex.org/W2110638188', 'https://openalex.org/W2064135025', 'https://openalex.org/W2963962561', 'https://openalex.org/W4377220931', 'https://openalex.org/W6834868713', 'https://openalex.org/W2160527964', 'https://openalex.org/W2059168261', 'https://openalex.org/W2154600605', 'https://openalex.org/W3163700796', 'https://openalex.org/W6681399687', 'https://openalex.org/W2971977259', 'https://openalex.org/W3084747096', 'https://openalex.org/W6677458792', 'https://openalex.org/W6677158074', 'https://openalex.org/W7064937209', 'https://openalex.org/W6641355812', 'https://openalex.org/W2032476212', 'https://openalex.org/W6601893370', 'https://openalex.org/W2805234167', 'https://openalex.org/W6681346506', 'https://openalex.org/W3190032417', 'https://openalex.org/W6635139342', 'https://openalex.org/W3119308075', 'https://openalex.org/W2089452757', 'https://openalex.org/W2990241049', 'https://openalex.org/W2147740811', 'https://openalex.org/W2037751943', 'https://openalex.org/W2101509422', 'https://openalex.org/W2398830367', 'https://openalex.org/W2058616551', 'https://openalex.org/W6634417500', 'https://openalex.org/W2169868772', 'https://openalex.org/W2917235195', 'https://openalex.org/W1532494781', 'https://openalex.org/W3100385063', 'https://openalex.org/W4200598898', 'https://openalex.org/W6800751262', 'https://openalex.org/W4297677272', 'https://openalex.org/W140261823', 'https://openalex.org/W2162505970', 'https://openalex.org/W2060204180', 'https://openalex.org/W2095223181', 'https://openalex.org/W4221038855', 'https://openalex.org/W4225726571', 'https://openalex.org/W3197259906', 'https://openalex.org/W833103999', 'https://openalex.org/W1705150430', 'https://openalex.org/W2118373646', 'https://openalex.org/W2141038596', 'https://openalex.org/W2595479191', 'https://openalex.org/W3005081886', 'https://openalex.org/W2163999179', 'https://openalex.org/W6642493903', 'https://openalex.org/W6672662947', 'https://openalex.org/W7071849196', 'https://openalex.org/W135984148', 'https://openalex.org/W1540073772', 'https://openalex.org/W6635894473', 'https://openalex.org/W6637818730', 'https://openalex.org/W2784570041', 'https://openalex.org/W2937297214', 'https://openalex.org/W3166292821', 'https://openalex.org/W3134108900', 'https://openalex.org/W6676636377', 'https://openalex.org/W1968225092', 'https://openalex.org/W3023172065', 'https://openalex.org/W2913939165', 'https://openalex.org/W2016292361', 'https://openalex.org/W414516981', 'https://openalex.org/W2149932965', 'https://openalex.org/W2005592929', 'https://openalex.org/W1540332606', 'https://openalex.org/W6655970245', 'https://openalex.org/W1993984071', 'https://openalex.org/W2107917162', 'https://openalex.org/W2395899413', 'https://openalex.org/W4313484307', 'https://openalex.org/W2972337257', 'https://openalex.org/W1995403064', 'https://openalex.org/W2585893098', 'https://openalex.org/W6676456322', 'https://openalex.org/W6623095062', 'https://openalex.org/W3171477941', 'https://openalex.org/W4246559809', 'https://openalex.org/W2125566341', 'https://openalex.org/W2000977437', 'https://openalex.org/W2303872361', 'https://openalex.org/W4320013820', 'https://openalex.org/W4242257761', 'https://openalex.org/W3196595845', 'https://openalex.org/W4243223559', 'https://openalex.org/W2032442824', 'https://openalex.org/W2059146861', 'https://openalex.org/W2995609441', 'https://openalex.org/W2119165475', 'https://openalex.org/W4313255477', 'https://openalex.org/W1597121597', 'https://openalex.org/W2398326651', 'https://openalex.org/W4254816979', 'https://openalex.org/W4288279357', 'https://openalex.org/W1543397219', 'https://openalex.org/W2618602706', 'https://openalex.org/W4297798492', 'https://openalex.org/W821509450', 'https://openalex.org/W4307680525', 'https://openalex.org/W4243618065', 'https://openalex.org/W2120713167', 'https://openalex.org/W4394671563', 'https://openalex.org/W4246867089', 'https://openalex.org/W2131070395', 'https://openalex.org/W4249920809', 'https://openalex.org/W2160997109', 'https://openalex.org/W4297938313', 'https://openalex.org/W4287365906', 'https://openalex.org/W4308231222', 'https://openalex.org/W4237938692', 'https://openalex.org/W4247178956', 'https://openalex.org/W4298742451', 'https://openalex.org/W3036601975', 'https://openalex.org/W2252657604', 'https://openalex.org/W2099164611', 'https://openalex.org/W1559022555', 'https://openalex.org/W2143296986', 'https://openalex.org/W4300721020', 'https://openalex.org/W2973180715', 'https://openalex.org/W3151534266', 'https://openalex.org/W3034905892', 'https://openalex.org/W2163097816', 'https://openalex.org/W4255020641', 'https://openalex.org/W2435103813', 'https://openalex.org/W1981253069', 'https://openalex.org/W4240474221', 'https://openalex.org/W2799770360', 'https://openalex.org/W4210307751', 'https://openalex.org/W2963648280', 'https://openalex.org/W2163028944', 'https://openalex.org/W2996728628', 'https://openalex.org/W3202070718', 'https://openalex.org/W2010188467', 'https://openalex.org/W4319862635', 'https://openalex.org/W3162231828', 'https://openalex.org/W4294955557', 'https://openalex.org/W2533523411', 'https://openalex.org/W3080620940', 'https://openalex.org/W2933138175', 'https://openalex.org/W2973049979', 'https://openalex.org/W3199093330', 'https://openalex.org/W2959443032', 'https://openalex.org/W4292779060', 'https://openalex.org/W4249366912', 'https://openalex.org/W2219249508', 'https://openalex.org/W2041394569', 'https://openalex.org/W4251221781', 'https://openalex.org/W3130041921', 'https://openalex.org/W4225815933', 'https://openalex.org/W2801193150', 'https://openalex.org/W2333023345', 'https://openalex.org/W3126722376', 'https://openalex.org/W3198815374', 'https://openalex.org/W4362220304', 'https://openalex.org/W3133848337', 'https://openalex.org/W4385822336', 'https://openalex.org/W4253001367', 'https://openalex.org/W4245984049', 'https://openalex.org/W4376140088', 'https://openalex.org/W2029008609', 'https://openalex.org/W3212943633', 'https://openalex.org/W4255249122', 'https://openalex.org/W1524333225', 'https://openalex.org/W1925965306', 'https://openalex.org/W3144810982', 'https://openalex.org/W2621934507', 'https://openalex.org/W4245117732', 'https://openalex.org/W2037662195', 'https://openalex.org/W4256695500', 'https://openalex.org/W2182291882', 'https://openalex.org/W4375868953', 'https://openalex.org/W4307320512', 'https://openalex.org/W2164274485', 'https://openalex.org/W2032543155', 'https://openalex.org/W4309419356', 'https://openalex.org/W2803055582', 'https://openalex.org/W4387865047', 'https://openalex.org/W4236000557', 'https://openalex.org/W3036063182', 'https://openalex.org/W2995680346', 'https://openalex.org/W2040344088', 'https://openalex.org/W2963321191', 'https://openalex.org/W1984717236', 'https://openalex.org/W577928986', 'https://openalex.org/W4381786045', 'https://openalex.org/W4243341362', 'https://openalex.org/W2888777493', 'https://openalex.org/W2980877534', 'https://openalex.org/W4385822676', 'https://openalex.org/W3097945073', 'https://openalex.org/W4253926802', 'https://openalex.org/W4292825791', 'https://openalex.org/W1969005071', 'https://openalex.org/W4242738990', 'https://openalex.org/W2972449503', 'https://openalex.org/W166170480', 'https://openalex.org/W2127523122', 'https://openalex.org/W4251435902', 'https://openalex.org/W2058878924', 'https://openalex.org/W4238964169', 'https://openalex.org/W1577624656', 'https://openalex.org/W2065159495', 'https://openalex.org/W4253947715', 'https://openalex.org/W2296607128', 'https://openalex.org/W3197479040', 'https://openalex.org/W2546861836', 'https://openalex.org/W4237154886', 'https://openalex.org/W4288072840', 'https://openalex.org/W4301785137', 'https://openalex.org/W4231114907', 'https://openalex.org/W2519091744', 'https://openalex.org/W1719717336', 'https://openalex.org/W2044321477', 'https://openalex.org/W1972102750', 'https://openalex.org/W4297808394', 'https://openalex.org/W2020944885', 'https://openalex.org/W4323066695', 'https://openalex.org/W1558150890', 'https://openalex.org/W4283332789', 'https://openalex.org/W2323385789', 'https://openalex.org/W2115099665', 'https://openalex.org/W2123599888', 'https://openalex.org/W4230806239', 'https://openalex.org/W2160464066', 'https://openalex.org/W4232589384', 'https://openalex.org/W2964052309', 'https://openalex.org/W4230804341', 'https://openalex.org/W1533561824', 'https://openalex.org/W4230637005', 'https://openalex.org/W2187824139', 'https://openalex.org/W2108582985', 'https://openalex.org/W4252366034', 'https://openalex.org/W2058354688', 'https://openalex.org/W4366994024', 'https://openalex.org/W4385822936', 'https://openalex.org/W3015944949', 'https://openalex.org/W2070653320', 'https://openalex.org/W2003341094', 'https://openalex.org/W2963604492', 'https://openalex.org/W4385823426', 'https://openalex.org/W4235338493', 'https://openalex.org/W2126377586', 'https://openalex.org/W4283762111', 'https://openalex.org/W3146245645', 'https://openalex.org/W2060238187', 'https://openalex.org/W4250832892', 'https://openalex.org/W4246103655', 'https://openalex.org/W4242334097', 'https://openalex.org/W3030437843', 'https://openalex.org/W3015877095', 'https://openalex.org/W2015075592', 'https://openalex.org/W4251965084', 'https://openalex.org/W2110221456', 'https://openalex.org/W4307979480', 'https://openalex.org/W3095410713', 'https://openalex.org/W1964575515', 'https://openalex.org/W2618478924', 'https://openalex.org/W2115975321', 'https://openalex.org/W3195577433', 'https://openalex.org/W2037752261', 'https://openalex.org/W2343593471', 'https://openalex.org/W3177829661', 'https://openalex.org/W2571532437', 'https://openalex.org/W4290673677', 'https://openalex.org/W2169403152', 'https://openalex.org/W3016181583', 'https://openalex.org/W4286984129', 'https://openalex.org/W1967834254', 'https://openalex.org/W2964054038', 'https://openalex.org/W2950416202', 'https://openalex.org/W2615444509', 'https://openalex.org/W1980862600', 'https://openalex.org/W3047246203', 'https://openalex.org/W4253971549', 'https://openalex.org/W4287591426', 'https://openalex.org/W2054948443', 'https://openalex.org/W3015783745', 'https://openalex.org/W2728435982']",2023-10-22
https://openalex.org/W4406461892,https://doi.org/10.1109/slt61566.2024.10832297,Discrete Unit Based Masking For Improving Disentanglement in Voice Conversion,,"['https://openalex.org/W3098557217', 'https://openalex.org/W2021986246', 'https://openalex.org/W2396025094', 'https://openalex.org/W2057609679', 'https://openalex.org/W2902070858', 'https://openalex.org/W3100696337', 'https://openalex.org/W6762533536', 'https://openalex.org/W2972659941', 'https://openalex.org/W3197659778', 'https://openalex.org/W3163475957', 'https://openalex.org/W4286747238', 'https://openalex.org/W4375868976', 'https://openalex.org/W4392902857', 'https://openalex.org/W2972403660', 'https://openalex.org/W4366147765', 'https://openalex.org/W2890704021', 'https://openalex.org/W3162512456', 'https://openalex.org/W6772357204', 'https://openalex.org/W4385823264', 'https://openalex.org/W4224301045', 'https://openalex.org/W4372337821', 'https://openalex.org/W3209059054', 'https://openalex.org/W3209984917', 'https://openalex.org/W4375868953', 'https://openalex.org/W2603777577', 'https://openalex.org/W3095361818', 'https://openalex.org/W3096524539', 'https://openalex.org/W6779459370', 'https://openalex.org/W6772349387', 'https://openalex.org/W3016181583', 'https://openalex.org/W2471520273', 'https://openalex.org/W3210530853', 'https://openalex.org/W3015338123', 'https://openalex.org/W2962788625', 'https://openalex.org/W6805710207', 'https://openalex.org/W2997430147', 'https://openalex.org/W2998572311', 'https://openalex.org/W3008391559', 'https://openalex.org/W1583837637']",2024-12-02
https://openalex.org/W4408345622,https://doi.org/10.1109/icassp49660.2025.10888310,Enhancing TTS Stability in Hebrew using Discrete Semantic Units,,"['https://openalex.org/W6810007534', 'https://openalex.org/W6780218876', 'https://openalex.org/W4406417959', 'https://openalex.org/W4307323391', 'https://openalex.org/W3024869864', 'https://openalex.org/W2120847449', 'https://openalex.org/W6852781825', 'https://openalex.org/W3209059054', 'https://openalex.org/W4287887366', 'https://openalex.org/W4390075359', 'https://openalex.org/W4391021739', 'https://openalex.org/W4392903174', 'https://openalex.org/W6783867762', 'https://openalex.org/W4385574033', 'https://openalex.org/W6790356757', 'https://openalex.org/W3180374548', 'https://openalex.org/W6854516525', 'https://openalex.org/W6869755106', 'https://openalex.org/W4385823130', 'https://openalex.org/W6861618871', 'https://openalex.org/W3140429000', 'https://openalex.org/W6852909395', 'https://openalex.org/W6847363464', 'https://openalex.org/W4402112148', 'https://openalex.org/W6793818051', 'https://openalex.org/W4385807460', 'https://openalex.org/W3037100408', 'https://openalex.org/W4375868953', 'https://openalex.org/W2807627734', 'https://openalex.org/W4297841357', 'https://openalex.org/W4402112439', 'https://openalex.org/W2094721231', 'https://openalex.org/W6848735303', 'https://openalex.org/W6857062747', 'https://openalex.org/W4409362462', 'https://openalex.org/W3215615641', 'https://openalex.org/W2972359262']",2025-03-12
https://openalex.org/W4408352488,https://doi.org/10.1109/icassp49660.2025.10888561,Salmon: A Suite for Acoustic Language Model Evaluation,,"['https://openalex.org/W4401246677', 'https://openalex.org/W6790356757', 'https://openalex.org/W6852781825', 'https://openalex.org/W4404782909', 'https://openalex.org/W6861618871', 'https://openalex.org/W4392904805', 'https://openalex.org/W4402112110', 'https://openalex.org/W6857054612', 'https://openalex.org/W4307680525', 'https://openalex.org/W6864829915', 'https://openalex.org/W4401042284', 'https://openalex.org/W4404783093', 'https://openalex.org/W6868986815', 'https://openalex.org/W6868911249', 'https://openalex.org/W4409348167', 'https://openalex.org/W3197259906', 'https://openalex.org/W3198217962', 'https://openalex.org/W4385822336', 'https://openalex.org/W6869365648', 'https://openalex.org/W4381786045', 'https://openalex.org/W6810325043', 'https://openalex.org/W4389524018', 'https://openalex.org/W6853530687', 'https://openalex.org/W4402112381', 'https://openalex.org/W4402111497', 'https://openalex.org/W4307323391', 'https://openalex.org/W3215615641', 'https://openalex.org/W4389524060', 'https://openalex.org/W4375868953', 'https://openalex.org/W3140429000', 'https://openalex.org/W4387595589', 'https://openalex.org/W6853998256', 'https://openalex.org/W6859099255', 'https://openalex.org/W6847363464', 'https://openalex.org/W4411119642', 'https://openalex.org/W4392902623', 'https://openalex.org/W4402684170', 'https://openalex.org/W4385823130', 'https://openalex.org/W6772349387', 'https://openalex.org/W6917585676', 'https://openalex.org/W4205689591', 'https://openalex.org/W2747874407', 'https://openalex.org/W6873786637', 'https://openalex.org/W6854866820', 'https://openalex.org/W3209059054']",2025-03-12
https://openalex.org/W4409311249,https://doi.org/10.1109/taslpro.2025.3559344,UnitCorrect: Unit-Based Mispronunciation Correcting System With a DTW-Based Detection,,"['https://openalex.org/W6763832098', 'https://openalex.org/W6778823374', 'https://openalex.org/W6796464841', 'https://openalex.org/W6851724922', 'https://openalex.org/W6858915148', 'https://openalex.org/W6749555683', 'https://openalex.org/W6795807602', 'https://openalex.org/W6750489868', 'https://openalex.org/W4396542467', 'https://openalex.org/W2050526637', 'https://openalex.org/W4221165942', 'https://openalex.org/W2146101954', 'https://openalex.org/W2737697117', 'https://openalex.org/W3160438760', 'https://openalex.org/W6810189000', 'https://openalex.org/W4221142789', 'https://openalex.org/W2973049979', 'https://openalex.org/W6780218876', 'https://openalex.org/W3209059054', 'https://openalex.org/W6847363464', 'https://openalex.org/W3209984917', 'https://openalex.org/W3215615641', 'https://openalex.org/W4400111385', 'https://openalex.org/W6848735303', 'https://openalex.org/W4375868953', 'https://openalex.org/W2127141656', 'https://openalex.org/W4225596771', 'https://openalex.org/W4297841480', 'https://openalex.org/W4385571941', 'https://openalex.org/W4252812408', 'https://openalex.org/W3140429000', 'https://openalex.org/W4287887366', 'https://openalex.org/W4385822372', 'https://openalex.org/W4406521093', 'https://openalex.org/W3180374548', 'https://openalex.org/W4287854499', 'https://openalex.org/W4385570550', 'https://openalex.org/W4392903174', 'https://openalex.org/W6846539466', 'https://openalex.org/W6752307458', 'https://openalex.org/W4392931276', 'https://openalex.org/W6861856086', 'https://openalex.org/W2747874407', 'https://openalex.org/W2128160875', 'https://openalex.org/W6772349387', 'https://openalex.org/W4385823191', 'https://openalex.org/W2888954148', 'https://openalex.org/W2972359262', 'https://openalex.org/W6639480849', 'https://openalex.org/W2962788625', 'https://openalex.org/W6838843145', 'https://openalex.org/W4225956675', 'https://openalex.org/W4322714819']",2025-01-01
https://openalex.org/W4410770311,https://doi.org/10.1109/icasspw65056.2025.11011236,Discrete Speech Unit Extraction via Independent Component Analysis,,"['https://openalex.org/W6780218876', 'https://openalex.org/W3209059054', 'https://openalex.org/W3209984917', 'https://openalex.org/W3213029956', 'https://openalex.org/W3197580070', 'https://openalex.org/W4285250921', 'https://openalex.org/W4385822439', 'https://openalex.org/W4392902623', 'https://openalex.org/W4226380987', 'https://openalex.org/W4375869259', 'https://openalex.org/W4392903098', 'https://openalex.org/W6845712036', 'https://openalex.org/W4402112198', 'https://openalex.org/W4402111789', 'https://openalex.org/W4392909068', 'https://openalex.org/W4381786045', 'https://openalex.org/W3180374548', 'https://openalex.org/W4385570550', 'https://openalex.org/W6853998256', 'https://openalex.org/W4392904805', 'https://openalex.org/W6790356757', 'https://openalex.org/W6852781825', 'https://openalex.org/W3210530853', 'https://openalex.org/W6674733807', 'https://openalex.org/W4375869060', 'https://openalex.org/W4296069362', 'https://openalex.org/W4402112125', 'https://openalex.org/W4389518770', 'https://openalex.org/W4226033575', 'https://openalex.org/W6794146050', 'https://openalex.org/W3139958517', 'https://openalex.org/W2946521785', 'https://openalex.org/W2143132653', 'https://openalex.org/W108815450', 'https://openalex.org/W1494198834', 'https://openalex.org/W4385822683', 'https://openalex.org/W4319862255', 'https://openalex.org/W4405532155', 'https://openalex.org/W4406461488', 'https://openalex.org/W4287854499', 'https://openalex.org/W6734040793', 'https://openalex.org/W2970172244', 'https://openalex.org/W1635512741', 'https://openalex.org/W4385823003', 'https://openalex.org/W4375868953']",2025-04-06
https://openalex.org/W4406800520,https://doi.org/10.1007/s11432-024-4222-0,The rise and potential of large language model based agents: a survey,,"['https://openalex.org/W2124344619', 'https://openalex.org/W1537234190', 'https://openalex.org/W2397253692', 'https://openalex.org/W2070545326', 'https://openalex.org/W2029130131', 'https://openalex.org/W2107726111', 'https://openalex.org/W2058517091', 'https://openalex.org/W2165718398', 'https://openalex.org/W4363671832', 'https://openalex.org/W6853127500', 'https://openalex.org/W4226278401', 'https://openalex.org/W6838461927', 'https://openalex.org/W6856464235', 'https://openalex.org/W4360836968', 'https://openalex.org/W1504553351', 'https://openalex.org/W2144442672', 'https://openalex.org/W6675145293', 'https://openalex.org/W2255817990', 'https://openalex.org/W1993251552', 'https://openalex.org/W2111438441', 'https://openalex.org/W1540044141', 'https://openalex.org/W1968079292', 'https://openalex.org/W1519698894', 'https://openalex.org/W2097856935', 'https://openalex.org/W2045031658', 'https://openalex.org/W2118756286', 'https://openalex.org/W2131600418', 'https://openalex.org/W2257979135', 'https://openalex.org/W6637967152', 'https://openalex.org/W6750629867', 'https://openalex.org/W2891790128', 'https://openalex.org/W3121342653', 'https://openalex.org/W3181634442', 'https://openalex.org/W6676875888', 'https://openalex.org/W2578206533', 'https://openalex.org/W2788904251', 'https://openalex.org/W2923504512', 'https://openalex.org/W6768602481', 'https://openalex.org/W2803180393', 'https://openalex.org/W6849169497', 'https://openalex.org/W6778883912', 'https://openalex.org/W4386184788', 'https://openalex.org/W4226227340', 'https://openalex.org/W4304195432', 'https://openalex.org/W4320165837', 'https://openalex.org/W4366566341', 'https://openalex.org/W6852755768', 'https://openalex.org/W4221143046', 'https://openalex.org/W6838865847', 'https://openalex.org/W4221161695', 'https://openalex.org/W4281483047', 'https://openalex.org/W4378470461', 'https://openalex.org/W4353112996', 'https://openalex.org/W4310998175', 'https://openalex.org/W4376654477', 'https://openalex.org/W4322718421', 'https://openalex.org/W6800875267', 'https://openalex.org/W3205068155', 'https://openalex.org/W6847076894', 'https://openalex.org/W7064840731', 'https://openalex.org/W6854738257', 'https://openalex.org/W4378509427', 'https://openalex.org/W4378945542', 'https://openalex.org/W6809908440', 'https://openalex.org/W4366850747', 'https://openalex.org/W6852989508', 'https://openalex.org/W6850503672', 'https://openalex.org/W4378465306', 'https://openalex.org/W2001784601', 'https://openalex.org/W4378711594', 'https://openalex.org/W4321011818', 'https://openalex.org/W4366999541', 'https://openalex.org/W2336741951', 'https://openalex.org/W6810581500', 'https://openalex.org/W4377111802', 'https://openalex.org/W4383473935', 'https://openalex.org/W6683738474', 'https://openalex.org/W6604551671', 'https://openalex.org/W1971434212', 'https://openalex.org/W1502957213', 'https://openalex.org/W3044438666', 'https://openalex.org/W4385567216', 'https://openalex.org/W2792026792', 'https://openalex.org/W6809838524', 'https://openalex.org/W4309804142', 'https://openalex.org/W6803096969', 'https://openalex.org/W4384561707', 'https://openalex.org/W3034238904', 'https://openalex.org/W1969735301', 'https://openalex.org/W2013982304', 'https://openalex.org/W4367189927', 'https://openalex.org/W6855425347', 'https://openalex.org/W4377163995', 'https://openalex.org/W4378768661', 'https://openalex.org/W4385714639', 'https://openalex.org/W4378509422', 'https://openalex.org/W4385970259', 'https://openalex.org/W4379933140', 'https://openalex.org/W1997480541', 'https://openalex.org/W1986884366', 'https://openalex.org/W6851275496', 'https://openalex.org/W4386978002', 'https://openalex.org/W4391710008', 'https://openalex.org/W6811284106', 'https://openalex.org/W2026085771', 'https://openalex.org/W1974922297', 'https://openalex.org/W2004550196', 'https://openalex.org/W2614653677', 'https://openalex.org/W4224912544', 'https://openalex.org/W4378942217', 'https://openalex.org/W4392637287', 'https://openalex.org/W4372272282', 'https://openalex.org/W4378770584', 'https://openalex.org/W4377130677', 'https://openalex.org/W4389520747', 'https://openalex.org/W4221152848', 'https://openalex.org/W4225405251', 'https://openalex.org/W4378468533', 'https://openalex.org/W4378505261', 'https://openalex.org/W4285428875', 'https://openalex.org/W4327667441', 'https://openalex.org/W2097585998', 'https://openalex.org/W6748634344', 'https://openalex.org/W2896457183', 'https://openalex.org/W4312205996', 'https://openalex.org/W6848909144', 'https://openalex.org/W2094848746', 'https://openalex.org/W3156470785', 'https://openalex.org/W4310832511', 'https://openalex.org/W4313679638', 'https://openalex.org/W3177174258', 'https://openalex.org/W6843258702', 'https://openalex.org/W4364387438', 'https://openalex.org/W4323651091', 'https://openalex.org/W2116360511', 'https://openalex.org/W2144730066', 'https://openalex.org/W4378474033', 'https://openalex.org/W2626804490', 'https://openalex.org/W6783880405', 'https://openalex.org/W3034975599', 'https://openalex.org/W6766818547', 'https://openalex.org/W6775772702', 'https://openalex.org/W6771429369', 'https://openalex.org/W3129503315', 'https://openalex.org/W6852776751', 'https://openalex.org/W6856012975', 'https://openalex.org/W4322718246', 'https://openalex.org/W4382490555', 'https://openalex.org/W4318718936', 'https://openalex.org/W4376312115', 'https://openalex.org/W6852447913', 'https://openalex.org/W4375958083', 'https://openalex.org/W4380994269', 'https://openalex.org/W4380137126', 'https://openalex.org/W4367061106', 'https://openalex.org/W4311000453', 'https://openalex.org/W2946200149', 'https://openalex.org/W3209059054', 'https://openalex.org/W4392669753', 'https://openalex.org/W4321472132', 'https://openalex.org/W3213407400', 'https://openalex.org/W6776750061', 'https://openalex.org/W4379138252', 'https://openalex.org/W3116286104', 'https://openalex.org/W4385374425', 'https://openalex.org/W4322718191', 'https://openalex.org/W4308760226', 'https://openalex.org/W2962736495', 'https://openalex.org/W6854340891', 'https://openalex.org/W6604405615', 'https://openalex.org/W2296073425', 'https://openalex.org/W6798182279', 'https://openalex.org/W6851896007', 'https://openalex.org/W4380993239', 'https://openalex.org/W4365597205', 'https://openalex.org/W4323717348', 'https://openalex.org/W2103104224', 'https://openalex.org/W4207072548', 'https://openalex.org/W2810785043', 'https://openalex.org/W4319165647', 'https://openalex.org/W2799002257', 'https://openalex.org/W6786772999', 'https://openalex.org/W3189250028', 'https://openalex.org/W2987774896', 'https://openalex.org/W4292178068', 'https://openalex.org/W6761234640', 'https://openalex.org/W4318908031', 'https://openalex.org/W4296414573', 'https://openalex.org/W2982118014', 'https://openalex.org/W3115640848', 'https://openalex.org/W4379924706', 'https://openalex.org/W3066254485', 'https://openalex.org/W4306175879', 'https://openalex.org/W6846512445', 'https://openalex.org/W4319323461', 'https://openalex.org/W4378945292', 'https://openalex.org/W4285069854', 'https://openalex.org/W6786622191', 'https://openalex.org/W6846310961', 'https://openalex.org/W4221144910', 'https://openalex.org/W6811476558', 'https://openalex.org/W2997528589', 'https://openalex.org/W4311559655', 'https://openalex.org/W4385473486', 'https://openalex.org/W4283218993', 'https://openalex.org/W3173930728', 'https://openalex.org/W6777324918', 'https://openalex.org/W4318751977', 'https://openalex.org/W4388483618', 'https://openalex.org/W4385327683', 'https://openalex.org/W4385262076', 'https://openalex.org/W4377372292', 'https://openalex.org/W4283828996', 'https://openalex.org/W3141082077', 'https://openalex.org/W6853453387', 'https://openalex.org/W6787130917', 'https://openalex.org/W4385573990', 'https://openalex.org/W4389109049', 'https://openalex.org/W4382498654', 'https://openalex.org/W4327550249', 'https://openalex.org/W4226159083', 'https://openalex.org/W4385947658', 'https://openalex.org/W4308165003', 'https://openalex.org/W6780281623', 'https://openalex.org/W4318751399', 'https://openalex.org/W2497473826', 'https://openalex.org/W6683839571', 'https://openalex.org/W6852426770', 'https://openalex.org/W4361865652', 'https://openalex.org/W4396902788', 'https://openalex.org/W4385963839', 'https://openalex.org/W1993533232', 'https://openalex.org/W2911296969', 'https://openalex.org/W2766447205', 'https://openalex.org/W2625113742', 'https://openalex.org/W7019202113', 'https://openalex.org/W4385849309', 'https://openalex.org/W6793423792', 'https://openalex.org/W4321760789', 'https://openalex.org/W1949907236', 'https://openalex.org/W46490633', 'https://openalex.org/W2636355936', 'https://openalex.org/W4411517540', 'https://openalex.org/W4390832893', 'https://openalex.org/W6730098006', 'https://openalex.org/W6737850504', 'https://openalex.org/W4290771878', 'https://openalex.org/W4224861986', 'https://openalex.org/W2798753108', 'https://openalex.org/W2970393840', 'https://openalex.org/W3150595019', 'https://openalex.org/W4287887895', 'https://openalex.org/W4361807044', 'https://openalex.org/W4300230145', 'https://openalex.org/W4384613928', 'https://openalex.org/W4366851012', 'https://openalex.org/W6842239938', 'https://openalex.org/W4383604266', 'https://openalex.org/W4389520259', 'https://openalex.org/W4385681988', 'https://openalex.org/W2623357307', 'https://openalex.org/W3100551981', 'https://openalex.org/W4376988648', 'https://openalex.org/W4380993798', 'https://openalex.org/W3139433464', 'https://openalex.org/W6767670765', 'https://openalex.org/W3089860869', 'https://openalex.org/W6839226615', 'https://openalex.org/W4385681459', 'https://openalex.org/W2897690397', 'https://openalex.org/W4284966012', 'https://openalex.org/W3159807213', 'https://openalex.org/W4391944659', 'https://openalex.org/W3104266443', 'https://openalex.org/W4305033123', 'https://openalex.org/W4309663019', 'https://openalex.org/W2970894611', 'https://openalex.org/W2913781869', 'https://openalex.org/W6853822724', 'https://openalex.org/W2952204218', 'https://openalex.org/W4385681712', 'https://openalex.org/W3206525235', 'https://openalex.org/W4240912089', 'https://openalex.org/W4232406588', 'https://openalex.org/W4386644471', 'https://openalex.org/W4387799829', 'https://openalex.org/W3013499767', 'https://openalex.org/W3215698779', 'https://openalex.org/W4384072911', 'https://openalex.org/W4283263983', 'https://openalex.org/W4386384991', 'https://openalex.org/W4380551925', 'https://openalex.org/W4378470708', 'https://openalex.org/W6849906535', 'https://openalex.org/W1993584577', 'https://openalex.org/W4312091865', 'https://openalex.org/W6854260779', 'https://openalex.org/W4302445826', 'https://openalex.org/W4379919636', 'https://openalex.org/W2091786736', 'https://openalex.org/W6753101812', 'https://openalex.org/W2972550240', 'https://openalex.org/W2922424071', 'https://openalex.org/W4385374144', 'https://openalex.org/W4380763235', 'https://openalex.org/W4367365575', 'https://openalex.org/W1515781139', 'https://openalex.org/W2734203669', 'https://openalex.org/W2158076918', 'https://openalex.org/W2010524426', 'https://openalex.org/W2799899844', 'https://openalex.org/W4375870056', 'https://openalex.org/W4237556202', 'https://openalex.org/W2074812030', 'https://openalex.org/W2117014758', 'https://openalex.org/W2106731506', 'https://openalex.org/W6854015811', 'https://openalex.org/W4237262806', 'https://openalex.org/W1672610948', 'https://openalex.org/W4322626329', 'https://openalex.org/W4226112058', 'https://openalex.org/W4365211621', 'https://openalex.org/W3188785232', 'https://openalex.org/W2755689238', 'https://openalex.org/W4309217888', 'https://openalex.org/W4378465112', 'https://openalex.org/W4362631702', 'https://openalex.org/W3172205429', 'https://openalex.org/W2963919731', 'https://openalex.org/W4383895105', 'https://openalex.org/W4221159410', 'https://openalex.org/W6847753483', 'https://openalex.org/W4223908421', 'https://openalex.org/W4399455192', 'https://openalex.org/W6856086692', 'https://openalex.org/W4385714628', 'https://openalex.org/W6772715161', 'https://openalex.org/W3205272844', 'https://openalex.org/W4389519042', 'https://openalex.org/W4241563224', 'https://openalex.org/W4362655849', 'https://openalex.org/W4386185147', 'https://openalex.org/W4226414096', 'https://openalex.org/W4296413526', 'https://openalex.org/W6839548382', 'https://openalex.org/W6637162671', 'https://openalex.org/W2640329709', 'https://openalex.org/W6855939272', 'https://openalex.org/W4226284056', 'https://openalex.org/W2602856279', 'https://openalex.org/W2963859254', 'https://openalex.org/W3006647218', 'https://openalex.org/W4385574291', 'https://openalex.org/W6735677848', 'https://openalex.org/W4290858323', 'https://openalex.org/W2989807128', 'https://openalex.org/W2971970905', 'https://openalex.org/W2949128310', 'https://openalex.org/W4379958452', 'https://openalex.org/W3204619801', 'https://openalex.org/W3199419198', 'https://openalex.org/W4296841006', 'https://openalex.org/W6849590751', 'https://openalex.org/W4385573090', 'https://openalex.org/W4380353722', 'https://openalex.org/W3044324512', 'https://openalex.org/W3177190797', 'https://openalex.org/W4285266418', 'https://openalex.org/W6755310938', 'https://openalex.org/W2913266441', 'https://openalex.org/W3036286896', 'https://openalex.org/W4377371478', 'https://openalex.org/W2981852735', 'https://openalex.org/W4308015675', 'https://openalex.org/W3037831233', 'https://openalex.org/W3034115845', 'https://openalex.org/W2483215953', 'https://openalex.org/W2893425640', 'https://openalex.org/W4309674289', 'https://openalex.org/W4378501037', 'https://openalex.org/W3034383590', 'https://openalex.org/W4383987670', 'https://openalex.org/W4402722824', 'https://openalex.org/W6852476831', 'https://openalex.org/W4388843580', 'https://openalex.org/W2787887017', 'https://openalex.org/W6800751262', 'https://openalex.org/W4378474356', 'https://openalex.org/W3134756955', 'https://openalex.org/W4391047179', 'https://openalex.org/W4378718522', 'https://openalex.org/W3092516542', 'https://openalex.org/W4377864377', 'https://openalex.org/W4368304377', 'https://openalex.org/W1562983757', 'https://openalex.org/W2013116016', 'https://openalex.org/W2275530856', 'https://openalex.org/W2135150302', 'https://openalex.org/W6635852658', 'https://openalex.org/W6810313920', 'https://openalex.org/W4322832290', 'https://openalex.org/W4385430086', 'https://openalex.org/W4287026640', 'https://openalex.org/W3154565472', 'https://openalex.org/W4385473492', 'https://openalex.org/W4404826238', 'https://openalex.org/W4293253344', 'https://openalex.org/W4387993371', 'https://openalex.org/W3185212449', 'https://openalex.org/W4386114002', 'https://openalex.org/W4205185581', 'https://openalex.org/W2612560781', 'https://openalex.org/W1583837637', 'https://openalex.org/W2748789698', 'https://openalex.org/W1479925024', 'https://openalex.org/W4387835442', 'https://openalex.org/W4380715521', 'https://openalex.org/W4311991106', 'https://openalex.org/W4401042671', 'https://openalex.org/W4307079201', 'https://openalex.org/W3034655362', 'https://openalex.org/W2620949368', 'https://openalex.org/W4385473851', 'https://openalex.org/W4298857966', 'https://openalex.org/W4376652803', 'https://openalex.org/W4385261769', 'https://openalex.org/W4298174377', 'https://openalex.org/W4379251535', 'https://openalex.org/W3148330722', 'https://openalex.org/W4319453300', 'https://openalex.org/W4388744821', 'https://openalex.org/W3177813494', 'https://openalex.org/W4386081135', 'https://openalex.org/W2569616450', 'https://openalex.org/W2893662673', 'https://openalex.org/W3039636162', 'https://openalex.org/W2019641150', 'https://openalex.org/W4389523771', 'https://openalex.org/W4311408938', 'https://openalex.org/W4294435850', 'https://openalex.org/W4379919478', 'https://openalex.org/W4214717370', 'https://openalex.org/W4385682136', 'https://openalex.org/W4389519587', 'https://openalex.org/W3129717163', 'https://openalex.org/W4313483544', 'https://openalex.org/W4285429195', 'https://openalex.org/W4382132560', 'https://openalex.org/W4394645559', 'https://openalex.org/W4377865309', 'https://openalex.org/W4385970197', 'https://openalex.org/W4385468994', 'https://openalex.org/W4364384540', 'https://openalex.org/W1869215669', 'https://openalex.org/W108702333', 'https://openalex.org/W4386200967', 'https://openalex.org/W4283026156', 'https://openalex.org/W2042538315', 'https://openalex.org/W2955254504', 'https://openalex.org/W4231016000', 'https://openalex.org/W1598960279', 'https://openalex.org/W4401042726', 'https://openalex.org/W4384111857', 'https://openalex.org/W4386528753', 'https://openalex.org/W2935689779', 'https://openalex.org/W4308902180', 'https://openalex.org/W4321471914', 'https://openalex.org/W4402671548', 'https://openalex.org/W4390874280', 'https://openalex.org/W4309395891', 'https://openalex.org/W3139377883', 'https://openalex.org/W4286892945', 'https://openalex.org/W3111265093', 'https://openalex.org/W4306179311', 'https://openalex.org/W4385928960', 'https://openalex.org/W3103559770', 'https://openalex.org/W3195577433', 'https://openalex.org/W4389636360', 'https://openalex.org/W4307106501', 'https://openalex.org/W4365211632', 'https://openalex.org/W4366328015', 'https://openalex.org/W4385970117', 'https://openalex.org/W3011120880', 'https://openalex.org/W2318875203', 'https://openalex.org/W4287900772', 'https://openalex.org/W2769533150', 'https://openalex.org/W2797527950', 'https://openalex.org/W4385963592', 'https://openalex.org/W4385889839', 'https://openalex.org/W1937795883', 'https://openalex.org/W4312091380', 'https://openalex.org/W4362508231', 'https://openalex.org/W4404782219', 'https://openalex.org/W4287115670', 'https://openalex.org/W4301423176', 'https://openalex.org/W4384111914', 'https://openalex.org/W4292424355', 'https://openalex.org/W371619641', 'https://openalex.org/W4376167553', 'https://openalex.org/W4389518771', 'https://openalex.org/W4380374951', 'https://openalex.org/W1841352775', 'https://openalex.org/W4401416363', 'https://openalex.org/W4309088836', 'https://openalex.org/W2606347107', 'https://openalex.org/W3108144224', 'https://openalex.org/W4317670814', 'https://openalex.org/W4367061108', 'https://openalex.org/W4405812781', 'https://openalex.org/W3107615218', 'https://openalex.org/W4388488349', 'https://openalex.org/W4389665575', 'https://openalex.org/W4205807230', 'https://openalex.org/W3084525380', 'https://openalex.org/W2122410182', 'https://openalex.org/W4385652328', 'https://openalex.org/W4281557623', 'https://openalex.org/W2498253860', 'https://openalex.org/W4378464864', 'https://openalex.org/W4311642023', 'https://openalex.org/W4389667254', 'https://openalex.org/W4316829821', 'https://openalex.org/W4385430679', 'https://openalex.org/W4384812233', 'https://openalex.org/W4361020574', 'https://openalex.org/W4378189609', 'https://openalex.org/W4385734161', 'https://openalex.org/W2149524486', 'https://openalex.org/W2750779823', 'https://openalex.org/W4380714623', 'https://openalex.org/W4389520273', 'https://openalex.org/W2521824566', 'https://openalex.org/W4378768622', 'https://openalex.org/W3094833381', 'https://openalex.org/W4385968125', 'https://openalex.org/W4321593931', 'https://openalex.org/W4383112908', 'https://openalex.org/W4378711593', 'https://openalex.org/W4361866080']",2025-01-17
https://openalex.org/W4389524500,https://doi.org/10.18653/v1/2023.findings-emnlp.1055,SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities,"Multi-modal large language models are regarded as a crucial step towards Artificial General Intelligence (AGI) and have garnered significant interest with the emergence of ChatGPT. However, current speech-language models typically adopt the cascade paradigm, preventing inter-modal knowledge transfer. In this paper, we propose SpeechGPT, a large language model with intrinsic cross-modal conversational abilities, capable of perceiving and generating multi-modal content. With discrete speech representations, we construct SpeechInstruct, the first large-scale cross-modal speech instruction dataset. Additionally, we employ a three-stage training strategy that includes modality-adaptation pre-training, cross-modal instruction fine-tuning, and chain-of-modality instruction fine-tuning. The experimental results demonstrate that SpeechGPT has an impressive capacity to follow cross-modal human instructions and highlight the potential of handling multiple modalities with one model. Code and models are available in https://github.com/0nutation/SpeechGPT. Demos are shown in https://0nutation.github.io/SpeechGPT.github.io/.","['https://openalex.org/W4385807416', 'https://openalex.org/W4394671563', 'https://openalex.org/W3166396011', 'https://openalex.org/W4367061106', 'https://openalex.org/W4381786045', 'https://openalex.org/W4385570101', 'https://openalex.org/W4385572615', 'https://openalex.org/W4323572061', 'https://openalex.org/W4361866031', 'https://openalex.org/W3140429000', 'https://openalex.org/W4322718246', 'https://openalex.org/W3169320628', 'https://openalex.org/W4310924890', 'https://openalex.org/W4287120025', 'https://openalex.org/W2995181338', 'https://openalex.org/W4307680525', 'https://openalex.org/W4313679638', 'https://openalex.org/W3036601975', 'https://openalex.org/W4224308101', 'https://openalex.org/W3094502228', 'https://openalex.org/W1494198834', 'https://openalex.org/W3168867926', 'https://openalex.org/W4366330503', 'https://openalex.org/W4375958083', 'https://openalex.org/W4361229539', 'https://openalex.org/W3030437843', 'https://openalex.org/W4386384714', 'https://openalex.org/W4377297670', 'https://openalex.org/W4323651091', 'https://openalex.org/W4322718191']",2023-01-01
https://openalex.org/W4391021666,https://doi.org/10.1109/asru57964.2023.10389705,On Decoder-Only Architecture For Speech-to-Text and Large Language Model Integration,"Large language models (LLMs) have achieved remarkable success in the field of natural language processing, enabling better human-computer interaction using natural language. However, the seamless integration of speech signals into LLMs has not been explored well. The ""decoder-only"" architecture has also not been well studied for speech processing tasks. In this research, we introduce Speech-LLaMA, a novel approach that effectively incorporates acoustic information into text-based large language models. Our method leverages Connectionist Temporal Classification and a simple audio encoder to map the compressed acoustic features to the continuous semantic space of the LLM. In addition, we further probe the decoder-only architecture for speech-to-text tasks by training a smaller scale randomly initialized speech-LLaMA model from speech-text paired data alone. We conduct experiments on multilingual speech-to-text translation tasks and demonstrate a significant improvement over strong baselines, highlighting the potential advantages of decoder-only models for speech-to-text conversion.","['https://openalex.org/W6778883912', 'https://openalex.org/W6810081322', 'https://openalex.org/W6850625674', 'https://openalex.org/W6739901393', 'https://openalex.org/W6851847159', 'https://openalex.org/W6851513886', 'https://openalex.org/W6852326057', 'https://openalex.org/W6852818750', 'https://openalex.org/W3211278025', 'https://openalex.org/W6851950068', 'https://openalex.org/W6851592950', 'https://openalex.org/W6852489829', 'https://openalex.org/W6810334672', 'https://openalex.org/W6853611000', 'https://openalex.org/W4389524500', 'https://openalex.org/W6853998256', 'https://openalex.org/W6848735303', 'https://openalex.org/W6850334629', 'https://openalex.org/W6851317108', 'https://openalex.org/W3153583341', 'https://openalex.org/W6796581206', 'https://openalex.org/W2901607128', 'https://openalex.org/W3034625919', 'https://openalex.org/W6846175339', 'https://openalex.org/W4224137820', 'https://openalex.org/W4385823495', 'https://openalex.org/W6780680273', 'https://openalex.org/W2963532001', 'https://openalex.org/W6769627184', 'https://openalex.org/W6732953234', 'https://openalex.org/W2605131327', 'https://openalex.org/W6847363464', 'https://openalex.org/W2739883972', 'https://openalex.org/W6773820404', 'https://openalex.org/W4388979610', 'https://openalex.org/W6757817989', 'https://openalex.org/W2963250244', 'https://openalex.org/W6854218657', 'https://openalex.org/W4366330503', 'https://openalex.org/W4393178509', 'https://openalex.org/W3168867926', 'https://openalex.org/W4391021781', 'https://openalex.org/W4361866031', 'https://openalex.org/W4323651091', 'https://openalex.org/W4292779060', 'https://openalex.org/W4381827575', 'https://openalex.org/W4301581299', 'https://openalex.org/W4375958083', 'https://openalex.org/W4322718191', 'https://openalex.org/W4288089799', 'https://openalex.org/W2908510526', 'https://openalex.org/W4385245566', 'https://openalex.org/W4367628410', 'https://openalex.org/W4391021457', 'https://openalex.org/W4377372369', 'https://openalex.org/W4224308101', 'https://openalex.org/W4313679638', 'https://openalex.org/W4225323055', 'https://openalex.org/W4366850747', 'https://openalex.org/W4364382977', 'https://openalex.org/W3043665049', 'https://openalex.org/W4378501656']",2023-12-16
https://openalex.org/W4406417959,https://doi.org/10.1109/taslpro.2025.3530270,Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers,,"['https://openalex.org/W2964243274', 'https://openalex.org/W6763832098', 'https://openalex.org/W2903739847', 'https://openalex.org/W4297841605', 'https://openalex.org/W6796464841', 'https://openalex.org/W6755135894', 'https://openalex.org/W3095035471', 'https://openalex.org/W6748588790', 'https://openalex.org/W6805710207', 'https://openalex.org/W6778883912', 'https://openalex.org/W6810081322', 'https://openalex.org/W2896457183', 'https://openalex.org/W6766673545', 'https://openalex.org/W4307323391', 'https://openalex.org/W4392903704', 'https://openalex.org/W2995181338', 'https://openalex.org/W2972359262', 'https://openalex.org/W1494198834', 'https://openalex.org/W6727697161', 'https://openalex.org/W6790220310', 'https://openalex.org/W3213544594', 'https://openalex.org/W6752888775', 'https://openalex.org/W2963371159', 'https://openalex.org/W6796730497', 'https://openalex.org/W4225746985', 'https://openalex.org/W6795261426', 'https://openalex.org/W6849953009', 'https://openalex.org/W4372259784', 'https://openalex.org/W6780218876', 'https://openalex.org/W3209059054', 'https://openalex.org/W3209984917', 'https://openalex.org/W6790356757', 'https://openalex.org/W4381786045', 'https://openalex.org/W3140429000', 'https://openalex.org/W2752796333', 'https://openalex.org/W3215615641', 'https://openalex.org/W6753797277', 'https://openalex.org/W3205644108', 'https://openalex.org/W2972374322', 'https://openalex.org/W6810189000', 'https://openalex.org/W6848735303', 'https://openalex.org/W6850334629', 'https://openalex.org/W4390075359', 'https://openalex.org/W4402671568', 'https://openalex.org/W6852870047', 'https://openalex.org/W6854199242', 'https://openalex.org/W6861001475', 'https://openalex.org/W6864145738', 'https://openalex.org/W6856434366', 'https://openalex.org/W6861342446', 'https://openalex.org/W6853188576', 'https://openalex.org/W4313021454', 'https://openalex.org/W6853937136', 'https://openalex.org/W4393147067', 'https://openalex.org/W6851724922', 'https://openalex.org/W6862144568', 'https://openalex.org/W6779823529', 'https://openalex.org/W4252812408', 'https://openalex.org/W6859583170', 'https://openalex.org/W6846539466', 'https://openalex.org/W4406417959', 'https://openalex.org/W6853165267', 'https://openalex.org/W6855885476', 'https://openalex.org/W4372270198', 'https://openalex.org/W6852581948', 'https://openalex.org/W6853515095', 'https://openalex.org/W4392903389', 'https://openalex.org/W4402672068', 'https://openalex.org/W4402670057', 'https://openalex.org/W6852381208', 'https://openalex.org/W6856126247', 'https://openalex.org/W6853611000', 'https://openalex.org/W6853998256', 'https://openalex.org/W6852800892', 'https://openalex.org/W2519091744', 'https://openalex.org/W6769196770', 'https://openalex.org/W4226132755', 'https://openalex.org/W3173715137', 'https://openalex.org/W2963300588', 'https://openalex.org/W3161480375', 'https://openalex.org/W3025844872', 'https://openalex.org/W3146550708', 'https://openalex.org/W6753049143', 'https://openalex.org/W4381827575', 'https://openalex.org/W4394671563', 'https://openalex.org/W4394007232', 'https://openalex.org/W4323651091', 'https://openalex.org/W4390306858', 'https://openalex.org/W2527729766', 'https://openalex.org/W4313679638', 'https://openalex.org/W4387323811', 'https://openalex.org/W4372279529', 'https://openalex.org/W4384615685', 'https://openalex.org/W4391833199', 'https://openalex.org/W4379540238', 'https://openalex.org/W4386384714', 'https://openalex.org/W4224308101', 'https://openalex.org/W4377010126', 'https://openalex.org/W4379924545', 'https://openalex.org/W4400111385', 'https://openalex.org/W2965373594', 'https://openalex.org/W4390962167', 'https://openalex.org/W4378501656', 'https://openalex.org/W4303647933', 'https://openalex.org/W4379259581', 'https://openalex.org/W2810914326', 'https://openalex.org/W3174758275']",2025-01-01
https://openalex.org/W4400111385,https://doi.org/10.1109/taslp.2024.3419418,SpeechX: Neural Codec Language Model as a Versatile Speech Transformer,,"['https://openalex.org/W6778883912', 'https://openalex.org/W4312933868', 'https://openalex.org/W4381786045', 'https://openalex.org/W6810334672', 'https://openalex.org/W6850204008', 'https://openalex.org/W4386072096', 'https://openalex.org/W4401042948', 'https://openalex.org/W6853998256', 'https://openalex.org/W6849105126', 'https://openalex.org/W6752888775', 'https://openalex.org/W3015826515', 'https://openalex.org/W3196584150', 'https://openalex.org/W6853888607', 'https://openalex.org/W6848735303', 'https://openalex.org/W4390075359', 'https://openalex.org/W6853771913', 'https://openalex.org/W6850334629', 'https://openalex.org/W6852870047', 'https://openalex.org/W2973062255', 'https://openalex.org/W2951130829', 'https://openalex.org/W3206706278', 'https://openalex.org/W4367597591', 'https://openalex.org/W4281820413', 'https://openalex.org/W2408688265', 'https://openalex.org/W3016185664', 'https://openalex.org/W2995181338', 'https://openalex.org/W6790978476', 'https://openalex.org/W6851724922', 'https://openalex.org/W4307323391', 'https://openalex.org/W4385245566', 'https://openalex.org/W6688816777', 'https://openalex.org/W3097777922', 'https://openalex.org/W3161480375', 'https://openalex.org/W1552314771', 'https://openalex.org/W4392908343', 'https://openalex.org/W3096408984', 'https://openalex.org/W3194338569', 'https://openalex.org/W6861001475', 'https://openalex.org/W6853165267', 'https://openalex.org/W6862144568', 'https://openalex.org/W4320458302', 'https://openalex.org/W4392538788', 'https://openalex.org/W4378945745', 'https://openalex.org/W4318351475', 'https://openalex.org/W4323651091', 'https://openalex.org/W2219249508', 'https://openalex.org/W4379924545', 'https://openalex.org/W4390962167', 'https://openalex.org/W4381827575', 'https://openalex.org/W4313679638']",2024-01-01
https://openalex.org/W4402301063,https://doi.org/10.1109/taslp.2024.3451951,ZMM-TTS: Zero-Shot Multilingual and Multispeaker Speech Synthesis Conditioned on Self-Supervised Discrete Speech Representations,"Neural text-to-speech (TTS) has achieved human-like synthetic speech for single-speaker, single-language synthesis. Multilingual TTS systems are limited to resource-rich languages due to the lack of large paired text and studio-quality audio data. TTS systems are typically built using a single speaker’s voice, but there is growing interest in developing systems that can synthesize voices for new speakers using only a few seconds of their speech. This paper presents ZMM-TTS, a multilingual and multispeaker framework utilizing quantized latent speech representations from a large-scale, pre-trained, self-supervised model. Our paper combines text-based and speech-based self-supervised learning models for multilingual speech synthesis. Our proposed model has zero-shot generalization ability not only for unseen speakers but also for unseen languages. We have conducted comprehensive subjective and objective evaluations through a series of experiments. Our model has proven effective in terms of speech naturalness and similarity for both seen and unseen speakers in six high-resource languages. We also tested the efficiency of our method on two hypothetically low-resource languages. The results are promising, indicating that our proposed approach can synthesize audio that is intelligible and has a high degree of similarity to the target speaker’s voice, even without any training data for the new, unseen language.","['https://openalex.org/W2963609956', 'https://openalex.org/W6778823374', 'https://openalex.org/W2964243274', 'https://openalex.org/W4391020683', 'https://openalex.org/W4385764360', 'https://openalex.org/W2972473628', 'https://openalex.org/W3095012670', 'https://openalex.org/W6805710207', 'https://openalex.org/W3197324626', 'https://openalex.org/W4296068816', 'https://openalex.org/W4372267432', 'https://openalex.org/W4385823466', 'https://openalex.org/W6752888775', 'https://openalex.org/W3015826515', 'https://openalex.org/W6780218876', 'https://openalex.org/W3209059054', 'https://openalex.org/W3209984917', 'https://openalex.org/W4225274946', 'https://openalex.org/W3206189675', 'https://openalex.org/W6803547063', 'https://openalex.org/W3207300132', 'https://openalex.org/W6848735303', 'https://openalex.org/W4385822745', 'https://openalex.org/W4226380987', 'https://openalex.org/W4381786045', 'https://openalex.org/W4390075359', 'https://openalex.org/W4252812408', 'https://openalex.org/W3215615641', 'https://openalex.org/W4307323391', 'https://openalex.org/W6851724922', 'https://openalex.org/W6862144568', 'https://openalex.org/W6858915148', 'https://openalex.org/W6748588790', 'https://openalex.org/W6750489868', 'https://openalex.org/W3196584150', 'https://openalex.org/W3161436426', 'https://openalex.org/W6811227718', 'https://openalex.org/W2903739847', 'https://openalex.org/W6763832098', 'https://openalex.org/W3150572638', 'https://openalex.org/W3097297926', 'https://openalex.org/W6800393981', 'https://openalex.org/W4283640572', 'https://openalex.org/W6796464841', 'https://openalex.org/W2973084242', 'https://openalex.org/W4392114301', 'https://openalex.org/W2964002616', 'https://openalex.org/W3048217770', 'https://openalex.org/W3194464626', 'https://openalex.org/W6752124048', 'https://openalex.org/W3205533980', 'https://openalex.org/W4297841714', 'https://openalex.org/W3197763626', 'https://openalex.org/W4225096077', 'https://openalex.org/W4385329631', 'https://openalex.org/W3198429080', 'https://openalex.org/W4226132755', 'https://openalex.org/W4382202703', 'https://openalex.org/W4281760581', 'https://openalex.org/W4385822479', 'https://openalex.org/W4392903365', 'https://openalex.org/W6853937136', 'https://openalex.org/W6850334629', 'https://openalex.org/W4389600306', 'https://openalex.org/W6783867762', 'https://openalex.org/W3196001064', 'https://openalex.org/W4225534571', 'https://openalex.org/W4296068817', 'https://openalex.org/W4367721746', 'https://openalex.org/W3197273793', 'https://openalex.org/W3095410713', 'https://openalex.org/W2084534958', 'https://openalex.org/W2972802841', 'https://openalex.org/W6917585676', 'https://openalex.org/W6783527727', 'https://openalex.org/W7062081054', 'https://openalex.org/W4225956675', 'https://openalex.org/W2972359262', 'https://openalex.org/W1494198834', 'https://openalex.org/W2187089797', 'https://openalex.org/W4392538788', 'https://openalex.org/W4226424742', 'https://openalex.org/W4366460484', 'https://openalex.org/W4313679638', 'https://openalex.org/W3090254849', 'https://openalex.org/W4388927799', 'https://openalex.org/W4323651091']",2024-01-01
https://openalex.org/W4401070302,https://doi.org/10.1109/taslp.2024.3434425,"VioLA: Conditional Language Models for Speech Recognition, Synthesis, and Translation",,"['https://openalex.org/W6739901393', 'https://openalex.org/W6755207826', 'https://openalex.org/W6778883912', 'https://openalex.org/W4386071687', 'https://openalex.org/W3034999214', 'https://openalex.org/W6769627184', 'https://openalex.org/W4381786045', 'https://openalex.org/W6848735303', 'https://openalex.org/W4307323391', 'https://openalex.org/W6850334629', 'https://openalex.org/W1995562189', 'https://openalex.org/W2998386507', 'https://openalex.org/W2136545725', 'https://openalex.org/W3211278025', 'https://openalex.org/W4388017359', 'https://openalex.org/W2127141656', 'https://openalex.org/W2962824709', 'https://openalex.org/W3161873870', 'https://openalex.org/W2963609956', 'https://openalex.org/W2964243274', 'https://openalex.org/W2903739847', 'https://openalex.org/W6763832098', 'https://openalex.org/W6778823374', 'https://openalex.org/W2997540646', 'https://openalex.org/W6679436768', 'https://openalex.org/W3209059054', 'https://openalex.org/W3209984917', 'https://openalex.org/W3205644108', 'https://openalex.org/W6795200824', 'https://openalex.org/W6847363464', 'https://openalex.org/W4389524500', 'https://openalex.org/W6853998256', 'https://openalex.org/W4391021623', 'https://openalex.org/W6860320428', 'https://openalex.org/W2962784628', 'https://openalex.org/W3203407300', 'https://openalex.org/W3095410713', 'https://openalex.org/W6634186343', 'https://openalex.org/W1494198834', 'https://openalex.org/W6770506093', 'https://openalex.org/W2936078256', 'https://openalex.org/W2101105183', 'https://openalex.org/W3097206152', 'https://openalex.org/W3118974591', 'https://openalex.org/W3163573274', 'https://openalex.org/W4292779060', 'https://openalex.org/W2946200149', 'https://openalex.org/W4288089799', 'https://openalex.org/W4381827575', 'https://openalex.org/W4390528611', 'https://openalex.org/W1572989473', 'https://openalex.org/W4313679638', 'https://openalex.org/W4323651091', 'https://openalex.org/W3161940574', 'https://openalex.org/W4385245566', 'https://openalex.org/W2130942839']",2024-01-01
https://openalex.org/W4406385636,https://doi.org/10.1038/s41586-024-08359-z,Joint speech and text machine translation for up to 100 languages,"Creating the Babel Fish, a tool that helps individuals translate speech between any two languages, requires advanced technological innovation and linguistic expertise. Although conventional speech-to-speech translation systems composed of multiple subsystems performing translation in a cascaded fashion exist<sup>1-3</sup>, scalable and high-performing unified systems<sup>4,5</sup> remain underexplored. To address this gap, here we introduce SEAMLESSM4T-Massively Multilingual and Multimodal Machine Translation-a single model that supports speech-to-speech translation (101 to 36 languages), speech-to-text translation (from 101 to 96 languages), text-to-speech translation (from 96 to 36 languages), text-to-text translation (96 languages) and automatic speech recognition (96 languages). Built using a new multimodal corpus of automatically aligned speech translations and other publicly available data, SEAMLESSM4T is one of the first multilingual systems that can translate from and into English for both speech and text. Moreover, it outperforms the existing state-of-the-art cascaded systems, achieving up to 8% and 23% higher BLEU (Bilingual Evaluation Understudy) scores in speech-to-text and speech-to-speech tasks, respectively. Beyond quality, when tested for robustness, our system is, on average, approximately 50% more resilient against background noise and speaker variations in speech-to-text tasks than the previous state-of-the-art systems. We evaluated SEAMLESSM4T on added toxicity and gender bias to assess translation safety. For the former, we included two strategies for added toxicity mitigation working at either training or inference time. Finally, all contributions in this work are publicly available for non-commercial use to propel further research on inclusive speech translation technologies.","['https://openalex.org/W2097203679', 'https://openalex.org/W1538023239', 'https://openalex.org/W2136545725', 'https://openalex.org/W2936184970', 'https://openalex.org/W2972495969', 'https://openalex.org/W3180374548', 'https://openalex.org/W6798080464', 'https://openalex.org/W4399365598', 'https://openalex.org/W6855524384', 'https://openalex.org/W2250342921', 'https://openalex.org/W2101105183', 'https://openalex.org/W3024869864', 'https://openalex.org/W3139878283', 'https://openalex.org/W4385569960', 'https://openalex.org/W4385574194', 'https://openalex.org/W3039695075', 'https://openalex.org/W4281621399', 'https://openalex.org/W4319862635', 'https://openalex.org/W4323651091', 'https://openalex.org/W4311000453', 'https://openalex.org/W4381827575', 'https://openalex.org/W4200631896', 'https://openalex.org/W6852909395', 'https://openalex.org/W4404781204', 'https://openalex.org/W4309129001', 'https://openalex.org/W4385571229', 'https://openalex.org/W4280617721', 'https://openalex.org/W4303648927', 'https://openalex.org/W4389518873', 'https://openalex.org/W4297841625', 'https://openalex.org/W4390810311', 'https://openalex.org/W4402670286', 'https://openalex.org/W2952328691', 'https://openalex.org/W3197577761', 'https://openalex.org/W4283809028', 'https://openalex.org/W3035070478', 'https://openalex.org/W4377865270', 'https://openalex.org/W4389524081', 'https://openalex.org/W4403431383', 'https://openalex.org/W3012624518', 'https://openalex.org/W4312391725', 'https://openalex.org/W4394778654', 'https://openalex.org/W2032374598', 'https://openalex.org/W4285131748', 'https://openalex.org/W4307416501', 'https://openalex.org/W3196509775', 'https://openalex.org/W3127012371', 'https://openalex.org/W3197771105', 'https://openalex.org/W4323066695', 'https://openalex.org/W2798389157', 'https://openalex.org/W2962735107', 'https://openalex.org/W2973088264', 'https://openalex.org/W4308756394', 'https://openalex.org/W4385572318', 'https://openalex.org/W4286359908', 'https://openalex.org/W6861295083', 'https://openalex.org/W4311731008', 'https://openalex.org/W4385570550', 'https://openalex.org/W3007068036', 'https://openalex.org/W3213029956', 'https://openalex.org/W4384648564', 'https://openalex.org/W4226033575', 'https://openalex.org/W3025165719', 'https://openalex.org/W3097777922', 'https://openalex.org/W2963250244', 'https://openalex.org/W2962784628', 'https://openalex.org/W4385573923', 'https://openalex.org/W2899716505', 'https://openalex.org/W2964161387', 'https://openalex.org/W3096490862', 'https://openalex.org/W6739901393', 'https://openalex.org/W4283834483', 'https://openalex.org/W6778823374', 'https://openalex.org/W3194000401', 'https://openalex.org/W4311994673', 'https://openalex.org/W4385569956', 'https://openalex.org/W4385574250']",2025-01-15
https://openalex.org/W4392904154,https://doi.org/10.1109/icassp48485.2024.10446998,Discrete Audio Representation as an Alternative to Mel-Spectrograms for Speaker and Speech Recognition,"Discrete audio representation, aka audio tokenization, has seen renewed interest driven by its potential to facilitate the application of text language modeling approaches in audio domain. To this end, various compression and representation-learning based tokenization schemes have been proposed. However, there is limited investigation into the performance of compression-based audio tokens compared to well-established mel-spectrogram features across various speaker and speech related tasks. In this paper, we evaluate compression based audio tokens on three tasks: Speaker Verification, Diarization and (Multi-lingual) Speech Recognition. Our findings indicate that (i) the models trained on audio tokens perform competitively, on average within 1% of mel-spectrogram features for all the tasks considered, and do not surpass them yet. (ii) these models exhibit robustness for out-of-domain narrowband data, particularly in speaker tasks. (iii) audio tokens allow for compression to 20x compared to mel-spectrogram features with minimal loss of performance in speech and speaker related tasks, which is crucial for low bit-rate applications, and (iv) the examined Residual Vector Quantization (RVQ) based audio tokenizer exhibits a low-pass frequency response characteristic, offering a plausible explanation for the observed results, and providing insight for future tokenizer designs.","['https://openalex.org/W6778883912', 'https://openalex.org/W6854866820', 'https://openalex.org/W6847363464', 'https://openalex.org/W3209059054', 'https://openalex.org/W4226033575', 'https://openalex.org/W3209984917', 'https://openalex.org/W6850218400', 'https://openalex.org/W6848735303', 'https://openalex.org/W6850334629', 'https://openalex.org/W6853611000', 'https://openalex.org/W6849105126', 'https://openalex.org/W4381786045', 'https://openalex.org/W6853998256', 'https://openalex.org/W3215615641', 'https://openalex.org/W4307323391', 'https://openalex.org/W6853515095', 'https://openalex.org/W3205878676', 'https://openalex.org/W4391021542', 'https://openalex.org/W2969985801', 'https://openalex.org/W3097777922', 'https://openalex.org/W2963250244', 'https://openalex.org/W2808631503', 'https://openalex.org/W1494198834', 'https://openalex.org/W3095410713', 'https://openalex.org/W6678809451', 'https://openalex.org/W6770434673', 'https://openalex.org/W6711908931', 'https://openalex.org/W6771467084', 'https://openalex.org/W3119308075', 'https://openalex.org/W2936774411', 'https://openalex.org/W4381827575', 'https://openalex.org/W4378501656', 'https://openalex.org/W3030437843', 'https://openalex.org/W4313679638', 'https://openalex.org/W4320013820', 'https://openalex.org/W4323066695', 'https://openalex.org/W4311000453', 'https://openalex.org/W4323651091', 'https://openalex.org/W2622566932', 'https://openalex.org/W4292779060', 'https://openalex.org/W4318351475', 'https://openalex.org/W4380551955', 'https://openalex.org/W4384918448']",2024-03-18
https://openalex.org/W4392903524,https://doi.org/10.1109/icassp48485.2024.10446203,Minimally-Supervised Speech Synthesis with Conditional Diffusion Model and Language Model: A Comparative Study of Semantic Coding,"Recently, there has been a growing interest in text-to-speech (TTS) methods that can be trained with minimal supervision by combining two types of discrete speech representations and using two sequence-to-sequence tasks to decouple TTS. However, existing methods suffer from three problems: the high-frequency waveform distortion of discrete speech representations, the prosodic averaging problem caused by the duration prediction model in non-autoregressive frameworks, and difficulty in prediction due to the information redundancy and dimension explosion of existing semantic coding methods. To address these problems, three progressive methods are proposed. First, we propose Diff-LM-Speech, an autoregressive structure consisting of a language model and diffusion models, which models the semantic embedding into the mel-spectrogram based on a diffusion model to achieve higher audio quality. We also introduce a prompt encoder structure based on a variational autoencoder and a prosody bottleneck to improve prompt representation ability. Second, we propose Tetra-Diff-Speech, a non-autoregressive structure consisting of four diffusion model-based modules that design a duration diffusion model to achieve diverse prosodic expressions. Finally, we propose Tri-Diff-Speech, a non-autoregressive structure consisting of three diffusion model-based modules that verify the non-necessity of existing semantic coding models and achieve the best results. Experimental results show that our proposed methods outperform baseline methods. We provide a website with audio samples. <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">1</sup>","['https://openalex.org/W2963609956', 'https://openalex.org/W2591927543', 'https://openalex.org/W2903739847', 'https://openalex.org/W6763832098', 'https://openalex.org/W6777694618', 'https://openalex.org/W3161296985', 'https://openalex.org/W6778883912', 'https://openalex.org/W4381786045', 'https://openalex.org/W4390075359', 'https://openalex.org/W4296068981', 'https://openalex.org/W6780218876', 'https://openalex.org/W3209059054', 'https://openalex.org/W3215615641', 'https://openalex.org/W6779823529', 'https://openalex.org/W6847363464', 'https://openalex.org/W4372260402', 'https://openalex.org/W2752782242', 'https://openalex.org/W4312069022', 'https://openalex.org/W4292779060', 'https://openalex.org/W3036601975', 'https://openalex.org/W3094002217', 'https://openalex.org/W2946200149', 'https://openalex.org/W4382603054', 'https://openalex.org/W3036167779', 'https://openalex.org/W2519091744', 'https://openalex.org/W4307323391', 'https://openalex.org/W1522301498', 'https://openalex.org/W4402301063', 'https://openalex.org/W4366460484', 'https://openalex.org/W3026874504', 'https://openalex.org/W4313679638', 'https://openalex.org/W4323651091']",2024-03-18
https://openalex.org/W4402301096,https://doi.org/10.1109/taslp.2024.3453606,U-Style: Cascading U-Nets With Multi-Level Speaker and Style Modeling for Zero-Shot Voice Cloning,,"['https://openalex.org/W2963609956', 'https://openalex.org/W6745697700', 'https://openalex.org/W4297841574', 'https://openalex.org/W3162794600', 'https://openalex.org/W4313148337', 'https://openalex.org/W3200756692', 'https://openalex.org/W6748588790', 'https://openalex.org/W3015826515', 'https://openalex.org/W3163654539', 'https://openalex.org/W4372259784', 'https://openalex.org/W6805710207', 'https://openalex.org/W6795807602', 'https://openalex.org/W6846143095', 'https://openalex.org/W4283731195', 'https://openalex.org/W3163475957', 'https://openalex.org/W6848735303', 'https://openalex.org/W3094785744', 'https://openalex.org/W3022876224', 'https://openalex.org/W4372260402', 'https://openalex.org/W4385823160', 'https://openalex.org/W3015645837', 'https://openalex.org/W6795261426', 'https://openalex.org/W4294311176', 'https://openalex.org/W6840257003', 'https://openalex.org/W2972659941', 'https://openalex.org/W3196584150', 'https://openalex.org/W2939913319', 'https://openalex.org/W6724804524', 'https://openalex.org/W6851724922', 'https://openalex.org/W6854199242', 'https://openalex.org/W6749555683', 'https://openalex.org/W2904459034', 'https://openalex.org/W3135644023', 'https://openalex.org/W6760861152', 'https://openalex.org/W4283832640', 'https://openalex.org/W4226421465', 'https://openalex.org/W4386536205', 'https://openalex.org/W6639480849', 'https://openalex.org/W4372260509', 'https://openalex.org/W6803547063', 'https://openalex.org/W6755300632', 'https://openalex.org/W4395957972', 'https://openalex.org/W3097777922', 'https://openalex.org/W3163573274', 'https://openalex.org/W6763832098', 'https://openalex.org/W6783867762', 'https://openalex.org/W6850334629', 'https://openalex.org/W4210433094', 'https://openalex.org/W4384615685', 'https://openalex.org/W4289383906', 'https://openalex.org/W4313679638', 'https://openalex.org/W2932022923', 'https://openalex.org/W4323651091', 'https://openalex.org/W4366460484', 'https://openalex.org/W2502312327']",2024-01-01
https://openalex.org/W4391021557,https://doi.org/10.1109/asru57964.2023.10389660,Few-Shot Spoken Language Understanding Via Joint Speech-Text Models,"Recent work on speech representation models jointly pre-trained with text has demonstrated the potential of improving speech representations by encoding speech and text in a shared space. In this paper, we leverage such shared representations to address the persistent challenge of limited data availability in spoken language understanding tasks. By employing a pre-trained speech-text model, we find that models fine-tuned on text can be effectively transferred to speech testing data. With as little as 1 hour of labeled speech data, our proposed approach achieves comparable performance on spoken language understanding tasks (specifically, sentiment analysis and named entity recognition) when compared to previous methods using speech-only pre-trained models fine-tuned on 10 times more data. Beyond the proof-of-concept study, we also analyze the latent representations. We find that the bottom layers of speech-text models are largely task-agnostic and align speech and text representations into a shared space, while the top layers are more task-specific.","['https://openalex.org/W3016181583', 'https://openalex.org/W3209059054', 'https://openalex.org/W6780218876', 'https://openalex.org/W4281492411', 'https://openalex.org/W3140429000', 'https://openalex.org/W6790356757', 'https://openalex.org/W3180374548', 'https://openalex.org/W4287854499', 'https://openalex.org/W4385823328', 'https://openalex.org/W6854228366', 'https://openalex.org/W3205644108', 'https://openalex.org/W6803092890', 'https://openalex.org/W6845338303', 'https://openalex.org/W4385573012', 'https://openalex.org/W6848735303', 'https://openalex.org/W3122044994', 'https://openalex.org/W6767737316', 'https://openalex.org/W4226103796', 'https://openalex.org/W4287887773', 'https://openalex.org/W6852410838', 'https://openalex.org/W4283749766', 'https://openalex.org/W4297841873', 'https://openalex.org/W6755207826', 'https://openalex.org/W6810259195', 'https://openalex.org/W4226120743', 'https://openalex.org/W4372260307', 'https://openalex.org/W4223622550', 'https://openalex.org/W6847568899', 'https://openalex.org/W6850334629', 'https://openalex.org/W6853611000', 'https://openalex.org/W4375869005', 'https://openalex.org/W6846865774', 'https://openalex.org/W6850218400', 'https://openalex.org/W2952638691', 'https://openalex.org/W2970854433', 'https://openalex.org/W3103368673', 'https://openalex.org/W1494198834', 'https://openalex.org/W6847181065', 'https://openalex.org/W4237723258', 'https://openalex.org/W2970820321', 'https://openalex.org/W4226380987', 'https://openalex.org/W2747874407', 'https://openalex.org/W6765469073', 'https://openalex.org/W6776039324', 'https://openalex.org/W6796464841', 'https://openalex.org/W2972359262', 'https://openalex.org/W4394671563', 'https://openalex.org/W3169905056', 'https://openalex.org/W2958953787', 'https://openalex.org/W4319862218', 'https://openalex.org/W4323651091', 'https://openalex.org/W4221155340', 'https://openalex.org/W4377864748', 'https://openalex.org/W4394773771', 'https://openalex.org/W3156326119', 'https://openalex.org/W2914120296', 'https://openalex.org/W3207222250', 'https://openalex.org/W4392979802', 'https://openalex.org/W4312052802', 'https://openalex.org/W2896457183', 'https://openalex.org/W3037217258', 'https://openalex.org/W4378501656', 'https://openalex.org/W4310826357', 'https://openalex.org/W4313679638', 'https://openalex.org/W4323066695', 'https://openalex.org/W3036601975']",2023-12-16
https://openalex.org/W4391021547,https://doi.org/10.1109/asru57964.2023.10389672,Towards General-Purpose Text-Instruction-Guided Voice Conversion,"This paper introduces a novel voice conversion (VC) model, guided by text instructions such as ""articulate slowly with a deep tone"" or ""speak in a cheerful boyish voice"". Unlike traditional methods that rely on reference utterances to determine the attributes of the converted speech, using text instruction adds versatility and specificity to voice conversion. The proposed VC model is a neural codec language model which processes a sequence of discrete codes, resulting in the code sequence of converted speech. It utilizes text instructions as style prompts to modify the prosody and emotional information of the given speech. In contrast to previous approaches, which often rely on employing separate encoders like prosody and content encoders to handle different aspects of the source speech, our model handles various information of speech in an end-to-end manner. Experiments have demonstrated the impressive capabilities of our model in comprehending instructions and delivering reasonable results <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">1</sup> .","['https://openalex.org/W6810738896', 'https://openalex.org/W6853998256', 'https://openalex.org/W6853888607', 'https://openalex.org/W6852240503', 'https://openalex.org/W6849416043', 'https://openalex.org/W4390075359', 'https://openalex.org/W6853188576', 'https://openalex.org/W6848735303', 'https://openalex.org/W6849109464', 'https://openalex.org/W6850334629', 'https://openalex.org/W6853096648', 'https://openalex.org/W6853611000', 'https://openalex.org/W4385822787', 'https://openalex.org/W4375869257', 'https://openalex.org/W6845479124', 'https://openalex.org/W3098557217', 'https://openalex.org/W2963035245', 'https://openalex.org/W2576309025', 'https://openalex.org/W6840412704', 'https://openalex.org/W4205742757', 'https://openalex.org/W4307323391', 'https://openalex.org/W6852781825', 'https://openalex.org/W3215615641', 'https://openalex.org/W4372270198', 'https://openalex.org/W4381786045', 'https://openalex.org/W4226162428', 'https://openalex.org/W6852859116', 'https://openalex.org/W6849798658', 'https://openalex.org/W2077801020', 'https://openalex.org/W2148846882', 'https://openalex.org/W2899361462', 'https://openalex.org/W4385574033', 'https://openalex.org/W3025680351', 'https://openalex.org/W3015241559', 'https://openalex.org/W1509691205', 'https://openalex.org/W2120605154', 'https://openalex.org/W6761580982', 'https://openalex.org/W6762533536', 'https://openalex.org/W6803547063', 'https://openalex.org/W6805710207', 'https://openalex.org/W3168719651', 'https://openalex.org/W2963539064', 'https://openalex.org/W2972667718', 'https://openalex.org/W3196667132', 'https://openalex.org/W6746801104', 'https://openalex.org/W2964069186', 'https://openalex.org/W2902070858', 'https://openalex.org/W2937579788', 'https://openalex.org/W3162512456', 'https://openalex.org/W3095936335', 'https://openalex.org/W2963830550', 'https://openalex.org/W6769216209', 'https://openalex.org/W2532494225', 'https://openalex.org/W2962896155', 'https://openalex.org/W2889061305', 'https://openalex.org/W2946555236', 'https://openalex.org/W3016243847', 'https://openalex.org/W3015805741', 'https://openalex.org/W3197763626', 'https://openalex.org/W3161627112', 'https://openalex.org/W3210530853', 'https://openalex.org/W4221146610', 'https://openalex.org/W4312732823', 'https://openalex.org/W3207300132', 'https://openalex.org/W3161695192', 'https://openalex.org/W3140429000', 'https://openalex.org/W3034999214', 'https://openalex.org/W3196475561', 'https://openalex.org/W4382603054', 'https://openalex.org/W4301371414', 'https://openalex.org/W2972659941', 'https://openalex.org/W4378501656', 'https://openalex.org/W4225680573', 'https://openalex.org/W4313679638', 'https://openalex.org/W4323651091', 'https://openalex.org/W4367365521', 'https://openalex.org/W4377010126', 'https://openalex.org/W4318718996', 'https://openalex.org/W2945478979', 'https://openalex.org/W4380136719', 'https://openalex.org/W4379539302', 'https://openalex.org/W2979938509', 'https://openalex.org/W4318752004', 'https://openalex.org/W4398152753', 'https://openalex.org/W4381827575', 'https://openalex.org/W3102628737', 'https://openalex.org/W4300980117', 'https://openalex.org/W4390912423', 'https://openalex.org/W4377865046', 'https://openalex.org/W2774848319', 'https://openalex.org/W4226278401']",2023-12-16
https://openalex.org/W4392931282,https://doi.org/10.1109/icassp48485.2024.10448495,High-Fidelity Speech Synthesis with Minimal Supervision: All Using Diffusion Models,"Text-to-speech (TTS) methods have shown promising results in voice cloning, but they require a large number of labeled text-speech pairs. Minimally-supervised speech synthesis decouples TTS by combining two types of discrete speech representations(semantic & acoustic) and using two sequence-to-sequence tasks to enable training with minimal supervision. However, existing methods suffer from information redundancy and dimension explosion in semantic representation, and high-frequency waveform distortion in discrete acoustic representation. Autoregressive frameworks exhibit typical instability and uncontrollability issues. And non-autoregressive frameworks suffer from prosodic averaging caused by duration prediction models. To address these issues, we propose a minimally-supervised high-fidelity speech synthesis method, where all modules are constructed based on the diffusion models. The non-autoregressive framework enhances controllability, and the duration diffusion model enables diversified prosodic expression. Contrastive Token-Acoustic Pretraining (CTAP) is used as an intermediate semantic representation to solve the problems of information redundancy and dimension explosion in existing semantic coding methods. Mel-spectrogram is used as the acoustic representation. Both semantic and acoustic representations are predicted by continuous variable regression tasks to solve the problem of high-frequency fine-grained waveform distortion. Experimental results show that our proposed method outperforms the baseline method. We provide audio samples on our website. <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">1</sup>","['https://openalex.org/W2963609956', 'https://openalex.org/W6734815144', 'https://openalex.org/W2903739847', 'https://openalex.org/W6763832098', 'https://openalex.org/W6777694618', 'https://openalex.org/W3161296985', 'https://openalex.org/W6780218876', 'https://openalex.org/W3209059054', 'https://openalex.org/W4307323391', 'https://openalex.org/W3215615641', 'https://openalex.org/W6860417749', 'https://openalex.org/W4381786045', 'https://openalex.org/W6848735303', 'https://openalex.org/W6850334629', 'https://openalex.org/W4390075359', 'https://openalex.org/W4296068981', 'https://openalex.org/W6851724922', 'https://openalex.org/W6853888607', 'https://openalex.org/W6779823529', 'https://openalex.org/W4226033575', 'https://openalex.org/W4392903524', 'https://openalex.org/W4254489317', 'https://openalex.org/W4392909624', 'https://openalex.org/W4319779739', 'https://openalex.org/W2752782242', 'https://openalex.org/W6631190155', 'https://openalex.org/W4372260402', 'https://openalex.org/W4312069022', 'https://openalex.org/W4402301063', 'https://openalex.org/W4366460484', 'https://openalex.org/W4323651091', 'https://openalex.org/W4382603054', 'https://openalex.org/W3036167779', 'https://openalex.org/W3036601975', 'https://openalex.org/W4313679638', 'https://openalex.org/W1522301498', 'https://openalex.org/W2519091744', 'https://openalex.org/W2946200149', 'https://openalex.org/W3026874504']",2024-03-18
https://openalex.org/W4402716129,https://doi.org/10.1109/cvpr52733.2024.02580,AV2AV: Direct Audio-Visual Speech to Audio-Visual Speech Translation with Unified Audio-Visual Speech Representation,,"['https://openalex.org/W2963216553', 'https://openalex.org/W2550821151', 'https://openalex.org/W3089472875', 'https://openalex.org/W3001434439', 'https://openalex.org/W6784447870', 'https://openalex.org/W4285077564', 'https://openalex.org/W2972495969', 'https://openalex.org/W3180374548', 'https://openalex.org/W6810419249', 'https://openalex.org/W4385570550', 'https://openalex.org/W6855650468', 'https://openalex.org/W2015394094', 'https://openalex.org/W2594690981', 'https://openalex.org/W4392669909', 'https://openalex.org/W6846720623', 'https://openalex.org/W4385478049', 'https://openalex.org/W4387251351', 'https://openalex.org/W2981767644', 'https://openalex.org/W6687566353', 'https://openalex.org/W3163793923', 'https://openalex.org/W4224319127', 'https://openalex.org/W3097030750', 'https://openalex.org/W6749489859', 'https://openalex.org/W6778823374', 'https://openalex.org/W4225746985', 'https://openalex.org/W3081492798', 'https://openalex.org/W4283818626', 'https://openalex.org/W3035016936', 'https://openalex.org/W2760656271', 'https://openalex.org/W3169369929', 'https://openalex.org/W3156404059', 'https://openalex.org/W4385822729', 'https://openalex.org/W3196509775', 'https://openalex.org/W3119308075', 'https://openalex.org/W3015698636', 'https://openalex.org/W6847363464', 'https://openalex.org/W3008125272', 'https://openalex.org/W3008549139', 'https://openalex.org/W6787407267', 'https://openalex.org/W3007068036', 'https://openalex.org/W6841035593', 'https://openalex.org/W4296070387', 'https://openalex.org/W2963609956', 'https://openalex.org/W4285189120', 'https://openalex.org/W6805710207', 'https://openalex.org/W3197199219', 'https://openalex.org/W3186090335', 'https://openalex.org/W4386072021', 'https://openalex.org/W4312095900', 'https://openalex.org/W6801536170', 'https://openalex.org/W6810168380', 'https://openalex.org/W6839936984', 'https://openalex.org/W4390873467', 'https://openalex.org/W4385571016', 'https://openalex.org/W6790356757', 'https://openalex.org/W2097203679', 'https://openalex.org/W2136545725', 'https://openalex.org/W2964161387', 'https://openalex.org/W6838789019', 'https://openalex.org/W4385570538', 'https://openalex.org/W2890952074', 'https://openalex.org/W3162293946', 'https://openalex.org/W4297841411', 'https://openalex.org/W4386071467', 'https://openalex.org/W3209059054', 'https://openalex.org/W2973049979', 'https://openalex.org/W6780218876', 'https://openalex.org/W4226033575', 'https://openalex.org/W3213029956', 'https://openalex.org/W3209984917', 'https://openalex.org/W6802465204', 'https://openalex.org/W4221153524', 'https://openalex.org/W4385822683', 'https://openalex.org/W6857524042', 'https://openalex.org/W6856719735', 'https://openalex.org/W4392904292', 'https://openalex.org/W4307680525', 'https://openalex.org/W6847652939', 'https://openalex.org/W4376481237', 'https://openalex.org/W4390874021', 'https://openalex.org/W4297841641', 'https://openalex.org/W4386076005', 'https://openalex.org/W4385823403', 'https://openalex.org/W2551572271', 'https://openalex.org/W6754420807', 'https://openalex.org/W2808631503', 'https://openalex.org/W3197771105', 'https://openalex.org/W4289665794', 'https://openalex.org/W4385245566', 'https://openalex.org/W6783867762', 'https://openalex.org/W2972909277', 'https://openalex.org/W3024869864', 'https://openalex.org/W2962788625', 'https://openalex.org/W6752888775', 'https://openalex.org/W2046056978', 'https://openalex.org/W6796464841', 'https://openalex.org/W6898505805', 'https://openalex.org/W2963532001', 'https://openalex.org/W6765779288', 'https://openalex.org/W3034552680', 'https://openalex.org/W2949662773', 'https://openalex.org/W6688816777', 'https://openalex.org/W6850334629', 'https://openalex.org/W4307286264', 'https://openalex.org/W3180391059', 'https://openalex.org/W3201519611', 'https://openalex.org/W3033411150', 'https://openalex.org/W3036601975', 'https://openalex.org/W2963691546', 'https://openalex.org/W3205644108', 'https://openalex.org/W4392904805', 'https://openalex.org/W3104792420', 'https://openalex.org/W4323651091', 'https://openalex.org/W4392909068', 'https://openalex.org/W4285595742', 'https://openalex.org/W3092028330', 'https://openalex.org/W4308164026', 'https://openalex.org/W4394671563', 'https://openalex.org/W2219249508', 'https://openalex.org/W3093871477', 'https://openalex.org/W3101631197', 'https://openalex.org/W2808706139', 'https://openalex.org/W4385970143', 'https://openalex.org/W3173767661', 'https://openalex.org/W2891205112', 'https://openalex.org/W4281789500', 'https://openalex.org/W1593271688', 'https://openalex.org/W4287854499', 'https://openalex.org/W1538023239', 'https://openalex.org/W4301206121']",2024-06-16
https://openalex.org/W4396815655,https://doi.org/10.1109/satml59370.2024.00035,Data Redaction from Conditional Generative Models,"Deep generative models are known to produce undesirable samples such as harmful content. Traditional mitigation methods include re-training from scratch, filtering, or editing; however, these are either computationally expensive or can be circumvented by third parties. In this paper, we take a different approach and study how to post-edit an already-trained conditional generative model so that it redacts certain conditionals that will, with high probability, lead to undesirable content. This is done by distilling the conditioning network in the models, giving a solution that is effective, efficient, controllable, and universal for a class of deep generative models. We conduct experiments on redacting prompts in text-to-image models and redacting voices in text-to-speech models. Our method is computationally light, leads to better redaction quality and robustness than baseline methods while still retaining high generation quality.","['https://openalex.org/W4312933868', 'https://openalex.org/W6790978476', 'https://openalex.org/W6809885388', 'https://openalex.org/W6849119191', 'https://openalex.org/W6783182287', 'https://openalex.org/W6838843145', 'https://openalex.org/W6850625674', 'https://openalex.org/W6810940779', 'https://openalex.org/W6802142950', 'https://openalex.org/W6846007759', 'https://openalex.org/W6845894799', 'https://openalex.org/W6848735303', 'https://openalex.org/W6850334629', 'https://openalex.org/W6747945526', 'https://openalex.org/W2982756474', 'https://openalex.org/W6783036129', 'https://openalex.org/W3100355250', 'https://openalex.org/W3184144760', 'https://openalex.org/W4385894687', 'https://openalex.org/W4220993274', 'https://openalex.org/W4386066536', 'https://openalex.org/W4378977315', 'https://openalex.org/W2966792645', 'https://openalex.org/W3106976604', 'https://openalex.org/W1488996941', 'https://openalex.org/W6769833289', 'https://openalex.org/W6775408278', 'https://openalex.org/W6780547051', 'https://openalex.org/W6791907524', 'https://openalex.org/W6790532531', 'https://openalex.org/W6791392103', 'https://openalex.org/W3154155772', 'https://openalex.org/W3193974325', 'https://openalex.org/W4387171800', 'https://openalex.org/W2961363059', 'https://openalex.org/W6779823529', 'https://openalex.org/W4312872987', 'https://openalex.org/W6841366371', 'https://openalex.org/W4386057725', 'https://openalex.org/W4385271134', 'https://openalex.org/W6846547581', 'https://openalex.org/W6784843700', 'https://openalex.org/W6789034737', 'https://openalex.org/W3177399056', 'https://openalex.org/W4390871724', 'https://openalex.org/W4394593019', 'https://openalex.org/W6851248805', 'https://openalex.org/W6852699082', 'https://openalex.org/W4390874260', 'https://openalex.org/W6840815571', 'https://openalex.org/W6678815747', 'https://openalex.org/W6600609147', 'https://openalex.org/W2398118205', 'https://openalex.org/W2963966654', 'https://openalex.org/W2937579788', 'https://openalex.org/W6847363464', 'https://openalex.org/W6631190155', 'https://openalex.org/W6718379498', 'https://openalex.org/W2183341477', 'https://openalex.org/W3107235539', 'https://openalex.org/W6917585676', 'https://openalex.org/W2972359262', 'https://openalex.org/W2141998673', 'https://openalex.org/W1565144712', 'https://openalex.org/W2125324924', 'https://openalex.org/W6855790366', 'https://openalex.org/W3035574324', 'https://openalex.org/W1522301498', 'https://openalex.org/W4311431699', 'https://openalex.org/W3035556513', 'https://openalex.org/W4289785045', 'https://openalex.org/W4287627508', 'https://openalex.org/W2783792814', 'https://openalex.org/W4306820534', 'https://openalex.org/W3013335600', 'https://openalex.org/W4322718191', 'https://openalex.org/W3203737321', 'https://openalex.org/W4402916987', 'https://openalex.org/W3040639636', 'https://openalex.org/W4288099666', 'https://openalex.org/W2125389028', 'https://openalex.org/W3086249591', 'https://openalex.org/W3036167779', 'https://openalex.org/W4224035735', 'https://openalex.org/W4385901090', 'https://openalex.org/W4323651091', 'https://openalex.org/W2963373786', 'https://openalex.org/W4305001257', 'https://openalex.org/W4226125322', 'https://openalex.org/W3122887115', 'https://openalex.org/W4377111763', 'https://openalex.org/W4317951215', 'https://openalex.org/W3135378441', 'https://openalex.org/W4311000453', 'https://openalex.org/W4313679638', 'https://openalex.org/W4320013936']",2024-04-09
https://openalex.org/W4405379347,https://doi.org/10.1051/itmconf/20246901003,Development of an intelligent virtual assistant for digitalization of Moroccan agriculture,"This paper presents the design, development, and implementation of an innovative text-to-text chatbot system aimed at digitalizing the agriculture sector in Morocco, with a focus on supporting Darija-speaking farmers. The project also encompasses the curation of a comprehensive database to facilitate future fine-tuning of Speech-to-Text (STT) and Text-to-Speech (TTS) models in Darija. The project’s primary objective is the development of chatbot capable of responding to farmers’ text queries in Darija, providing them with instant access to critical agricultural information and support. Concurrently, we have curated an extensive database of Darija agricultural terminology, phrases, and dialogues, laying the groundwork for future voice-enabled interactions. Throughout the project, we have conducted thorough research into Darija linguistics and agricultural practices, followed by an in-depth development phase of the chatbot system. This included natural language processing, intent recognition, and response generation tailored to the nuances of Darija. The database curation involved extensive collaboration with agricultural experts to ensure authenticity and relevance. Looking forward, this project serves as a crucial stepping stone towards a fully voice-enabled agricultural support system in Darija. The curated database will be instrumental in fine-tuning STT and TTS models, potentially revolutionizing how Moroccan farmers access and interact with digital agricultural resources.","['https://openalex.org/W2037901597', 'https://openalex.org/W2907049732', 'https://openalex.org/W3003261680', 'https://openalex.org/W3006588924', 'https://openalex.org/W2806962830', 'https://openalex.org/W2788269531', 'https://openalex.org/W4387048877', 'https://openalex.org/W4323651091', 'https://openalex.org/W4372260088', 'https://openalex.org/W4382603054', 'https://openalex.org/W4389500133']",2024-01-01
https://openalex.org/W4385571610,https://doi.org/10.18653/v1/2023.iwslt-1.33,The Kyoto Speech-to-Speech Translation System for IWSLT 2023,"This paper describes the Kyoto speech-to-speech translation system for IWSLT 2023. Our system is a combination of speech-to-text translation and text-to-speech synthesis. For the speech-to-text translation model, we used the dual-decoderTransformer model. For text-to-speech synthesis model, we took a cascade approach of an acoustic model and a vocoder.","['https://openalex.org/W2962784628', 'https://openalex.org/W3092028330', 'https://openalex.org/W4385245566', 'https://openalex.org/W1522301498', 'https://openalex.org/W4385570170', 'https://openalex.org/W4385573012', 'https://openalex.org/W2964227577', 'https://openalex.org/W3037217258', 'https://openalex.org/W4323651091', 'https://openalex.org/W4385823111', 'https://openalex.org/W4281569374', 'https://openalex.org/W2998386507', 'https://openalex.org/W3198533616', 'https://openalex.org/W2595715041', 'https://openalex.org/W2945700568', 'https://openalex.org/W3033411150', 'https://openalex.org/W3102811925']",2023-01-01
https://openalex.org/W4401597614,https://doi.org/10.1109/icasspw62465.2024.10626580,Low-Resource Cross-Domain Singing Voice Synthesis via Reduced Self-Supervised Speech Representations,,"['https://openalex.org/W4391021724', 'https://openalex.org/W6796464841', 'https://openalex.org/W6778823374', 'https://openalex.org/W4385895691', 'https://openalex.org/W4372266915', 'https://openalex.org/W4375869015', 'https://openalex.org/W6851724922', 'https://openalex.org/W6850334629', 'https://openalex.org/W4385823074', 'https://openalex.org/W4385571362', 'https://openalex.org/W3158762648', 'https://openalex.org/W3170751106', 'https://openalex.org/W4385823416', 'https://openalex.org/W4297841449', 'https://openalex.org/W6780218876', 'https://openalex.org/W3209984917', 'https://openalex.org/W4388979610', 'https://openalex.org/W6724804524', 'https://openalex.org/W6781550413', 'https://openalex.org/W6790220310', 'https://openalex.org/W6738560588', 'https://openalex.org/W3097777922', 'https://openalex.org/W1901129140', 'https://openalex.org/W2785678896', 'https://openalex.org/W6755977528', 'https://openalex.org/W4372347654', 'https://openalex.org/W2936774411', 'https://openalex.org/W6838910450', 'https://openalex.org/W6853844661', 'https://openalex.org/W2972359262', 'https://openalex.org/W2963091184', 'https://openalex.org/W6631190155', 'https://openalex.org/W4391305764', 'https://openalex.org/W2622563070', 'https://openalex.org/W2502312327', 'https://openalex.org/W2899663614', 'https://openalex.org/W4366460484', 'https://openalex.org/W4323651091', 'https://openalex.org/W4288257146']",2024-04-14
https://openalex.org/W4402594291,https://doi.org/10.1109/icce-taiwan62264.2024.10674564,Using Large Language Model and Speech Synthesis Technology to Achieve Realistic Interactive Experiences in Smart City Applications,,"['https://openalex.org/W4210621764', 'https://openalex.org/W4312120796', 'https://openalex.org/W6855007681', 'https://openalex.org/W6850334629', 'https://openalex.org/W6860028411', 'https://openalex.org/W4390602555', 'https://openalex.org/W4401042136', 'https://openalex.org/W4323651091']",2024-07-09
https://openalex.org/W4411569810,https://doi.org/10.1007/s44443-025-00082-7,Emotion transfer in audio using mel-cepstral representation and CycleGANs,"Abstract The field of audio synthesis is currently confronted with two major challenges: to more effectively eliminate non-emotional influences in emotional feature extraction work, and to improve the emotional expression when reference audio is scarce. Therefore, an innovative audio deep feature decoupling and emotion adaptive fusion model, which combines Mel Frequency Cepstral Coefficients (MFCCs) with Cycle-consistent Generative Adversarial Networks (CycleGANs), is proposed in this paper. We designed a Deep Feature Decoupled Encoder Group (DFDEG), which is based on Gated Linear Units (GLU), Self-Attention, and Average Pooling. Meanwhile, we designed a feature fusion method called Emotion Adaptive Instance Normalization (Emo-AdaIN), which is based on AdaIN. By integrating the DFDEG, Emo-AdaIN, and CycleGANs, an unsupervised bidirectional multi-emotion transfer method within the MFCCs is successfully achieved. This method performs well in terms of emotion decoupling and transfer on unseen datasets: for different speakers, the transfer result’s Lowest Emotional Similarity (LES) is 94.56%, and Average Confidence Level (ACL) is 0.51. This demonstrates the generalization performance across different speakers and the robustness across different emotion granularity.","['https://openalex.org/W4313178214', 'https://openalex.org/W4394666973', 'https://openalex.org/W4298426053', 'https://openalex.org/W1924770834', 'https://openalex.org/W2567070169', 'https://openalex.org/W3096039514', 'https://openalex.org/W2194775991', 'https://openalex.org/W2940630528', 'https://openalex.org/W2797650215', 'https://openalex.org/W2963073614', 'https://openalex.org/W2116984840', 'https://openalex.org/W3034838124', 'https://openalex.org/W3170283647', 'https://openalex.org/W2964121744', 'https://openalex.org/W4392781941', 'https://openalex.org/W3150994787', 'https://openalex.org/W2963263347', 'https://openalex.org/W4319452539', 'https://openalex.org/W2763421725', 'https://openalex.org/W3168527213', 'https://openalex.org/W2125389028', 'https://openalex.org/W2982600914', 'https://openalex.org/W4200282610', 'https://openalex.org/W3192307151', 'https://openalex.org/W4319587015', 'https://openalex.org/W3174758275', 'https://openalex.org/W3085139254', 'https://openalex.org/W2502312327', 'https://openalex.org/W4385245566', 'https://openalex.org/W3034058691', 'https://openalex.org/W2963444790', 'https://openalex.org/W2963840672', 'https://openalex.org/W4323651091', 'https://openalex.org/W2768083292', 'https://openalex.org/W3095255070', 'https://openalex.org/W2605287558']",2025-06-23
https://openalex.org/W4415313017,https://doi.org/10.1016/j.specom.2025.103317,Direct speech-to-speech neural machine translation: A survey,,"['https://openalex.org/W2973088264', 'https://openalex.org/W3213029956', 'https://openalex.org/W2163922914', 'https://openalex.org/W4327656064', 'https://openalex.org/W3209984917', 'https://openalex.org/W4402112198', 'https://openalex.org/W1980861001', 'https://openalex.org/W2120847449', 'https://openalex.org/W3209059054', 'https://openalex.org/W3011411500', 'https://openalex.org/W3017535695', 'https://openalex.org/W4402538165', 'https://openalex.org/W3119378114', 'https://openalex.org/W4390604258', 'https://openalex.org/W2103091632', 'https://openalex.org/W3096709315', 'https://openalex.org/W4281492411', 'https://openalex.org/W4402669689', 'https://openalex.org/W2136545725', 'https://openalex.org/W2165698076', 'https://openalex.org/W2758950307', 'https://openalex.org/W4388017359', 'https://openalex.org/W3197411683', 'https://openalex.org/W2129120544', 'https://openalex.org/W2141998673', 'https://openalex.org/W3011462663', 'https://openalex.org/W2159591770', 'https://openalex.org/W4384211302', 'https://openalex.org/W4295857769', 'https://openalex.org/W4287322212', 'https://openalex.org/W3215615641', 'https://openalex.org/W2969521066', 'https://openalex.org/W4297808394', 'https://openalex.org/W2623399293', 'https://openalex.org/W4399317047', 'https://openalex.org/W4376548770', 'https://openalex.org/W4401306756', 'https://openalex.org/W4385245566', 'https://openalex.org/W4408354546', 'https://openalex.org/W4402533227', 'https://openalex.org/W3183859557', 'https://openalex.org/W4307323391', 'https://openalex.org/W4401607735', 'https://openalex.org/W2896457183', 'https://openalex.org/W4234842379', 'https://openalex.org/W3037469336', 'https://openalex.org/W4365799947', 'https://openalex.org/W4205807230', 'https://openalex.org/W4387596303', 'https://openalex.org/W3180374548', 'https://openalex.org/W3101118213', 'https://openalex.org/W3105214104', 'https://openalex.org/W4376632801', 'https://openalex.org/W2606555609', 'https://openalex.org/W2914584698', 'https://openalex.org/W3213018012', 'https://openalex.org/W2936695845', 'https://openalex.org/W4287854885', 'https://openalex.org/W2620949368', 'https://openalex.org/W4389500133', 'https://openalex.org/W1593271688', 'https://openalex.org/W4393027241', 'https://openalex.org/W1552314771', 'https://openalex.org/W2610930722', 'https://openalex.org/W2599674900', 'https://openalex.org/W2750779823', 'https://openalex.org/W3091928890', 'https://openalex.org/W4293171495', 'https://openalex.org/W2607303097', 'https://openalex.org/W4406163711', 'https://openalex.org/W4283026156', 'https://openalex.org/W4323651091', 'https://openalex.org/W2103934944', 'https://openalex.org/W4286903243', 'https://openalex.org/W4385569956', 'https://openalex.org/W3175871055', 'https://openalex.org/W2798389157', 'https://openalex.org/W128638292', 'https://openalex.org/W2915722758', 'https://openalex.org/W3036601975', 'https://openalex.org/W4384648564', 'https://openalex.org/W4389600306', 'https://openalex.org/W2597601064', 'https://openalex.org/W4226278401', 'https://openalex.org/W4255113413', 'https://openalex.org/W4221155340', 'https://openalex.org/W4409647763', 'https://openalex.org/W4238846128', 'https://openalex.org/W2963799213', 'https://openalex.org/W4311430515', 'https://openalex.org/W2747329762', 'https://openalex.org/W1538023239', 'https://openalex.org/W2939131199', 'https://openalex.org/W4287072252', 'https://openalex.org/W4285267877', 'https://openalex.org/W2915824643', 'https://openalex.org/W2113106066', 'https://openalex.org/W2501982834', 'https://openalex.org/W3141239769', 'https://openalex.org/W4412888943', 'https://openalex.org/W2097203679', 'https://openalex.org/W4288345582', 'https://openalex.org/W4404783772', 'https://openalex.org/W1631063262', 'https://openalex.org/W2419292002', 'https://openalex.org/W2625561335', 'https://openalex.org/W4402669744', 'https://openalex.org/W4378105483', 'https://openalex.org/W4399151597', 'https://openalex.org/W1583837637', 'https://openalex.org/W4379539302', 'https://openalex.org/W1821462560', 'https://openalex.org/W4292779060', 'https://openalex.org/W4381827575', 'https://openalex.org/W97072897', 'https://openalex.org/W4285306484']",2025-10-16
https://openalex.org/W4415321223,https://doi.org/10.1080/1448837x.2025.2568790,Multimodal fusion for enhancing English text translation: integrating multimedia information,,"['https://openalex.org/W4399376241', 'https://openalex.org/W4413053564', 'https://openalex.org/W3215763807', 'https://openalex.org/W4400771096', 'https://openalex.org/W4213388865', 'https://openalex.org/W3136823269', 'https://openalex.org/W3180506122', 'https://openalex.org/W4393407199', 'https://openalex.org/W4223941643', 'https://openalex.org/W4401377247', 'https://openalex.org/W4392812555', 'https://openalex.org/W4385780033', 'https://openalex.org/W4410582379', 'https://openalex.org/W3133473264', 'https://openalex.org/W4400086954', 'https://openalex.org/W2994772196', 'https://openalex.org/W3197400575', 'https://openalex.org/W3181440838', 'https://openalex.org/W4400300641', 'https://openalex.org/W4367041061', 'https://openalex.org/W3156804398', 'https://openalex.org/W4306655832', 'https://openalex.org/W3097393636', 'https://openalex.org/W4404503596', 'https://openalex.org/W4323651091', 'https://openalex.org/W4400300940']",2025-10-18
https://openalex.org/W4388017359,https://doi.org/10.1109/taslp.2023.3328283,End-to-End Speech Recognition: A Survey,"In the last decade of automatic speech recognition (ASR) research, the introduction of deep learning has brought considerable reductions in word error rate of more than 50% relative, compared to modeling without deep learning. In the wake of this transition, a number of all-neural ASR architectures have been introduced. These so-called <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">end-to-end</i> (E2E) models provide highly integrated, completely neural ASR models, which rely strongly on general machine learning knowledge, learn more consistently from data, with lower dependence on ASR domain-specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments.","['https://openalex.org/W6715097780', 'https://openalex.org/W2125838338', 'https://openalex.org/W2394932179', 'https://openalex.org/W98857008', 'https://openalex.org/W2165712214', 'https://openalex.org/W1588735863', 'https://openalex.org/W6680532216', 'https://openalex.org/W2056590938', 'https://openalex.org/W2408093180', 'https://openalex.org/W2288217446', 'https://openalex.org/W2127141656', 'https://openalex.org/W6638749077', 'https://openalex.org/W6623517193', 'https://openalex.org/W2327501763', 'https://openalex.org/W2143564602', 'https://openalex.org/W6683738474', 'https://openalex.org/W6675365184', 'https://openalex.org/W2889129739', 'https://openalex.org/W2962760690', 'https://openalex.org/W2129545859', 'https://openalex.org/W2100180150', 'https://openalex.org/W6780218876', 'https://openalex.org/W3008762051', 'https://openalex.org/W2962699523', 'https://openalex.org/W2972889948', 'https://openalex.org/W2545177271', 'https://openalex.org/W2962784628', 'https://openalex.org/W6728811460', 'https://openalex.org/W6734588641', 'https://openalex.org/W2899879954', 'https://openalex.org/W3198455051', 'https://openalex.org/W2121879602', 'https://openalex.org/W2046932483', 'https://openalex.org/W2889187401', 'https://openalex.org/W3197991202', 'https://openalex.org/W2750499125', 'https://openalex.org/W2064675550', 'https://openalex.org/W2105482032', 'https://openalex.org/W4385245566', 'https://openalex.org/W3097777922', 'https://openalex.org/W2746192915', 'https://openalex.org/W3016234571', 'https://openalex.org/W2143612262', 'https://openalex.org/W3211040052', 'https://openalex.org/W6690026940', 'https://openalex.org/W3008174054', 'https://openalex.org/W3028545098', 'https://openalex.org/W2962826786', 'https://openalex.org/W6727690538', 'https://openalex.org/W2889504751', 'https://openalex.org/W2915977493', 'https://openalex.org/W2745439869', 'https://openalex.org/W3008898571', 'https://openalex.org/W6685711979', 'https://openalex.org/W6735706088', 'https://openalex.org/W6747158283', 'https://openalex.org/W2952992734', 'https://openalex.org/W2962742956', 'https://openalex.org/W2936123380', 'https://openalex.org/W2972995428', 'https://openalex.org/W6793472422', 'https://openalex.org/W4319862683', 'https://openalex.org/W3015671919', 'https://openalex.org/W2514741789', 'https://openalex.org/W6727336983', 'https://openalex.org/W66978610', 'https://openalex.org/W2748816379', 'https://openalex.org/W4319862408', 'https://openalex.org/W2963211739', 'https://openalex.org/W6640090968', 'https://openalex.org/W2608712415', 'https://openalex.org/W2577366047', 'https://openalex.org/W2530876040', 'https://openalex.org/W2963303028', 'https://openalex.org/W2964012862', 'https://openalex.org/W6754576867', 'https://openalex.org/W2889163603', 'https://openalex.org/W3008525923', 'https://openalex.org/W2131968858', 'https://openalex.org/W2606722458', 'https://openalex.org/W2766219058', 'https://openalex.org/W2973122799', 'https://openalex.org/W3011339933', 'https://openalex.org/W3163203022', 'https://openalex.org/W6784400248', 'https://openalex.org/W6784800133', 'https://openalex.org/W2972625221', 'https://openalex.org/W2886319145', 'https://openalex.org/W2886025712', 'https://openalex.org/W2937402758', 'https://openalex.org/W2889374926', 'https://openalex.org/W3095173472', 'https://openalex.org/W2892009249', 'https://openalex.org/W3016010032', 'https://openalex.org/W6839026989', 'https://openalex.org/W2972818416', 'https://openalex.org/W3163793923', 'https://openalex.org/W3197976839', 'https://openalex.org/W3015686596', 'https://openalex.org/W3160551958', 'https://openalex.org/W3161375121', 'https://openalex.org/W3202419788', 'https://openalex.org/W4319862418', 'https://openalex.org/W6853611000', 'https://openalex.org/W6853998256', 'https://openalex.org/W3008284571', 'https://openalex.org/W3015927303', 'https://openalex.org/W3015383801', 'https://openalex.org/W3198116002', 'https://openalex.org/W1806891645', 'https://openalex.org/W6910546390', 'https://openalex.org/W2105594594', 'https://openalex.org/W6679128827', 'https://openalex.org/W1991133427', 'https://openalex.org/W2155368638', 'https://openalex.org/W4224518768', 'https://openalex.org/W6796656850', 'https://openalex.org/W3202184514', 'https://openalex.org/W2024539680', 'https://openalex.org/W3198439131', 'https://openalex.org/W3206876927', 'https://openalex.org/W4372259859', 'https://openalex.org/W2033565080', 'https://openalex.org/W2157749010', 'https://openalex.org/W1979136262', 'https://openalex.org/W2114016253', 'https://openalex.org/W2001679125', 'https://openalex.org/W2953561564', 'https://openalex.org/W2963747784', 'https://openalex.org/W3095697114', 'https://openalex.org/W2900209846', 'https://openalex.org/W2963144852', 'https://openalex.org/W2892124901', 'https://openalex.org/W3095376166', 'https://openalex.org/W2136922672', 'https://openalex.org/W2110798204', 'https://openalex.org/W2471933213', 'https://openalex.org/W2799923439', 'https://openalex.org/W2799800213', 'https://openalex.org/W6757856092', 'https://openalex.org/W2963571336', 'https://openalex.org/W2951974815', 'https://openalex.org/W1501286448', 'https://openalex.org/W1975550806', 'https://openalex.org/W6752630080', 'https://openalex.org/W2963431393', 'https://openalex.org/W3096215352', 'https://openalex.org/W3096032230', 'https://openalex.org/W4210463634', 'https://openalex.org/W3204696009', 'https://openalex.org/W4226120743', 'https://openalex.org/W2033245860', 'https://openalex.org/W1587755118', 'https://openalex.org/W2000200144', 'https://openalex.org/W6757817989', 'https://openalex.org/W6745410505', 'https://openalex.org/W2963026768', 'https://openalex.org/W6863618527', 'https://openalex.org/W3163842339', 'https://openalex.org/W2151834591', 'https://openalex.org/W2296073425', 'https://openalex.org/W6687566353', 'https://openalex.org/W3097747488', 'https://openalex.org/W3017474798', 'https://openalex.org/W1988720110', 'https://openalex.org/W6604254268', 'https://openalex.org/W6631190155', 'https://openalex.org/W3198654230', 'https://openalex.org/W4206410067', 'https://openalex.org/W6681151457', 'https://openalex.org/W2145249131', 'https://openalex.org/W6692956712', 'https://openalex.org/W6640036494', 'https://openalex.org/W2618530766', 'https://openalex.org/W2331143823', 'https://openalex.org/W2972451902', 'https://openalex.org/W3162249256', 'https://openalex.org/W6600213771', 'https://openalex.org/W6714142977', 'https://openalex.org/W2183341477', 'https://openalex.org/W6621543089', 'https://openalex.org/W6749075489', 'https://openalex.org/W2057653135', 'https://openalex.org/W6749518548', 'https://openalex.org/W3163839574', 'https://openalex.org/W1989674786', 'https://openalex.org/W2407080277', 'https://openalex.org/W6675409298', 'https://openalex.org/W2937780860', 'https://openalex.org/W3015995734', 'https://openalex.org/W3095189764', 'https://openalex.org/W2883586237', 'https://openalex.org/W4225334634', 'https://openalex.org/W2964107261', 'https://openalex.org/W1583239513', 'https://openalex.org/W2050526637', 'https://openalex.org/W1986184096', 'https://openalex.org/W2516457973', 'https://openalex.org/W2808939837', 'https://openalex.org/W2127095586', 'https://openalex.org/W2914018192', 'https://openalex.org/W2888909726', 'https://openalex.org/W206545267', 'https://openalex.org/W4473315', 'https://openalex.org/W6793076252', 'https://openalex.org/W6785891320', 'https://openalex.org/W2944255943', 'https://openalex.org/W3026041220', 'https://openalex.org/W2936774411', 'https://openalex.org/W3015726069', 'https://openalex.org/W2291975472', 'https://openalex.org/W2971840980', 'https://openalex.org/W108866686', 'https://openalex.org/W3097882114', 'https://openalex.org/W6774835902', 'https://openalex.org/W3096160024', 'https://openalex.org/W3016167541', 'https://openalex.org/W3197140813', 'https://openalex.org/W3206573929', 'https://openalex.org/W3094713728', 'https://openalex.org/W2963506925', 'https://openalex.org/W2963260202', 'https://openalex.org/W2886180730', 'https://openalex.org/W6854240803', 'https://openalex.org/W4299649720', 'https://openalex.org/W2151058131', 'https://openalex.org/W2008554732', 'https://openalex.org/W2066378046', 'https://openalex.org/W6765658108', 'https://openalex.org/W3015190365', 'https://openalex.org/W1710082047', 'https://openalex.org/W3015974384', 'https://openalex.org/W6770245836', 'https://openalex.org/W3097973766', 'https://openalex.org/W3197304116', 'https://openalex.org/W2972977747', 'https://openalex.org/W3148654612', 'https://openalex.org/W2963022149', 'https://openalex.org/W2627092829', 'https://openalex.org/W2963240019', 'https://openalex.org/W3163300396', 'https://openalex.org/W2972780808', 'https://openalex.org/W2787663903', 'https://openalex.org/W3008912312', 'https://openalex.org/W2972837679', 'https://openalex.org/W2938348542', 'https://openalex.org/W3197478142', 'https://openalex.org/W6797037654', 'https://openalex.org/W2972953886', 'https://openalex.org/W3005302685', 'https://openalex.org/W6713134421', 'https://openalex.org/W2933138175', 'https://openalex.org/W6760633627', 'https://openalex.org/W2962728618', 'https://openalex.org/W2972630480', 'https://openalex.org/W2949975180', 'https://openalex.org/W3015369343', 'https://openalex.org/W2091981305', 'https://openalex.org/W2972528057', 'https://openalex.org/W3016053754', 'https://openalex.org/W2964103964', 'https://openalex.org/W2963382396', 'https://openalex.org/W2970692082', 'https://openalex.org/W2078354939', 'https://openalex.org/W2136617108', 'https://openalex.org/W3015501067', 'https://openalex.org/W2972799770', 'https://openalex.org/W2972621414', 'https://openalex.org/W6752334204', 'https://openalex.org/W2097927681', 'https://openalex.org/W179875071', 'https://openalex.org/W2402268235', 'https://openalex.org/W2566563465', 'https://openalex.org/W6731370813', 'https://openalex.org/W6757424787', 'https://openalex.org/W2940180244', 'https://openalex.org/W2963088785', 'https://openalex.org/W2943845043', 'https://openalex.org/W2964110616', 'https://openalex.org/W2150355110', 'https://openalex.org/W6770251742', 'https://openalex.org/W6640059789', 'https://openalex.org/W2888779557', 'https://openalex.org/W2939111082', 'https://openalex.org/W3008037978', 'https://openalex.org/W3152221657', 'https://openalex.org/W3205201903', 'https://openalex.org/W6755207826', 'https://openalex.org/W3024308166', 'https://openalex.org/W2962745521', 'https://openalex.org/W3197507772', 'https://openalex.org/W1966812932', 'https://openalex.org/W2014151772', 'https://openalex.org/W2080213370', 'https://openalex.org/W1985258458', 'https://openalex.org/W2396464458', 'https://openalex.org/W2166637769', 'https://openalex.org/W1494198834', 'https://openalex.org/W3008191852', 'https://openalex.org/W3209059054', 'https://openalex.org/W6770506093', 'https://openalex.org/W3147414526', 'https://openalex.org/W2995181338', 'https://openalex.org/W2981857663', 'https://openalex.org/W4319862255', 'https://openalex.org/W2972692349', 'https://openalex.org/W2962824709', 'https://openalex.org/W3007528493', 'https://openalex.org/W3094667432', 'https://openalex.org/W3048407879', 'https://openalex.org/W3162665866', 'https://openalex.org/W3161873870', 'https://openalex.org/W3015194534', 'https://openalex.org/W3160766462', 'https://openalex.org/W3198442913', 'https://openalex.org/W6803092890', 'https://openalex.org/W6810259195', 'https://openalex.org/W4223622550', 'https://openalex.org/W3148001440', 'https://openalex.org/W3205644108', 'https://openalex.org/W4225319488', 'https://openalex.org/W4319862474', 'https://openalex.org/W2963739817', 'https://openalex.org/W6735168207', 'https://openalex.org/W3211278025', 'https://openalex.org/W4221155340', 'https://openalex.org/W2079656678', 'https://openalex.org/W2952230511', 'https://openalex.org/W3034775979', 'https://openalex.org/W4394662461', 'https://openalex.org/W2792376130', 'https://openalex.org/W4297781872', 'https://openalex.org/W1922655562', 'https://openalex.org/W3207222250', 'https://openalex.org/W3147187328', 'https://openalex.org/W3007328579', 'https://openalex.org/W3151269043', 'https://openalex.org/W1508165687', 'https://openalex.org/W1904365287', 'https://openalex.org/W3170405627', 'https://openalex.org/W4381827575', 'https://openalex.org/W4378501656', 'https://openalex.org/W4383605108', 'https://openalex.org/W3167895882', 'https://openalex.org/W2987019345', 'https://openalex.org/W3100910367', 'https://openalex.org/W2525778437', 'https://openalex.org/W1915251500', 'https://openalex.org/W2242818861', 'https://openalex.org/W2411921399', 'https://openalex.org/W2808640845', 'https://openalex.org/W2520160253', 'https://openalex.org/W3092122846', 'https://openalex.org/W3105532142', 'https://openalex.org/W2928941594', 'https://openalex.org/W4288290348', 'https://openalex.org/W1553004968', 'https://openalex.org/W2904818793', 'https://openalex.org/W3094957294', 'https://openalex.org/W3103005696']",2023-10-30
https://openalex.org/W4392903389,https://doi.org/10.1109/icassp48485.2024.10447523,"FunCodec: A Fundamental, Reproducible and Integrable Open-Source Toolkit for Neural Speech Codec","This paper presents FunCodec, a fundamental neural speech codec toolkit, which is an extension of the open-source speech processing toolkit FunASR. FunCodec provides reproducible training recipes and inference scripts for the latest neural speech codec models, such as SoundStream and Encodec. Thanks to the unified design with FunASR, FunCodec can be easily integrated into downstream tasks, such as speech recognition. Along with FunCodec, pretrained models are also provided, which can be used for academic or generalized purposes. Based on the toolkit, we further propose the frequency-domain codec models, FreqCodec, which can achieve comparable speech quality with much lower computation and parameter complexity. Experimental results show that, under the same compression ratio, FunCodec can achieve better reconstruction quality compared with other toolkits and released models. We also demonstrate that the pre-trained models are suitable for downstream tasks, including automatic speech recognition and personalized text-to-speech synthesis. This toolkit is publicly available at https://github.com/alibaba-damo-academy/FunCodec.","['https://openalex.org/W6639363673', 'https://openalex.org/W1481955708', 'https://openalex.org/W6767111847', 'https://openalex.org/W3215615641', 'https://openalex.org/W6783867762', 'https://openalex.org/W4307323391', 'https://openalex.org/W3095095816', 'https://openalex.org/W3163243746', 'https://openalex.org/W2064675550', 'https://openalex.org/W4385245566', 'https://openalex.org/W4372190822', 'https://openalex.org/W4375869380', 'https://openalex.org/W4372348514', 'https://openalex.org/W4372260101', 'https://openalex.org/W4375869436', 'https://openalex.org/W6848735303', 'https://openalex.org/W6853611000', 'https://openalex.org/W6853998256', 'https://openalex.org/W4372270198', 'https://openalex.org/W6853515095', 'https://openalex.org/W2752796333', 'https://openalex.org/W4221159457', 'https://openalex.org/W2798405286', 'https://openalex.org/W6631362777', 'https://openalex.org/W3209059054', 'https://openalex.org/W2972359262', 'https://openalex.org/W1494198834', 'https://openalex.org/W2963242190', 'https://openalex.org/W6754473786', 'https://openalex.org/W3203407300', 'https://openalex.org/W3198694222', 'https://openalex.org/W1728888090', 'https://openalex.org/W2889048668', 'https://openalex.org/W4313679638', 'https://openalex.org/W4205788663', 'https://openalex.org/W2963799213', 'https://openalex.org/W2970006822', 'https://openalex.org/W1524333225', 'https://openalex.org/W4378501656', 'https://openalex.org/W4381827575', 'https://openalex.org/W3092028330', 'https://openalex.org/W4380551955']",2024-03-18
https://openalex.org/W4393236964,https://doi.org/10.1016/j.enbenv.2024.03.010,"Evaluation of large language models (LLMs) on the mastery of knowledge and skills in the heating, ventilation and air conditioning (HVAC) industry","Large language models (LLMs) have shown human-level capabilities in solving various complex tasks. However, it is still unknown whether state-of-the-art LLMs master sufficient knowledge related to heating, ventilation and air conditioning (HVAC) systems. It will be inspiring if LLMs can think and learn like professionals in the HVAC industry. Hence, this study investigates the performance of LLMs on mastering the knowledge and skills related to the HVAC industry by letting them take the ASHRAE Certified HVAC Designer examination, an authoritative examination in the HVAC industry. Three key knowledge capabilities are explored: recall, analysis and application. Twelve representative LLMs are tested such as GPT-3.5, GPT-4 and LLaMA. According to the results, GPT-4 passes the ASHRAE Certified HVAC Designer examination with scores from 74 to 78, which is higher than about half of human examinees. Besides, GPT-3.5 passes the examination twice out of five times. It demonstrates that some LLMs such as GPT-4 and GPT-3.5 have great potential to assist or replace humans in designing and operating HVAC systems. However, they still make some mistakes sometimes due to the lack of knowledge, poor reasoning capabilities and unsatisfactory equation calculation abilities. Accordingly, four future research directions are proposed to reveal how to utilize and improve LLMs in the HVAC industry: teaching LLMs to use design tools or software in the HVAC industry, enabling LLMs to read and analyze the operational data from HVAC systems, developing tailored corpuses for the HVAC industry, and assessing the performance of LLMs in real-world HVAC design and operation scenarios.","['https://openalex.org/W3168442825', 'https://openalex.org/W4283388850', 'https://openalex.org/W3092537909', 'https://openalex.org/W4360618334', 'https://openalex.org/W6857939860', 'https://openalex.org/W6793792376', 'https://openalex.org/W4385566703', 'https://openalex.org/W1976960445', 'https://openalex.org/W2804844200', 'https://openalex.org/W2079074068', 'https://openalex.org/W2917212430', 'https://openalex.org/W6854039168', 'https://openalex.org/W6810608687', 'https://openalex.org/W2587347436', 'https://openalex.org/W1776296525', 'https://openalex.org/W1973944436', 'https://openalex.org/W3132263092', 'https://openalex.org/W4283770334', 'https://openalex.org/W4380987486', 'https://openalex.org/W4390498569', 'https://openalex.org/W4316012702', 'https://openalex.org/W6795217850', 'https://openalex.org/W6777023006', 'https://openalex.org/W3153794886', 'https://openalex.org/W4388248488', 'https://openalex.org/W4363671827', 'https://openalex.org/W4322718191', 'https://openalex.org/W4223442835', 'https://openalex.org/W3162029264', 'https://openalex.org/W4377865110', 'https://openalex.org/W4362693613', 'https://openalex.org/W4381487652', 'https://openalex.org/W4378501656', 'https://openalex.org/W4360891289']",2024-03-27
https://openalex.org/W4392904805,https://doi.org/10.1109/icassp48485.2024.10447112,"VoxtLM: Unified Decoder-Only Models for Consolidating Speech Recognition, Synthesis and Speech, Text Continuation Tasks","We propose a decoder-only language model, VoxtLM, that can perform four tasks: speech recognition, speech synthesis, text generation, and speech continuation. VoxtLM integrates text vocabulary with discrete speech tokens from self-supervised speech features and uses special tokens to enable multitask learning. Compared to a single-task model, VoxtLM exhibits a significant improvement in speech synthesis, with improvements in both speech intelligibility from 28.9 to 5.6 and objective quality from 2.68 to 3.90. VoxtLM also improves speech generation and speech recognition performance over the single-task counterpart. Further, VoxtLM is trained with publicly available data and training recipes and model checkpoints are open-sourced to make fully reproducible work.","['https://openalex.org/W6778883912', 'https://openalex.org/W6790356757', 'https://openalex.org/W4381786045', 'https://openalex.org/W6777028661', 'https://openalex.org/W6848735303', 'https://openalex.org/W4388017359', 'https://openalex.org/W2964243274', 'https://openalex.org/W6778823374', 'https://openalex.org/W6802465204', 'https://openalex.org/W4226120743', 'https://openalex.org/W3209059054', 'https://openalex.org/W4226033575', 'https://openalex.org/W3215615641', 'https://openalex.org/W4307323391', 'https://openalex.org/W6803092890', 'https://openalex.org/W6852381208', 'https://openalex.org/W6853611000', 'https://openalex.org/W4389524500', 'https://openalex.org/W6811340617', 'https://openalex.org/W6852781825', 'https://openalex.org/W2963250244', 'https://openalex.org/W2962784628', 'https://openalex.org/W2963979492', 'https://openalex.org/W4385822683', 'https://openalex.org/W6783867762', 'https://openalex.org/W2890964092', 'https://openalex.org/W6786696081', 'https://openalex.org/W2972394484', 'https://openalex.org/W3202278141', 'https://openalex.org/W2995181338', 'https://openalex.org/W1494198834', 'https://openalex.org/W3095410713', 'https://openalex.org/W2972359262', 'https://openalex.org/W2998572311', 'https://openalex.org/W6631190155', 'https://openalex.org/W6796464841', 'https://openalex.org/W4319862255', 'https://openalex.org/W4313679638', 'https://openalex.org/W2899575547', 'https://openalex.org/W3024605872', 'https://openalex.org/W4378501656', 'https://openalex.org/W3207222250', 'https://openalex.org/W4379540238', 'https://openalex.org/W4394671563', 'https://openalex.org/W4229005866', 'https://openalex.org/W4377865046']",2024-03-18
https://openalex.org/W4392909760,https://doi.org/10.1109/icassp48485.2024.10447751,Towards Universal Speech Discrete Tokens: A Case Study for ASR and TTS,"Self-supervised learning (SSL) proficiency in speech-related tasks has driven research into utilizing discrete tokens for speech tasks like recognition and translation, which offer lower storage requirements and great potential to employ natural language processing techniques. However, these studies, mainly single-task focused, faced challenges like overfitting and performance degradation in speech recognition tasks, often at the cost of sacrificing performance in multi-task scenarios. This study presents a comprehensive comparison and optimization of discrete tokens generated by various leading SSL models in speech recognition and synthesis tasks. We aim to explore the universality of speech discrete tokens across multiple speech tasks. Experimental results demonstrate that discrete tokens achieve comparable results against systems trained on FBank features in speech recognition tasks and outperform mel-spectrogram features in speech synthesis in subjective and objective metrics. These findings suggest that universal discrete tokens have enormous potential in various speech-related tasks. Our work is open-source and publicly available at https://github.com/k2-fsa/icefall.","['https://openalex.org/W4281492411', 'https://openalex.org/W6780218876', 'https://openalex.org/W6769196770', 'https://openalex.org/W3209059054', 'https://openalex.org/W3209984917', 'https://openalex.org/W4385823092', 'https://openalex.org/W4385823152', 'https://openalex.org/W4381786045', 'https://openalex.org/W3215615641', 'https://openalex.org/W4307323391', 'https://openalex.org/W6770514103', 'https://openalex.org/W6755207826', 'https://openalex.org/W4385822683', 'https://openalex.org/W4226132755', 'https://openalex.org/W6853244311', 'https://openalex.org/W4385823130', 'https://openalex.org/W6853611000', 'https://openalex.org/W3211278025', 'https://openalex.org/W3197580070', 'https://openalex.org/W2936774411', 'https://openalex.org/W3096159803', 'https://openalex.org/W3097777922', 'https://openalex.org/W6778823374', 'https://openalex.org/W1494198834', 'https://openalex.org/W3198694222', 'https://openalex.org/W2963242190', 'https://openalex.org/W2962784628', 'https://openalex.org/W4283700324', 'https://openalex.org/W6857062747', 'https://openalex.org/W3015686596', 'https://openalex.org/W4372260432', 'https://openalex.org/W2972359262', 'https://openalex.org/W6853515095', 'https://openalex.org/W4380551955', 'https://openalex.org/W4387799863', 'https://openalex.org/W4380714544', 'https://openalex.org/W2988736778', 'https://openalex.org/W4378501656']",2024-03-18
https://openalex.org/W4392902656,https://doi.org/10.1109/icassp48485.2024.10447296,Loss Masking Is Not Needed In Decoder-Only Transformer For Discrete-Token-Based ASR,"Recently, unified speech-text models, such as SpeechGPT, VioLA, and AudioPaLM, have achieved remarkable performance on various speech tasks. These models discretize speech signals into tokens (speech discretization) and use a shared vocabulary for both text and speech tokens. Then they train a single decoder-only Transformer on a mixture of speech tasks. However, these models rely on the Loss Masking strategy for the ASR task, which ignores the dependency among speech tokens. In this paper, we propose to model speech tokens in an autoregressive way, similar to text. We find that applying the conventional cross-entropy loss on input speech tokens does not consistently improve the ASR performance over the Loss Masking approach. To address this issue, we propose a novel approach denoted Smoothed Label Distillation (SLD), which applies a KL divergence loss with smoothed labels on speech tokens. Our experiments show that SLD effectively models speech tokens and outperforms Loss Masking for decoder-only Transformers in ASR tasks with different speech discretization methods <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">1</sup> .","['https://openalex.org/W6852800892', 'https://openalex.org/W6850625674', 'https://openalex.org/W4389524500', 'https://openalex.org/W6853611000', 'https://openalex.org/W6853998256', 'https://openalex.org/W6857968694', 'https://openalex.org/W6739901393', 'https://openalex.org/W6769196770', 'https://openalex.org/W6770514103', 'https://openalex.org/W4385822683', 'https://openalex.org/W4319862255', 'https://openalex.org/W3209984917', 'https://openalex.org/W3209059054', 'https://openalex.org/W4307323391', 'https://openalex.org/W6850218400', 'https://openalex.org/W2963979492', 'https://openalex.org/W2962784628', 'https://openalex.org/W2113158412', 'https://openalex.org/W6638523607', 'https://openalex.org/W2183341477', 'https://openalex.org/W1494198834', 'https://openalex.org/W2407080277', 'https://openalex.org/W4323066695', 'https://openalex.org/W4381827575', 'https://openalex.org/W2747329762', 'https://openalex.org/W4387595589', 'https://openalex.org/W4385245566', 'https://openalex.org/W4378501656', 'https://openalex.org/W1821462560', 'https://openalex.org/W4322718191', 'https://openalex.org/W2988736778']",2024-03-18
https://openalex.org/W4400070537,https://doi.org/10.1109/lsp.2024.3419719,Tuning Large Language Model for Speech Recognition With Mixed-Scale Re-Tokenization,,"['https://openalex.org/W6800875267', 'https://openalex.org/W6850625674', 'https://openalex.org/W4391021666', 'https://openalex.org/W6857054612', 'https://openalex.org/W6861626678', 'https://openalex.org/W4381786045', 'https://openalex.org/W4389524500', 'https://openalex.org/W6852447913', 'https://openalex.org/W6853611000', 'https://openalex.org/W6855691466', 'https://openalex.org/W6855801281', 'https://openalex.org/W4292825791', 'https://openalex.org/W4385573012', 'https://openalex.org/W6855885476', 'https://openalex.org/W4385822683', 'https://openalex.org/W4392902656', 'https://openalex.org/W3180374548', 'https://openalex.org/W4385822337', 'https://openalex.org/W4391021773', 'https://openalex.org/W4389520395', 'https://openalex.org/W4391021779', 'https://openalex.org/W4391021623', 'https://openalex.org/W6860809563', 'https://openalex.org/W4226507725', 'https://openalex.org/W2963250244', 'https://openalex.org/W6797019122', 'https://openalex.org/W4385573788', 'https://openalex.org/W4385571769', 'https://openalex.org/W4385805202', 'https://openalex.org/W6856179682', 'https://openalex.org/W4390190613', 'https://openalex.org/W3209059054', 'https://openalex.org/W3209873929', 'https://openalex.org/W1494198834', 'https://openalex.org/W6796581206', 'https://openalex.org/W4322718191', 'https://openalex.org/W4386351448', 'https://openalex.org/W4378501656', 'https://openalex.org/W4385328213', 'https://openalex.org/W4378711593', 'https://openalex.org/W4391835492']",2024-01-01
https://openalex.org/W4406461437,https://doi.org/10.1109/slt61566.2024.10832289,"ESPnet-Codec: Comprehensive Training and Evaluation of Neural Codecs For Audio, Music, and Speech",,"['https://openalex.org/W3209059054', 'https://openalex.org/W3209984917', 'https://openalex.org/W6810673746', 'https://openalex.org/W6857589352', 'https://openalex.org/W3197580070', 'https://openalex.org/W4385822439', 'https://openalex.org/W3203140070', 'https://openalex.org/W4385822683', 'https://openalex.org/W4392909068', 'https://openalex.org/W4372347505', 'https://openalex.org/W6777028661', 'https://openalex.org/W3180374548', 'https://openalex.org/W4372260052', 'https://openalex.org/W4385565440', 'https://openalex.org/W4392909760', 'https://openalex.org/W6848735303', 'https://openalex.org/W6853096648', 'https://openalex.org/W6856434366', 'https://openalex.org/W4389524500', 'https://openalex.org/W4402111789', 'https://openalex.org/W3215615641', 'https://openalex.org/W4307323391', 'https://openalex.org/W6853515095', 'https://openalex.org/W2962780374', 'https://openalex.org/W3016160783', 'https://openalex.org/W6802659129', 'https://openalex.org/W4280572880', 'https://openalex.org/W4402111799', 'https://openalex.org/W4297841651', 'https://openalex.org/W3151851237', 'https://openalex.org/W4385823192', 'https://openalex.org/W4372270198', 'https://openalex.org/W6852581948', 'https://openalex.org/W4392903389', 'https://openalex.org/W4406461271', 'https://openalex.org/W1552314771', 'https://openalex.org/W2141998673', 'https://openalex.org/W1728888090', 'https://openalex.org/W6857134842', 'https://openalex.org/W3163243746', 'https://openalex.org/W6762931180', 'https://openalex.org/W3015338123', 'https://openalex.org/W3161236344', 'https://openalex.org/W6783867762', 'https://openalex.org/W3163217847', 'https://openalex.org/W4402111636', 'https://openalex.org/W3161480375', 'https://openalex.org/W4225956675', 'https://openalex.org/W4385823256', 'https://openalex.org/W6869945801', 'https://openalex.org/W6847363464', 'https://openalex.org/W6853611000', 'https://openalex.org/W4392902656', 'https://openalex.org/W4390224291', 'https://openalex.org/W4402111612', 'https://openalex.org/W4402112534', 'https://openalex.org/W6778823374', 'https://openalex.org/W6796464841', 'https://openalex.org/W2964243274', 'https://openalex.org/W4400111385', 'https://openalex.org/W6869301554', 'https://openalex.org/W6862144568', 'https://openalex.org/W4402111456', 'https://openalex.org/W4297841773', 'https://openalex.org/W3024869864', 'https://openalex.org/W4392904154', 'https://openalex.org/W4385756463', 'https://openalex.org/W4380434618', 'https://openalex.org/W4392903251', 'https://openalex.org/W4392909101', 'https://openalex.org/W4319862462', 'https://openalex.org/W4402112643', 'https://openalex.org/W4379797396', 'https://openalex.org/W4402111425', 'https://openalex.org/W4402111669', 'https://openalex.org/W4385823416', 'https://openalex.org/W3160427568', 'https://openalex.org/W4391021746', 'https://openalex.org/W4385807463', 'https://openalex.org/W4391021652', 'https://openalex.org/W2972359262', 'https://openalex.org/W3198533616', 'https://openalex.org/W3170787215', 'https://openalex.org/W3153263923', 'https://openalex.org/W4285345683', 'https://openalex.org/W6892481026', 'https://openalex.org/W3159302906', 'https://openalex.org/W4296068763', 'https://openalex.org/W4402112388', 'https://openalex.org/W6779090866', 'https://openalex.org/W3081800019', 'https://openalex.org/W3158762648', 'https://openalex.org/W4402670057', 'https://openalex.org/W1494198834', 'https://openalex.org/W2726515241', 'https://openalex.org/W2995181338', 'https://openalex.org/W3100460087', 'https://openalex.org/W4392538788', 'https://openalex.org/W4313679638', 'https://openalex.org/W3024605872', 'https://openalex.org/W3206375275', 'https://openalex.org/W4399425629', 'https://openalex.org/W4378501656', 'https://openalex.org/W4387323811', 'https://openalex.org/W4399794707']",2024-12-02
https://openalex.org/W4392931320,https://doi.org/10.1109/icassp48485.2024.10446991,A Study on the Adverse Impact of Synthetic Speech on Speech Recognition,"The high-quality synthetic speech by TTS has been widely used in the field of human-computer interaction, bringing users better experience. However, synthetic speech is prone to be mixed with real human speech as part of the noise and recorded by the microphone, which leads to performance decrease for speech recognition. To address this issue, we propose different methods to study the adverse impact of synthetic speech on speech recognition, thereby enhancing its robustness. On the one hand, we adopt the concept of fake audio detection and incorporate an additional module into speech recognition model to differentiate between real and synthetic speech. On the other hand, we propose various methods of incorporating prompt labels from a language semantics perspective to achieve differentiation. These prompt labels provide contextual cues that help speech recognition model to better understand the difference between the two types of speech. The experimental results demonstrate the acoustic modeling of ASR is capable of distinguishing between real and synthetic speech effectively. Putting the prompt labels at the beginning achieves the best performance in a clean synthetic data scenario, while emptying the transcripts of synthetic speech obtains the best performance in a noisy synthetic data scenario.","['https://openalex.org/W6783867762', 'https://openalex.org/W4297841605', 'https://openalex.org/W6848735303', 'https://openalex.org/W3006752097', 'https://openalex.org/W3016008406', 'https://openalex.org/W3080248383', 'https://openalex.org/W4281712850', 'https://openalex.org/W4225873749', 'https://openalex.org/W4385573729', 'https://openalex.org/W4298633873', 'https://openalex.org/W3134568285', 'https://openalex.org/W4372259861', 'https://openalex.org/W3013139777', 'https://openalex.org/W6778883912', 'https://openalex.org/W6810738896', 'https://openalex.org/W6847363464', 'https://openalex.org/W6853998256', 'https://openalex.org/W6853611000', 'https://openalex.org/W2963242190', 'https://openalex.org/W4283067311', 'https://openalex.org/W4385822407', 'https://openalex.org/W4313679638', 'https://openalex.org/W4292779060', 'https://openalex.org/W4226278401', 'https://openalex.org/W3092028330', 'https://openalex.org/W4378501656', 'https://openalex.org/W4381827575']",2024-03-18
https://openalex.org/W4406461468,https://doi.org/10.1109/slt61566.2024.10832186,Mamba-Based Decoder-Only Approach with Bidirectional Speech Modeling for Speech Recognition,,"['https://openalex.org/W3097777922', 'https://openalex.org/W4385823140', 'https://openalex.org/W6803444062', 'https://openalex.org/W6839235732', 'https://openalex.org/W4313442864', 'https://openalex.org/W4375869285', 'https://openalex.org/W4372260519', 'https://openalex.org/W4385822815', 'https://openalex.org/W4392910298', 'https://openalex.org/W6810325043', 'https://openalex.org/W4385823047', 'https://openalex.org/W4385822478', 'https://openalex.org/W6859298233', 'https://openalex.org/W6861387779', 'https://openalex.org/W6860920680', 'https://openalex.org/W4406461266', 'https://openalex.org/W6863679278', 'https://openalex.org/W6868207820', 'https://openalex.org/W4402112499', 'https://openalex.org/W2739883972', 'https://openalex.org/W6778883912', 'https://openalex.org/W4297841687', 'https://openalex.org/W4391021666', 'https://openalex.org/W4392904094', 'https://openalex.org/W6860809563', 'https://openalex.org/W6859099255', 'https://openalex.org/W4392902656', 'https://openalex.org/W6856400107', 'https://openalex.org/W6853611000', 'https://openalex.org/W6853998256', 'https://openalex.org/W4392904805', 'https://openalex.org/W6868789466', 'https://openalex.org/W6841205203', 'https://openalex.org/W3180374548', 'https://openalex.org/W4381786045', 'https://openalex.org/W4392909760', 'https://openalex.org/W4392909068', 'https://openalex.org/W2962780374', 'https://openalex.org/W2963250244', 'https://openalex.org/W6861376004', 'https://openalex.org/W6769627184', 'https://openalex.org/W1494198834', 'https://openalex.org/W3209984917', 'https://openalex.org/W2799473636', 'https://openalex.org/W3198694222', 'https://openalex.org/W2963242190', 'https://openalex.org/W6601563604', 'https://openalex.org/W4403727496', 'https://openalex.org/W4378501656', 'https://openalex.org/W4398230172', 'https://openalex.org/W4393943345', 'https://openalex.org/W4381827575', 'https://openalex.org/W4391244998', 'https://openalex.org/W4386875055', 'https://openalex.org/W4391013663', 'https://openalex.org/W4389326242', 'https://openalex.org/W4388718054', 'https://openalex.org/W3101648800']",2024-12-02
https://openalex.org/W4408352608,https://doi.org/10.1109/icassp49660.2025.10888128,MoWE-Audio: Multitask AudioLLMs with Mixture of Weak Encoders,,"['https://openalex.org/W4384918448', 'https://openalex.org/W4387891768', 'https://openalex.org/W4388718054', 'https://openalex.org/W4377372369', 'https://openalex.org/W4393903963', 'https://openalex.org/W4396945500', 'https://openalex.org/W4376312115', 'https://openalex.org/W4406033011', 'https://openalex.org/W4378501656', 'https://openalex.org/W4386351448', 'https://openalex.org/W4381827575', 'https://openalex.org/W4391591726', 'https://openalex.org/W4404784428', 'https://openalex.org/W4311000453', 'https://openalex.org/W3209984917', 'https://openalex.org/W3209059054', 'https://openalex.org/W4312048190', 'https://openalex.org/W4391021627', 'https://openalex.org/W3168867926', 'https://openalex.org/W4395022840', 'https://openalex.org/W1494198834', 'https://openalex.org/W2963686995', 'https://openalex.org/W4313014461', 'https://openalex.org/W2962854302', 'https://openalex.org/W4400104114', 'https://openalex.org/W4387994989', 'https://openalex.org/W4395474395', 'https://openalex.org/W2936774411']",2025-03-12
https://openalex.org/W4412570610,https://doi.org/10.1002/aidi.202500085,"Large Language Model in Materials Science: Roles, Challenges, and Strategic Outlook","Large language models (LLMs) are creating a new paradigm for materials science by transforming textual insights into experimental findings. Leveraging their strengths in natural language understanding, multimodal alignment, and few‐shot reasoning, LLMs already show potential in property prediction, synthesis planning, and uncertainty quantification. This perspective highlights four key roles, Oracle, Surrogate, Quant, and Arbiter, to systematize recent advancements of LLMs in knowledge extraction, property inference, risk assessment, and decision‐making. Experience suggests that true value arises from integrating these capabilities into a verifiable, traceable loop rather than merely scaling model size. However, LLMs still face challenges due to data heterogeneity, limited interpretability, hallucination control, and misalignment with scientific tasks. To address these issues, we propose three forward‐looking directions: developing domain‐adapted foundation models infused with materials science context, establishing a standardized cross‐modal data infrastructure, and incorporating expert feedback alongside robotic automated experimentation into a fully traceable research loop. Through enhanced human–AI collaboration and methodological innovation, LLMs can transform from general‐purpose language tools into scientifically aware partners, advancing materials discovery toward a more efficient, interpretable, and sustainable future.","['https://openalex.org/W4392737546', 'https://openalex.org/W4306705676', 'https://openalex.org/W4405622351', 'https://openalex.org/W2919115771', 'https://openalex.org/W3180477523', 'https://openalex.org/W2962843773', 'https://openalex.org/W2008056655', 'https://openalex.org/W3014504517', 'https://openalex.org/W2163605009', 'https://openalex.org/W1485009520', 'https://openalex.org/W3010336026', 'https://openalex.org/W4298289240', 'https://openalex.org/W4385245566', 'https://openalex.org/W3195577433', 'https://openalex.org/W4327810158', 'https://openalex.org/W4390041933', 'https://openalex.org/W4384918448', 'https://openalex.org/W4405903187', 'https://openalex.org/W4283026156', 'https://openalex.org/W4391709329', 'https://openalex.org/W4323697341', 'https://openalex.org/W4402683897', 'https://openalex.org/W4404782859', 'https://openalex.org/W4281690148', 'https://openalex.org/W4399453708', 'https://openalex.org/W4321013654', 'https://openalex.org/W4367000100', 'https://openalex.org/W4394745423', 'https://openalex.org/W4387561135', 'https://openalex.org/W4393027318', 'https://openalex.org/W4390529036', 'https://openalex.org/W4394673016', 'https://openalex.org/W4389727268', 'https://openalex.org/W4385645323', 'https://openalex.org/W4380994269', 'https://openalex.org/W4402386435', 'https://openalex.org/W4389991792', 'https://openalex.org/W3020710627', 'https://openalex.org/W2902762889', 'https://openalex.org/W3110165646', 'https://openalex.org/W4382318938', 'https://openalex.org/W4408196005', 'https://openalex.org/W3047184465', 'https://openalex.org/W4402926388', 'https://openalex.org/W4388274718', 'https://openalex.org/W4321392130', 'https://openalex.org/W4294435850', 'https://openalex.org/W6680532216', 'https://openalex.org/W4297734170', 'https://openalex.org/W4386977391', 'https://openalex.org/W4392903956', 'https://openalex.org/W4378501656', 'https://openalex.org/W4310418667', 'https://openalex.org/W2097927681', 'https://openalex.org/W2896457183', 'https://openalex.org/W2965373594', 'https://openalex.org/W3198659451', 'https://openalex.org/W6810081322', 'https://openalex.org/W4322718191', 'https://openalex.org/W4375956160', 'https://openalex.org/W4388623498', 'https://openalex.org/W4387334721', 'https://openalex.org/W2064675550', 'https://openalex.org/W1986760892', 'https://openalex.org/W4213019189', 'https://openalex.org/W3178976598', 'https://openalex.org/W3118781290', 'https://openalex.org/W3129576130', 'https://openalex.org/W2791753912', 'https://openalex.org/W4310230601', 'https://openalex.org/W4362707064', 'https://openalex.org/W4389984066', 'https://openalex.org/W4389519118', 'https://openalex.org/W4387156634', 'https://openalex.org/W4309674289', 'https://openalex.org/W4386721614', 'https://openalex.org/W4389713766', 'https://openalex.org/W4399115485', 'https://openalex.org/W3168867926', 'https://openalex.org/W2736601468', 'https://openalex.org/W4311991106', 'https://openalex.org/W4378771755', 'https://openalex.org/W4386437475', 'https://openalex.org/W3034954837', 'https://openalex.org/W4379801285', 'https://openalex.org/W4399803256', 'https://openalex.org/W4404192248', 'https://openalex.org/W4393335770', 'https://openalex.org/W4392011666', 'https://openalex.org/W4403591916', 'https://openalex.org/W4292719230', 'https://openalex.org/W4391836235', 'https://openalex.org/W4394007314', 'https://openalex.org/W4407479096', 'https://openalex.org/W4399290669', 'https://openalex.org/W4400222628', 'https://openalex.org/W4391421491', 'https://openalex.org/W4404349998', 'https://openalex.org/W4402427294', 'https://openalex.org/W4404354593', 'https://openalex.org/W4390511840', 'https://openalex.org/W6967048876', 'https://openalex.org/W4390722655', 'https://openalex.org/W4412025960', 'https://openalex.org/W4399912458', 'https://openalex.org/W4411120014', 'https://openalex.org/W4405355411', 'https://openalex.org/W4387694367', 'https://openalex.org/W6966985652', 'https://openalex.org/W4407015717', 'https://openalex.org/W4407922392', 'https://openalex.org/W3109615746', 'https://openalex.org/W3195348523', 'https://openalex.org/W4396745882', 'https://openalex.org/W4400025514', 'https://openalex.org/W3203974877', 'https://openalex.org/W4404781665', 'https://openalex.org/W4403228802', 'https://openalex.org/W4401132497', 'https://openalex.org/W4401442519', 'https://openalex.org/W4388843229', 'https://openalex.org/W2474706806', 'https://openalex.org/W4376641465', 'https://openalex.org/W4401549128', 'https://openalex.org/W4226050570', 'https://openalex.org/W4385490607', 'https://openalex.org/W4296154431', 'https://openalex.org/W4389132715', 'https://openalex.org/W4362664882', 'https://openalex.org/W4381510318', 'https://openalex.org/W4390011017', 'https://openalex.org/W4386501199', 'https://openalex.org/W3139002032', 'https://openalex.org/W3186870698', 'https://openalex.org/W3092530885', 'https://openalex.org/W3152966503', 'https://openalex.org/W3151042244', 'https://openalex.org/W4307138865', 'https://openalex.org/W4401789752', 'https://openalex.org/W4406779522', 'https://openalex.org/W4322767099', 'https://openalex.org/W3042021489', 'https://openalex.org/W4212913440', 'https://openalex.org/W3031157367', 'https://openalex.org/W4403884259', 'https://openalex.org/W2897969207', 'https://openalex.org/W2783249037', 'https://openalex.org/W2998311588', 'https://openalex.org/W3207309731', 'https://openalex.org/W4404356992', 'https://openalex.org/W4280578746', 'https://openalex.org/W4385497042', 'https://openalex.org/W3107581532', 'https://openalex.org/W4389921502', 'https://openalex.org/W4319323461', 'https://openalex.org/W4404691742', 'https://openalex.org/W4364380196', 'https://openalex.org/W4399176479', 'https://openalex.org/W3139463858', 'https://openalex.org/W4405419007', 'https://openalex.org/W4399377978', 'https://openalex.org/W4224308101', 'https://openalex.org/W2122410182', 'https://openalex.org/W4393065599', 'https://openalex.org/W4404936357', 'https://openalex.org/W4253877692', 'https://openalex.org/W2998704965', 'https://openalex.org/W4200551341', 'https://openalex.org/W4391561379', 'https://openalex.org/W3092557781', 'https://openalex.org/W2618530766', 'https://openalex.org/W4318718899', 'https://openalex.org/W4366330503', 'https://openalex.org/W2158195707', 'https://openalex.org/W4408534627']",2025-07-22
https://openalex.org/W4394773771,https://doi.org/10.1162/tacl_a_00656,What Do Self-Supervised Speech Models Know About Words?,"Abstract Many self-supervised speech models (S3Ms) have been introduced over the last few years, improving performance and data efficiency on various speech tasks. However, these empirical successes alone do not give a complete picture of what is learned during pre-training. Recent work has begun analyzing how S3Ms encode certain properties, such as phonetic and speaker information, but we still lack a proper understanding of knowledge encoded at the word level and beyond. In this work, we use lightweight analysis methods to study segment-level linguistic properties—word identity, boundaries, pronunciation, syntactic features, and semantic features—encoded in S3Ms. We present a comparative study of layer-wise representations from ten S3Ms and find that (i) the frame-level representations within each word segment are not all equally informative, and (ii) the pre-training objective and model size heavily influence the accessibility and distribution of linguistic information across layers. We also find that on several tasks—word discrimination, word segmentation, and semantic sentence similarity—S3Ms trained with visual grounding outperform their speech-only counterparts. Finally, our task-based analyses demonstrate improved performance on word segmentation and acoustic word discrimination while using simpler methods than prior work.1","['https://openalex.org/W4385823003', 'https://openalex.org/W6754420807', 'https://openalex.org/W4296710617', 'https://openalex.org/W3044967013', 'https://openalex.org/W4385823338', 'https://openalex.org/W6795952400', 'https://openalex.org/W6810007534', 'https://openalex.org/W6780218876', 'https://openalex.org/W4319862401', 'https://openalex.org/W3202070718', 'https://openalex.org/W2906152891', 'https://openalex.org/W3198782837', 'https://openalex.org/W2407151108', 'https://openalex.org/W3203140070', 'https://openalex.org/W3198694222', 'https://openalex.org/W3209984917', 'https://openalex.org/W6803547063', 'https://openalex.org/W6748452836', 'https://openalex.org/W3209993061', 'https://openalex.org/W6755207826', 'https://openalex.org/W3093096176', 'https://openalex.org/W6787335539', 'https://openalex.org/W2251253014', 'https://openalex.org/W2963419157', 'https://openalex.org/W6839512648', 'https://openalex.org/W4372346125', 'https://openalex.org/W2166637769', 'https://openalex.org/W3097777922', 'https://openalex.org/W2962753610', 'https://openalex.org/W6731763572', 'https://openalex.org/W2970862333', 'https://openalex.org/W2025341678', 'https://openalex.org/W3174311593', 'https://openalex.org/W6792927658', 'https://openalex.org/W3160799772', 'https://openalex.org/W3095706145', 'https://openalex.org/W4225529283', 'https://openalex.org/W1967924372', 'https://openalex.org/W6839364956', 'https://openalex.org/W2995181338', 'https://openalex.org/W4313182775', 'https://openalex.org/W2190506272', 'https://openalex.org/W4223651314', 'https://openalex.org/W6761472960', 'https://openalex.org/W3096656254', 'https://openalex.org/W6790356757', 'https://openalex.org/W2059652594', 'https://openalex.org/W4319862479', 'https://openalex.org/W4391021793', 'https://openalex.org/W4385823426', 'https://openalex.org/W2972584841', 'https://openalex.org/W3163596720', 'https://openalex.org/W1632114991', 'https://openalex.org/W2747874407', 'https://openalex.org/W3198266945', 'https://openalex.org/W4306317873', 'https://openalex.org/W2065157922', 'https://openalex.org/W4281492411', 'https://openalex.org/W6752726010', 'https://openalex.org/W4303649106', 'https://openalex.org/W3110458199', 'https://openalex.org/W4307680525', 'https://openalex.org/W2963259843', 'https://openalex.org/W1494198834', 'https://openalex.org/W4226380987', 'https://openalex.org/W4375869259', 'https://openalex.org/W4287887773', 'https://openalex.org/W4224875474', 'https://openalex.org/W6786885278', 'https://openalex.org/W2250539671', 'https://openalex.org/W2145410271', 'https://openalex.org/W3034273309', 'https://openalex.org/W6745682157', 'https://openalex.org/W1558402681', 'https://openalex.org/W3155744586', 'https://openalex.org/W4206075291', 'https://openalex.org/W4375869060', 'https://openalex.org/W6948152991', 'https://openalex.org/W2932675979', 'https://openalex.org/W2962736743', 'https://openalex.org/W6788328058', 'https://openalex.org/W4385823328', 'https://openalex.org/W6810168380', 'https://openalex.org/W3150750326', 'https://openalex.org/W4385571440', 'https://openalex.org/W4226103796', 'https://openalex.org/W1606268232', 'https://openalex.org/W2946417913', 'https://openalex.org/W4285250921', 'https://openalex.org/W2963482440', 'https://openalex.org/W2251066368', 'https://openalex.org/W3198815374', 'https://openalex.org/W3150635893', 'https://openalex.org/W6739901393', 'https://openalex.org/W3008003211', 'https://openalex.org/W2970820321', 'https://openalex.org/W3119308075', 'https://openalex.org/W4372270126', 'https://openalex.org/W4385574560', 'https://openalex.org/W4385822254', 'https://openalex.org/W6853627120', 'https://openalex.org/W3197580070', 'https://openalex.org/W4385484924', 'https://openalex.org/W4386273179', 'https://openalex.org/W4385573456', 'https://openalex.org/W398859631', 'https://openalex.org/W569478347', 'https://openalex.org/W3096196861', 'https://openalex.org/W4283694096', 'https://openalex.org/W2593390416', 'https://openalex.org/W4394671563', 'https://openalex.org/W4385245566', 'https://openalex.org/W4319779871', 'https://openalex.org/W2891205112', 'https://openalex.org/W4280638376', 'https://openalex.org/W2602024037', 'https://openalex.org/W4310895557']",2024-01-01
https://openalex.org/W4401117812,https://doi.org/10.1162/coli_a_00526,Perception of Phonological Assimilation by Neural Speech Recognition Models,"Abstract Human listeners effortlessly compensate for phonological changes during speech perception, often unconsciously inferring the intended sounds. For example, listeners infer the underlying /n/ when hearing an utterance such as “clea[m] pan”, where [m] arises from place assimilation to the following labial [p]. This article explores how the neural speech recognition model Wav2Vec2 perceives assimilated sounds, and identifies the linguistic knowledge that is implemented by the model to compensate for assimilation during Automatic Speech Recognition (ASR). Using psycholinguistic stimuli, we systematically analyze how various linguistic context cues influence compensation patterns in the model’s output. Complementing these behavioral experiments, our probing experiments indicate that the model shifts its interpretation of assimilated sounds from their acoustic form to their underlying form in its final layers. Finally, our causal intervention experiments suggest that the model relies on minimal phonological context cues to accomplish this shift. These findings represent a step towards better understanding the similarities and differences in phonological processing between neural ASR models and humans.","['https://openalex.org/W2625455707', 'https://openalex.org/W6780218876', 'https://openalex.org/W3115586233', 'https://openalex.org/W4389518242', 'https://openalex.org/W2114393637', 'https://openalex.org/W2505429802', 'https://openalex.org/W2014652991', 'https://openalex.org/W2052156816', 'https://openalex.org/W6789826613', 'https://openalex.org/W1996079964', 'https://openalex.org/W2060689695', 'https://openalex.org/W2050866747', 'https://openalex.org/W4246991306', 'https://openalex.org/W2964222268', 'https://openalex.org/W4248968314', 'https://openalex.org/W2127141656', 'https://openalex.org/W6851934580', 'https://openalex.org/W1951934685', 'https://openalex.org/W2884225676', 'https://openalex.org/W2028630806', 'https://openalex.org/W3211278025', 'https://openalex.org/W4391099575', 'https://openalex.org/W2013543993', 'https://openalex.org/W2125199092', 'https://openalex.org/W2990597852', 'https://openalex.org/W1494198834', 'https://openalex.org/W4394773771', 'https://openalex.org/W4226380987', 'https://openalex.org/W6847363464', 'https://openalex.org/W4385823328', 'https://openalex.org/W6785887628', 'https://openalex.org/W6846261036', 'https://openalex.org/W2172066118', 'https://openalex.org/W2979826702', 'https://openalex.org/W4385571392', 'https://openalex.org/W4288072840', 'https://openalex.org/W3127686677', 'https://openalex.org/W9762390', 'https://openalex.org/W3105148948', 'https://openalex.org/W4231003508', 'https://openalex.org/W4367694478', 'https://openalex.org/W4253213911', 'https://openalex.org/W4256717825', 'https://openalex.org/W3036601975', 'https://openalex.org/W9028451', 'https://openalex.org/W3216401400']",2024-01-01
https://openalex.org/W4389520784,https://doi.org/10.18653/v1/2023.emnlp-main.513,Homophone Disambiguation Reveals Patterns of Context Mixing in Speech Transformers,"Transformers have become a key architecture in speech processing, but our understanding of how they build up representations of acoustic and linguistic structure is limited. In this study, we address this gap by investigating how measures of ‘context-mixing’ developed for text models can be adapted and applied to models of spoken language. We identify a linguistic phenomenon that is ideal for such a case study: homophony in French (e.g. livre vs livres), where a speech recognition model has to attend to syntactic cues such as determiners and pronouns in order to disambiguate spoken words with identical pronunciations and transcribe them while respecting grammatical agreement. We perform a series of controlled experiments and probing analyses on Transformer-based speech models. Our findings reveal that representations in encoder-only models effectively incorporate these cues to identify the correct transcription, whereas encoders in encoder-decoder models mainly relegate the task of capturing contextual dependencies to decoder modules.","['https://openalex.org/W2948771346', 'https://openalex.org/W3030437843', 'https://openalex.org/W4297841458', 'https://openalex.org/W2970120757', 'https://openalex.org/W4385574383', 'https://openalex.org/W3189296823', 'https://openalex.org/W2973154008', 'https://openalex.org/W2127141656', 'https://openalex.org/W3107600318', 'https://openalex.org/W4385570829', 'https://openalex.org/W4283332789', 'https://openalex.org/W4385574263', 'https://openalex.org/W4287887174', 'https://openalex.org/W4226380987', 'https://openalex.org/W4386566794', 'https://openalex.org/W2981991061', 'https://openalex.org/W3099143320', 'https://openalex.org/W2899663614', 'https://openalex.org/W3200704197', 'https://openalex.org/W2972324944', 'https://openalex.org/W3097777922', 'https://openalex.org/W3121914243', 'https://openalex.org/W4385245566', 'https://openalex.org/W4214784181', 'https://openalex.org/W2747874407', 'https://openalex.org/W3036601975', 'https://openalex.org/W3198429080', 'https://openalex.org/W4311000453', 'https://openalex.org/W4385823328']",2023-01-01
https://openalex.org/W4400376370,https://doi.org/10.21437/interspeech.2024-2490,Human-like Linguistic Biases in Neural Speech Models: Phonetic Categorization and Phonotactic Constraints in Wav2Vec2.0,"What do deep neural speech models know about phonology? Existing work has\nexamined the encoding of individual linguistic units such as phonemes in these\nmodels. Here we investigate interactions between units. Inspired by classic\nexperiments on human speech perception, we study how Wav2Vec2 resolves\nphonotactic constraints. We synthesize sounds on an acoustic continuum between\n/l/ and /r/ and embed them in controlled contexts where only /l/, only /r/, or\nneither occur in English. Like humans, Wav2Vec2 models show a bias towards the\nphonotactically admissable category in processing such ambiguous sounds. Using\nsimple measures to analyze model internals on the level of individual stimuli,\nwe find that this bias emerges in early layers of the model's Transformer\nmodule. This effect is amplified by ASR finetuning but also present in fully\nself-supervised models. Our approach demonstrates how controlled stimulus\ndesigns can help localize specific linguistic knowledge in neural speech\nmodels.\n","['https://openalex.org/W4321764341', 'https://openalex.org/W1977722422', 'https://openalex.org/W3035750922', 'https://openalex.org/W3036601975', 'https://openalex.org/W2127141656', 'https://openalex.org/W2133590932', 'https://openalex.org/W3105148948', 'https://openalex.org/W4256720429', 'https://openalex.org/W2471520273', 'https://openalex.org/W4221102486', 'https://openalex.org/W4401043052', 'https://openalex.org/W2038110455', 'https://openalex.org/W4385822337', 'https://openalex.org/W4385823223', 'https://openalex.org/W4389520784', 'https://openalex.org/W3216401400', 'https://openalex.org/W4390465217', 'https://openalex.org/W4246695671', 'https://openalex.org/W1494198834', 'https://openalex.org/W2979826702', 'https://openalex.org/W4283332789', 'https://openalex.org/W4385823328', 'https://openalex.org/W3127686677']",2024-09-01
https://openalex.org/W4406478807,https://doi.org/10.13064/ksss.2024.16.4.073,Uncovering between-categorical details in L2 pronunciation errors using Wav2Vec2.0 code vectors*,,"['https://openalex.org/W4385987252', 'https://openalex.org/W6639350448', 'https://openalex.org/W3209984917', 'https://openalex.org/W2134604569', 'https://openalex.org/W3126633256', 'https://openalex.org/W3198429080', 'https://openalex.org/W1635512741', 'https://openalex.org/W2061114942', 'https://openalex.org/W3209059054', 'https://openalex.org/W4223651314', 'https://openalex.org/W6603838645', 'https://openalex.org/W3095014057', 'https://openalex.org/W2901389167', 'https://openalex.org/W2889358387', 'https://openalex.org/W3003560423', 'https://openalex.org/W4311137818', 'https://openalex.org/W2889562042', 'https://openalex.org/W4385822337', 'https://openalex.org/W2747874407', 'https://openalex.org/W2721916986', 'https://openalex.org/W2114347655', 'https://openalex.org/W6981748126', 'https://openalex.org/W4394773771', 'https://openalex.org/W3198712976', 'https://openalex.org/W4221161768', 'https://openalex.org/W2067955968', 'https://openalex.org/W4385823328', 'https://openalex.org/W2019591463', 'https://openalex.org/W2027993708', 'https://openalex.org/W1985084205', 'https://openalex.org/W3197816268', 'https://openalex.org/W3196525293', 'https://openalex.org/W2607417839', 'https://openalex.org/W2038537421', 'https://openalex.org/W2888954148', 'https://openalex.org/W2931811736']",2024-12-01
https://openalex.org/W4403779633,https://doi.org/10.1111/lnc3.70001,The Roles of Neural Networks in Language Acquisition,"ABSTRACT How can modern neural networks like language models be useful to the field of language acquisition, and more broadly cognitive science, if they are not a priori designed to be cognitive models? As developments towards natural language understanding and generation have improved leaps and bounds, with models like GPT‐4, the question of how they can inform our understanding of human language acquisition has re‐emerged. As such, it is critical to examine how in practice linking hypotheses between models and human learners can be safely established. To address these questions, we propose a model taxonomy, including four modelling approaches, each having differing goals, from exploratory hypothesis generation to hypothesis differentiation and testing. We show how the goals of these approaches align with the overarching goals of science and linguistics by connecting our taxonomy to the realist versus instrumentalist approaches in philosophy of science. We survey recent work having adopted each of our modelling approaches and address the importance of computational modelling in language acquisition studies.","['https://openalex.org/W4309419389', 'https://openalex.org/W3031894486', 'https://openalex.org/W3034723486', 'https://openalex.org/W3100307207', 'https://openalex.org/W4319160409', 'https://openalex.org/W6800751262', 'https://openalex.org/W2064699871', 'https://openalex.org/W4210489638', 'https://openalex.org/W4229781645', 'https://openalex.org/W2166391802', 'https://openalex.org/W2160193011', 'https://openalex.org/W2484448352', 'https://openalex.org/W2124505740', 'https://openalex.org/W2110485445', 'https://openalex.org/W2087946919', 'https://openalex.org/W4232516125', 'https://openalex.org/W2998527566', 'https://openalex.org/W2612205435', 'https://openalex.org/W2921890305', 'https://openalex.org/W2954931071', 'https://openalex.org/W4252057175', 'https://openalex.org/W3123354371', 'https://openalex.org/W3105184673', 'https://openalex.org/W2128291347', 'https://openalex.org/W2986138048', 'https://openalex.org/W3034510440', 'https://openalex.org/W3213014097', 'https://openalex.org/W2788371362', 'https://openalex.org/W4221073978', 'https://openalex.org/W4363645377', 'https://openalex.org/W2118232585', 'https://openalex.org/W4301407432', 'https://openalex.org/W2963305465', 'https://openalex.org/W3139019561', 'https://openalex.org/W2531882892', 'https://openalex.org/W4385822936', 'https://openalex.org/W3009215973', 'https://openalex.org/W4392825180', 'https://openalex.org/W2916562859', 'https://openalex.org/W2549835527', 'https://openalex.org/W4308223369', 'https://openalex.org/W4392935324', 'https://openalex.org/W3031914912', 'https://openalex.org/W1983758697', 'https://openalex.org/W3088418428', 'https://openalex.org/W2052425030', 'https://openalex.org/W3211593711', 'https://openalex.org/W4380422369', 'https://openalex.org/W2156411867', 'https://openalex.org/W4386596863', 'https://openalex.org/W4396893649', 'https://openalex.org/W3201089379', 'https://openalex.org/W2032516407', 'https://openalex.org/W2333004866', 'https://openalex.org/W2103064571', 'https://openalex.org/W4249882522', 'https://openalex.org/W4229757449', 'https://openalex.org/W2571532437', 'https://openalex.org/W3178628016', 'https://openalex.org/W2342461303', 'https://openalex.org/W4384918448', 'https://openalex.org/W3171477941', 'https://openalex.org/W4210828651', 'https://openalex.org/W4226334035', 'https://openalex.org/W4391428296', 'https://openalex.org/W4382010844', 'https://openalex.org/W4309419356', 'https://openalex.org/W4389519222', 'https://openalex.org/W2978670439', 'https://openalex.org/W3195577433', 'https://openalex.org/W2805227907', 'https://openalex.org/W583821675', 'https://openalex.org/W2030527368', 'https://openalex.org/W2529745415', 'https://openalex.org/W1966109131', 'https://openalex.org/W1542006548', 'https://openalex.org/W2622700781', 'https://openalex.org/W3106255532', 'https://openalex.org/W2328687126', 'https://openalex.org/W4387949708', 'https://openalex.org/W2141038596', 'https://openalex.org/W2961535087', 'https://openalex.org/W1982374456', 'https://openalex.org/W4302287655', 'https://openalex.org/W2047569285', 'https://openalex.org/W2541061885', 'https://openalex.org/W1584053331', 'https://openalex.org/W2999905431', 'https://openalex.org/W4234058580', 'https://openalex.org/W4251717463', 'https://openalex.org/W2076486742']",2024-10-24
https://openalex.org/W4401609323,https://doi.org/10.1109/icasspw62465.2024.10626416,Analysis of Self-Supervised Speech Models on Children’s Speech and Infant Vocalizations,"To understand why self-supervised learning (SSL) models have empirically achieved strong performances on several speech-processing downstream tasks, numerous studies have focused on analyzing the encoded information of the SSL layer representations in adult speech. Limited work has investigated how pre-training and fine-tuning affect SSL models encoding children's speech and vocalizations. In this study, we aim to bridge this gap by probing SSL models on two relevant downstream tasks: (1) phoneme recognition (PR) on the speech of adults, older children (8-10 years old), and younger children (1-4 years old), and (2) vocalization classification (VC) distinguishing cry, fuss, and babble for infants under 14 months old. For younger children's PR, the superiority of fine-tuned SSL models is largely due to their ability to learn features that represent older children's speech and then adapt those features to the speech of younger children. For infant VC, SSL models pre-trained on large-scale home recordings learn to leverage phonetic representations at middle layers, and thereby enhance the performance of this task.","['https://openalex.org/W2888744627', 'https://openalex.org/W4226291682', 'https://openalex.org/W2124812654', 'https://openalex.org/W6780218876', 'https://openalex.org/W3209059054', 'https://openalex.org/W4283073456', 'https://openalex.org/W4293793697', 'https://openalex.org/W4382201918', 'https://openalex.org/W4385822468', 'https://openalex.org/W4385478409', 'https://openalex.org/W4385823034', 'https://openalex.org/W4385822277', 'https://openalex.org/W4226380987', 'https://openalex.org/W4319862479', 'https://openalex.org/W4385823368', 'https://openalex.org/W4319862652', 'https://openalex.org/W4385822936', 'https://openalex.org/W2889212027', 'https://openalex.org/W4385807395', 'https://openalex.org/W2164181499', 'https://openalex.org/W1494198834', 'https://openalex.org/W2107162140', 'https://openalex.org/W2125814841', 'https://openalex.org/W3167533889', 'https://openalex.org/W2127141656', 'https://openalex.org/W4387183160', 'https://openalex.org/W6631216910', 'https://openalex.org/W6752726010', 'https://openalex.org/W2747874407', 'https://openalex.org/W1586176709', 'https://openalex.org/W2085662862', 'https://openalex.org/W2239141610', 'https://openalex.org/W2026189271', 'https://openalex.org/W2187089797', 'https://openalex.org/W2187824139', 'https://openalex.org/W1583837637', 'https://openalex.org/W146900863']",2024-04-14
https://openalex.org/W4395036961,https://doi.org/10.31234/osf.io/gc5kp,Modeling the initial state of early phonetic learning in infants,"What are the necessary conditions to acquire language? Do infants rely on simple statistical mechanisms, or do they come pre-wired with innate capabilities allowing them to learn their native language(s)? Previous modeling studies have shown that unsupervised learning algorithms could reproduce some aspects of infant phonetic learning. Despite these successes, algorithms still fail to reproduce the learning trajectories observed in infants. Here, we advocate that this failure is partly due to a wrong initial state. Contrary to infants, unsupervised learning algorithms start with little to no prior knowledge of speech sounds. In this work, we propose a modeling approach to investigate the relative contribution of innate factors and language experience in infant speech perception. Our approach allows us to investigate theories hypothesizing a more significant role of innate factors, offering new modeling opportunities for studying infant language acquisition.","['https://openalex.org/W2214604124', 'https://openalex.org/W2027219560', 'https://openalex.org/W4232516125', 'https://openalex.org/W2548930763', 'https://openalex.org/W2001365213', 'https://openalex.org/W2786031913', 'https://openalex.org/W3015783745', 'https://openalex.org/W4229781645', 'https://openalex.org/W4225815933', 'https://openalex.org/W2765364385', 'https://openalex.org/W4382918397', 'https://openalex.org/W4225726571', 'https://openalex.org/W4378619943', 'https://openalex.org/W3197259906', 'https://openalex.org/W2483390977', 'https://openalex.org/W2050517152', 'https://openalex.org/W2011238950', 'https://openalex.org/W2595479191', 'https://openalex.org/W2593116425', 'https://openalex.org/W2605959375', 'https://openalex.org/W2165545766', 'https://openalex.org/W4230449744', 'https://openalex.org/W2999130843', 'https://openalex.org/W2133189729', 'https://openalex.org/W2995181338', 'https://openalex.org/W1597121597', 'https://openalex.org/W3144810982', 'https://openalex.org/W2020944885', 'https://openalex.org/W2103091632', 'https://openalex.org/W2063525438', 'https://openalex.org/W2005311247', 'https://openalex.org/W4311481261', 'https://openalex.org/W4391669171', 'https://openalex.org/W4385822936', 'https://openalex.org/W6791720001', 'https://openalex.org/W3034729383', 'https://openalex.org/W4384626726', 'https://openalex.org/W2104752510', 'https://openalex.org/W2776941264', 'https://openalex.org/W2062956221', 'https://openalex.org/W281094599', 'https://openalex.org/W3110458199', 'https://openalex.org/W2050864369', 'https://openalex.org/W6656414902', 'https://openalex.org/W2113332115', 'https://openalex.org/W2145410271', 'https://openalex.org/W1970688873', 'https://openalex.org/W2010188467', 'https://openalex.org/W2621649611', 'https://openalex.org/W3016181583', 'https://openalex.org/W577928986', 'https://openalex.org/W2615444509', 'https://openalex.org/W3125087428', 'https://openalex.org/W2395899413', 'https://openalex.org/W66627554', 'https://openalex.org/W4303629135', 'https://openalex.org/W1604716266', 'https://openalex.org/W2160464066', 'https://openalex.org/W2003341094', 'https://openalex.org/W1925965306', 'https://openalex.org/W292738443', 'https://openalex.org/W2153767712', 'https://openalex.org/W4238846128', 'https://openalex.org/W4389521008', 'https://openalex.org/W4246559809', 'https://openalex.org/W2037751943', 'https://openalex.org/W2088724121', 'https://openalex.org/W4396127524', 'https://openalex.org/W3133848337', 'https://openalex.org/W3119308075', 'https://openalex.org/W4389519222', 'https://openalex.org/W4287591426', 'https://openalex.org/W598767079', 'https://openalex.org/W2024490156', 'https://openalex.org/W4297808394']",2024-04-23
https://openalex.org/W4388496578,https://doi.org/10.31234/osf.io/b6978,The roles of neural networks in language acquisition,"How can modern neural networks like large language models be useful to the field of language acquisition, and more broadly cognitive science, if they are not a priori designed to be cognitive models? As developments towards natural language understanding and generation have improved leaps and bounds, with models like GPT-4, the question of how they can inform our understanding of human language acquisition has re-emerged. As such, it is critical to examine how in practice linking hypotheses between models and human learners can be safely established. To address these questions, we propose a model taxonomy, including four modeling approaches, each having differing goals, from exploratory hypothesis generation to hypothesis differentiation and testing. We show how the goals of these approaches align with the overarching goals of science and linguistics by connecting our taxonomy to the realist vs. instrumentalist approaches in philosophy of science. We survey recent work having adopted each of our modelling approaches and address the importance of computational modelling in language acquisition studies.","['https://openalex.org/W4309419389', 'https://openalex.org/W3031894486', 'https://openalex.org/W3034723486', 'https://openalex.org/W6777324918', 'https://openalex.org/W4308231578', 'https://openalex.org/W2064699871', 'https://openalex.org/W6814874207', 'https://openalex.org/W6801699001', 'https://openalex.org/W2897513296', 'https://openalex.org/W6811685372', 'https://openalex.org/W6636124663', 'https://openalex.org/W6684840438', 'https://openalex.org/W2166391802', 'https://openalex.org/W2483191164', 'https://openalex.org/W2160193011', 'https://openalex.org/W6602958830', 'https://openalex.org/W6678707947', 'https://openalex.org/W2130328464', 'https://openalex.org/W2047569285', 'https://openalex.org/W6676391964', 'https://openalex.org/W2087946919', 'https://openalex.org/W1485243506', 'https://openalex.org/W2141038596', 'https://openalex.org/W2998527566', 'https://openalex.org/W2612205435', 'https://openalex.org/W2921890305', 'https://openalex.org/W2954931071', 'https://openalex.org/W3087785102', 'https://openalex.org/W6761154740', 'https://openalex.org/W3123354371', 'https://openalex.org/W2076486742', 'https://openalex.org/W2128291347', 'https://openalex.org/W3004997297', 'https://openalex.org/W2973992035', 'https://openalex.org/W3022853932', 'https://openalex.org/W3213014097', 'https://openalex.org/W2788371362', 'https://openalex.org/W6807011314', 'https://openalex.org/W4363645377', 'https://openalex.org/W6739194381', 'https://openalex.org/W2118232585', 'https://openalex.org/W2789352267', 'https://openalex.org/W4387949708', 'https://openalex.org/W2908662516', 'https://openalex.org/W6701573534', 'https://openalex.org/W6645793533', 'https://openalex.org/W6792328021', 'https://openalex.org/W6733782738', 'https://openalex.org/W2531882892', 'https://openalex.org/W4379474370', 'https://openalex.org/W3009215973', 'https://openalex.org/W2916562859', 'https://openalex.org/W2549835527', 'https://openalex.org/W4297817836', 'https://openalex.org/W3031914912', 'https://openalex.org/W2030527368', 'https://openalex.org/W1966109131', 'https://openalex.org/W1983758697', 'https://openalex.org/W3088418428', 'https://openalex.org/W2052425030', 'https://openalex.org/W3211593711', 'https://openalex.org/W3134354476', 'https://openalex.org/W3185761978', 'https://openalex.org/W4380422369', 'https://openalex.org/W2156411867', 'https://openalex.org/W6948936239', 'https://openalex.org/W3120700840', 'https://openalex.org/W3135131435', 'https://openalex.org/W4385953436', 'https://openalex.org/W3201089379', 'https://openalex.org/W6632339639', 'https://openalex.org/W6658582600', 'https://openalex.org/W6702707151', 'https://openalex.org/W2103064571', 'https://openalex.org/W1488309867', 'https://openalex.org/W2934881010', 'https://openalex.org/W3178628016', 'https://openalex.org/W2342461303', 'https://openalex.org/W2805227907', 'https://openalex.org/W3171477941', 'https://openalex.org/W3032966519', 'https://openalex.org/W4205145744', 'https://openalex.org/W4310617065', 'https://openalex.org/W4300021539', 'https://openalex.org/W4389519222', 'https://openalex.org/W6752342493', 'https://openalex.org/W4384918448', 'https://openalex.org/W4308223369', 'https://openalex.org/W4327810158', 'https://openalex.org/W1982374456', 'https://openalex.org/W4288633968', 'https://openalex.org/W2963305465', 'https://openalex.org/W2896457183', 'https://openalex.org/W4319160409', 'https://openalex.org/W4302287655', 'https://openalex.org/W4226334035', 'https://openalex.org/W4317463334', 'https://openalex.org/W4248668560', 'https://openalex.org/W2986138048', 'https://openalex.org/W1584053331', 'https://openalex.org/W3139019561', 'https://openalex.org/W4382010844', 'https://openalex.org/W4301259831', 'https://openalex.org/W3034510440', 'https://openalex.org/W2978670439', 'https://openalex.org/W4396893649', 'https://openalex.org/W3184030040', 'https://openalex.org/W1607278777', 'https://openalex.org/W4309419356', 'https://openalex.org/W4385822936', 'https://openalex.org/W4292779060', 'https://openalex.org/W4252057175', 'https://openalex.org/W2333004866', 'https://openalex.org/W3105184673', 'https://openalex.org/W3100307207', 'https://openalex.org/W2032516407', 'https://openalex.org/W4253896841', 'https://openalex.org/W3195577433', 'https://openalex.org/W4239923245', 'https://openalex.org/W4300402905', 'https://openalex.org/W4251717463', 'https://openalex.org/W2484448352', 'https://openalex.org/W2592245327', 'https://openalex.org/W4254816979', 'https://openalex.org/W4210489638', 'https://openalex.org/W4230342701', 'https://openalex.org/W4243326049', 'https://openalex.org/W2622700781', 'https://openalex.org/W4221073978', 'https://openalex.org/W4287118015', 'https://openalex.org/W4236383353', 'https://openalex.org/W3106255532', 'https://openalex.org/W1542006548', 'https://openalex.org/W4248358431']",2023-11-07
https://openalex.org/W4399742250,https://doi.org/10.31234/osf.io/29muj,The difficulty and importance of estimating the lower and upper bounds of infant speech exposure,"Estimates of infants’ language exposure are necessary for computational studies that attempt to model and learn from infant language experiences. However, there are no well-established input estimates usable for this purpose. This paper explores empirical data on infant language exposure across various cultural settings to derive plausible limits on the speech exposure infants might receive during their first years of life. First, we argue that several assumptions lack unanimous agreement and demonstrate that existing data are problematic in multiple ways. Integrating these uncertainties and published information, we find estimates that range from 1 to 3,300 hours per year. We end by discussing how such a large possible range may impact evaluation of the plausibility and benchmarking of computational models.","['https://openalex.org/W3080620940', 'https://openalex.org/W4225815933', 'https://openalex.org/W2055692257', 'https://openalex.org/W3004481867', 'https://openalex.org/W2021548302', 'https://openalex.org/W4298742451', 'https://openalex.org/W2802302202', 'https://openalex.org/W2153899510', 'https://openalex.org/W4387865047', 'https://openalex.org/W4225079082', 'https://openalex.org/W4287591426', 'https://openalex.org/W2133726713', 'https://openalex.org/W2997253105', 'https://openalex.org/W4206039057', 'https://openalex.org/W4250492183', 'https://openalex.org/W2098428317', 'https://openalex.org/W2989204084', 'https://openalex.org/W2061594239', 'https://openalex.org/W2125766564', 'https://openalex.org/W2041119287', 'https://openalex.org/W4245555090', 'https://openalex.org/W2161155706', 'https://openalex.org/W2097515925', 'https://openalex.org/W2396361046', 'https://openalex.org/W4244748443', 'https://openalex.org/W4385822936', 'https://openalex.org/W4389519222', 'https://openalex.org/W2033491386', 'https://openalex.org/W4388628628', 'https://openalex.org/W4389524018', 'https://openalex.org/W2978939261', 'https://openalex.org/W4240474221', 'https://openalex.org/W4247178956', 'https://openalex.org/W3013841624']",2024-06-17
https://openalex.org/W4406803348,https://doi.org/10.1145/3714458,A Survey on Speech Deepfake Detection,"The availability of smart devices leads to an exponential increase in multimedia content. However, advancements in deep learning have also enabled the creation of highly sophisticated Deepfake content, including speech Deepfakes, which pose a serious threat by generating realistic voices and spreading misinformation. To combat this, numerous challenges have been organized to advance speech Deepfake detection techniques. In this survey, we systematically analyze more than 200 papers published up to March 2024. We provide a comprehensive review of each component in the detection pipeline, including model architectures, optimization techniques, generalizability, evaluation metrics, performance comparisons, available datasets, and open source availability. For each aspect, we assess recent progress and discuss ongoing challenges. In addition, we explore emerging topics such as partial Deepfake detection, cross-dataset evaluation, and defenses against adversarial attacks, while suggesting promising research directions. This survey not only identifies the current state of the art to establish strong baselines for future experiments but also offers clear guidance for researchers aiming to enhance speech Deepfake detection systems.","['https://openalex.org/W6888797151', 'https://openalex.org/W4297841654', 'https://openalex.org/W4225420087', 'https://openalex.org/W2972786657', 'https://openalex.org/W3213029956', 'https://openalex.org/W2950733131', 'https://openalex.org/W4214896311', 'https://openalex.org/W4386185355', 'https://openalex.org/W4386081277', 'https://openalex.org/W4283070071', 'https://openalex.org/W4385189362', 'https://openalex.org/W4386784299', 'https://openalex.org/W3024920698', 'https://openalex.org/W3183763412', 'https://openalex.org/W3092742905', 'https://openalex.org/W3081424945', 'https://openalex.org/W3033711348', 'https://openalex.org/W3207579445', 'https://openalex.org/W3200319900', 'https://openalex.org/W2148154194', 'https://openalex.org/W4298635755', 'https://openalex.org/W3197762302', 'https://openalex.org/W4366828058', 'https://openalex.org/W4382491653', 'https://openalex.org/W4387122446', 'https://openalex.org/W4214909824', 'https://openalex.org/W4327486018', 'https://openalex.org/W3104090442', 'https://openalex.org/W3170179936', 'https://openalex.org/W4323022270', 'https://openalex.org/W4297841768', 'https://openalex.org/W4229023940', 'https://openalex.org/W4385080277', 'https://openalex.org/W4379046716', 'https://openalex.org/W4382371735', 'https://openalex.org/W3217302282', 'https://openalex.org/W3041816239', 'https://openalex.org/W3104914837', 'https://openalex.org/W4395443751', 'https://openalex.org/W4323794554', 'https://openalex.org/W4226013277', 'https://openalex.org/W3204732550', 'https://openalex.org/W4385521743', 'https://openalex.org/W4385224813', 'https://openalex.org/W4382619839', 'https://openalex.org/W4293257502', 'https://openalex.org/W4223915588', 'https://openalex.org/W4390691474', 'https://openalex.org/W4382491261', 'https://openalex.org/W6784323503', 'https://openalex.org/W4303443321', 'https://openalex.org/W2796495654', 'https://openalex.org/W3160325739', 'https://openalex.org/W4401437283', 'https://openalex.org/W4360992936', 'https://openalex.org/W6842506836', 'https://openalex.org/W6849794704', 'https://openalex.org/W4226264925', 'https://openalex.org/W3135809943', 'https://openalex.org/W4297841787', 'https://openalex.org/W4391046687', 'https://openalex.org/W4313342969', 'https://openalex.org/W3200527256', 'https://openalex.org/W4297841596', 'https://openalex.org/W4385823415', 'https://openalex.org/W4386320359', 'https://openalex.org/W2979938509', 'https://openalex.org/W3199266942', 'https://openalex.org/W4401042610', 'https://openalex.org/W6852909395', 'https://openalex.org/W4386505700', 'https://openalex.org/W4387272110', 'https://openalex.org/W2295634712', 'https://openalex.org/W4296412762', 'https://openalex.org/W2970779662', 'https://openalex.org/W4392487686', 'https://openalex.org/W4224903341', 'https://openalex.org/W3111548756', 'https://openalex.org/W2748488820', 'https://openalex.org/W3017092864', 'https://openalex.org/W4225527248', 'https://openalex.org/W3183948972', 'https://openalex.org/W3199161700', 'https://openalex.org/W4298633873', 'https://openalex.org/W4380353702', 'https://openalex.org/W2406845569', 'https://openalex.org/W4313051601', 'https://openalex.org/W4402501105', 'https://openalex.org/W4385848954', 'https://openalex.org/W3212117663', 'https://openalex.org/W4221140814', 'https://openalex.org/W4319862460', 'https://openalex.org/W4386721750', 'https://openalex.org/W4283067891', 'https://openalex.org/W4399597923', 'https://openalex.org/W4381161978', 'https://openalex.org/W4396816534', 'https://openalex.org/W4317358019', 'https://openalex.org/W2991187463', 'https://openalex.org/W3132550238', 'https://openalex.org/W4386363146', 'https://openalex.org/W6852755086', 'https://openalex.org/W6855853421', 'https://openalex.org/W4382721438', 'https://openalex.org/W4313306150', 'https://openalex.org/W4385823015', 'https://openalex.org/W3184587639', 'https://openalex.org/W4205695807', 'https://openalex.org/W4380187117', 'https://openalex.org/W3127781933', 'https://openalex.org/W3096023981', 'https://openalex.org/W4393241408', 'https://openalex.org/W4221140846', 'https://openalex.org/W3175036090', 'https://openalex.org/W4313193511', 'https://openalex.org/W4386840160', 'https://openalex.org/W2955054437', 'https://openalex.org/W4298635730', 'https://openalex.org/W3152218910', 'https://openalex.org/W4285188346', 'https://openalex.org/W3100448777', 'https://openalex.org/W2593463961', 'https://openalex.org/W3161011913', 'https://openalex.org/W4378974970', 'https://openalex.org/W1494198834', 'https://openalex.org/W3110588169', 'https://openalex.org/W4285049448', 'https://openalex.org/W4312891570', 'https://openalex.org/W4298397149', 'https://openalex.org/W3158663310', 'https://openalex.org/W4400111385', 'https://openalex.org/W3163596559', 'https://openalex.org/W4401609584', 'https://openalex.org/W4298394324', 'https://openalex.org/W2176804518', 'https://openalex.org/W4378105483', 'https://openalex.org/W3199131409', 'https://openalex.org/W4292957223', 'https://openalex.org/W4392910562']",2025-01-24
https://openalex.org/W4407904113,https://doi.org/10.1007/s13042-025-02535-x,Personalized Lao language synthesis via disentangled neural codec language model,,"['https://openalex.org/W2964243274', 'https://openalex.org/W6607786901', 'https://openalex.org/W4385822596', 'https://openalex.org/W3095035471', 'https://openalex.org/W6600050674', 'https://openalex.org/W4225746985', 'https://openalex.org/W6600741150', 'https://openalex.org/W4313225743', 'https://openalex.org/W1981276685', 'https://openalex.org/W3161109662', 'https://openalex.org/W3095199334', 'https://openalex.org/W4297841574', 'https://openalex.org/W4284690259', 'https://openalex.org/W4390075359', 'https://openalex.org/W3197659778', 'https://openalex.org/W4372260434', 'https://openalex.org/W4391156274', 'https://openalex.org/W3095012670', 'https://openalex.org/W2972473628', 'https://openalex.org/W2995181338', 'https://openalex.org/W3196584150', 'https://openalex.org/W2890964092', 'https://openalex.org/W6632668414', 'https://openalex.org/W4400111169', 'https://openalex.org/W4385848954']",2025-02-24
https://openalex.org/W4410184628,https://doi.org/10.2139/ssrn.5244226,A Speech Prediction Model Based on Codec Modeling and Transformer Decoding,,"['https://openalex.org/W2296153915', 'https://openalex.org/W1864555471', 'https://openalex.org/W4226265417', 'https://openalex.org/W3025035610', 'https://openalex.org/W2981687423', 'https://openalex.org/W2926827382', 'https://openalex.org/W4307323391', 'https://openalex.org/W4224875149', 'https://openalex.org/W6755257315', 'https://openalex.org/W2145103350', 'https://openalex.org/W2980292555', 'https://openalex.org/W4365205190', 'https://openalex.org/W2112464782', 'https://openalex.org/W4392538788', 'https://openalex.org/W6748409065', 'https://openalex.org/W4404102497', 'https://openalex.org/W6769276668', 'https://openalex.org/W6631190155', 'https://openalex.org/W82776184', 'https://openalex.org/W3092028330', 'https://openalex.org/W1561829009', 'https://openalex.org/W4297841545', 'https://openalex.org/W1550397807', 'https://openalex.org/W4296068992', 'https://openalex.org/W2799789537', 'https://openalex.org/W4389317961', 'https://openalex.org/W4393294847', 'https://openalex.org/W2898371500', 'https://openalex.org/W2321297794', 'https://openalex.org/W1964600646', 'https://openalex.org/W4387682234', 'https://openalex.org/W4283697979', 'https://openalex.org/W4307536105', 'https://openalex.org/W4379256228', 'https://openalex.org/W6784121926', 'https://openalex.org/W3178638614', 'https://openalex.org/W2793014896', 'https://openalex.org/W2556910157', 'https://openalex.org/W2898847420', 'https://openalex.org/W3002741552', 'https://openalex.org/W4225302959', 'https://openalex.org/W1552314771', 'https://openalex.org/W2132036212', 'https://openalex.org/W2802304149', 'https://openalex.org/W6796450881', 'https://openalex.org/W2889442120', 'https://openalex.org/W4280561221', 'https://openalex.org/W4280561867', 'https://openalex.org/W3207100935', 'https://openalex.org/W4385848954', 'https://openalex.org/W4224903235', 'https://openalex.org/W4387687749', 'https://openalex.org/W4386764852', 'https://openalex.org/W1955313418', 'https://openalex.org/W3215615641', 'https://openalex.org/W3141042598', 'https://openalex.org/W6769487070']",2025-01-01
https://openalex.org/W4392903872,https://doi.org/10.1109/icassp48485.2024.10447553,SALM: Speech-Augmented Language Model with in-Context Learning for Speech Recognition and Translation,"We present a novel Speech Augmented Language Model (SALM) with multitask and in-context learning capabilities. SALM comprises a frozen text LLM, a audio encoder, a modality adapter module, and LoRA layers to accommodate speech input and associated task instructions. The unified SALM not only achieves performance on par with task-specific Conformer baselines for Automatic Speech Recognition (ASR) and Speech Translation (AST), but also exhibits zero-shot in-context learning capabilities, demonstrated through keyword-boosting task for ASR and AST. Moreover, speech supervised in-context training is proposed to bridge the gap between LLM training and downstream speech tasks, which further boosts the in-context learning ability of speech-to-text models. Proposed model is open-sourced via NeMo toolkit <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">1</sup> .","['https://openalex.org/W4393178509', 'https://openalex.org/W6852326057', 'https://openalex.org/W4372269772', 'https://openalex.org/W4385822949', 'https://openalex.org/W4389524500', 'https://openalex.org/W6853998256', 'https://openalex.org/W6853249747', 'https://openalex.org/W4392910583', 'https://openalex.org/W4391021666', 'https://openalex.org/W6855414158', 'https://openalex.org/W6767997687', 'https://openalex.org/W6767671539', 'https://openalex.org/W4385822953', 'https://openalex.org/W6848735303', 'https://openalex.org/W4252812408', 'https://openalex.org/W4391021773', 'https://openalex.org/W2889012072', 'https://openalex.org/W2886319145', 'https://openalex.org/W4225308107', 'https://openalex.org/W4226120743', 'https://openalex.org/W4392979802', 'https://openalex.org/W4391021542', 'https://openalex.org/W3097777922', 'https://openalex.org/W6796581206', 'https://openalex.org/W6800875267', 'https://openalex.org/W6846665566', 'https://openalex.org/W6761551260', 'https://openalex.org/W1494198834', 'https://openalex.org/W4385570170', 'https://openalex.org/W3092085609', 'https://openalex.org/W3005302685', 'https://openalex.org/W6857054612', 'https://openalex.org/W4387595589', 'https://openalex.org/W2963499882', 'https://openalex.org/W4387891768', 'https://openalex.org/W4375958083', 'https://openalex.org/W2938704169', 'https://openalex.org/W4392903956', 'https://openalex.org/W4381827575', 'https://openalex.org/W2974231335', 'https://openalex.org/W4313679638', 'https://openalex.org/W3168867926', 'https://openalex.org/W4310428868', 'https://openalex.org/W2973727699', 'https://openalex.org/W4377130946']",2024-03-18
https://openalex.org/W4403780722,https://doi.org/10.1145/3664647.3681697,Generative Expressive Conversational Speech Synthesis,,"['https://openalex.org/W4392384650', 'https://openalex.org/W2963349408', 'https://openalex.org/W4382202703', 'https://openalex.org/W4308852802', 'https://openalex.org/W4389983267', 'https://openalex.org/W4387969386', 'https://openalex.org/W4392908891', 'https://openalex.org/W3095319910', 'https://openalex.org/W3151309757', 'https://openalex.org/W3209059054', 'https://openalex.org/W4320813209', 'https://openalex.org/W4384615685', 'https://openalex.org/W4391709903', 'https://openalex.org/W3129009457', 'https://openalex.org/W4372260474', 'https://openalex.org/W4225300652', 'https://openalex.org/W4304013787', 'https://openalex.org/W4390306229', 'https://openalex.org/W4392931281', 'https://openalex.org/W4393160807', 'https://openalex.org/W4387968649', 'https://openalex.org/W4226092197', 'https://openalex.org/W4283067649', 'https://openalex.org/W3195592874', 'https://openalex.org/W4378446074', 'https://openalex.org/W3155340931', 'https://openalex.org/W4313679638', 'https://openalex.org/W4387595589', 'https://openalex.org/W4391021666', 'https://openalex.org/W4390528829', 'https://openalex.org/W4375868859', 'https://openalex.org/W4389524500', 'https://openalex.org/W4281397735', 'https://openalex.org/W4394671563']",2024-10-26
https://openalex.org/W4406138340,https://doi.org/10.1109/taslpro.2025.3525966,The Codecfake Dataset and Countermeasures for the Universally Detection of Deepfake Audio,,"['https://openalex.org/W6856434366', 'https://openalex.org/W3128666957', 'https://openalex.org/W4381198892', 'https://openalex.org/W4221138880', 'https://openalex.org/W4225854381', 'https://openalex.org/W4226264925', 'https://openalex.org/W4297841787', 'https://openalex.org/W4392910562', 'https://openalex.org/W2964243274', 'https://openalex.org/W2903739847', 'https://openalex.org/W6763832098', 'https://openalex.org/W6778823374', 'https://openalex.org/W6777694618', 'https://openalex.org/W6795261426', 'https://openalex.org/W3158762648', 'https://openalex.org/W2769810959', 'https://openalex.org/W2963300588', 'https://openalex.org/W6767111847', 'https://openalex.org/W3015338123', 'https://openalex.org/W6783867762', 'https://openalex.org/W6783182287', 'https://openalex.org/W6782760101', 'https://openalex.org/W6796464841', 'https://openalex.org/W4391020683', 'https://openalex.org/W6851724922', 'https://openalex.org/W6862144568', 'https://openalex.org/W2518172956', 'https://openalex.org/W3209059054', 'https://openalex.org/W2046056978', 'https://openalex.org/W4381786045', 'https://openalex.org/W6845479124', 'https://openalex.org/W6848735303', 'https://openalex.org/W6849105126', 'https://openalex.org/W6850334629', 'https://openalex.org/W6853611000', 'https://openalex.org/W6853096648', 'https://openalex.org/W4400111385', 'https://openalex.org/W4387595589', 'https://openalex.org/W3215615641', 'https://openalex.org/W3095095816', 'https://openalex.org/W4307323391', 'https://openalex.org/W2255466643', 'https://openalex.org/W4372270198', 'https://openalex.org/W6852581948', 'https://openalex.org/W6853515095', 'https://openalex.org/W4392903389', 'https://openalex.org/W4226033575', 'https://openalex.org/W6853998256', 'https://openalex.org/W6856800273', 'https://openalex.org/W3097777922', 'https://openalex.org/W6799089041', 'https://openalex.org/W4381708595', 'https://openalex.org/W4401437283', 'https://openalex.org/W6852755086', 'https://openalex.org/W4402351686', 'https://openalex.org/W4403955716', 'https://openalex.org/W3162366763', 'https://openalex.org/W2752796333', 'https://openalex.org/W2064675550', 'https://openalex.org/W3096159803', 'https://openalex.org/W6779577414', 'https://openalex.org/W2972359262', 'https://openalex.org/W1494198834', 'https://openalex.org/W6936113694', 'https://openalex.org/W3198533616', 'https://openalex.org/W3213029956', 'https://openalex.org/W3209984917', 'https://openalex.org/W4402111467', 'https://openalex.org/W6864076324', 'https://openalex.org/W4403791925', 'https://openalex.org/W3197580070', 'https://openalex.org/W4297841635', 'https://openalex.org/W2972811785', 'https://openalex.org/W3201773091', 'https://openalex.org/W4225527248', 'https://openalex.org/W4385822390', 'https://openalex.org/W6682891771', 'https://openalex.org/W2936802426', 'https://openalex.org/W6790545018']",2025-01-01
https://openalex.org/W4399096462,https://doi.org/10.1186/s13636-024-00351-9,Optimizing feature fusion for improved zero-shot adaptation in text-to-speech synthesis,"Abstract In the era of advanced text-to-speech (TTS) systems capable of generating high-fidelity, human-like speech by referring a reference speech, voice cloning (VC), or zero-shot TTS (ZS-TTS), stands out as an important subtask. A primary challenge in VC is maintaining speech quality and speaker similarity with limited reference data for a specific speaker. However, existing VC systems often rely on naive combinations of embedded speaker vectors for speaker control, which compromises the capture of speaking style, voice print, and semantic accuracy. To overcome this, we introduce the Two-branch Speaker Control Module (TSCM), a novel and highly adaptable voice cloning module designed to precisely processing speaker or style control for a target speaker. Our method uses an advanced fusion of local-level features from a Gated Convolutional Network (GCN) and utterance-level features from a gated recurrent unit (GRU) to enhance speaker control. We demonstrate the effectiveness of TSCM by integrating it into advanced TTS systems like FastSpeech 2 and VITS architectures, significantly optimizing their performance. Experimental results show that TSCM enables accurate voice cloning for a target speaker with minimal data through both zero-shot or few-shot fine-tuning of pretrained TTS models. Furthermore, our TSCM-based VITS (TSCM-VITS) showcases superior performance in zero-shot scenarios compared to existing state-of-the-art VC systems, even with basic dataset configurations. Our method’s superiority is validated through comprehensive subjective and objective evaluations. A demonstration of our system is available at https://great-research.github.io/tsct-tts-demo/ , providing practical insights into its application and effectiveness.","['https://openalex.org/W3162794600', 'https://openalex.org/W6607786901', 'https://openalex.org/W4313148337', 'https://openalex.org/W3213984348', 'https://openalex.org/W6601949647', 'https://openalex.org/W2808706139', 'https://openalex.org/W2964243274', 'https://openalex.org/W3015826515', 'https://openalex.org/W4225746985', 'https://openalex.org/W4385823163', 'https://openalex.org/W4385822787', 'https://openalex.org/W4375869257', 'https://openalex.org/W2166469361', 'https://openalex.org/W1999885698', 'https://openalex.org/W1861172732', 'https://openalex.org/W2111284386', 'https://openalex.org/W4319586596', 'https://openalex.org/W6600741150', 'https://openalex.org/W4387595589', 'https://openalex.org/W6828894009', 'https://openalex.org/W2972359262', 'https://openalex.org/W3198533616', 'https://openalex.org/W2107860279', 'https://openalex.org/W2144994235']",2024-05-28
https://openalex.org/W4411232650,https://doi.org/10.1109/taslpro.2025.3579310,ERVQ: Enhanced Residual Vector Quantization With Intra-and-Inter-Codebook Optimization for Neural Audio Codecs,,"['https://openalex.org/W6633114069', 'https://openalex.org/W2159644785', 'https://openalex.org/W2168098717', 'https://openalex.org/W4381786045', 'https://openalex.org/W4406417959', 'https://openalex.org/W6851724922', 'https://openalex.org/W4387595589', 'https://openalex.org/W6862144568', 'https://openalex.org/W2752796333', 'https://openalex.org/W2935711438', 'https://openalex.org/W4200219715', 'https://openalex.org/W3197590976', 'https://openalex.org/W4224916783', 'https://openalex.org/W3215615641', 'https://openalex.org/W4372270198', 'https://openalex.org/W4375869380', 'https://openalex.org/W6873870642', 'https://openalex.org/W4403127074', 'https://openalex.org/W4392902628', 'https://openalex.org/W4402672068', 'https://openalex.org/W6776218486', 'https://openalex.org/W6853515095', 'https://openalex.org/W4307323391', 'https://openalex.org/W2133665775', 'https://openalex.org/W4399875170', 'https://openalex.org/W4392903389', 'https://openalex.org/W6762931180', 'https://openalex.org/W6802517614', 'https://openalex.org/W6852581948', 'https://openalex.org/W3186609711', 'https://openalex.org/W4385823076', 'https://openalex.org/W4284957875', 'https://openalex.org/W2963182577', 'https://openalex.org/W2775336875', 'https://openalex.org/W2972354707', 'https://openalex.org/W3161744562', 'https://openalex.org/W4225287045', 'https://openalex.org/W4390872598', 'https://openalex.org/W4386065342', 'https://openalex.org/W6936113694', 'https://openalex.org/W2972359262', 'https://openalex.org/W4205689591', 'https://openalex.org/W4296068763', 'https://openalex.org/W1728888090', 'https://openalex.org/W2067295501', 'https://openalex.org/W4283067311', 'https://openalex.org/W4385822407', 'https://openalex.org/W2962788625', 'https://openalex.org/W4406461271', 'https://openalex.org/W4225956675']",2025-01-01
https://openalex.org/W4405709385,https://doi.org/10.1109/iscslp63861.2024.10800694,"The ISCSLP 2024 Conversational Voice Clone (CoVoC) Challenge: Tasks, Results and Findings",,"['https://openalex.org/W2963609956', 'https://openalex.org/W6763832098', 'https://openalex.org/W6796464841', 'https://openalex.org/W6852421699', 'https://openalex.org/W6848735303', 'https://openalex.org/W4392904093', 'https://openalex.org/W4402112175', 'https://openalex.org/W3198152857', 'https://openalex.org/W4402111455', 'https://openalex.org/W3203407300', 'https://openalex.org/W6852870047', 'https://openalex.org/W4395957972', 'https://openalex.org/W4390872297', 'https://openalex.org/W6853096648', 'https://openalex.org/W4390075359', 'https://openalex.org/W6846539466', 'https://openalex.org/W4387595589', 'https://openalex.org/W4283067311', 'https://openalex.org/W2962788625', 'https://openalex.org/W4307323391', 'https://openalex.org/W4402111239', 'https://openalex.org/W4372346850']",2024-11-07
https://openalex.org/W4405709441,https://doi.org/10.1109/iscslp63861.2024.10800708,Lightweight Language Model for Speech Synthesis: Attempts and Analysis,,"['https://openalex.org/W2964243274', 'https://openalex.org/W6763832098', 'https://openalex.org/W2903739847', 'https://openalex.org/W6777694618', 'https://openalex.org/W6778083308', 'https://openalex.org/W6795261426', 'https://openalex.org/W6778823374', 'https://openalex.org/W6767111847', 'https://openalex.org/W2963300588', 'https://openalex.org/W2975414524', 'https://openalex.org/W3015338123', 'https://openalex.org/W6783867762', 'https://openalex.org/W6796464841', 'https://openalex.org/W4385823163', 'https://openalex.org/W4382202703', 'https://openalex.org/W6848735303', 'https://openalex.org/W6936129901', 'https://openalex.org/W4307323391', 'https://openalex.org/W3030163527', 'https://openalex.org/W6850625674', 'https://openalex.org/W4385571011', 'https://openalex.org/W4387595589', 'https://openalex.org/W4392903389', 'https://openalex.org/W6640963894', 'https://openalex.org/W3215615641', 'https://openalex.org/W4402111455', 'https://openalex.org/W3161480375', 'https://openalex.org/W6847478871', 'https://openalex.org/W4391833199']",2024-11-07
https://openalex.org/W4406610179,https://doi.org/10.1109/lsp.2025.3532218,Improving Audio Explanations Using Audio Language Models,"Foundation models are widely utilised for their strong representational capabilities, driven by training on extensive datasets with self-supervised learning. The increasing complexity of these models highlights the importance of interpretability to enhance transparency and improve human understanding of their decision-making processes. Most existing interpretability methods explain model behaviour by attributing importance to individual data elements across different layers, based on their influence on the final prediction. These approaches often emphasise only the most relevant features, overlooking the broader representational space, removing less important features. In this study, we propose a novel framework for explanation generation that serves as an alternative to feature removal, offering a more comprehensive understanding of model behaviour. Our framework leverages the generative abilities of audio language models to replace removed features with contextually appropriate alternatives, providing a more complete view of the model's decision-making process. Through extensive evaluations on standard benchmarks, including keyword spotting and speech emotion recognition, our approach demonstrates its effectiveness in generating high-quality audio explanations.","['https://openalex.org/W6780218876', 'https://openalex.org/W6847363464', 'https://openalex.org/W3196974791', 'https://openalex.org/W3209059054', 'https://openalex.org/W3209984917', 'https://openalex.org/W6769196770', 'https://openalex.org/W4402669711', 'https://openalex.org/W6803378298', 'https://openalex.org/W4392172995', 'https://openalex.org/W6854866820', 'https://openalex.org/W6778883912', 'https://openalex.org/W4251179700', 'https://openalex.org/W6845479124', 'https://openalex.org/W2516809705', 'https://openalex.org/W6752170072', 'https://openalex.org/W1787224781', 'https://openalex.org/W6734194636', 'https://openalex.org/W6728458142', 'https://openalex.org/W6746084291', 'https://openalex.org/W4294975502', 'https://openalex.org/W6810185292', 'https://openalex.org/W6680012447', 'https://openalex.org/W6750391026', 'https://openalex.org/W2963749936', 'https://openalex.org/W6873799666', 'https://openalex.org/W4307323391', 'https://openalex.org/W3215615641', 'https://openalex.org/W6853188576', 'https://openalex.org/W4387595589', 'https://openalex.org/W6750665317', 'https://openalex.org/W6786585944', 'https://openalex.org/W6853096648', 'https://openalex.org/W2797583228', 'https://openalex.org/W4403364412', 'https://openalex.org/W4377010126', 'https://openalex.org/W3211224152', 'https://openalex.org/W2770398803', 'https://openalex.org/W3109943296', 'https://openalex.org/W4384918448']",2025-01-01
https://openalex.org/W4408351812,https://doi.org/10.1109/icassp49660.2025.10890141,Get Large Language Models Ready to Speak: A Late-fusion Approach for Speech Generation,,"['https://openalex.org/W6782879696', 'https://openalex.org/W6771713106', 'https://openalex.org/W2963159690', 'https://openalex.org/W6856794988', 'https://openalex.org/W6852975727', 'https://openalex.org/W6868761718', 'https://openalex.org/W4307323391', 'https://openalex.org/W6850334629', 'https://openalex.org/W6848735303', 'https://openalex.org/W4390075359', 'https://openalex.org/W4392903956', 'https://openalex.org/W4391021666', 'https://openalex.org/W6857054612', 'https://openalex.org/W4408353629', 'https://openalex.org/W6796581206', 'https://openalex.org/W2964243274', 'https://openalex.org/W2903739847', 'https://openalex.org/W6763832098', 'https://openalex.org/W4381786045', 'https://openalex.org/W4402672020', 'https://openalex.org/W6790356757', 'https://openalex.org/W6853611000', 'https://openalex.org/W4387595589', 'https://openalex.org/W6853998256', 'https://openalex.org/W6852781825', 'https://openalex.org/W4392904805', 'https://openalex.org/W4389524500', 'https://openalex.org/W6853530687', 'https://openalex.org/W4389518827', 'https://openalex.org/W6861618871', 'https://openalex.org/W6850218400', 'https://openalex.org/W6810673746', 'https://openalex.org/W6853096648', 'https://openalex.org/W4398777692', 'https://openalex.org/W6805710207', 'https://openalex.org/W4392903704', 'https://openalex.org/W7073593060', 'https://openalex.org/W6749838110']",2025-03-12
https://openalex.org/W4408352362,https://doi.org/10.1109/icassp49660.2025.10890560,Chain-of-Thought Prompting for Speech Translation,,"['https://openalex.org/W6810081322', 'https://openalex.org/W6778883912', 'https://openalex.org/W6860041859', 'https://openalex.org/W6850625674', 'https://openalex.org/W6856800273', 'https://openalex.org/W4391021623', 'https://openalex.org/W4392903956', 'https://openalex.org/W4391021666', 'https://openalex.org/W4392903872', 'https://openalex.org/W4392903288', 'https://openalex.org/W4392902925', 'https://openalex.org/W6861859833', 'https://openalex.org/W4392679398', 'https://openalex.org/W4385567149', 'https://openalex.org/W4392931630', 'https://openalex.org/W4205991051', 'https://openalex.org/W3174770825', 'https://openalex.org/W6809646742', 'https://openalex.org/W4226302523', 'https://openalex.org/W3011339933', 'https://openalex.org/W6743726175', 'https://openalex.org/W4391021773', 'https://openalex.org/W4391021627', 'https://openalex.org/W6847363464', 'https://openalex.org/W4402667113', 'https://openalex.org/W6859863615', 'https://openalex.org/W6873018358', 'https://openalex.org/W4402670331', 'https://openalex.org/W6767997687', 'https://openalex.org/W6769627184', 'https://openalex.org/W4402111558', 'https://openalex.org/W6857054612', 'https://openalex.org/W4387595589', 'https://openalex.org/W6796581206', 'https://openalex.org/W4319862635', 'https://openalex.org/W6767671539', 'https://openalex.org/W6767440493']",2025-03-12
https://openalex.org/W4408345880,https://doi.org/10.1109/icassp49660.2025.10887605,A Non-autoregressive Model for Joint STT and TTS,,"['https://openalex.org/W6762242920', 'https://openalex.org/W3205644108', 'https://openalex.org/W4387595589', 'https://openalex.org/W6866575372', 'https://openalex.org/W4401070302', 'https://openalex.org/W6869471027', 'https://openalex.org/W4402671610', 'https://openalex.org/W2127141656', 'https://openalex.org/W6763832098', 'https://openalex.org/W4319862474', 'https://openalex.org/W4225308107', 'https://openalex.org/W4392904348', 'https://openalex.org/W3169714379', 'https://openalex.org/W3097882114', 'https://openalex.org/W4385567350', 'https://openalex.org/W4372260576', 'https://openalex.org/W4391021684', 'https://openalex.org/W6780218876', 'https://openalex.org/W4225956675', 'https://openalex.org/W6847363464', 'https://openalex.org/W4402111799', 'https://openalex.org/W6917585676', 'https://openalex.org/W2972359262', 'https://openalex.org/W1494198834', 'https://openalex.org/W4385823191', 'https://openalex.org/W3097777922', 'https://openalex.org/W3024869864', 'https://openalex.org/W6783867762', 'https://openalex.org/W2936774411', 'https://openalex.org/W2407080277', 'https://openalex.org/W2963587345', 'https://openalex.org/W2183341477', 'https://openalex.org/W6600213771', 'https://openalex.org/W2937780860', 'https://openalex.org/W3197140813', 'https://openalex.org/W6778823374']",2025-03-12
https://openalex.org/W4405709464,https://doi.org/10.1109/iscslp63861.2024.10800375,Does Current Deepfake Audio Detection Model Effectively Detect ALM-Based Deepfake Audio?,,"['https://openalex.org/W4381786045', 'https://openalex.org/W6845479124', 'https://openalex.org/W6848735303', 'https://openalex.org/W6849105126', 'https://openalex.org/W6850334629', 'https://openalex.org/W6853611000', 'https://openalex.org/W6853096648', 'https://openalex.org/W6856126247', 'https://openalex.org/W4387595589', 'https://openalex.org/W6856434366', 'https://openalex.org/W6869425021', 'https://openalex.org/W4225527248', 'https://openalex.org/W4385822347', 'https://openalex.org/W4402112251', 'https://openalex.org/W4402111655', 'https://openalex.org/W4387665604', 'https://openalex.org/W3128666957', 'https://openalex.org/W4381198892', 'https://openalex.org/W6866143339', 'https://openalex.org/W4307323391', 'https://openalex.org/W6861001475', 'https://openalex.org/W6862435102', 'https://openalex.org/W6864145738', 'https://openalex.org/W6862144568', 'https://openalex.org/W6856362840', 'https://openalex.org/W4297841635', 'https://openalex.org/W2972811785', 'https://openalex.org/W3201773091']",2024-11-07
https://openalex.org/W4406611855,https://doi.org/10.1109/smc54092.2024.10831059,Vrefine: A Self-Refinement Approach for Enhanced Clarity and Quality in Text-to-Speech Models,,"['https://openalex.org/W6739901393', 'https://openalex.org/W4327525621', 'https://openalex.org/W4297677272', 'https://openalex.org/W6778883912', 'https://openalex.org/W4391833199', 'https://openalex.org/W4383860339', 'https://openalex.org/W4362508231', 'https://openalex.org/W4225784348', 'https://openalex.org/W3105867580', 'https://openalex.org/W3036601975', 'https://openalex.org/W3209059054', 'https://openalex.org/W3209984917', 'https://openalex.org/W3160799772', 'https://openalex.org/W1494198834', 'https://openalex.org/W3097945073', 'https://openalex.org/W2990594533', 'https://openalex.org/W4387595589', 'https://openalex.org/W2940703732']",2024-10-06
https://openalex.org/W4408352589,https://doi.org/10.1109/icassp49660.2025.10888384,Can Large Audio-Language Models Truly Hear? Tackling Hallucinations with Multi-Task Assessment and Stepwise Audio Reasoning,,"['https://openalex.org/W6859099255', 'https://openalex.org/W6870775139', 'https://openalex.org/W6857054612', 'https://openalex.org/W6853249747', 'https://openalex.org/W4391021627', 'https://openalex.org/W4404781855', 'https://openalex.org/W4404784428', 'https://openalex.org/W6861859833', 'https://openalex.org/W4387595589', 'https://openalex.org/W4392909390', 'https://openalex.org/W4391021666', 'https://openalex.org/W6852818750', 'https://openalex.org/W4391021623', 'https://openalex.org/W4402111222', 'https://openalex.org/W6870627845', 'https://openalex.org/W6856227084', 'https://openalex.org/W4404782655', 'https://openalex.org/W4406461677', 'https://openalex.org/W4402112110', 'https://openalex.org/W6856227841', 'https://openalex.org/W4412158322', 'https://openalex.org/W4404534210', 'https://openalex.org/W6857566567', 'https://openalex.org/W6861195436', 'https://openalex.org/W4309674289', 'https://openalex.org/W4321351832', 'https://openalex.org/W6856037140', 'https://openalex.org/W6857198620', 'https://openalex.org/W4386566667', 'https://openalex.org/W6857555576', 'https://openalex.org/W6858883836', 'https://openalex.org/W4404682098', 'https://openalex.org/W4392902623', 'https://openalex.org/W4402684170', 'https://openalex.org/W6871847987', 'https://openalex.org/W4402112183', 'https://openalex.org/W4389523832', 'https://openalex.org/W4403947172', 'https://openalex.org/W2945761034', 'https://openalex.org/W6869415701', 'https://openalex.org/W4225299287', 'https://openalex.org/W6857657557', 'https://openalex.org/W4392679398', 'https://openalex.org/W4392902953']",2025-03-12
https://openalex.org/W4408353388,https://doi.org/10.1109/icassp49660.2025.10888177,Codec-ASV: Exploring Neural Audio Codec For Speaker Representation Learning,,"['https://openalex.org/W3024869864', 'https://openalex.org/W2963371159', 'https://openalex.org/W4221154745', 'https://openalex.org/W2726515241', 'https://openalex.org/W2808631503', 'https://openalex.org/W4392902963', 'https://openalex.org/W4402112479', 'https://openalex.org/W6780218876', 'https://openalex.org/W3209984917', 'https://openalex.org/W3209059054', 'https://openalex.org/W4307323391', 'https://openalex.org/W6852581948', 'https://openalex.org/W4402111239', 'https://openalex.org/W3215615641', 'https://openalex.org/W4398152753', 'https://openalex.org/W4400111385', 'https://openalex.org/W6848735303', 'https://openalex.org/W6859099255', 'https://openalex.org/W4387595589', 'https://openalex.org/W4392904154', 'https://openalex.org/W4402118927', 'https://openalex.org/W2936774411', 'https://openalex.org/W3015611708', 'https://openalex.org/W2969985801', 'https://openalex.org/W3010893827', 'https://openalex.org/W6846187620', 'https://openalex.org/W3205878676']",2025-03-12
https://openalex.org/W4413167718,https://doi.org/10.1016/j.procs.2025.07.116,Leveraging Audio LLMs for Data Fault Detection in Audio Datasets,,"['https://openalex.org/W6750701765', 'https://openalex.org/W2088517004', 'https://openalex.org/W3146670357', 'https://openalex.org/W2598946096', 'https://openalex.org/W4387210951', 'https://openalex.org/W4388718054', 'https://openalex.org/W4387891768', 'https://openalex.org/W4387595589', 'https://openalex.org/W3083185154', 'https://openalex.org/W3034414373', 'https://openalex.org/W2748789698', 'https://openalex.org/W4393285751', 'https://openalex.org/W6739088070', 'https://openalex.org/W3163222347', 'https://openalex.org/W6756333562', 'https://openalex.org/W2900018096', 'https://openalex.org/W2990270730', 'https://openalex.org/W3128663834', 'https://openalex.org/W2903996579', 'https://openalex.org/W4286905325', 'https://openalex.org/W3156669901', 'https://openalex.org/W4318751724', 'https://openalex.org/W3208248887', 'https://openalex.org/W2052666245', 'https://openalex.org/W2030931454', 'https://openalex.org/W369786348', 'https://openalex.org/W4224903910']",2025-01-01
https://openalex.org/W4413229325,https://doi.org/10.1007/978-3-032-00712-4_20,Abnormal Speech Restoration for Speech Impaired Patients Using Deep Learning: Literature Survey,,"['https://openalex.org/W4235053688', 'https://openalex.org/W4308279136', 'https://openalex.org/W4403548557', 'https://openalex.org/W2142300631', 'https://openalex.org/W2152637773', 'https://openalex.org/W4402402589', 'https://openalex.org/W2972838300', 'https://openalex.org/W4403095159', 'https://openalex.org/W4247403446', 'https://openalex.org/W4403706479', 'https://openalex.org/W428767110', 'https://openalex.org/W4399657731', 'https://openalex.org/W4392909911', 'https://openalex.org/W4392910324', 'https://openalex.org/W3015707856', 'https://openalex.org/W4403322424', 'https://openalex.org/W4225289116', 'https://openalex.org/W3097881066', 'https://openalex.org/W4287905584', 'https://openalex.org/W4404855029', 'https://openalex.org/W1995193848', 'https://openalex.org/W4302765731', 'https://openalex.org/W180052447', 'https://openalex.org/W2018363392', 'https://openalex.org/W1494198834', 'https://openalex.org/W3036132020']",2025-01-01
https://openalex.org/W4405547956,https://doi.org/10.32388/758n37,Benchmarking Open-ended Audio Dialogue Understanding for Large Audio-Language Models,"Large Audio-Language Models (LALMs) have unclocked audio dialogue capabilities, where audio dialogues are a direct exchange of spoken language between LALMs and humans. Recent advances, such as GPT-4o, have enabled LALMs in back-and-forth audio dialogues with humans. This progression not only underscores the potential of LALMs but also broadens their applicability across a wide range of practical scenarios supported by audio dialogues. However, given these advancements, a comprehensive benchmark to evaluate the performance of LALMs in the open-ended audio dialogue understanding remains absent currently. To address this gap, we propose an Audio Dialogue Understanding Benchmark (ADU-Bench), which consists of 4 benchmark datasets. They assess the open-ended audio dialogue ability for LALMs in 3 general scenarios, 12 skills, 9 multilingual languages, and 4 categories of ambiguity handling. Notably, we _firstly propose the evaluation of ambiguity handling in audio dialogues_ that expresses different intentions beyond the same literal meaning of sentences, e.g., “Really!?” with different intonations. In summary, ADU-Bench includes over 20,000 open-ended audio dialogues for the assessment of LALMs. Through extensive experiments conducted on 13 LALMs, our analysis reveals that there is still considerable room for improvement in the audio dialogue understanding abilities of existing LALMs. In particular, they struggle with mathematical symbols and formulas, understanding human behavior such as roleplay, comprehending multiple languages, and handling audio dialogue ambiguities from different phonetic elements, such as intonations, pause positions, and homophones.","['https://openalex.org/W4389524500', 'https://openalex.org/W4386552581', 'https://openalex.org/W4388718054', 'https://openalex.org/W4387891768', 'https://openalex.org/W4391021666', 'https://openalex.org/W4391591726', 'https://openalex.org/W4402683976', 'https://openalex.org/W4403556012', 'https://openalex.org/W4402386435', 'https://openalex.org/W3196509775', 'https://openalex.org/W4226444650', 'https://openalex.org/W2030931454', 'https://openalex.org/W2803193013', 'https://openalex.org/W4402684170', 'https://openalex.org/W6852874933', 'https://openalex.org/W4402671584', 'https://openalex.org/W6852447913', 'https://openalex.org/W6856794988', 'https://openalex.org/W4392902623', 'https://openalex.org/W2912924812', 'https://openalex.org/W4385568240', 'https://openalex.org/W4385571440', 'https://openalex.org/W2995929068', 'https://openalex.org/W6803096969', 'https://openalex.org/W4367000491', 'https://openalex.org/W6800166007', 'https://openalex.org/W3083410900', 'https://openalex.org/W2889787757', 'https://openalex.org/W3159959439', 'https://openalex.org/W4384918448', 'https://openalex.org/W1985975449', 'https://openalex.org/W4387321091', 'https://openalex.org/W3034302278', 'https://openalex.org/W3217804443', 'https://openalex.org/W4400375155', 'https://openalex.org/W4397028323', 'https://openalex.org/W4386076050', 'https://openalex.org/W4388726687', 'https://openalex.org/W4391157527', 'https://openalex.org/W4395687052', 'https://openalex.org/W4403571375', 'https://openalex.org/W4399554777']",2024-12-18
https://openalex.org/W4413148405,https://doi.org/10.1016/j.engappai.2025.111909,An approach to optimizing semantic consistency for text-to-digital human generation,,"['https://openalex.org/W6851946153', 'https://openalex.org/W2944294033', 'https://openalex.org/W4310379947', 'https://openalex.org/W4404782964', 'https://openalex.org/W4402715838', 'https://openalex.org/W6870604698', 'https://openalex.org/W4390872769', 'https://openalex.org/W3211147706', 'https://openalex.org/W6839928859', 'https://openalex.org/W6862962928', 'https://openalex.org/W6877869408', 'https://openalex.org/W2981767644', 'https://openalex.org/W4404965628', 'https://openalex.org/W4386066799', 'https://openalex.org/W4388739184', 'https://openalex.org/W6858688131', 'https://openalex.org/W4305028650', 'https://openalex.org/W6852410717', 'https://openalex.org/W4396723768', 'https://openalex.org/W6849845267', 'https://openalex.org/W6851275496', 'https://openalex.org/W6848670183', 'https://openalex.org/W6839202631', 'https://openalex.org/W6852792400', 'https://openalex.org/W3081492798', 'https://openalex.org/W3204680331', 'https://openalex.org/W6873379071', 'https://openalex.org/W6851513886', 'https://openalex.org/W4386075487', 'https://openalex.org/W6850886341', 'https://openalex.org/W6767264202', 'https://openalex.org/W4391940619', 'https://openalex.org/W4393065402', 'https://openalex.org/W3180770160', 'https://openalex.org/W6809646742', 'https://openalex.org/W6879392220', 'https://openalex.org/W2883183894', 'https://openalex.org/W4406800520', 'https://openalex.org/W6864518445', 'https://openalex.org/W4403780835', 'https://openalex.org/W6853465110', 'https://openalex.org/W4304195432', 'https://openalex.org/W6872505480', 'https://openalex.org/W4402754089', 'https://openalex.org/W4386072021', 'https://openalex.org/W3109114891', 'https://openalex.org/W4402726937', 'https://openalex.org/W4380552023', 'https://openalex.org/W4378474282', 'https://openalex.org/W4394906559', 'https://openalex.org/W4234842379', 'https://openalex.org/W4403556012', 'https://openalex.org/W4409381826', 'https://openalex.org/W4283818626', 'https://openalex.org/W4221143046', 'https://openalex.org/W4361866031', 'https://openalex.org/W4362508231', 'https://openalex.org/W3105763085', 'https://openalex.org/W4403345408', 'https://openalex.org/W4353112996', 'https://openalex.org/W4413145441', 'https://openalex.org/W4377130677', 'https://openalex.org/W3101631197', 'https://openalex.org/W4403555397', 'https://openalex.org/W3008823916', 'https://openalex.org/W4409368378', 'https://openalex.org/W4366974303', 'https://openalex.org/W4366566341', 'https://openalex.org/W4382469130']",2025-08-13
https://openalex.org/W4404961720,https://doi.org/10.4018/979-8-3693-6562-5.ch011,Empowering Local Communities Through Blockchain Tourism Initiatives,"Using blockchain technology offers new opportunities in the tourism industry, primarily when focusing on local communities. This chapter identifies the workings of blockchain, focusing on theories, proposing the implementation of direct P2P transactions, smart contracts, and the concept of sustainable and responsible tourism. Blockchain eradicating intermediaries decreases the control of local service providers, helps them gain access to the international market, and gets a proper recompense. Besides, tokenizing assets and services offers the market new ways of crowdfunding and resource management. Further study areas should be oriented toward enhancing digital accessibility, fostering favourable regulatory policies, evaluating the effectiveness of the blockchain's implementation in local economies and investigating cross-platform integration with miscellaneous advanced technologies. Finally, the blockchain can open a new future for tourism development where local communities will be real gatekeepers of their lands in the contemporary globalization environment.","['https://openalex.org/W4401162003', 'https://openalex.org/W4401554369', 'https://openalex.org/W4393008877', 'https://openalex.org/W4399534939', 'https://openalex.org/W4399790363', 'https://openalex.org/W4388681003', 'https://openalex.org/W4401570865', 'https://openalex.org/W4399875913', 'https://openalex.org/W4386852992', 'https://openalex.org/W2921677524', 'https://openalex.org/W4400862452', 'https://openalex.org/W6885031890', 'https://openalex.org/W4399314472', 'https://openalex.org/W4381108851', 'https://openalex.org/W4394924727', 'https://openalex.org/W4400907049', 'https://openalex.org/W4400672472', 'https://openalex.org/W4401989734', 'https://openalex.org/W6922397414', 'https://openalex.org/W4387349298', 'https://openalex.org/W4388654756', 'https://openalex.org/W4401217032', 'https://openalex.org/W4400259844', 'https://openalex.org/W4394710907', 'https://openalex.org/W4399301428', 'https://openalex.org/W4402008063', 'https://openalex.org/W4391003031', 'https://openalex.org/W4390639866', 'https://openalex.org/W4393260001', 'https://openalex.org/W4394924777', 'https://openalex.org/W4391220021', 'https://openalex.org/W4391257290', 'https://openalex.org/W4401266099', 'https://openalex.org/W4392864082', 'https://openalex.org/W4394576933', 'https://openalex.org/W4400403740', 'https://openalex.org/W4398178018', 'https://openalex.org/W4390045927', 'https://openalex.org/W4383649628', 'https://openalex.org/W4395668666', 'https://openalex.org/W3081385448', 'https://openalex.org/W4399131158', 'https://openalex.org/W4385447773', 'https://openalex.org/W4401499507', 'https://openalex.org/W4401283983', 'https://openalex.org/W4387069701', 'https://openalex.org/W3128316308', 'https://openalex.org/W4392432446', 'https://openalex.org/W4401577065', 'https://openalex.org/W4390717274', 'https://openalex.org/W4401020689', 'https://openalex.org/W4401664890', 'https://openalex.org/W4394603007', 'https://openalex.org/W4401910807', 'https://openalex.org/W4399175345', 'https://openalex.org/W4391614328', 'https://openalex.org/W4390544338', 'https://openalex.org/W3194251664', 'https://openalex.org/W6884944819', 'https://openalex.org/W4392006143', 'https://openalex.org/W4403590045', 'https://openalex.org/W4398253984', 'https://openalex.org/W4313119398']",2024-12-03
https://openalex.org/W4405365191,https://doi.org/10.1016/j.eswa.2024.126036,Biologically inspired oscillating activation functions can bridge the performance gap between biological and artificial neurons,,"['https://openalex.org/W3023212902', 'https://openalex.org/W6803757184', 'https://openalex.org/W1955857676', 'https://openalex.org/W2963273475', 'https://openalex.org/W1971735090', 'https://openalex.org/W4400875868', 'https://openalex.org/W2998412226', 'https://openalex.org/W1572063013', 'https://openalex.org/W4213019189', 'https://openalex.org/W2069143585', 'https://openalex.org/W4400410093', 'https://openalex.org/W4388654737', 'https://openalex.org/W6869936331', 'https://openalex.org/W4401664886', 'https://openalex.org/W2139507590', 'https://openalex.org/W6870457274', 'https://openalex.org/W4319985117', 'https://openalex.org/W2016812413', 'https://openalex.org/W6756026151', 'https://openalex.org/W6870374150', 'https://openalex.org/W4387125416', 'https://openalex.org/W2751261182', 'https://openalex.org/W4300972885', 'https://openalex.org/W4289422878', 'https://openalex.org/W1677182931', 'https://openalex.org/W2086789740', 'https://openalex.org/W3041940404', 'https://openalex.org/W4287019248', 'https://openalex.org/W2969937244', 'https://openalex.org/W2963285578', 'https://openalex.org/W4400648152', 'https://openalex.org/W4288112928', 'https://openalex.org/W2899663614', 'https://openalex.org/W4223447028', 'https://openalex.org/W3118608800', 'https://openalex.org/W4403883071', 'https://openalex.org/W4220690982', 'https://openalex.org/W4206470917', 'https://openalex.org/W3202774390', 'https://openalex.org/W4320930577', 'https://openalex.org/W4320492148', 'https://openalex.org/W4400646707']",2024-12-13
https://openalex.org/W4409763016,https://doi.org/10.1109/taslpro.2025.3564168,VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing,,"['https://openalex.org/W6791353385', 'https://openalex.org/W6803872405', 'https://openalex.org/W6790019176', 'https://openalex.org/W4284898017', 'https://openalex.org/W3176445421', 'https://openalex.org/W4372266552', 'https://openalex.org/W4386071707', 'https://openalex.org/W6856659047', 'https://openalex.org/W4390075359', 'https://openalex.org/W6780218876', 'https://openalex.org/W3197411683', 'https://openalex.org/W6769196770', 'https://openalex.org/W3209059054', 'https://openalex.org/W4226033575', 'https://openalex.org/W2518172956', 'https://openalex.org/W4392903524', 'https://openalex.org/W4392909624', 'https://openalex.org/W4392931282', 'https://openalex.org/W2972943112', 'https://openalex.org/W3015265920', 'https://openalex.org/W2982223350', 'https://openalex.org/W3209984917', 'https://openalex.org/W2896457183', 'https://openalex.org/W6810673746', 'https://openalex.org/W4281492411', 'https://openalex.org/W2963609956', 'https://openalex.org/W6734815144', 'https://openalex.org/W2903739847', 'https://openalex.org/W6763832098', 'https://openalex.org/W6777694618', 'https://openalex.org/W3161296985', 'https://openalex.org/W6778883912', 'https://openalex.org/W4381786045', 'https://openalex.org/W4406417959', 'https://openalex.org/W6850334629', 'https://openalex.org/W4296068981', 'https://openalex.org/W6851724922', 'https://openalex.org/W4252812408', 'https://openalex.org/W3083423753', 'https://openalex.org/W3154451338', 'https://openalex.org/W3096524539', 'https://openalex.org/W3163475957', 'https://openalex.org/W4372260053', 'https://openalex.org/W4372260402', 'https://openalex.org/W4319779739', 'https://openalex.org/W2752796333', 'https://openalex.org/W3139170550', 'https://openalex.org/W3194613004', 'https://openalex.org/W3083565479', 'https://openalex.org/W6757422803', 'https://openalex.org/W6779823529', 'https://openalex.org/W6847363464', 'https://openalex.org/W2752782242', 'https://openalex.org/W6631190155', 'https://openalex.org/W3198533616', 'https://openalex.org/W2972359262', 'https://openalex.org/W4307323391', 'https://openalex.org/W6862144568', 'https://openalex.org/W6855885476', 'https://openalex.org/W4403883071', 'https://openalex.org/W3215615641']",2025-01-01
https://openalex.org/W4414416643,https://doi.org/10.1016/j.icte.2025.09.003,Reasoning beyond limits: Advances and open problems for LLMs,,"['https://openalex.org/W4398220480', 'https://openalex.org/W4380200821', 'https://openalex.org/W4409442257', 'https://openalex.org/W4407766932', 'https://openalex.org/W4409690413', 'https://openalex.org/W4403738616', 'https://openalex.org/W4401070451', 'https://openalex.org/W4399264055', 'https://openalex.org/W4390660205', 'https://openalex.org/W4404356490', 'https://openalex.org/W4408167800', 'https://openalex.org/W4407070057', 'https://openalex.org/W4404782883', 'https://openalex.org/W4391494850', 'https://openalex.org/W4395680645', 'https://openalex.org/W4385565879', 'https://openalex.org/W4406241919', 'https://openalex.org/W4409365576', 'https://openalex.org/W4319997775', 'https://openalex.org/W4328053639', 'https://openalex.org/W4405956164', 'https://openalex.org/W4403815770', 'https://openalex.org/W4404261162', 'https://openalex.org/W3175079695', 'https://openalex.org/W2736601468', 'https://openalex.org/W4406779522', 'https://openalex.org/W4406961529', 'https://openalex.org/W4401201879', 'https://openalex.org/W4399533471', 'https://openalex.org/W4378771755', 'https://openalex.org/W4404783063', 'https://openalex.org/W4412886823', 'https://openalex.org/W4403882351', 'https://openalex.org/W4406755521', 'https://openalex.org/W4406302175', 'https://openalex.org/W4389520462', 'https://openalex.org/W4403788644', 'https://openalex.org/W4386875181', 'https://openalex.org/W4393178592', 'https://openalex.org/W4404783166', 'https://openalex.org/W4307079201', 'https://openalex.org/W4403852092', 'https://openalex.org/W4403365357', 'https://openalex.org/W4402427562', 'https://openalex.org/W4400375367', 'https://openalex.org/W4394591144', 'https://openalex.org/W4405903187', 'https://openalex.org/W4406273114', 'https://openalex.org/W4287674181', 'https://openalex.org/W4403754500', 'https://openalex.org/W4403928638', 'https://openalex.org/W4391631327', 'https://openalex.org/W4403573893', 'https://openalex.org/W4402669965', 'https://openalex.org/W4310290453', 'https://openalex.org/W4362508231', 'https://openalex.org/W4405035707', 'https://openalex.org/W4287121196', 'https://openalex.org/W4353112996', 'https://openalex.org/W4404987838', 'https://openalex.org/W4406033006', 'https://openalex.org/W4405418995', 'https://openalex.org/W4391555989', 'https://openalex.org/W4403571128', 'https://openalex.org/W4407569461', 'https://openalex.org/W4385825419', 'https://openalex.org/W4406167410', 'https://openalex.org/W4399511904', 'https://openalex.org/W4409032716', 'https://openalex.org/W4321392130', 'https://openalex.org/W4286892945', 'https://openalex.org/W4406231568', 'https://openalex.org/W4409362682', 'https://openalex.org/W4403853618', 'https://openalex.org/W4400065264', 'https://openalex.org/W4405254469', 'https://openalex.org/W4390833439', 'https://openalex.org/W4386528753', 'https://openalex.org/W3169483174', 'https://openalex.org/W4391632210', 'https://openalex.org/W4403883071', 'https://openalex.org/W4407451021', 'https://openalex.org/W4396945613', 'https://openalex.org/W4251576962', 'https://openalex.org/W4393399080', 'https://openalex.org/W4402671952', 'https://openalex.org/W4403885362', 'https://openalex.org/W4406733515', 'https://openalex.org/W4394866661', 'https://openalex.org/W4226369848', 'https://openalex.org/W4405468015', 'https://openalex.org/W4406774573', 'https://openalex.org/W4389814663', 'https://openalex.org/W2594899909', 'https://openalex.org/W4385968027', 'https://openalex.org/W4226278401', 'https://openalex.org/W4391901232', 'https://openalex.org/W4404688462', 'https://openalex.org/W4402733601', 'https://openalex.org/W4402952822', 'https://openalex.org/W4385245566', 'https://openalex.org/W4390723179', 'https://openalex.org/W4391211961', 'https://openalex.org/W4221143046', 'https://openalex.org/W4403882887', 'https://openalex.org/W4404354211', 'https://openalex.org/W4390215452', 'https://openalex.org/W4404792937', 'https://openalex.org/W4389326242', 'https://openalex.org/W4392576594', 'https://openalex.org/W4387294612', 'https://openalex.org/W4407092048', 'https://openalex.org/W4399597391', 'https://openalex.org/W4403344241', 'https://openalex.org/W4406491470', 'https://openalex.org/W4400337928', 'https://openalex.org/W4407091812', 'https://openalex.org/W4404792928', 'https://openalex.org/W4407794264', 'https://openalex.org/W4311642023', 'https://openalex.org/W4402671689', 'https://openalex.org/W4293718192', 'https://openalex.org/W4410151876', 'https://openalex.org/W4411119998', 'https://openalex.org/W3040573126', 'https://openalex.org/W4403007247', 'https://openalex.org/W4407806833', 'https://openalex.org/W4399655853', 'https://openalex.org/W4412888562', 'https://openalex.org/W4403885103', 'https://openalex.org/W4406072085', 'https://openalex.org/W4398859186', 'https://openalex.org/W4392679398', 'https://openalex.org/W4402671600', 'https://openalex.org/W4404783159', 'https://openalex.org/W4406603682', 'https://openalex.org/W4366460421', 'https://openalex.org/W4397028161', 'https://openalex.org/W4391767144', 'https://openalex.org/W4403808820', 'https://openalex.org/W4406840883', 'https://openalex.org/W4406489046', 'https://openalex.org/W4393284539', 'https://openalex.org/W4402705340', 'https://openalex.org/W4407174758', 'https://openalex.org/W4399795506', 'https://openalex.org/W4405901456']",2025-09-23
https://openalex.org/W4412129261,https://doi.org/10.1109/taslpro.2025.3587459,MFA-KWS: Effective Keyword Spotting With Multi-Head Frame-Asynchronous Decoding,,"['https://openalex.org/W2783089003', 'https://openalex.org/W4206567542', 'https://openalex.org/W4389524500', 'https://openalex.org/W6873748455', 'https://openalex.org/W6873432530', 'https://openalex.org/W6873611305', 'https://openalex.org/W4403883071', 'https://openalex.org/W6875416224', 'https://openalex.org/W1496120315', 'https://openalex.org/W2962980711', 'https://openalex.org/W6757022092', 'https://openalex.org/W2972613398', 'https://openalex.org/W3160257947', 'https://openalex.org/W3162273446', 'https://openalex.org/W4296069322', 'https://openalex.org/W4283767777', 'https://openalex.org/W4372346399', 'https://openalex.org/W4372260220', 'https://openalex.org/W4385822437', 'https://openalex.org/W4385823483', 'https://openalex.org/W4392932011', 'https://openalex.org/W4392902956', 'https://openalex.org/W2034940213', 'https://openalex.org/W1485222997', 'https://openalex.org/W2963628261', 'https://openalex.org/W3096421563', 'https://openalex.org/W3097878195', 'https://openalex.org/W4372267500', 'https://openalex.org/W4392904576', 'https://openalex.org/W2407023693', 'https://openalex.org/W1983205135', 'https://openalex.org/W2587529061', 'https://openalex.org/W2963414149', 'https://openalex.org/W2938873567', 'https://openalex.org/W2510945575', 'https://openalex.org/W3163582231', 'https://openalex.org/W4283828241', 'https://openalex.org/W4391021514', 'https://openalex.org/W4392904393', 'https://openalex.org/W4408354367', 'https://openalex.org/W4402111963', 'https://openalex.org/W4408352627', 'https://openalex.org/W4224932156', 'https://openalex.org/W2507319753', 'https://openalex.org/W2748659049', 'https://openalex.org/W2962707338', 'https://openalex.org/W2797759721', 'https://openalex.org/W3015639015', 'https://openalex.org/W3161425572', 'https://openalex.org/W6638749077', 'https://openalex.org/W2976556660', 'https://openalex.org/W6769806307', 'https://openalex.org/W3016010032', 'https://openalex.org/W3095173472', 'https://openalex.org/W3160405885', 'https://openalex.org/W2526425061', 'https://openalex.org/W2739883972', 'https://openalex.org/W2766219058', 'https://openalex.org/W2962780374', 'https://openalex.org/W6767671539', 'https://openalex.org/W3207815550', 'https://openalex.org/W2127141656', 'https://openalex.org/W2507132449', 'https://openalex.org/W2548332580', 'https://openalex.org/W6851766456', 'https://openalex.org/W2969991587', 'https://openalex.org/W1494198834', 'https://openalex.org/W6754473786', 'https://openalex.org/W2972541922', 'https://openalex.org/W4283067311', 'https://openalex.org/W2407080277', 'https://openalex.org/W2936774411', 'https://openalex.org/W4221141722', 'https://openalex.org/W4224916427', 'https://openalex.org/W6757817989', 'https://openalex.org/W3163237592', 'https://openalex.org/W3094791070', 'https://openalex.org/W6845069390']",2025-01-01
https://openalex.org/W4417073408,https://doi.org/10.1145/3743093.3771012,A Visual Speech Language Model for Visual Text-to-Speech Task,,"['https://openalex.org/W2890952074', 'https://openalex.org/W4381786045', 'https://openalex.org/W4313065316', 'https://openalex.org/W4399554695', 'https://openalex.org/W4408352795', 'https://openalex.org/W4386057728', 'https://openalex.org/W4405354834', 'https://openalex.org/W4402683936', 'https://openalex.org/W4403883071', 'https://openalex.org/W3209059054', 'https://openalex.org/W3204420730', 'https://openalex.org/W4385822362', 'https://openalex.org/W4392904805', 'https://openalex.org/W2747874407', 'https://openalex.org/W4392931276', 'https://openalex.org/W6948441778', 'https://openalex.org/W3035626590', 'https://openalex.org/W4225956675', 'https://openalex.org/W4399695528', 'https://openalex.org/W4414833914', 'https://openalex.org/W2962780374', 'https://openalex.org/W4387323811', 'https://openalex.org/W3215615641', 'https://openalex.org/W4403791995', 'https://openalex.org/W4403160597', 'https://openalex.org/W4405900327']",2025-12-06
https://openalex.org/W4413178481,https://doi.org/10.1109/aiiot65859.2025.11105332,Multimodal AI for Seamless Communication: Integrating Computer Vision and Speech Translation with LLMs,,"['https://openalex.org/W2619383789', 'https://openalex.org/W2972495969', 'https://openalex.org/W6778883912', 'https://openalex.org/W4400169194', 'https://openalex.org/W4361994820', 'https://openalex.org/W6875249317', 'https://openalex.org/W4400896721', 'https://openalex.org/W6874953249', 'https://openalex.org/W6875015062', 'https://openalex.org/W4402618618', 'https://openalex.org/W6856794988', 'https://openalex.org/W6861363789', 'https://openalex.org/W6852776751', 'https://openalex.org/W4404784276', 'https://openalex.org/W6940711155', 'https://openalex.org/W6691603626', 'https://openalex.org/W6802318714', 'https://openalex.org/W2560730294', 'https://openalex.org/W3204130541', 'https://openalex.org/W4292779060', 'https://openalex.org/W4295246343', 'https://openalex.org/W4404990673', 'https://openalex.org/W4392341509', 'https://openalex.org/W4386655647', 'https://openalex.org/W4405470213', 'https://openalex.org/W4376167553', 'https://openalex.org/W4405032505']",2025-05-28
https://openalex.org/W4409120210,https://doi.org/10.1016/j.compbiomed.2025.110082,"Multimodal learning-based speech enhancement and separation, recent innovations, new horizons, challenges and real-world applications",,"['https://openalex.org/W4387350634', 'https://openalex.org/W6862177770', 'https://openalex.org/W4389459413', 'https://openalex.org/W1989034586', 'https://openalex.org/W6719599463', 'https://openalex.org/W4402645353', 'https://openalex.org/W4389677587', 'https://openalex.org/W2014621385', 'https://openalex.org/W2962866211', 'https://openalex.org/W2167734090', 'https://openalex.org/W6748691017', 'https://openalex.org/W3006414215', 'https://openalex.org/W3154807520', 'https://openalex.org/W2065428732', 'https://openalex.org/W2015394094', 'https://openalex.org/W2032099237', 'https://openalex.org/W2126366445', 'https://openalex.org/W2026914444', 'https://openalex.org/W2121861296', 'https://openalex.org/W3101410425', 'https://openalex.org/W3042111210', 'https://openalex.org/W4281479549', 'https://openalex.org/W4311122490', 'https://openalex.org/W3095323226', 'https://openalex.org/W2161226030', 'https://openalex.org/W6870660549', 'https://openalex.org/W6775598543', 'https://openalex.org/W6802218682', 'https://openalex.org/W2973231102', 'https://openalex.org/W4368361703', 'https://openalex.org/W4295951577', 'https://openalex.org/W4307286264', 'https://openalex.org/W4386826611', 'https://openalex.org/W4394606408', 'https://openalex.org/W4402419701', 'https://openalex.org/W6847062058', 'https://openalex.org/W4390452972', 'https://openalex.org/W3195438473', 'https://openalex.org/W4379929801', 'https://openalex.org/W3168463823', 'https://openalex.org/W6869882090', 'https://openalex.org/W6841484515', 'https://openalex.org/W4362579348', 'https://openalex.org/W4401387482', 'https://openalex.org/W4400625028', 'https://openalex.org/W2040782121', 'https://openalex.org/W1973669708', 'https://openalex.org/W2168610508', 'https://openalex.org/W6809859160', 'https://openalex.org/W2096819401', 'https://openalex.org/W4391216223', 'https://openalex.org/W6797438204', 'https://openalex.org/W4399447044', 'https://openalex.org/W6686978693', 'https://openalex.org/W2791524682', 'https://openalex.org/W2070126272', 'https://openalex.org/W4391286412', 'https://openalex.org/W2041498927', 'https://openalex.org/W4392878494', 'https://openalex.org/W2092262399', 'https://openalex.org/W6770282137', 'https://openalex.org/W2991361823', 'https://openalex.org/W4385938237', 'https://openalex.org/W6861492129', 'https://openalex.org/W6872015726', 'https://openalex.org/W4401117607', 'https://openalex.org/W6861465545', 'https://openalex.org/W6795338935', 'https://openalex.org/W2788241093', 'https://openalex.org/W6846089307', 'https://openalex.org/W6847683484', 'https://openalex.org/W6861006133', 'https://openalex.org/W3083484791', 'https://openalex.org/W2890952074', 'https://openalex.org/W2962831434', 'https://openalex.org/W6851351398', 'https://openalex.org/W4399472059', 'https://openalex.org/W4283722442', 'https://openalex.org/W4307640249', 'https://openalex.org/W4396835373', 'https://openalex.org/W6857563048', 'https://openalex.org/W4401268044', 'https://openalex.org/W4404370181', 'https://openalex.org/W6785775328', 'https://openalex.org/W6700087828', 'https://openalex.org/W3057611960', 'https://openalex.org/W4391853611', 'https://openalex.org/W6776614067', 'https://openalex.org/W4226025707', 'https://openalex.org/W6839279691', 'https://openalex.org/W4226208605', 'https://openalex.org/W4402535401', 'https://openalex.org/W6860324206', 'https://openalex.org/W3011424113', 'https://openalex.org/W6860358296', 'https://openalex.org/W6777214184', 'https://openalex.org/W6777308879', 'https://openalex.org/W4393405428', 'https://openalex.org/W6859162071', 'https://openalex.org/W2152826865', 'https://openalex.org/W2987172297', 'https://openalex.org/W4380373744', 'https://openalex.org/W6750591037', 'https://openalex.org/W6731918254', 'https://openalex.org/W4200635083', 'https://openalex.org/W6745600319', 'https://openalex.org/W2963082324', 'https://openalex.org/W6870905882', 'https://openalex.org/W6700220855', 'https://openalex.org/W2568308529', 'https://openalex.org/W6754904195', 'https://openalex.org/W6772946708', 'https://openalex.org/W2150769028', 'https://openalex.org/W1163572983', 'https://openalex.org/W4323664761', 'https://openalex.org/W4387557508', 'https://openalex.org/W2398776621', 'https://openalex.org/W6860641871', 'https://openalex.org/W4289665794', 'https://openalex.org/W6773488572', 'https://openalex.org/W6761565007', 'https://openalex.org/W4280557595', 'https://openalex.org/W6851138285', 'https://openalex.org/W6847259909', 'https://openalex.org/W6776868381', 'https://openalex.org/W6684851488', 'https://openalex.org/W6670245598', 'https://openalex.org/W6849908995', 'https://openalex.org/W4399980762', 'https://openalex.org/W2016574277', 'https://openalex.org/W4400874386', 'https://openalex.org/W4402536012', 'https://openalex.org/W4386254667', 'https://openalex.org/W2888868298', 'https://openalex.org/W4385163913', 'https://openalex.org/W6846918587', 'https://openalex.org/W2957628672', 'https://openalex.org/W4394011052', 'https://openalex.org/W4392136979', 'https://openalex.org/W4390943488', 'https://openalex.org/W6679434410', 'https://openalex.org/W6739901393', 'https://openalex.org/W6755207826', 'https://openalex.org/W6778883912', 'https://openalex.org/W4286640379', 'https://openalex.org/W3095405717', 'https://openalex.org/W6811146622', 'https://openalex.org/W6806280147', 'https://openalex.org/W4408354349', 'https://openalex.org/W3087647883', 'https://openalex.org/W4361284377', 'https://openalex.org/W2619383789', 'https://openalex.org/W6736855692', 'https://openalex.org/W6733328719', 'https://openalex.org/W3213995918', 'https://openalex.org/W6803954652', 'https://openalex.org/W3043636152', 'https://openalex.org/W4403495344', 'https://openalex.org/W3202520168', 'https://openalex.org/W6790654181', 'https://openalex.org/W4394798733', 'https://openalex.org/W6784372515', 'https://openalex.org/W6872618371', 'https://openalex.org/W6849977901', 'https://openalex.org/W6858492253', 'https://openalex.org/W6847140967', 'https://openalex.org/W4390742209', 'https://openalex.org/W4213299273', 'https://openalex.org/W6851358443', 'https://openalex.org/W2767290858', 'https://openalex.org/W6872214102', 'https://openalex.org/W4406156270', 'https://openalex.org/W4401594104', 'https://openalex.org/W6872507657', 'https://openalex.org/W2270470215', 'https://openalex.org/W6856471487', 'https://openalex.org/W6872571010', 'https://openalex.org/W6858724457', 'https://openalex.org/W6856163296', 'https://openalex.org/W6784764134', 'https://openalex.org/W4379797396', 'https://openalex.org/W3085139254', 'https://openalex.org/W6779163297', 'https://openalex.org/W6783944145', 'https://openalex.org/W6750570362', 'https://openalex.org/W6872150732', 'https://openalex.org/W6871103603', 'https://openalex.org/W6868897608', 'https://openalex.org/W6856841874', 'https://openalex.org/W4398138934', 'https://openalex.org/W4391631381', 'https://openalex.org/W6873531483', 'https://openalex.org/W4390692126', 'https://openalex.org/W3091830790', 'https://openalex.org/W6840170660', 'https://openalex.org/W6761691686', 'https://openalex.org/W4311890281', 'https://openalex.org/W2405774341', 'https://openalex.org/W6862682077', 'https://openalex.org/W6779216093', 'https://openalex.org/W4403059241', 'https://openalex.org/W6859855902', 'https://openalex.org/W6870370677', 'https://openalex.org/W4405028185', 'https://openalex.org/W6875125706', 'https://openalex.org/W6807193292', 'https://openalex.org/W6717465090', 'https://openalex.org/W4381598211', 'https://openalex.org/W6810338734', 'https://openalex.org/W4399154371', 'https://openalex.org/W6755788378', 'https://openalex.org/W6809694246', 'https://openalex.org/W6872070959', 'https://openalex.org/W2127851351', 'https://openalex.org/W4401607820', 'https://openalex.org/W2991487804', 'https://openalex.org/W6873921501', 'https://openalex.org/W6788484017', 'https://openalex.org/W6777340644', 'https://openalex.org/W4402592533', 'https://openalex.org/W6752376809', 'https://openalex.org/W6736158552', 'https://openalex.org/W2029199293', 'https://openalex.org/W6629717138', 'https://openalex.org/W4404178880', 'https://openalex.org/W4403095773', 'https://openalex.org/W6754420807', 'https://openalex.org/W6858166015', 'https://openalex.org/W2030931454', 'https://openalex.org/W4400111734', 'https://openalex.org/W6862148313', 'https://openalex.org/W6681313430', 'https://openalex.org/W4387394061', 'https://openalex.org/W3092190487', 'https://openalex.org/W2015143272', 'https://openalex.org/W6790727354', 'https://openalex.org/W4362610547', 'https://openalex.org/W6633117090', 'https://openalex.org/W2144404214', 'https://openalex.org/W4405755483', 'https://openalex.org/W2752380988', 'https://openalex.org/W2782626405', 'https://openalex.org/W6869026359', 'https://openalex.org/W4292387427', 'https://openalex.org/W4226372244', 'https://openalex.org/W6869357873', 'https://openalex.org/W6873077222', 'https://openalex.org/W4391873121', 'https://openalex.org/W3210240180', 'https://openalex.org/W4393899550', 'https://openalex.org/W4388878643', 'https://openalex.org/W3179031620', 'https://openalex.org/W4404293832', 'https://openalex.org/W6852525119', 'https://openalex.org/W4394734808', 'https://openalex.org/W4319875660', 'https://openalex.org/W4392044348', 'https://openalex.org/W6872189494', 'https://openalex.org/W4404446001', 'https://openalex.org/W4313328558', 'https://openalex.org/W4386800155', 'https://openalex.org/W4399468309', 'https://openalex.org/W4400935719', 'https://openalex.org/W4287147129', 'https://openalex.org/W4392520346', 'https://openalex.org/W6870890082', 'https://openalex.org/W4401728708', 'https://openalex.org/W6777337586', 'https://openalex.org/W4389300776', 'https://openalex.org/W2074587722', 'https://openalex.org/W6763500344', 'https://openalex.org/W4396985793', 'https://openalex.org/W6862494724', 'https://openalex.org/W2796431263', 'https://openalex.org/W4387872684', 'https://openalex.org/W2767014232', 'https://openalex.org/W4402112274', 'https://openalex.org/W4392222497', 'https://openalex.org/W4385478414', 'https://openalex.org/W2973062255', 'https://openalex.org/W2593463961', 'https://openalex.org/W4408354236', 'https://openalex.org/W4236352589', 'https://openalex.org/W4391832512', 'https://openalex.org/W4292910123', 'https://openalex.org/W4309793872', 'https://openalex.org/W4401809404', 'https://openalex.org/W4230347712', 'https://openalex.org/W3157352387', 'https://openalex.org/W4385486049', 'https://openalex.org/W2808631503', 'https://openalex.org/W4239508585', 'https://openalex.org/W4391854320', 'https://openalex.org/W3097777922', 'https://openalex.org/W4321392758', 'https://openalex.org/W4205577366', 'https://openalex.org/W3097173744', 'https://openalex.org/W4402343736', 'https://openalex.org/W4390690438', 'https://openalex.org/W3096214032', 'https://openalex.org/W2951529591', 'https://openalex.org/W4405796375', 'https://openalex.org/W4200164089', 'https://openalex.org/W4394596529', 'https://openalex.org/W4385819777', 'https://openalex.org/W4401151194', 'https://openalex.org/W4390874266', 'https://openalex.org/W2421316443', 'https://openalex.org/W3098686642', 'https://openalex.org/W3094502228', 'https://openalex.org/W1495679096', 'https://openalex.org/W3177525997', 'https://openalex.org/W4405335761', 'https://openalex.org/W4408356748', 'https://openalex.org/W4392903364', 'https://openalex.org/W335832833', 'https://openalex.org/W4387872955', 'https://openalex.org/W2188162373', 'https://openalex.org/W4246270042', 'https://openalex.org/W2133564696', 'https://openalex.org/W4288391450', 'https://openalex.org/W4399848548', 'https://openalex.org/W4391743098', 'https://openalex.org/W4402776467', 'https://openalex.org/W4406611083', 'https://openalex.org/W4392903825', 'https://openalex.org/W4234842379', 'https://openalex.org/W2972568703', 'https://openalex.org/W2962715207', 'https://openalex.org/W4318464963', 'https://openalex.org/W4231293494', 'https://openalex.org/W4389650257', 'https://openalex.org/W4292958273', 'https://openalex.org/W2606429533', 'https://openalex.org/W4404782655', 'https://openalex.org/W4386362212', 'https://openalex.org/W2921437497', 'https://openalex.org/W2604169470', 'https://openalex.org/W3033529678', 'https://openalex.org/W4205738764', 'https://openalex.org/W4403123192', 'https://openalex.org/W4405033245', 'https://openalex.org/W146900863', 'https://openalex.org/W2944972166', 'https://openalex.org/W4391770236', 'https://openalex.org/W4252531498', 'https://openalex.org/W4239752290', 'https://openalex.org/W4297841411', 'https://openalex.org/W2964171275', 'https://openalex.org/W4285506154', 'https://openalex.org/W3197260772', 'https://openalex.org/W2894931878', 'https://openalex.org/W4400488358', 'https://openalex.org/W4399597385', 'https://openalex.org/W3035837245', 'https://openalex.org/W3017923487', 'https://openalex.org/W4241908918', 'https://openalex.org/W2730845691', 'https://openalex.org/W2615063356', 'https://openalex.org/W2525579820', 'https://openalex.org/W4283837854', 'https://openalex.org/W2146334809', 'https://openalex.org/W2891205112', 'https://openalex.org/W4387617694', 'https://openalex.org/W4232379509', 'https://openalex.org/W4235670393', 'https://openalex.org/W4312747027', 'https://openalex.org/W4402896631', 'https://openalex.org/W139257441', 'https://openalex.org/W2963887950', 'https://openalex.org/W3096164988', 'https://openalex.org/W3024147341', 'https://openalex.org/W2972513594', 'https://openalex.org/W2889540509', 'https://openalex.org/W4400102178', 'https://openalex.org/W4235804971', 'https://openalex.org/W3033696290', 'https://openalex.org/W2790428568', 'https://openalex.org/W4403853820', 'https://openalex.org/W4402112611', 'https://openalex.org/W1570700205', 'https://openalex.org/W2290949550', 'https://openalex.org/W4400267085', 'https://openalex.org/W2541711215']",2025-04-03
https://openalex.org/W4412395640,https://doi.org/10.2139/ssrn.5350863,Histactor: Summon Your Favorite Historical Persona,,"['https://openalex.org/W4396601102', 'https://openalex.org/W4402671748', 'https://openalex.org/W4362655426', 'https://openalex.org/W3027879771', 'https://openalex.org/W4402671526', 'https://openalex.org/W4406271052', 'https://openalex.org/W4403620839', 'https://openalex.org/W4389157038', 'https://openalex.org/W4405470171', 'https://openalex.org/W4405765965', 'https://openalex.org/W4377865309', 'https://openalex.org/W4389524372', 'https://openalex.org/W4385822729', 'https://openalex.org/W4389599168', 'https://openalex.org/W4404781368', 'https://openalex.org/W4402670540', 'https://openalex.org/W4402343138', 'https://openalex.org/W4389984066', 'https://openalex.org/W4386044041', 'https://openalex.org/W4402501165', 'https://openalex.org/W2235592943']",2025-01-01
https://openalex.org/W4412395641,https://doi.org/10.2139/ssrn.5350864,Histactor: Summon Your Favorite Historical Persona,,"['https://openalex.org/W4396601102', 'https://openalex.org/W4402671748', 'https://openalex.org/W4362655426', 'https://openalex.org/W3027879771', 'https://openalex.org/W4402671526', 'https://openalex.org/W4404781368', 'https://openalex.org/W4402501165', 'https://openalex.org/W4389524372', 'https://openalex.org/W4405765965', 'https://openalex.org/W4389599168', 'https://openalex.org/W4403620839', 'https://openalex.org/W4377865309', 'https://openalex.org/W4385822729', 'https://openalex.org/W4389984066', 'https://openalex.org/W2235592943', 'https://openalex.org/W4405470171', 'https://openalex.org/W4386044041', 'https://openalex.org/W4402670540', 'https://openalex.org/W4402343138', 'https://openalex.org/W4406271052', 'https://openalex.org/W4389157038']",2025-01-01
https://openalex.org/W4409571543,https://doi.org/10.18287/2223-9537-2025-15-2-239-248,Using ontologies to contextualize queries to large language models,"The use of large language models has become a common phenomenon in question-answering and dialog systems. For this, the model must be pre-trained on prepared text data, enabling it to generate highly probable correct responses in a dialog with the user. However, answer quality decreases when the questions pertain to objects, processes, or phenomena that are less described in the texts used to train the model. For this purpose, data that is new to the model is transferred to it along with the user query in the form of context, which is usually generated using a vector database of text fragments. The article proposes to use an ontology of a subject area as a source of contextual data instead of a vector database. Ontologies are supplied with a lexical representation of their formalized terminology system to identify an ontological fragment relevant to the user query and convert it into a natural language text of the formed context. This allows to reduce the response text volume while improving its semantic alignment with the user query. The article discusses the minimum structural requirements for the lexical representation of an ontology, including natural language names, their forms for concepts and relations, as well as their lexical meanings. The application of the proposed approach is shown through an example of obtaining an answer to a question on scientific articles using a large language model. The advantages and disadvantages of the proposed approach are discussed.","['https://openalex.org/W4362515116', 'https://openalex.org/W4391766565', 'https://openalex.org/W4400434131', 'https://openalex.org/W4287811156', 'https://openalex.org/W4407806352', 'https://openalex.org/W4375870043', 'https://openalex.org/W4404835216', 'https://openalex.org/W3007672467', 'https://openalex.org/W6929416691', 'https://openalex.org/W4403589311', 'https://openalex.org/W3152801999', 'https://openalex.org/W4366460890', 'https://openalex.org/W4225580830', 'https://openalex.org/W4399253046', 'https://openalex.org/W3091908737', 'https://openalex.org/W153886719', 'https://openalex.org/W4389486960', 'https://openalex.org/W2525993530', 'https://openalex.org/W4288253152', 'https://openalex.org/W4302617179', 'https://openalex.org/W4386942668']",2025-04-18
https://openalex.org/W4412610143,https://doi.org/10.1109/lsp.2025.3591726,Dual-Branch Codec With Orthogonality Constraint and Knowledge Distillation for Noisy Environment,,"['https://openalex.org/W3215615641', 'https://openalex.org/W4307323391', 'https://openalex.org/W6853515095', 'https://openalex.org/W6848735303', 'https://openalex.org/W6853611000', 'https://openalex.org/W4406495593', 'https://openalex.org/W6852581948', 'https://openalex.org/W3163243746', 'https://openalex.org/W4385245566', 'https://openalex.org/W6874282688', 'https://openalex.org/W2752796333', 'https://openalex.org/W4402111239', 'https://openalex.org/W6871686990', 'https://openalex.org/W4402111456', 'https://openalex.org/W4403918744', 'https://openalex.org/W4400111385', 'https://openalex.org/W6966643191', 'https://openalex.org/W4372268681', 'https://openalex.org/W3160576174', 'https://openalex.org/W6856182397', 'https://openalex.org/W2078528584', 'https://openalex.org/W3049226960', 'https://openalex.org/W2998832642', 'https://openalex.org/W3016056257', 'https://openalex.org/W4404688015', 'https://openalex.org/W3097906045', 'https://openalex.org/W3096184950', 'https://openalex.org/W2006696725', 'https://openalex.org/W1494198834', 'https://openalex.org/W4392908343', 'https://openalex.org/W6757817989', 'https://openalex.org/W4224917453', 'https://openalex.org/W4402670057', 'https://openalex.org/W6783867762', 'https://openalex.org/W2067295501', 'https://openalex.org/W1552314771', 'https://openalex.org/W3196475561', 'https://openalex.org/W2204310803', 'https://openalex.org/W6847363464', 'https://openalex.org/W3081192838', 'https://openalex.org/W4402669711']",2025-01-01
https://openalex.org/W4413125390,https://doi.org/10.1109/lsp.2025.3596826,Token-Prediction-Based Post-Processing for Low-Bitrate Speech Coding,,"['https://openalex.org/W4399875170', 'https://openalex.org/W4375869380', 'https://openalex.org/W4403918744', 'https://openalex.org/W2126441393', 'https://openalex.org/W2131094339', 'https://openalex.org/W3097945073', 'https://openalex.org/W4395447416', 'https://openalex.org/W4410314146', 'https://openalex.org/W2809824582', 'https://openalex.org/W3016057201', 'https://openalex.org/W3015780049', 'https://openalex.org/W4225860133', 'https://openalex.org/W3188073270', 'https://openalex.org/W4408353418', 'https://openalex.org/W4252812408', 'https://openalex.org/W4406461725', 'https://openalex.org/W2972359262', 'https://openalex.org/W3196475561', 'https://openalex.org/W4225302959', 'https://openalex.org/W4225956675']",2025-01-01
https://openalex.org/W7105764868,https://doi.org/10.1007/s00034-025-03420-2,Enhanced Speech Compression in G.723 Audio Codec Through Mahalanobis Distance-Based Error Concealment Technique,,"['https://openalex.org/W3021717829', 'https://openalex.org/W4401093962', 'https://openalex.org/W4388296810', 'https://openalex.org/W4402905495', 'https://openalex.org/W4403918744', 'https://openalex.org/W3123316183', 'https://openalex.org/W3130150650', 'https://openalex.org/W3198785558', 'https://openalex.org/W4404132699', 'https://openalex.org/W4410242416']",2025-11-15
https://openalex.org/W4414880188,https://doi.org/10.1145/3746027.3755575,HiProbe-VAD: Video Anomaly Detection via Hidden States Probing in Tuning-Free Multimodal LLMs,"Video Anomaly Detection (VAD) aims to identify and locate deviations from normal patterns in video sequences. Traditional methods often struggle with substantial computational demands and a reliance on extensive labeled datasets, thereby restricting their practical applicability. To address these constraints, we propose HiProbe-VAD, a novel framework that leverages pre-trained Multimodal Large Language Models (MLLMs) for VAD without requiring fine-tuning. In this paper, we discover that the intermediate hidden states of MLLMs contain information-rich representations, exhibiting higher sensitivity and linear separability for anomalies compared to the output layer. To capitalize on this, we propose a Dynamic Layer Saliency Probing (DLSP) mechanism that intelligently identifies and extracts the most informative hidden states from the optimal intermediate layer during the MLLMs reasoning. Then a lightweight anomaly scorer and temporal localization module efficiently detects anomalies using these extracted hidden states and finally generate explanations. Experiments on the UCF-Crime and XD-Violence datasets demonstrate that HiProbe-VAD outperforms existing training-free and most traditional approaches. Furthermore, our framework exhibits remarkable cross-model generalization capabilities in different MLLMs without any tuning, unlocking the potential of pre-trained MLLMs for video anomaly detection and paving the way for more practical and scalable solutions.","['https://openalex.org/W4301785137', 'https://openalex.org/W6966624887', 'https://openalex.org/W4407794264', 'https://openalex.org/W4292787455', 'https://openalex.org/W4360836968', 'https://openalex.org/W4389501289', 'https://openalex.org/W4310421034', 'https://openalex.org/W4395687490', 'https://openalex.org/W4402713111', 'https://openalex.org/W4392489664', 'https://openalex.org/W3168600998', 'https://openalex.org/W4386071707', 'https://openalex.org/W2341058432', 'https://openalex.org/W4387735499', 'https://openalex.org/W4394737196', 'https://openalex.org/W4386597062', 'https://openalex.org/W4392224168', 'https://openalex.org/W4378072741', 'https://openalex.org/W2913338238', 'https://openalex.org/W4403370767', 'https://openalex.org/W4313053147', 'https://openalex.org/W4318718936', 'https://openalex.org/W4283811196', 'https://openalex.org/W4402727764', 'https://openalex.org/W2963610939', 'https://openalex.org/W3202590754', 'https://openalex.org/W2163612318', 'https://openalex.org/W3176309086', 'https://openalex.org/W4390833235', 'https://openalex.org/W4386076087', 'https://openalex.org/W2164489414', 'https://openalex.org/W4399758617', 'https://openalex.org/W4403928636', 'https://openalex.org/W4388514540', 'https://openalex.org/W4402265131', 'https://openalex.org/W3166396011', 'https://openalex.org/W3169651898', 'https://openalex.org/W4405355407', 'https://openalex.org/W4407185554', 'https://openalex.org/W2963795951', 'https://openalex.org/W4392271820', 'https://openalex.org/W4319299831', 'https://openalex.org/W3136793533', 'https://openalex.org/W4386597243', 'https://openalex.org/W4383468982', 'https://openalex.org/W4403791756', 'https://openalex.org/W2989623883', 'https://openalex.org/W4312723609', 'https://openalex.org/W3089682612', 'https://openalex.org/W4388685236', 'https://openalex.org/W4386150423', 'https://openalex.org/W4405434026', 'https://openalex.org/W2540481276', 'https://openalex.org/W4409051416', 'https://openalex.org/W4394839047', 'https://openalex.org/W4386076578', 'https://openalex.org/W4406032915', 'https://openalex.org/W4213101961', 'https://openalex.org/W4405033886', 'https://openalex.org/W4402704561', 'https://openalex.org/W4312554543', 'https://openalex.org/W4402753378', 'https://openalex.org/W4379918953', 'https://openalex.org/W4392781536', 'https://openalex.org/W4405253972', 'https://openalex.org/W4403749628', 'https://openalex.org/W4320559344', 'https://openalex.org/W4366850747']",2025-10-25
https://openalex.org/W4415215100,https://doi.org/10.3389/fnana.2025.1672016,Cajal’s legacy in the digital era: from neuroscience foundations to deep learning,"Santiago Ramón y Cajal’s pioneering work laid the foundations for modern neuroscience and continues to impact the development of artificial intelligence, particularly deep learning. His neuron theory, the principle of dynamic polarization, and his insights into brain plasticity and network organization have significantly influenced both our understanding of the nervous system and the design of artificial neural networks. This article reviews Cajal’s key contributions, explores their role in the evolution of AI, and emphasizes the enduring links between neuroscience and machine learning in the digital era.","['https://openalex.org/W4255825300', 'https://openalex.org/W4318351475', 'https://openalex.org/W4403345778', 'https://openalex.org/W4404392017', 'https://openalex.org/W3195577433', 'https://openalex.org/W4292779060', 'https://openalex.org/W2150602957', 'https://openalex.org/W2041640880', 'https://openalex.org/W3094502228', 'https://openalex.org/W2059371088', 'https://openalex.org/W4407422861', 'https://openalex.org/W2970100022', 'https://openalex.org/W4297631950', 'https://openalex.org/W2017561954', 'https://openalex.org/W4406779522', 'https://openalex.org/W2738724892', 'https://openalex.org/W2136922672', 'https://openalex.org/W2100495367', 'https://openalex.org/W2064675550', 'https://openalex.org/W4225591000', 'https://openalex.org/W2137983211', 'https://openalex.org/W2150884987', 'https://openalex.org/W4390723197', 'https://openalex.org/W2025653905', 'https://openalex.org/W3001279689', 'https://openalex.org/W65738273', 'https://openalex.org/W4405903187', 'https://openalex.org/W2965373594', 'https://openalex.org/W6948051673', 'https://openalex.org/W2735650662', 'https://openalex.org/W2596988505', 'https://openalex.org/W2735575534', 'https://openalex.org/W1995341919', 'https://openalex.org/W4327810158', 'https://openalex.org/W4399911984', 'https://openalex.org/W4311000453', 'https://openalex.org/W2406265206', 'https://openalex.org/W4295371519', 'https://openalex.org/W4401307635', 'https://openalex.org/W2040870580', 'https://openalex.org/W1498436455', 'https://openalex.org/W3194730353', 'https://openalex.org/W2076063813', 'https://openalex.org/W4406492615', 'https://openalex.org/W2001771035', 'https://openalex.org/W1527571715', 'https://openalex.org/W4409051416', 'https://openalex.org/W3010521003', 'https://openalex.org/W2122410182', 'https://openalex.org/W648152870', 'https://openalex.org/W4414014207', 'https://openalex.org/W2955050082', 'https://openalex.org/W1986702921']",2025-10-15
https://openalex.org/W4415538220,https://doi.org/10.1145/3746027.3762031,MERIA: Empathetic Response Generation via Parallel Disentanglement and Uncertainty-Gated Fusion,,"['https://openalex.org/W4389519275', 'https://openalex.org/W4283168218', 'https://openalex.org/W4387838478', 'https://openalex.org/W4404330874', 'https://openalex.org/W4408345871', 'https://openalex.org/W4402669711', 'https://openalex.org/W4412406576', 'https://openalex.org/W2096733369', 'https://openalex.org/W4415035877', 'https://openalex.org/W4409051416', 'https://openalex.org/W4382468300', 'https://openalex.org/W4410088807', 'https://openalex.org/W4404404954']",2025-10-25
https://openalex.org/W4415538776,https://doi.org/10.1145/3746027.3755575,HiProbe-VAD: Video Anomaly Detection via Hidden States Probing in Tuning-Free Multimodal LLMs,,"['https://openalex.org/W4301785137', 'https://openalex.org/W6966624887', 'https://openalex.org/W4407794264', 'https://openalex.org/W4292787455', 'https://openalex.org/W4360836968', 'https://openalex.org/W4389501289', 'https://openalex.org/W4310421034', 'https://openalex.org/W4395687490', 'https://openalex.org/W4402713111', 'https://openalex.org/W4392489664', 'https://openalex.org/W3168600998', 'https://openalex.org/W4386071707', 'https://openalex.org/W2341058432', 'https://openalex.org/W4387735499', 'https://openalex.org/W4394737196', 'https://openalex.org/W4386597062', 'https://openalex.org/W4392224168', 'https://openalex.org/W4378072741', 'https://openalex.org/W2913338238', 'https://openalex.org/W4403370767', 'https://openalex.org/W4313053147', 'https://openalex.org/W4318718936', 'https://openalex.org/W4283811196', 'https://openalex.org/W4402727764', 'https://openalex.org/W2963610939', 'https://openalex.org/W3202590754', 'https://openalex.org/W2163612318', 'https://openalex.org/W3176309086', 'https://openalex.org/W4390833235', 'https://openalex.org/W4386076087', 'https://openalex.org/W2164489414', 'https://openalex.org/W4399758617', 'https://openalex.org/W4403928636', 'https://openalex.org/W4388514540', 'https://openalex.org/W4402265131', 'https://openalex.org/W3166396011', 'https://openalex.org/W3169651898', 'https://openalex.org/W4405355407', 'https://openalex.org/W4407185554', 'https://openalex.org/W2963795951', 'https://openalex.org/W4392271820', 'https://openalex.org/W4319299831', 'https://openalex.org/W3136793533', 'https://openalex.org/W4386597243', 'https://openalex.org/W4383468982', 'https://openalex.org/W4403791756', 'https://openalex.org/W2989623883', 'https://openalex.org/W4312723609', 'https://openalex.org/W3089682612', 'https://openalex.org/W4388685236', 'https://openalex.org/W4386150423', 'https://openalex.org/W4405434026', 'https://openalex.org/W2540481276', 'https://openalex.org/W4409051416', 'https://openalex.org/W4394839047', 'https://openalex.org/W4386076578', 'https://openalex.org/W4406032915', 'https://openalex.org/W4213101961', 'https://openalex.org/W4405033886', 'https://openalex.org/W4402704561', 'https://openalex.org/W4312554543', 'https://openalex.org/W4402753378', 'https://openalex.org/W4379918953', 'https://openalex.org/W4392781536', 'https://openalex.org/W4405253972', 'https://openalex.org/W4403749628', 'https://openalex.org/W4320559344', 'https://openalex.org/W4366850747']",2025-10-25
https://openalex.org/W2483390977,https://doi.org/10.1016/j.cognition.2017.11.008,Cognitive science in the era of artificial intelligence: A roadmap for reverse-engineering the infant language-learner,,"['https://openalex.org/W2435103813', 'https://openalex.org/W2490982513', 'https://openalex.org/W6752889038', 'https://openalex.org/W6687566353', 'https://openalex.org/W6631811114', 'https://openalex.org/W1933349210', 'https://openalex.org/W2020607164', 'https://openalex.org/W2251803266', 'https://openalex.org/W3138934687', 'https://openalex.org/W2063303346', 'https://openalex.org/W2076493153', 'https://openalex.org/W6682841993', 'https://openalex.org/W588654549', 'https://openalex.org/W6678441659', 'https://openalex.org/W1984586950', 'https://openalex.org/W6680094886', 'https://openalex.org/W2407151108', 'https://openalex.org/W1911662473', 'https://openalex.org/W6675966832', 'https://openalex.org/W2164274485', 'https://openalex.org/W2134991647', 'https://openalex.org/W6679222651', 'https://openalex.org/W2161800831', 'https://openalex.org/W6745414609', 'https://openalex.org/W4234313254', 'https://openalex.org/W2084734691', 'https://openalex.org/W2035126305', 'https://openalex.org/W1982302451', 'https://openalex.org/W2027751800', 'https://openalex.org/W2046432510', 'https://openalex.org/W6697293080', 'https://openalex.org/W4245984049', 'https://openalex.org/W2011238950', 'https://openalex.org/W2110485445', 'https://openalex.org/W2046432185', 'https://openalex.org/W2107959623', 'https://openalex.org/W2000196122', 'https://openalex.org/W2057923756', 'https://openalex.org/W6648500443', 'https://openalex.org/W160318044', 'https://openalex.org/W6718561954', 'https://openalex.org/W2085297150', 'https://openalex.org/W2252172689', 'https://openalex.org/W6648374803', 'https://openalex.org/W2595479191', 'https://openalex.org/W2130518563', 'https://openalex.org/W2141038596', 'https://openalex.org/W1892018222', 'https://openalex.org/W2622671002', 'https://openalex.org/W2183182206', 'https://openalex.org/W2052262800', 'https://openalex.org/W2054704909', 'https://openalex.org/W1969005071', 'https://openalex.org/W2137967501', 'https://openalex.org/W2882319491', 'https://openalex.org/W2556930864', 'https://openalex.org/W2738724892', 'https://openalex.org/W2165545766', 'https://openalex.org/W2120321299', 'https://openalex.org/W1677182931', 'https://openalex.org/W2160815625', 'https://openalex.org/W2041394569', 'https://openalex.org/W2165345255', 'https://openalex.org/W2045495963', 'https://openalex.org/W2115912164', 'https://openalex.org/W2025482506', 'https://openalex.org/W1997125736', 'https://openalex.org/W2126953647', 'https://openalex.org/W2038056950', 'https://openalex.org/W2045343524', 'https://openalex.org/W2068116204', 'https://openalex.org/W2059824090', 'https://openalex.org/W6628771001', 'https://openalex.org/W2024899192', 'https://openalex.org/W1821584645', 'https://openalex.org/W2145056192', 'https://openalex.org/W2098500169', 'https://openalex.org/W2163605009', 'https://openalex.org/W1972159947', 'https://openalex.org/W2086880169', 'https://openalex.org/W2140661818', 'https://openalex.org/W1557379068', 'https://openalex.org/W1983578042', 'https://openalex.org/W6609936677', 'https://openalex.org/W2748742383', 'https://openalex.org/W2531882892', 'https://openalex.org/W2100768664', 'https://openalex.org/W6635469476', 'https://openalex.org/W2161002933', 'https://openalex.org/W2114156501', 'https://openalex.org/W2158653313', 'https://openalex.org/W2549835527', 'https://openalex.org/W2252142375', 'https://openalex.org/W2251025892', 'https://openalex.org/W6659825068', 'https://openalex.org/W2056323522', 'https://openalex.org/W6677594329', 'https://openalex.org/W2074488330', 'https://openalex.org/W2152496361', 'https://openalex.org/W2054948443', 'https://openalex.org/W2113153226', 'https://openalex.org/W2104752510', 'https://openalex.org/W2165627680', 'https://openalex.org/W2169991335', 'https://openalex.org/W2131070395', 'https://openalex.org/W1972102750', 'https://openalex.org/W2110221456', 'https://openalex.org/W1614298861', 'https://openalex.org/W2145339207', 'https://openalex.org/W1539935047', 'https://openalex.org/W2167834252', 'https://openalex.org/W2347098582', 'https://openalex.org/W2137918883', 'https://openalex.org/W2114347655', 'https://openalex.org/W2774845701', 'https://openalex.org/W4256214048', 'https://openalex.org/W2164747046', 'https://openalex.org/W6671047921', 'https://openalex.org/W2010188467', 'https://openalex.org/W2415378728', 'https://openalex.org/W2171849228', 'https://openalex.org/W2138410680', 'https://openalex.org/W6680143972', 'https://openalex.org/W4237938692', 'https://openalex.org/W2169578671', 'https://openalex.org/W1980862600', 'https://openalex.org/W2024534578', 'https://openalex.org/W2150820540', 'https://openalex.org/W2395899413', 'https://openalex.org/W2064135025', 'https://openalex.org/W2097515925', 'https://openalex.org/W2069048904', 'https://openalex.org/W6730578045', 'https://openalex.org/W2257979135', 'https://openalex.org/W6690317381', 'https://openalex.org/W2160783091', 'https://openalex.org/W1977811986', 'https://openalex.org/W2088110681', 'https://openalex.org/W2072364373', 'https://openalex.org/W2075208075', 'https://openalex.org/W2119165475', 'https://openalex.org/W2160464066', 'https://openalex.org/W1606268232', 'https://openalex.org/W2108443500', 'https://openalex.org/W1967307281', 'https://openalex.org/W2404799143', 'https://openalex.org/W4234079003', 'https://openalex.org/W2115099665', 'https://openalex.org/W2235661107', 'https://openalex.org/W6749972507', 'https://openalex.org/W2114831903', 'https://openalex.org/W2001771035', 'https://openalex.org/W1662133657', 'https://openalex.org/W2153767712', 'https://openalex.org/W2343593471', 'https://openalex.org/W2117041980', 'https://openalex.org/W2346964103', 'https://openalex.org/W6973666849', 'https://openalex.org/W1977531436', 'https://openalex.org/W2102040782', 'https://openalex.org/W4236521339', 'https://openalex.org/W2089883580', 'https://openalex.org/W2101509422', 'https://openalex.org/W2398830367', 'https://openalex.org/W2058616551', 'https://openalex.org/W2166571083', 'https://openalex.org/W2765364385', 'https://openalex.org/W4249427113', 'https://openalex.org/W2193413348', 'https://openalex.org/W2083148906', 'https://openalex.org/W2131273696', 'https://openalex.org/W2951493993', 'https://openalex.org/W2550821151', 'https://openalex.org/W2951279274', 'https://openalex.org/W4242257761', 'https://openalex.org/W1992638577', 'https://openalex.org/W2002103405', 'https://openalex.org/W1533806699', 'https://openalex.org/W2145482038', 'https://openalex.org/W1494198834', 'https://openalex.org/W2241947032', 'https://openalex.org/W2911978475', 'https://openalex.org/W4230637005', 'https://openalex.org/W1993750641', 'https://openalex.org/W4249920809', 'https://openalex.org/W2978172410', 'https://openalex.org/W4214717370', 'https://openalex.org/W2949382160', 'https://openalex.org/W2129705892', 'https://openalex.org/W2950761309', 'https://openalex.org/W2950005842', 'https://openalex.org/W635561569', 'https://openalex.org/W1993049588', 'https://openalex.org/W2963924008', 'https://openalex.org/W2727371918', 'https://openalex.org/W2442329935', 'https://openalex.org/W308248915', 'https://openalex.org/W2417262652', 'https://openalex.org/W2038185393', 'https://openalex.org/W2950416202', 'https://openalex.org/W2073022807', 'https://openalex.org/W1969885740', 'https://openalex.org/W579619532', 'https://openalex.org/W1508165687', 'https://openalex.org/W2063597751', 'https://openalex.org/W2103091632', 'https://openalex.org/W2740606810', 'https://openalex.org/W2004411856', 'https://openalex.org/W2121863487', 'https://openalex.org/W2159080219', 'https://openalex.org/W1534064252', 'https://openalex.org/W2038332531', 'https://openalex.org/W2328078142', 'https://openalex.org/W2101524054', 'https://openalex.org/W3098596645', 'https://openalex.org/W1568812407', 'https://openalex.org/W2153579005', 'https://openalex.org/W4210307751', 'https://openalex.org/W1524333225', 'https://openalex.org/W4238828888', 'https://openalex.org/W2070696251', 'https://openalex.org/W2011192906', 'https://openalex.org/W2914746235', 'https://openalex.org/W2233008733', 'https://openalex.org/W2026376994', 'https://openalex.org/W1581386830', 'https://openalex.org/W2162994165', 'https://openalex.org/W2963305465', 'https://openalex.org/W2460442863', 'https://openalex.org/W2778709969', 'https://openalex.org/W2101605059', 'https://openalex.org/W580971997', 'https://openalex.org/W2010315297', 'https://openalex.org/W2101196694', 'https://openalex.org/W1732736211', 'https://openalex.org/W2604132379', 'https://openalex.org/W2163028944', 'https://openalex.org/W50473013', 'https://openalex.org/W1532704504', 'https://openalex.org/W1706899115', 'https://openalex.org/W4298742451', 'https://openalex.org/W1480583224', 'https://openalex.org/W1740027839', 'https://openalex.org/W1602475114', 'https://openalex.org/W2519091744', 'https://openalex.org/W2111668269', 'https://openalex.org/W1778492285', 'https://openalex.org/W2026484633', 'https://openalex.org/W4285719527', 'https://openalex.org/W1493713542', 'https://openalex.org/W1974881914', 'https://openalex.org/W2055408826', 'https://openalex.org/W2786608204', 'https://openalex.org/W4254174115', 'https://openalex.org/W4252434862', 'https://openalex.org/W2949338531', 'https://openalex.org/W2168488947', 'https://openalex.org/W2125165590', 'https://openalex.org/W2105994703', 'https://openalex.org/W2111440402', 'https://openalex.org/W2025384410', 'https://openalex.org/W91514521', 'https://openalex.org/W2580178245', 'https://openalex.org/W2083367980', 'https://openalex.org/W1897139626', 'https://openalex.org/W2128359344', 'https://openalex.org/W4246559809', 'https://openalex.org/W1967924372', 'https://openalex.org/W2557283755', 'https://openalex.org/W1511986666', 'https://openalex.org/W4302803477', 'https://openalex.org/W2291963065', 'https://openalex.org/W1599016936', 'https://openalex.org/W2962753610', 'https://openalex.org/W2166206801', 'https://openalex.org/W2533523411', 'https://openalex.org/W4300988206', 'https://openalex.org/W2074546930', 'https://openalex.org/W4375819112', 'https://openalex.org/W2167543949', 'https://openalex.org/W2525778437', 'https://openalex.org/W2559169016', 'https://openalex.org/W4385773817', 'https://openalex.org/W2107917162', 'https://openalex.org/W4300721020', 'https://openalex.org/W1534728496', 'https://openalex.org/W1602422083', 'https://openalex.org/W4252994157', 'https://openalex.org/W2949640717', 'https://openalex.org/W4245122798', 'https://openalex.org/W2170716495', 'https://openalex.org/W1501555131', 'https://openalex.org/W2086426947', 'https://openalex.org/W1487155516', 'https://openalex.org/W2137735870', 'https://openalex.org/W2040300040', 'https://openalex.org/W1970208997', 'https://openalex.org/W2912805354', 'https://openalex.org/W2509570823', 'https://openalex.org/W3036063182', 'https://openalex.org/W182831726', 'https://openalex.org/W2798149936', 'https://openalex.org/W2328091329', 'https://openalex.org/W2728435982', 'https://openalex.org/W2108598243', 'https://openalex.org/W1532494781', 'https://openalex.org/W1832360048', 'https://openalex.org/W1917342115', 'https://openalex.org/W1932198206', 'https://openalex.org/W2312310973', 'https://openalex.org/W2541334028', 'https://openalex.org/W4388156388', 'https://openalex.org/W1993984071', 'https://openalex.org/W2950577311', 'https://openalex.org/W4300047444', 'https://openalex.org/W1922655562', 'https://openalex.org/W2963620343', 'https://openalex.org/W1506887983', 'https://openalex.org/W2134453531', 'https://openalex.org/W2398664438', 'https://openalex.org/W2963266252', 'https://openalex.org/W2398326651', 'https://openalex.org/W2164770604', 'https://openalex.org/W2078769636', 'https://openalex.org/W3083894204', 'https://openalex.org/W2161466446', 'https://openalex.org/W267509179', 'https://openalex.org/W2154095608', 'https://openalex.org/W2775670315', 'https://openalex.org/W2285479881', 'https://openalex.org/W4254816979', 'https://openalex.org/W2484448352', 'https://openalex.org/W2121114452', 'https://openalex.org/W4297159649', 'https://openalex.org/W2108622839', 'https://openalex.org/W1554540371', 'https://openalex.org/W72959365', 'https://openalex.org/W2094249282']",2018-01-08
https://openalex.org/W1529056402,https://doi.org/10.1017/cbo9780511576164,The Cambridge Handbook of Child Language,"The Cambridge Handbook of Child Language brings together the world's foremost researchers to provide a one-stop resource for the study of language acquisition and development. Grouped into five thematic sections, the handbook is organized by topic, making it easier for students and researchers to use when looking up specific in-depth information. It covers a wider range of subjects than any other handbook on the market, with chapters covering both theories and methods in child language research and tracing the development of language from prelinguistic infancy to teenager. Drawing on both established and more recent research, the Handbook surveys the crosslinguistic study of language acquisition; prelinguistic development; bilingualism; sign languages; specific language impairment, language and autism, Down syndrome and Williams syndrome. This book will be an essential reference for students and researchers working in linguistics, psychology, cognitive science, speech pathology, education and anthropology.",[],2009-01-01
https://openalex.org/W3197580070,https://doi.org/10.21437/interspeech.2021-1775,SUPERB: Speech Processing Universal PERformance Benchmark,"Self-supervised learning (SSL) has proven vital for advancing research in natural language processing (NLP) and computer vision (CV).The paradigm pretrains a shared model on large volumes of unlabeled data and achieves state-of-the-art (SOTA) for various tasks with minimal adaptation.However, the speech processing community lacks a similar setup to systematically explore the paradigm.To bridge this gap, we introduce Speech processing Universal PERformance Benchmark (SUPERB).SUPERB is a leaderboard to benchmark the performance of a shared model across a wide range of speech processing tasks with minimal architecture changes and labeled data.Among multiple usages of the shared model, we especially focus on extracting the representation learned from SSL for its preferable re-usability.We present a simple framework to solve SUPERB tasks by learning task-specialized lightweight prediction heads on top of the frozen shared model.Our results demonstrate that the framework is promising as SSL representations show competitive generalizability and accessibility across SUPERB tasks.We release SUPERB as a challenge with a leaderboard 1 and a benchmark toolkit 2 to fuel the research in representation learning and general speech processing.","['https://openalex.org/W2962739339', 'https://openalex.org/W3035164673', 'https://openalex.org/W4287553982', 'https://openalex.org/W2982223350', 'https://openalex.org/W4297808394', 'https://openalex.org/W2972943112', 'https://openalex.org/W3016181583', 'https://openalex.org/W3036601975', 'https://openalex.org/W3099944122', 'https://openalex.org/W2953190524', 'https://openalex.org/W2990873191', 'https://openalex.org/W3034238904', 'https://openalex.org/W2973157397', 'https://openalex.org/W2294718077', 'https://openalex.org/W3161223924', 'https://openalex.org/W2923014074', 'https://openalex.org/W4298277274', 'https://openalex.org/W1494198834', 'https://openalex.org/W2972584841', 'https://openalex.org/W2883725317', 'https://openalex.org/W2896457183', 'https://openalex.org/W3112034174', 'https://openalex.org/W2972949456', 'https://openalex.org/W4297683418', 'https://openalex.org/W3006926732', 'https://openalex.org/W3041561163', 'https://openalex.org/W3015213852', 'https://openalex.org/W2890964092', 'https://openalex.org/W2979476256', 'https://openalex.org/W2973049979', 'https://openalex.org/W3198858531', 'https://openalex.org/W3161627112', 'https://openalex.org/W3027008958', 'https://openalex.org/W2134800885', 'https://openalex.org/W3209059054', 'https://openalex.org/W2972382840', 'https://openalex.org/W2981087920', 'https://openalex.org/W4287591426', 'https://openalex.org/W3097286738', 'https://openalex.org/W2146334809']",2021-08-27
https://openalex.org/W2098500169,https://doi.org/10.1109/2.28,The 'neural' phonetic typewriter,"The factors that make speech recognition difficult are examined, and the potential of neural computers for this purpose is discussed. A speaker-adaptive system that transcribes dictation using an unlimited vocabulary is presented that is based on a neural network processor for the recognition of phonetic units of speech. The acoustic preprocessing, vector quantization, neural network model, and shortcut learning algorithm used are described. The utilization of phonotopic maps and of postprocessing in symbolic forms are discussed. Hardware implementations and performance of the neural networks are considered.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>","['https://openalex.org/W4240043473', 'https://openalex.org/W2002182716', 'https://openalex.org/W2083145261', 'https://openalex.org/W2034610397', 'https://openalex.org/W2171850596', 'https://openalex.org/W23758216', 'https://openalex.org/W3036512766', 'https://openalex.org/W2766736793', 'https://openalex.org/W2010470211', 'https://openalex.org/W1587362683', 'https://openalex.org/W1652505363']",1988-03-01
https://openalex.org/W2117041980,https://doi.org/10.3115/1557690.1557736,Unsupervised learning of acoustic sub-word units,"Accurate unsupervised learning of phonemes of a language directly from speech is demonstrated via an algorithm for joint unsupervised learning of the topology and parameters of a hidden Markov model (HMM); states and short state-sequences through this HMM correspond to the learnt sub-word units. The algorithm, originally proposed for unsupervised learning of allophonic variations within a given phoneme set, has been adapted to learn without any knowledge of the phonemes. An evaluation methodology is also proposed, whereby the state-sequence that aligns to a test utterance is transduced in an automatic manner to a phoneme-sequence and compared to its manual transcription. Over 85% phoneme recognition accuracy is demonstrated for speaker-dependent learning from fluent, large-vocabulary speech.","['https://openalex.org/W4298166701', 'https://openalex.org/W3034729383', 'https://openalex.org/W2101536075', 'https://openalex.org/W1971081490', 'https://openalex.org/W1949782964', 'https://openalex.org/W1918599710']",2008-01-01
https://openalex.org/W2170659185,https://doi.org/10.1109/icassp.2011.5947338,Unsupervised acoustic sub-word unit detection for query-by-example spoken term detection,"In this paper we present a method for automatically generating acoustic sub-word units that can substitute conventional phone models in a query-by-example spoken term detection system. We generate the sub-word units with a modified version of our speaker diarization system. Given a speech recording, the original diarization system generates a set of speaker models in an unsupervised manner without the need for training or development data. Modifying the diarization system to process the speech of a single speaker and decreasing the minimum segment duration constraint allows us to detect speaker-dependent sub-word units. For the task of query-by-example spoken term detection, we show that the pro posed system performs well on both broadcast and non-broadcast recordings, unlike a conventional phone-based system trained solely on broadcast data. A mean average precision of 0.28 and 0.38 was obtained for experiments on broadcast news and on a set of war veteran interviews, respectively.","['https://openalex.org/W1591300715', 'https://openalex.org/W6628911050', 'https://openalex.org/W2103360771', 'https://openalex.org/W6601311673', 'https://openalex.org/W6647712556', 'https://openalex.org/W2079460648', 'https://openalex.org/W1606268232', 'https://openalex.org/W2171019095', 'https://openalex.org/W2117041980', 'https://openalex.org/W6679327398', 'https://openalex.org/W6632102281', 'https://openalex.org/W2168175751', 'https://openalex.org/W2130408113', 'https://openalex.org/W1583620810', 'https://openalex.org/W1482605500', 'https://openalex.org/W2187637362', 'https://openalex.org/W1988540447', 'https://openalex.org/W1556474518', 'https://openalex.org/W2168561756', 'https://openalex.org/W30845872', 'https://openalex.org/W1534656595']",2011-05-01
https://openalex.org/W2025482506,https://doi.org/10.1109/icassp.2013.6639245,A summary of the 2012 JHU CLSP workshop on zero resource speech technologies and models of early language acquisition,"We summarize the accomplishments of a multi-disciplinary workshop exploring the computational and scientific issues surrounding zero resource (unsupervised) speech technologies and related models of early language acquisition. Centered around the tasks of phonetic and lexical discovery, we consider unified evaluation metrics, present two new approaches for improving speaker independence in the absence of supervision, and evaluate the application of Bayesian word segmentation algorithms to automatic subword unit tokenizations. Finally, we present two strategies for integrating zero resource techniques into supervised settings, demonstrating the potential of unsupervised methods to improve mainstream technologies.","['https://openalex.org/W2126377586', 'https://openalex.org/W2160306971', 'https://openalex.org/W2054948443', 'https://openalex.org/W1993660824', 'https://openalex.org/W2142152793', 'https://openalex.org/W1526995323', 'https://openalex.org/W2161952424', 'https://openalex.org/W2110073835', 'https://openalex.org/W6602180557', 'https://openalex.org/W6677207036', 'https://openalex.org/W2166391802', 'https://openalex.org/W2162638453', 'https://openalex.org/W2057007397', 'https://openalex.org/W2074546930', 'https://openalex.org/W2126449874', 'https://openalex.org/W6678998471', 'https://openalex.org/W6714100551', 'https://openalex.org/W1967924372', 'https://openalex.org/W1857273500', 'https://openalex.org/W2121947440', 'https://openalex.org/W2170580867', 'https://openalex.org/W6677461952', 'https://openalex.org/W30845872', 'https://openalex.org/W2114347655', 'https://openalex.org/W2406820985', 'https://openalex.org/W2401464865', 'https://openalex.org/W6607928866', 'https://openalex.org/W2117041980', 'https://openalex.org/W2062914951', 'https://openalex.org/W2142390309', 'https://openalex.org/W2399869768', 'https://openalex.org/W6676025551', 'https://openalex.org/W2126203737', 'https://openalex.org/W6675022971', 'https://openalex.org/W2114478143', 'https://openalex.org/W2407151108', 'https://openalex.org/W1779834323', 'https://openalex.org/W2126953647', 'https://openalex.org/W196692374', 'https://openalex.org/W2107959623', 'https://openalex.org/W3136512150', 'https://openalex.org/W2952343510', 'https://openalex.org/W2100768664', 'https://openalex.org/W2117786207', 'https://openalex.org/W52412328', 'https://openalex.org/W2117126688']",2013-05-01
https://openalex.org/W2020607164,https://doi.org/10.1109/icassp.2014.6855085,An auto-encoder based approach to unsupervised learning of subword units,In this paper we propose an autoencoder-based method for the unsupervised identification of subword units. We experiment with different types and architectures of autoencoders to asses what autoencoder properties are most important for this task. We first show that the encoded representation of speech produced by standard autencoders is more effective than Gaussian posteriorgrams in a spoken query classification task. Finally we evaluate the subword inventories produced by the proposed method both in terms of classification accuracy in a word classification task (with lexicon size up to 263 words) and in terms of consistency between subword transcription of different word examples of a same word type. The evaluation is carried out on Italian and American English datasets. © 2014 IEEE.,"['https://openalex.org/W6789826613', 'https://openalex.org/W2100495367', 'https://openalex.org/W7011707065', 'https://openalex.org/W6676071220', 'https://openalex.org/W2035424729', 'https://openalex.org/W2117041980', 'https://openalex.org/W2123237149', 'https://openalex.org/W6677919164', 'https://openalex.org/W6675022971', 'https://openalex.org/W2167655920', 'https://openalex.org/W1964917299', 'https://openalex.org/W6681096077', 'https://openalex.org/W2099415988', 'https://openalex.org/W2401464865', 'https://openalex.org/W2107789863', 'https://openalex.org/W2100768664', 'https://openalex.org/W2619993508', 'https://openalex.org/W3127686677', 'https://openalex.org/W2145094598', 'https://openalex.org/W2118858186', 'https://openalex.org/W2072128103', 'https://openalex.org/W2997574889', 'https://openalex.org/W2010800472']",2014-05-01
https://openalex.org/W2346964103,https://doi.org/10.1016/j.procs.2016.04.031,The Zero Resource Speech Challenge 2015: Proposed Approaches and Results,"This paper reports on the results of the Zero Resource Speech Challenge 2015, the first unified benchmark for zero resource speech technology, which aims at the unsupervised discovery of subword and word units from raw speech. This paper discusses the motivation for the challenge, its data sets, tasks and baseline systems. We outline the ideas behind the systems that were submitted for the two challenge tracks: unsupervised subword unit modeling and spoken term discovery, and summarize their results. The results obtained by participating teams show great promise; many systems beat the provided baselines and some even perform better than comparable supervised systems.","['https://openalex.org/W2025482506', 'https://openalex.org/W2346964103', 'https://openalex.org/W2400668844', 'https://openalex.org/W2396043527', 'https://openalex.org/W2402366697', 'https://openalex.org/W2399576818', 'https://openalex.org/W2407614114', 'https://openalex.org/W2398490608', 'https://openalex.org/W1796128977', 'https://openalex.org/W2404799143', 'https://openalex.org/W2044138293', 'https://openalex.org/W2238331496', 'https://openalex.org/W2247128061', 'https://openalex.org/W2395899413', 'https://openalex.org/W2406349064', 'https://openalex.org/W2251025892', 'https://openalex.org/W2057007397', 'https://openalex.org/W2117126688', 'https://openalex.org/W2052697931', 'https://openalex.org/W2011845089', 'https://openalex.org/W2786608204']",2016-01-01
https://openalex.org/W2940544976,https://doi.org/10.21437/interspeech.2019-2904,The Zero Resource Speech Challenge 2019: TTS Without T,"We present the Zero Resource Speech Challenge 2019, which proposes to build a\nspeech synthesizer without any text or phonetic labels: hence, TTS without T\n(text-to-speech without text). We provide raw audio for a target voice in an\nunknown language (the Voice dataset), but no alignment, text or labels.\nParticipants must discover subword units in an unsupervised way (using the Unit\nDiscovery dataset) and align them to the voice recordings in a way that works\nbest for the purpose of synthesizing novel utterances from novel speakers,\nsimilar to the target speaker's voice. We describe the metrics used for\nevaluation, a baseline system consisting of unsupervised subword unit discovery\nplus a standard TTS system, and a topline TTS using gold phoneme\ntranscriptions. We present an overview of the 19 submitted systems from 10\nteams and discuss the main results.\n","['https://openalex.org/W3125709657', 'https://openalex.org/W2962693497', 'https://openalex.org/W2963830550', 'https://openalex.org/W1524333225', 'https://openalex.org/W2892140764', 'https://openalex.org/W2134202996', 'https://openalex.org/W2964243274', 'https://openalex.org/W2972867623', 'https://openalex.org/W2963799213', 'https://openalex.org/W2774848319', 'https://openalex.org/W2962699523', 'https://openalex.org/W2973013862', 'https://openalex.org/W2947445680', 'https://openalex.org/W2766812927', 'https://openalex.org/W2963620343', 'https://openalex.org/W2950414763', 'https://openalex.org/W2547039119', 'https://openalex.org/W2598638573', 'https://openalex.org/W2745710152', 'https://openalex.org/W2519091744', 'https://openalex.org/W2972374322', 'https://openalex.org/W2584032004', 'https://openalex.org/W2964135678', 'https://openalex.org/W2532494225', 'https://openalex.org/W2347098582', 'https://openalex.org/W2972964185', 'https://openalex.org/W2346964103', 'https://openalex.org/W2787447541', 'https://openalex.org/W2964115348', 'https://openalex.org/W2020607164']",2019-09-13
https://openalex.org/W3093096176,https://doi.org/10.21437/interspeech.2020-2743,The Zero Resource Speech Challenge 2020: Discovering Discrete Subword and Word Units,"We present the Zero Resource Speech Challenge 2020, which aims at learning speech representations from raw audio signals without any labels. It combines the data sets and metrics from two previous benchmarks (2017 and 2019) and features two tasks which tap into two levels of speech representation. The first task is to discover low bit-rate subword representations that optimize the quality of speech synthesis; the second one is to discover word-like units from unsegmented raw speech. We present the results of the twenty submitted models and discuss the implications of the main findings for unsupervised speech learning.",[],2020-10-25
https://openalex.org/W2396043527,https://doi.org/10.21437/interspeech.2015-639,Discovering discrete subword units with binarized autoencoders and hidden-Markov-model encoders,,"['https://openalex.org/W1545920196', 'https://openalex.org/W2099415988', 'https://openalex.org/W2055408826', 'https://openalex.org/W2913932916', 'https://openalex.org/W2049633694', 'https://openalex.org/W2117041980', 'https://openalex.org/W2231075402', 'https://openalex.org/W2170353620', 'https://openalex.org/W1964917299', 'https://openalex.org/W2100768664', 'https://openalex.org/W2020607164', 'https://openalex.org/W2401464865', 'https://openalex.org/W2100495367']",2015-09-06
https://openalex.org/W2402366697,https://doi.org/10.21437/interspeech.2015-643,Using articulatory features and inferred phonological segments in zero resource speech processing,,[],2015-09-06
https://openalex.org/W2399576818,https://doi.org/10.21437/interspeech.2015-642,Parallel inference of dirichlet process Gaussian mixture models for unsupervised acoustic modeling: a feasibility study,"We adopt a Dirichlet process Gaussian mixture model (DPGMM) for unsupervised acoustic modeling and represent speech frames with Gaussian posteriorgrams. The model performs unsupervised clustering on untranscribed data, and each Gaussian component can be considered as a cluster of sounds from various speakers. The model infers its model complexity (i.e. the number of Gaussian components) from the data. For computation efficiency, we use a parallel sampler for the model inference. Our experiments are conducted on the corpus provided by the zero resource speech challenge. Experimental results show that the unsupervised DPGMM posteriorgrams obviously outperformMFCC, and perform comparably to the posteriorgrams derived from language-mismatched phoneme recognizers in terms of the error rate of ABX discrimination test. The error rates can be further reduced by the fusion of these two kinds of posteriorgrams.","['https://openalex.org/W2406349064', 'https://openalex.org/W2119187236', 'https://openalex.org/W2106284094', 'https://openalex.org/W2114347655', 'https://openalex.org/W2049142189', 'https://openalex.org/W2125534887', 'https://openalex.org/W2127498532', 'https://openalex.org/W2151967501', 'https://openalex.org/W66167291', 'https://openalex.org/W2125247927', 'https://openalex.org/W2395899413', 'https://openalex.org/W2079460648', 'https://openalex.org/W1967924372', 'https://openalex.org/W2020607164', 'https://openalex.org/W2213520355', 'https://openalex.org/W2399363370', 'https://openalex.org/W2126203737', 'https://openalex.org/W2406820985', 'https://openalex.org/W2117041980', 'https://openalex.org/W2100768664', 'https://openalex.org/W1997505733', 'https://openalex.org/W2170659185', 'https://openalex.org/W2078769636', 'https://openalex.org/W2052697931', 'https://openalex.org/W2171019095', 'https://openalex.org/W2065136108', 'https://openalex.org/W1503398984', 'https://openalex.org/W2168319451', 'https://openalex.org/W2044138293', 'https://openalex.org/W2080972498', 'https://openalex.org/W1975728937', 'https://openalex.org/W2162021827', 'https://openalex.org/W1833498382', 'https://openalex.org/W1545920196', 'https://openalex.org/W2154085905', 'https://openalex.org/W2128032727', 'https://openalex.org/W2110589736']",2015-09-06
https://openalex.org/W2745710152,https://doi.org/10.21437/glu.2017-6,Partitioning of Posteriorgrams Using Siamese Models for Unsupervised Acoustic Modelling,"Unsupervised methods tend to discover highly speaker-specific representations of speech.We propose a method for improving the quality of posteriorgrams generated from an unsupervised model through partitioning of the latent classes.We do this by training a sparse siamese model to find a linear transformation of the input posteriorgrams to lower-dimensional posteriorgrams.The siamese model makes use of same-category and differentcategory speech fragment pairs obtained by unsupervised term discovery.After training, the model is converted into an exact partitioning of the posteriorgrams.We evaluate the model on the minimal-pair ABX task in the context of the Zero Resource Speech Challenge.We are able to demonstrate that our method significantly reduces the dimensionality of standard Gaussian mixture model posteriorgrams, while still making them more robust to speaker variations.This suggests that the model may be viable as a general post-processing step to improve probabilistic acoustic features obtained by unsupervised learning.","['https://openalex.org/W2404799143', 'https://openalex.org/W2964121744', 'https://openalex.org/W1987971958', 'https://openalex.org/W1486019888', 'https://openalex.org/W2052697931', 'https://openalex.org/W113159538', 'https://openalex.org/W2171590421', 'https://openalex.org/W2101234009', 'https://openalex.org/W1796128977', 'https://openalex.org/W2401464865', 'https://openalex.org/W2395899413', 'https://openalex.org/W2097473479', 'https://openalex.org/W1991274470', 'https://openalex.org/W2245493112', 'https://openalex.org/W2346964103', 'https://openalex.org/W2114347655', 'https://openalex.org/W2400549570', 'https://openalex.org/W2057007397', 'https://openalex.org/W2117041980', 'https://openalex.org/W2786608204', 'https://openalex.org/W2078769636', 'https://openalex.org/W1522301498', 'https://openalex.org/W2128780426', 'https://openalex.org/W2072396742', 'https://openalex.org/W1967924372', 'https://openalex.org/W1545920196', 'https://openalex.org/W2079460648', 'https://openalex.org/W148837159', 'https://openalex.org/W2399576818', 'https://openalex.org/W2384495648', 'https://openalex.org/W2345811097', 'https://openalex.org/W2100768664', 'https://openalex.org/W2400864884', 'https://openalex.org/W2170659185', 'https://openalex.org/W2104104263', 'https://openalex.org/W1957665339', 'https://openalex.org/W2345968833', 'https://openalex.org/W2036964623', 'https://openalex.org/W2132481658']",2017-08-25
https://openalex.org/W2345811097,https://doi.org/10.1016/j.procs.2016.04.032,Unsupervised Linear Discriminant Analysis for Supporting DPGMM Clustering in the Zero Resource Scenario,"In this work we make use of unsupervised linear discriminant analysis (LDA) to support acoustic unit discovery in a zero resource scenario. The idea is to automatically find a mapping of feature vectors into a subspace that is more suitable for Dirichlet process Gaussian mixture model (DPGMM) based clustering, without the need of supervision. Supervised acoustic modeling typically makes use of feature transformations such as LDA to minimize intra-class discriminability, to maximize inter-class discriminability and to extract relevant informations from high-dimensional features spanning larger contexts. The need of class labels makes it difficult to use this technique in a zero resource setting where the classes and even their amount are unknown. To overcome this issue we use a first iteration of DPGMM clustering on standard features to generate labels for the data, that serve as basis for learning a proper transformation. A second clustering operates on the transformed features. The application of unsupervised LDA demonstrably leads to better clustering results given the unsupervised data. We show that the improved input features consistently outperform our baseline input features.","['https://openalex.org/W2118841860', 'https://openalex.org/W2114347655', 'https://openalex.org/W2117041980', 'https://openalex.org/W2126203737', 'https://openalex.org/W1502957213', 'https://openalex.org/W1997505733', 'https://openalex.org/W2399576818', 'https://openalex.org/W2001619934', 'https://openalex.org/W2064210461', 'https://openalex.org/W2402014506', 'https://openalex.org/W1981276685', 'https://openalex.org/W2346964103', 'https://openalex.org/W2395899413', 'https://openalex.org/W2294798173', 'https://openalex.org/W2071128523', 'https://openalex.org/W66167291', 'https://openalex.org/W2119187236', 'https://openalex.org/W2786608204', 'https://openalex.org/W2128032727']",2016-01-01
https://openalex.org/W1796128977,https://doi.org/10.21437/interspeech.2015-644,A comparison of neural network methods for unsupervised representation learning on the zero resource speech challenge,"The success of supervised deep neural networks (DNNs) in speech recognition cannot be transferred to zero-resource languages where the requisite transcriptions are unavailable. We investigate unsupervised neural network based methods for learning frame-level representations. Good frame representations eliminate differences in accent, gender, channel characteristics, and other factors to model subword units for withinand acrossspeaker phonetic discrimination. We enhance the correspondence autoencoder (cAE) and show that it can transform Mel Frequency Cepstral Coefficients (MFCCs) into more effective frame representations given a set of matched word pairs from an unsupervised term discovery (UTD) system. The cAE combines the feature extraction power of autoencoders with the weak supervision signal from UTD pairs to better approximate the extrinsic task’s objective during training. We use the Zero Resource Speech Challenge’s minimal triphone pair ABX discrimination task to evaluate our methods. Optimizing a cAE architecture on English and applying it to a zero-resource language, Xitsonga, we obtain a relative error rate reduction of 35% compared to the original MFCCs. We also show that Xitsonga frame representations extracted from the bottleneck layer of a supervised DNN trained on English can be further enhanced by the cAE, yielding a relative error rate reduction of 39%.","['https://openalex.org/W2044138293', 'https://openalex.org/W2107878631', 'https://openalex.org/W2112688413', 'https://openalex.org/W1606347560', 'https://openalex.org/W2002318609', 'https://openalex.org/W2786608204', 'https://openalex.org/W2057007397', 'https://openalex.org/W2026369565', 'https://openalex.org/W66167291', 'https://openalex.org/W2146502635', 'https://openalex.org/W2100495367', 'https://openalex.org/W2395899413', 'https://openalex.org/W2017257315', 'https://openalex.org/W2145094598', 'https://openalex.org/W2148154194', 'https://openalex.org/W2407151108', 'https://openalex.org/W2052697931', 'https://openalex.org/W3028642772', 'https://openalex.org/W2145410271', 'https://openalex.org/W2020607164', 'https://openalex.org/W4285719527', 'https://openalex.org/W2025768430', 'https://openalex.org/W1524333225', 'https://openalex.org/W1545920196', 'https://openalex.org/W2406349064']",2015-09-06
https://openalex.org/W2522012644,https://doi.org/10.1007/978-3-319-45925-7_7,Articulatory Gesture Rich Representation Learning of Phonological Units in Low Resource Settings,,"['https://openalex.org/W2396043527', 'https://openalex.org/W2097308346', 'https://openalex.org/W2008957335', 'https://openalex.org/W2043199434', 'https://openalex.org/W2068447135', 'https://openalex.org/W174019601', 'https://openalex.org/W4254499902', 'https://openalex.org/W2129901640', 'https://openalex.org/W1677182931', 'https://openalex.org/W1545920196', 'https://openalex.org/W2062652351', 'https://openalex.org/W2078366715', 'https://openalex.org/W2136655611', 'https://openalex.org/W1796128977', 'https://openalex.org/W2053186076', 'https://openalex.org/W2001141328', 'https://openalex.org/W1984857732', 'https://openalex.org/W2082864603', 'https://openalex.org/W2084869268', 'https://openalex.org/W2013678509', 'https://openalex.org/W2091288983', 'https://openalex.org/W2040184894', 'https://openalex.org/W2963620343', 'https://openalex.org/W1531103298', 'https://openalex.org/W1509905243', 'https://openalex.org/W2101234009', 'https://openalex.org/W1486625509']",2016-01-01
https://openalex.org/W2404799143,https://doi.org/10.21437/interspeech.2015-640,A hybrid dynamic time warping-deep neural network architecture for unsupervised acoustic modeling,"We report on an architecture for the unsupervised discovery of talker-invariant subword embeddings. It is made out of two components: a dynamic-time warping based spoken term discovery (STD) system and a Siamese deep neural network (DNN). The STD system clusters word-sized repeated fragments in the acoustic streams while the DNN is trained to minimize the distance between time aligned frames of tokens of the same cluster, and maximize the distance between tokens of different clusters. We use additional side information regarding the average duration of phonemic units, as well as talker identity tags. For evaluation we use the datasets and metrics of the Zero Resource Speech Challenge. The model shows improvement over the baseline in subword unit modeling.","['https://openalex.org/W2619993508', 'https://openalex.org/W2608958052', 'https://openalex.org/W2138621090', 'https://openalex.org/W1997460147', 'https://openalex.org/W3127686677', 'https://openalex.org/W1545920196', 'https://openalex.org/W1985371235', 'https://openalex.org/W2251545788', 'https://openalex.org/W2079623482', 'https://openalex.org/W2164770604', 'https://openalex.org/W1993755070', 'https://openalex.org/W2171590421', 'https://openalex.org/W1972159947', 'https://openalex.org/W148837159', 'https://openalex.org/W2048741136', 'https://openalex.org/W2052697931', 'https://openalex.org/W2127589108', 'https://openalex.org/W2054948443', 'https://openalex.org/W1606347560', 'https://openalex.org/W6908809', 'https://openalex.org/W904206136', 'https://openalex.org/W2114347655', 'https://openalex.org/W2057007397', 'https://openalex.org/W21006490']",2015-09-06
https://openalex.org/W2400549570,https://doi.org/10.1109/icassp.2016.7472622,A deep scattering spectrum — Deep Siamese network pipeline for unsupervised acoustic modeling,"Recent work has explored deep architectures for learning acoustic features in an unsupervised or weakly-supervised way for phone recognition. Here we investigate the role of the input features, and in particular we test whether standard mel-scaled filterbanks could be replaced by inherently richer representations, such as derived from an analytic scattering spectrum. We use a Siamese network using lexical side information similar to a well-performing architecture used in the Zero Resource Speech Challenge (2015), and show a substantial improvement when the filterbanks are replaced by scattering features, even though these features yield similar performance when tested without training. This shows that unsupervised and weakly-supervised architectures can benefit from richer features than the traditional ones.","['https://openalex.org/W2171590421', 'https://openalex.org/W2128160875', 'https://openalex.org/W6602180557', 'https://openalex.org/W2252172689', 'https://openalex.org/W6973666849', 'https://openalex.org/W2044138293', 'https://openalex.org/W2057007397', 'https://openalex.org/W2404799143', 'https://openalex.org/W6638159135', 'https://openalex.org/W6712202099', 'https://openalex.org/W2093231248', 'https://openalex.org/W6677154653', 'https://openalex.org/W6712444837', 'https://openalex.org/W6637061625', 'https://openalex.org/W2052697931', 'https://openalex.org/W6713745070', 'https://openalex.org/W6712553779', 'https://openalex.org/W2154833897', 'https://openalex.org/W52412328', 'https://openalex.org/W2786608204', 'https://openalex.org/W1666984270', 'https://openalex.org/W2025482506', 'https://openalex.org/W2395899413', 'https://openalex.org/W2962701684', 'https://openalex.org/W2406349064', 'https://openalex.org/W2399576818', 'https://openalex.org/W2396043527', 'https://openalex.org/W2112688413', 'https://openalex.org/W1796128977', 'https://openalex.org/W2963620343']",2016-03-01
https://openalex.org/W2787223168,https://doi.org/10.1109/asru.2017.8269013,Deep learning methods for unsupervised acoustic modeling — Leap submission to ZeroSpeech challenge 2017,"In this paper, we present our system submission to the ZeroSpeech 2017 Challenge. The track1 of this challenge is intended to develop language independent speech representations that provide the least pairwise ABX distance computed for within speaker and across speaker pairs of spoken words. We investigate two approaches based on deep learning methods for unsupervised modeling. In the first approach, a deep neural network (DNN) is trained on the posteriors of mixture component indices obtained from training a Gaussian mixture model (GMM)-UBM. In the second approach, we develop a similar hidden Markov model (HMM) based DNN model to learn the unsupervised acoustic units provided by HMM state alignments. In addition, we also develop a deep autoencoder which learns language independent embeddings of speech to train the HMM-DNN model. Both the approaches do not use any labeled training data or require any supervision. We perform several experiments using the ZeroSpeech 2017 corpus with the minimal pair ABX error measure. In these experiments, we find that the two proposed approaches significantly improve over the baseline system using MFCC features (average relative improvements of 30–40%). Furthermore, the system combination of the two proposed approaches improves the performance over the best individual system.","['https://openalex.org/W6713256719', 'https://openalex.org/W4231109964', 'https://openalex.org/W6685777803', 'https://openalex.org/W2120480077', 'https://openalex.org/W6682825348', 'https://openalex.org/W2041823554', 'https://openalex.org/W2785860501', 'https://openalex.org/W6973666849', 'https://openalex.org/W2009388533', 'https://openalex.org/W2126203737', 'https://openalex.org/W2963620343', 'https://openalex.org/W6638159135', 'https://openalex.org/W6713745070', 'https://openalex.org/W6601311673', 'https://openalex.org/W2117041980', 'https://openalex.org/W2513125788', 'https://openalex.org/W2115008841', 'https://openalex.org/W6631362777', 'https://openalex.org/W2072128103', 'https://openalex.org/W30845872', 'https://openalex.org/W1553004968', 'https://openalex.org/W222076935', 'https://openalex.org/W2406349064', 'https://openalex.org/W1796128977', 'https://openalex.org/W1524333225', 'https://openalex.org/W1560013842', 'https://openalex.org/W2404799143', 'https://openalex.org/W2786608204', 'https://openalex.org/W2152175008', 'https://openalex.org/W2181347294']",2017-12-01
https://openalex.org/W2786902352,https://doi.org/10.1109/asru.2017.8269009,Multilingual bottle-neck feature learning from untranscribed speech,"We propose to learn a low-dimensional feature representation for multiple languages without access to their manual transcription. The multilingual features are extracted from a shared bottleneck layer of a multi-task learning deep neural network which is trained using un-supervised phoneme-like labels. The unsupervised phoneme-like labels are obtained from language-dependent Dirichlet process Gaussian mixture models (DPGMMs). Vocal tract length normalization (VTLN) is applied to mel-frequency cepstral coefficients to reduce talker variation when DPGMMs are trained. The proposed features are evaluated using the ABX phoneme discriminability test in the Zero Resource Speech Challenge 2017. In the experiments, we show that the proposed features perform well across different languages, and they consistently outperform our previously proposed DPGMM posteriorgrams which topped the performance in the same challenge in 2015.","['https://openalex.org/W2509930204', 'https://openalex.org/W2345811097', 'https://openalex.org/W6607040217', 'https://openalex.org/W6631362777', 'https://openalex.org/W6675022971', 'https://openalex.org/W2962903176', 'https://openalex.org/W2154093685', 'https://openalex.org/W2020607164', 'https://openalex.org/W1545920196', 'https://openalex.org/W2785415724', 'https://openalex.org/W2052697931', 'https://openalex.org/W2513125788', 'https://openalex.org/W2059652594', 'https://openalex.org/W2190506272', 'https://openalex.org/W2913340405', 'https://openalex.org/W2126203737', 'https://openalex.org/W6678007500', 'https://openalex.org/W2295297373', 'https://openalex.org/W1577418252', 'https://openalex.org/W2110589736', 'https://openalex.org/W6712553779', 'https://openalex.org/W2592866267', 'https://openalex.org/W6638059883', 'https://openalex.org/W1967924372', 'https://openalex.org/W2118841860', 'https://openalex.org/W2963571336', 'https://openalex.org/W1970890968', 'https://openalex.org/W2767122664', 'https://openalex.org/W6713745070', 'https://openalex.org/W6712444837', 'https://openalex.org/W6678947187', 'https://openalex.org/W6649703416', 'https://openalex.org/W2406349064', 'https://openalex.org/W2120636621', 'https://openalex.org/W2100768664', 'https://openalex.org/W2399576818', 'https://openalex.org/W2395899413', 'https://openalex.org/W1524333225', 'https://openalex.org/W2128032727', 'https://openalex.org/W173010698', 'https://openalex.org/W1778492285', 'https://openalex.org/W1997505733']",2017-12-01
https://openalex.org/W2787447541,https://doi.org/10.1109/asru.2017.8269011,Feature optimized DPGMM clustering for unsupervised subword modeling: A contribution to zerospeech 2017,"This paper describes our unsupervised subword modeling pipeline for the zero resource speech challenge (ZeroSpeech) 2017. Our approach is built around the Dirichlet process Gaussian mixture model (DPGMM) that we use to cluster speech feature vectors into a dynamically sized set of classes. By considering each class an acoustic unit, speech can be represented as sequence of class posteriorgrams. We enhance this method by automatically optimizing the DPGMM sampler's input features in a multi-stage clustering framework, where we unsupervisedly learn transformations using LDA, MLLT and (basis) fMLLR to reduce variance in the features. We show that this optimization considerably boosts the subword modeling quality, according to the performance on the ABX phone discriminability task. For the first time, we apply inferred subword models to previously unseen data from a new set of speakers. We demonstrate our method's good generalization and the effectiveness of its blind speaker adaptation in extensive experiments on a multitude of datasets. Our pipeline has very little need for hyper-parameter adjustment and is entirely unsupervised, i.e., it only takes raw audio recordings as input, without requiring any pre-defined segmentation, explicit speaker IDs or other meta data.","['https://openalex.org/W6678947187', 'https://openalex.org/W2001619934', 'https://openalex.org/W2124629003', 'https://openalex.org/W2106554350', 'https://openalex.org/W1599512239', 'https://openalex.org/W2002342963', 'https://openalex.org/W2019042707', 'https://openalex.org/W2078769636', 'https://openalex.org/W6712444837', 'https://openalex.org/W6712202099', 'https://openalex.org/W6638159135', 'https://openalex.org/W6712553779', 'https://openalex.org/W6713256719', 'https://openalex.org/W2509930204', 'https://openalex.org/W6704305767', 'https://openalex.org/W2963620343', 'https://openalex.org/W6973666849', 'https://openalex.org/W2586754519', 'https://openalex.org/W6631362777', 'https://openalex.org/W2113641473', 'https://openalex.org/W1631260214', 'https://openalex.org/W2395899413', 'https://openalex.org/W2396043527', 'https://openalex.org/W2404799143', 'https://openalex.org/W2128032727', 'https://openalex.org/W1796128977', 'https://openalex.org/W2786608204', 'https://openalex.org/W1524333225', 'https://openalex.org/W2399576818', 'https://openalex.org/W2345811097']",2017-12-01
https://openalex.org/W2787426069,https://doi.org/10.1109/asru.2017.8269012,Composite embedding systems for ZeroSpeech2017 Track1,"This paper investigates novel composite embedding systems for language-independent high-performance feature extraction using triphone-based DNN-HMM and character-based end-to-end speech recognition systems. The DNN-HMM is trained with phoneme transcripts based on a large-scale Japanese ASR recipe included in the Kaldi toolkit from the Corpus of Spontaneous Japanese (CSJ) with some modifications. The end-to-end ASR system is based on a hybrid architecture consisting of an attention-based encoder-decoder and connectionist temporal classification. This model is trained with multi-language speech data using character transcripts in a pure end-to-end fashion without requiring phonemic representation. Posterior features, PCA-transformed features, and bottleneck features are extracted from the two systems; then, various combinations of features are explored. Additionally, a bypassed autoencoder (bypassed AE) is proposed to normalize speaker characteristics in an unsupervised manner. An evaluation using the ABX test showed that the DNN-HMM-based CSJ bottleneck features resulted in a good performance regardless of the input language. The pre-activation vectors extracted from the multilingual end-to-end system with PCA provided a somewhat better performance than did the CSJ bottleneck features. The bypassed AE yielded an improved performance over a baseline AE. The lowest error rates were obtained by composite features that concatenated the end-to-end features with the CSJ bottleneck features.","['https://openalex.org/W2079460648', 'https://openalex.org/W2148154194', 'https://openalex.org/W6712202099', 'https://openalex.org/W1545920196', 'https://openalex.org/W2586327937', 'https://openalex.org/W1801780804', 'https://openalex.org/W6712807034', 'https://openalex.org/W2515119768', 'https://openalex.org/W2627092829', 'https://openalex.org/W2114347655', 'https://openalex.org/W6695606915', 'https://openalex.org/W6712553779', 'https://openalex.org/W6640777149', 'https://openalex.org/W2747414243', 'https://openalex.org/W2142390309', 'https://openalex.org/W2033436836', 'https://openalex.org/W6973666849', 'https://openalex.org/W2963620343', 'https://openalex.org/W2085628288', 'https://openalex.org/W2288471100', 'https://openalex.org/W2396043527', 'https://openalex.org/W2402741009', 'https://openalex.org/W2286443923', 'https://openalex.org/W1942713348', 'https://openalex.org/W1686810756', 'https://openalex.org/W2786608204', 'https://openalex.org/W2399576818']",2017-12-01
https://openalex.org/W2785415724,https://doi.org/10.1109/asru.2017.8269010,Extracting bottleneck features and word-like pairs from untranscribed speech for feature representation,"We propose a framework to learn a frame-level speech representation in a scenario where no manual transcription is available. Our framework is based on pairwise learning using bottleneck features (BNFs). Initial frame-level features are extracted from a bottleneck-shaped multilingual deep neural network (DNN) which is trained with unsupervised phoneme-like labels. Word-like pairs are discovered in the untranscribed speech using the initial features, and frame alignment is performed on each word-like speech pair. The matching frame pairs are used as input-output to train another DNN with the mean square error (MSE) loss function. The final frame-level features are extracted from an internal hidden layer of MSE-based DNN. Our pairwise learned feature representation is evaluated on the ZeroSpeech 2017 challenge. The experiments show that pairwise learning improves phoneme discrimination in 10s and 120s test conditions. We find that it is important to use BNFs as initial features when pairwise learning is performed. With more word pairs obtained from the Switchboard corpus and its manual transcription, the phoneme discrimination of three languages in the evaluation data can further be improved despite data mismatch.","['https://openalex.org/W2127589108', 'https://openalex.org/W2157364932', 'https://openalex.org/W2052697931', 'https://openalex.org/W2511733680', 'https://openalex.org/W6748489002', 'https://openalex.org/W2057007397', 'https://openalex.org/W6712553779', 'https://openalex.org/W2346964103', 'https://openalex.org/W1967924372', 'https://openalex.org/W1545920196', 'https://openalex.org/W6725820645', 'https://openalex.org/W2110589736', 'https://openalex.org/W6677734967', 'https://openalex.org/W2614542633', 'https://openalex.org/W1968095326', 'https://openalex.org/W2154085905', 'https://openalex.org/W2126203737', 'https://openalex.org/W6973666849', 'https://openalex.org/W2160815625', 'https://openalex.org/W6638159135', 'https://openalex.org/W6777926273', 'https://openalex.org/W6681096077', 'https://openalex.org/W6637373629', 'https://openalex.org/W6636358008', 'https://openalex.org/W6731763572', 'https://openalex.org/W1796128977', 'https://openalex.org/W3028642772', 'https://openalex.org/W2566587499', 'https://openalex.org/W2513125788', 'https://openalex.org/W2786608204', 'https://openalex.org/W1686810756', 'https://openalex.org/W2963620343', 'https://openalex.org/W1606347560', 'https://openalex.org/W2399576818', 'https://openalex.org/W2951216052', 'https://openalex.org/W2119187236', 'https://openalex.org/W2962835968', 'https://openalex.org/W2786902352', 'https://openalex.org/W2997574889', 'https://openalex.org/W2145094598']",2017-12-01
https://openalex.org/W3100270690,https://doi.org/10.1109/taslp.2019.2938863,Unsupervised Speech Representation Learning Using WaveNet Autoencoders,"We consider the task of unsupervised extraction of meaningful latent\nrepresentations of speech by applying autoencoding neural networks to speech\nwaveforms. The goal is to learn a representation able to capture high level\nsemantic content from the signal, e.g.\\ phoneme identities, while being\ninvariant to confounding low level details in the signal such as the underlying\npitch contour or background noise. Since the learned representation is tuned to\ncontain only phonetic content, we resort to using a high capacity WaveNet\ndecoder to infer information discarded by the encoder from previous samples.\nMoreover, the behavior of autoencoder models depends on the kind of constraint\nthat is applied to the latent representation. We compare three variants: a\nsimple dimensionality reduction bottleneck, a Gaussian Variational Autoencoder\n(VAE), and a discrete Vector Quantized VAE (VQ-VAE). We analyze the quality of\nlearned representations in terms of speaker independence, the ability to\npredict phonetic content, and the ability to accurately reconstruct individual\nspectrogram frames. Moreover, for discrete encodings extracted using the\nVQ-VAE, we measure the ease of mapping them to phonemes. We introduce a\nregularization scheme that forces the representations to focus on the phonetic\ncontent of the utterance and report performance comparable with the top entries\nin the ZeroSpeech 2017 unsupervised acoustic unit discovery task.\n","['https://openalex.org/W2888911345', 'https://openalex.org/W2750248772', 'https://openalex.org/W2180849752', 'https://openalex.org/W2347098582', 'https://openalex.org/W2963425185', 'https://openalex.org/W6745388339', 'https://openalex.org/W2114347655', 'https://openalex.org/W6744627333', 'https://openalex.org/W2468716020', 'https://openalex.org/W6640963894', 'https://openalex.org/W6751433836', 'https://openalex.org/W2057007397', 'https://openalex.org/W1840435438', 'https://openalex.org/W6742080785', 'https://openalex.org/W6678292227', 'https://openalex.org/W1970890968', 'https://openalex.org/W2145889472', 'https://openalex.org/W1902027874', 'https://openalex.org/W6857890821', 'https://openalex.org/W2963918774', 'https://openalex.org/W2787223168', 'https://openalex.org/W2964243274', 'https://openalex.org/W2785415724', 'https://openalex.org/W2061883090', 'https://openalex.org/W2108598243', 'https://openalex.org/W6736723571', 'https://openalex.org/W6712560600', 'https://openalex.org/W6637618735', 'https://openalex.org/W6745117592', 'https://openalex.org/W6682132143', 'https://openalex.org/W6764882207', 'https://openalex.org/W6712553779', 'https://openalex.org/W6675022971', 'https://openalex.org/W2025768430', 'https://openalex.org/W2100495367', 'https://openalex.org/W2963620343', 'https://openalex.org/W6679718588', 'https://openalex.org/W1498436455', 'https://openalex.org/W2132037657', 'https://openalex.org/W2059652044', 'https://openalex.org/W6637061625', 'https://openalex.org/W2408093180', 'https://openalex.org/W2095705004', 'https://openalex.org/W6714142977', 'https://openalex.org/W2786902352', 'https://openalex.org/W2345811097', 'https://openalex.org/W6713745070', 'https://openalex.org/W6712444837', 'https://openalex.org/W6631362777', 'https://openalex.org/W6755490972', 'https://openalex.org/W2086161653', 'https://openalex.org/W6631190155', 'https://openalex.org/W6751097180', 'https://openalex.org/W1849277567', 'https://openalex.org/W6729906282', 'https://openalex.org/W6734194636', 'https://openalex.org/W6742082877', 'https://openalex.org/W2963804033', 'https://openalex.org/W2120209245', 'https://openalex.org/W1993660824', 'https://openalex.org/W1494198834', 'https://openalex.org/W2752796333', 'https://openalex.org/W6761568071', 'https://openalex.org/W2097117768', 'https://openalex.org/W2618530766', 'https://openalex.org/W6727690538', 'https://openalex.org/W6679434410', 'https://openalex.org/W2962824709', 'https://openalex.org/W2143612262', 'https://openalex.org/W2963223306', 'https://openalex.org/W2740747242', 'https://openalex.org/W6755300632', 'https://openalex.org/W6749825310', 'https://openalex.org/W2146444479', 'https://openalex.org/W6731535438', 'https://openalex.org/W6690026940', 'https://openalex.org/W6733471323', 'https://openalex.org/W6731370813']",2019-09-03
https://openalex.org/W3144810982,https://doi.org/10.48550/arxiv.2007.00991,Data Augmenting Contrastive Learning of Speech Representations in the\n Time Domain,"Contrastive Predictive Coding (CPC), based on predicting future segments of\nspeech based on past segments is emerging as a powerful algorithm for\nrepresentation learning of speech signal. However, it still under-performs\nother methods on unsupervised evaluation benchmarks. Here, we introduce\nWavAugment, a time-domain data augmentation library and find that applying\naugmentation in the past is generally more efficient and yields better\nperformances than other methods. We find that a combination of pitch\nmodification, additive noise and reverberation substantially increase the\nperformance of CPC (relative improvement of 18-22%), beating the reference\nLibri-light results with 600 times less data. Using an out-of-domain dataset,\ntime-domain data augmentation can push CPC to be on par with the state of the\nart on the Zero Speech Benchmark 2017. We also show that time-domain data\naugmentation consistently improves downstream limited-supervision phoneme\nclassification tasks by a factor of 12-15% relative.\n","['https://openalex.org/W3015213852', 'https://openalex.org/W2148349024', 'https://openalex.org/W2346964103', 'https://openalex.org/W2593779438', 'https://openalex.org/W2407080277', 'https://openalex.org/W3005680577', 'https://openalex.org/W2972943112', 'https://openalex.org/W2696967604', 'https://openalex.org/W2184343439', 'https://openalex.org/W2990583358', 'https://openalex.org/W2963620343', 'https://openalex.org/W2055408826', 'https://openalex.org/W2883725317', 'https://openalex.org/W3100270690', 'https://openalex.org/W2973049979', 'https://openalex.org/W4288107125', 'https://openalex.org/W2786608204', 'https://openalex.org/W3016011332', 'https://openalex.org/W2995181338', 'https://openalex.org/W4297808394', 'https://openalex.org/W3016181583', 'https://openalex.org/W3002741552', 'https://openalex.org/W2973026522', 'https://openalex.org/W2930682606', 'https://openalex.org/W2100768664', 'https://openalex.org/W2787447541', 'https://openalex.org/W3093427098', 'https://openalex.org/W3015783745', 'https://openalex.org/W3102342027', 'https://openalex.org/W4300047444', 'https://openalex.org/W3093096176', 'https://openalex.org/W2940544976', 'https://openalex.org/W3125709657', 'https://openalex.org/W4214784181', 'https://openalex.org/W2983785920', 'https://openalex.org/W2952217990', 'https://openalex.org/W2963074118', 'https://openalex.org/W2509930204', 'https://openalex.org/W2117041980', 'https://openalex.org/W2946822591', 'https://openalex.org/W1494198834', 'https://openalex.org/W2219249508', 'https://openalex.org/W2970971581', 'https://openalex.org/W2842511635', 'https://openalex.org/W2347098582', 'https://openalex.org/W3003875258', 'https://openalex.org/W4295312788', 'https://openalex.org/W1989674786', 'https://openalex.org/W2020607164', 'https://openalex.org/W2936774411']",2020-07-02
https://openalex.org/W2057007397,https://doi.org/10.1109/asru.2011.6163965,Efficient spoken term discovery using randomized algorithms,"Spoken term discovery is the task of automatically identifying words and phrases in speech data by searching for long repeated acoustic patterns. Initial solutions relied on exhaustive dynamic time warping-based searches across the entire similarity matrix, a method whose scalability is ultimately limited by the O(n <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">2</sup> ) nature of the search space. Recent strategies have attempted to improve search efficiency by using either unsupervised or mismatched-language acoustic models to reduce the complexity of the feature representation. Taking a completely different approach, this paper investigates the use of randomized algorithms that operate directly on the raw acoustic features to produce sparse approximate similarity matrices in O(n) space and O(n log n) time. We demonstrate these techniques facilitate spoken term discovery performance capable of outperforming a model-based strategy in the zero resource setting.","['https://openalex.org/W2112038498', 'https://openalex.org/W2116343079', 'https://openalex.org/W6680730250', 'https://openalex.org/W2113932204', 'https://openalex.org/W2397535009', 'https://openalex.org/W2170580867', 'https://openalex.org/W6795644987', 'https://openalex.org/W2122056984', 'https://openalex.org/W6714100551', 'https://openalex.org/W2152565070', 'https://openalex.org/W2401464865', 'https://openalex.org/W2079460648', 'https://openalex.org/W2147717514', 'https://openalex.org/W1606268232', 'https://openalex.org/W4230940751', 'https://openalex.org/W2108120477', 'https://openalex.org/W2114347655', 'https://openalex.org/W308497914', 'https://openalex.org/W2166343746', 'https://openalex.org/W30845872', 'https://openalex.org/W2096834449', 'https://openalex.org/W1539935047', 'https://openalex.org/W6602705600', 'https://openalex.org/W2112107221', 'https://openalex.org/W2140427797', 'https://openalex.org/W3160851792', 'https://openalex.org/W66167291', 'https://openalex.org/W2012833704', 'https://openalex.org/W2407151108']",2011-12-01
https://openalex.org/W2964169922,,,"Unsupervised segmentation and clustering of unlabelled speech are core problems in zero-resource speech processing. Most approaches lie at methodological extremes: some use probabilistic Bayesian models with convergence guarantees, while others opt for more efficient heuristic techniques. Despite competitive performance in previous work, the full Bayesian approach is difficult to scale to large speech corpora. We introduce an approximation to a recent Bayesian model that still has a clear objective function but improves efficiency by using hard clustering and segmentation rather than full Bayesian inference. Like its Bayesian counterpart, this embedded segmental K-means model (ES-KMeans) represents arbitrary-length word segments as fixed-dimensional acoustic word embeddings. We first compare ES-KMeans to previous approaches on common English and Xitsonga data sets (5 and 2.5 hours of speech): ES-KMeans outperforms a leading heuristic method in word segmentation, giving similar scores to the Bayesian model while being 5 times faster with fewer hyperparameters. However, its clusters are less pure than those of the other models. We then show that ES-KMeans scales to larger corpora by applying it to the 5 languages of the Zero Resource Speech Challenge 2017 (up to 45 hours), where it performs competitively compared to the challenge baseline.","['https://openalex.org/W2048648518', 'https://openalex.org/W2758697525', 'https://openalex.org/W3102667484', 'https://openalex.org/W2951216052', 'https://openalex.org/W2117041980', 'https://openalex.org/W2114347655', 'https://openalex.org/W2962736743', 'https://openalex.org/W2463237750', 'https://openalex.org/W2686360660', 'https://openalex.org/W2719865699', 'https://openalex.org/W2641832364', 'https://openalex.org/W1796128977', 'https://openalex.org/W2291770225', 'https://openalex.org/W2295297373', 'https://openalex.org/W2020607164', 'https://openalex.org/W2346964103', 'https://openalex.org/W2963311389', 'https://openalex.org/W2161562001', 'https://openalex.org/W2116330964', 'https://openalex.org/W2190506272', 'https://openalex.org/W113159538', 'https://openalex.org/W2962980711', 'https://openalex.org/W2032943813', 'https://openalex.org/W3098643042', 'https://openalex.org/W2963571336', 'https://openalex.org/W2483390977', 'https://openalex.org/W2251025892', 'https://openalex.org/W2154093685', 'https://openalex.org/W1577418252', 'https://openalex.org/W2566587499', 'https://openalex.org/W1778492285', 'https://openalex.org/W2072396742', 'https://openalex.org/W2143776582', 'https://openalex.org/W2022058071', 'https://openalex.org/W2468716020', 'https://openalex.org/W2059652594', 'https://openalex.org/W2100768664', 'https://openalex.org/W51277926', 'https://openalex.org/W2091746061', 'https://openalex.org/W2398490608', 'https://openalex.org/W2142775654', 'https://openalex.org/W1590183771', 'https://openalex.org/W2516890051', 'https://openalex.org/W2010188467', 'https://openalex.org/W2057007397', 'https://openalex.org/W2786608204']",
https://openalex.org/W2407614114,https://doi.org/10.21437/interspeech.2015-646,An evaluation of graph clustering methods for unsupervised term discovery,"Unsupervised term discovery (UTD) is the task of automatically identifying the repeated words and phrases in a collection of speech audio without relying on any language-specific resources. While the solution space for the task is far from fully explored, the dominant approach to date decomposes the discovery problem into two steps, where (i) segmental dynamic time warping is used to search the speech audio for repeated acoustic patterns, and (ii) these individual repetitions are partitioned into word/phrase categories using graph clustering. In this paper, we perform an unprecedented evaluation of a wide range of advanced graph clustering methods for the UTD task. We conduct our study in the evaluation framework of the Zero Resource Speech Challenge. We find that, for a range of features and languages, modularity-based clustering improves UTD performance most consistently, often by a wide margin. When paired with out-of-language deep neural net bottleneck features, we find performance near that of a high-resource UTD system.","['https://openalex.org/W66167291', 'https://openalex.org/W2164998314', 'https://openalex.org/W2047940964', 'https://openalex.org/W2059652594', 'https://openalex.org/W2060108852', 'https://openalex.org/W2025482506', 'https://openalex.org/W2151936673', 'https://openalex.org/W2168080440', 'https://openalex.org/W2786608204', 'https://openalex.org/W2052697931', 'https://openalex.org/W1539935047', 'https://openalex.org/W1991274470', 'https://openalex.org/W2132202037', 'https://openalex.org/W2089458547', 'https://openalex.org/W1967924372', 'https://openalex.org/W1580203226', 'https://openalex.org/W1545920196', 'https://openalex.org/W2036964623', 'https://openalex.org/W2072396742', 'https://openalex.org/W1983345514', 'https://openalex.org/W2018562712', 'https://openalex.org/W2401464865', 'https://openalex.org/W2124209874', 'https://openalex.org/W2062914951', 'https://openalex.org/W2294799344', 'https://openalex.org/W2131681506', 'https://openalex.org/W2057007397', 'https://openalex.org/W30845872', 'https://openalex.org/W229097380', 'https://openalex.org/W2078769636', 'https://openalex.org/W2109726592', 'https://openalex.org/W2114347655', 'https://openalex.org/W2095293504']",2015-09-06
https://openalex.org/W2398490608,https://doi.org/10.21437/interspeech.2015-645,Unsupervised word discovery from speech using automatic segmentation into syllable-like units,,"['https://openalex.org/W2252172689', 'https://openalex.org/W2164356097', 'https://openalex.org/W2400622388', 'https://openalex.org/W2056486423', 'https://openalex.org/W2055408826', 'https://openalex.org/W1993287287', 'https://openalex.org/W1991274470', 'https://openalex.org/W2020944885', 'https://openalex.org/W2053952913', 'https://openalex.org/W1985163701', 'https://openalex.org/W2029948425', 'https://openalex.org/W2004833594', 'https://openalex.org/W2044138293', 'https://openalex.org/W2049142189', 'https://openalex.org/W2078769636', 'https://openalex.org/W2071665560', 'https://openalex.org/W2059824090', 'https://openalex.org/W28194048', 'https://openalex.org/W2251025892', 'https://openalex.org/W2114777034', 'https://openalex.org/W2067539019', 'https://openalex.org/W2133148365', 'https://openalex.org/W1965635292', 'https://openalex.org/W2026764577', 'https://openalex.org/W1774234760', 'https://openalex.org/W2126203737']",2015-09-06
https://openalex.org/W4313182775,https://doi.org/10.1109/taslp.2022.3229264,Word Segmentation on Discovered Phone Units With Dynamic Programming and Self-Supervised Scoring,"Recent work on unsupervised speech segmentation has used self-supervised models with phone and word segmentation modules that are trained jointly. This paper instead revisits an older approach to word segmentation: bottom-up phone-like unit discovery is performed first, and symbolic word segmentation is then performed on top of the discovered units (without influencing the lower level). To do this, I propose a new unit discovery model, a new symbolic word segmentation model, and then chain the two models to segment speech. Both models use dynamic programming to minimize segment costs from a self-supervised network with an additional duration penalty that encourages longer units. Concretely, for acoustic unit discovery, duration-penalized dynamic programming (DPDP) is used with a contrastive predictive coding model as the scoring network. For word segmentation, DPDP is applied with an autoencoding recurrent neural as the scoring network. The two models are chained in order to segment speech. This approach gives comparable word segmentation results to state-of-the-art joint self-supervised segmentation models on an English benchmark. On French, Mandarin, German and Wolof data, it outperforms previous systems on the ZeroSpeech benchmarks. Analysis shows that the chained DPDP system segments shorter filler words well, but longer words might require some external top-down signal.","['https://openalex.org/W2025482506', 'https://openalex.org/W2126377586', 'https://openalex.org/W2126449874', 'https://openalex.org/W6676025551', 'https://openalex.org/W1778492285', 'https://openalex.org/W3102667484', 'https://openalex.org/W2978134885', 'https://openalex.org/W4313053756', 'https://openalex.org/W2398490608', 'https://openalex.org/W2468716020', 'https://openalex.org/W2964169922', 'https://openalex.org/W2802557066', 'https://openalex.org/W6844194202', 'https://openalex.org/W3198782837', 'https://openalex.org/W3209993061', 'https://openalex.org/W2940544976', 'https://openalex.org/W3093096176', 'https://openalex.org/W2140991203', 'https://openalex.org/W2251563156', 'https://openalex.org/W2035750955', 'https://openalex.org/W3198134274', 'https://openalex.org/W2758697525', 'https://openalex.org/W2963620343', 'https://openalex.org/W3197974236', 'https://openalex.org/W2117041980', 'https://openalex.org/W51277926', 'https://openalex.org/W6675022971', 'https://openalex.org/W2963137467', 'https://openalex.org/W2962799131', 'https://openalex.org/W2927191280', 'https://openalex.org/W2972943112', 'https://openalex.org/W3095361818', 'https://openalex.org/W3198815374', 'https://openalex.org/W3100270690', 'https://openalex.org/W6769196770', 'https://openalex.org/W6786696081', 'https://openalex.org/W3209059054', 'https://openalex.org/W2971775690', 'https://openalex.org/W6774456908', 'https://openalex.org/W1945490744', 'https://openalex.org/W3096656254', 'https://openalex.org/W130754613', 'https://openalex.org/W2995181338', 'https://openalex.org/W6738767006', 'https://openalex.org/W3006094508', 'https://openalex.org/W4247319331', 'https://openalex.org/W6676028815', 'https://openalex.org/W2074546930', 'https://openalex.org/W2345913943', 'https://openalex.org/W2952125979', 'https://openalex.org/W2786608204', 'https://openalex.org/W2295297373', 'https://openalex.org/W2145410271', 'https://openalex.org/W6631190155', 'https://openalex.org/W2057007397', 'https://openalex.org/W3097485645', 'https://openalex.org/W3097159218', 'https://openalex.org/W4296710617', 'https://openalex.org/W2114347655', 'https://openalex.org/W2415378728', 'https://openalex.org/W6729977899', 'https://openalex.org/W6728167234', 'https://openalex.org/W2964115348', 'https://openalex.org/W4285110637', 'https://openalex.org/W4224875474', 'https://openalex.org/W4206075291', 'https://openalex.org/W6634986005', 'https://openalex.org/W1984076147', 'https://openalex.org/W3098643042', 'https://openalex.org/W2973026522', 'https://openalex.org/W2972574141', 'https://openalex.org/W4297808394', 'https://openalex.org/W2949115596']",2022-12-14
https://openalex.org/W4296710617,https://doi.org/10.1162/tacl_a_00505,DP-Parse: Finding Word Boundaries from Raw Speech with an Instance Lexicon,"Abstract Finding word boundaries in continuous speech is challenging as there is little or no equivalent of a ‘space’ delimiter between words. Popular Bayesian non-parametric models for text segmentation (Goldwater et al., 2006, 2009) use a Dirichlet process to jointly segment sentences and build a lexicon of word types. We introduce DP-Parse, which uses similar principles but only relies on an instance lexicon of word tokens, avoiding the clustering errors that arise with a lexicon of word types. On the Zero Resource Speech Benchmark 2017, our model sets a new speech segmentation state-of-the-art in 5 languages. The algorithm monotonically improves with better input representations, achieving yet higher scores when fed with weakly supervised inputs. Despite lacking a type lexicon, DP-Parse can be pipelined to a language model and learn semantic and syntactic representations as assessed by a new spoken word embedding benchmark. 1","['https://openalex.org/W4223486244', 'https://openalex.org/W3044967013', 'https://openalex.org/W6780218876', 'https://openalex.org/W6640135064', 'https://openalex.org/W3097159218', 'https://openalex.org/W3198782837', 'https://openalex.org/W3015783745', 'https://openalex.org/W2407151108', 'https://openalex.org/W2963425185', 'https://openalex.org/W3209993061', 'https://openalex.org/W6755207826', 'https://openalex.org/W2963620343', 'https://openalex.org/W3093096176', 'https://openalex.org/W6731922460', 'https://openalex.org/W4235505822', 'https://openalex.org/W2946322623', 'https://openalex.org/W2126377586', 'https://openalex.org/W2122228338', 'https://openalex.org/W6682948231', 'https://openalex.org/W6796554684', 'https://openalex.org/W3108506107', 'https://openalex.org/W3037580942', 'https://openalex.org/W3146777637', 'https://openalex.org/W2057007397', 'https://openalex.org/W2117126688', 'https://openalex.org/W6756098772', 'https://openalex.org/W6810047917', 'https://openalex.org/W2468716020', 'https://openalex.org/W1997505733', 'https://openalex.org/W2964169922', 'https://openalex.org/W3198134274', 'https://openalex.org/W2952125979', 'https://openalex.org/W6790356757', 'https://openalex.org/W6675022971', 'https://openalex.org/W1778492285', 'https://openalex.org/W6793306531', 'https://openalex.org/W6691362072', 'https://openalex.org/W6636510571', 'https://openalex.org/W2140991203', 'https://openalex.org/W3110458199', 'https://openalex.org/W2842511635', 'https://openalex.org/W1494198834', 'https://openalex.org/W2114347655', 'https://openalex.org/W2118020555', 'https://openalex.org/W2962850179', 'https://openalex.org/W2398490608', 'https://openalex.org/W2395899413', 'https://openalex.org/W2962736743', 'https://openalex.org/W2913062184', 'https://openalex.org/W2346964103', 'https://openalex.org/W1700952868', 'https://openalex.org/W3036601975', 'https://openalex.org/W2896457183', 'https://openalex.org/W4313182775', 'https://openalex.org/W101045393', 'https://openalex.org/W2771976988', 'https://openalex.org/W4394671563', 'https://openalex.org/W2519091744', 'https://openalex.org/W2963720603', 'https://openalex.org/W4287591426', 'https://openalex.org/W2613000335', 'https://openalex.org/W4297808394', 'https://openalex.org/W3095706145', 'https://openalex.org/W3096196861', 'https://openalex.org/W1614298861', 'https://openalex.org/W2916009164', 'https://openalex.org/W3151510603', 'https://openalex.org/W3209059054', 'https://openalex.org/W3098643042', 'https://openalex.org/W4240908132']",2022-01-01
https://openalex.org/W2468716020,https://doi.org/10.1016/j.csl.2017.04.008,A segmental framework for fully-unsupervised large-vocabulary speech recognition,,"['https://openalex.org/W6712016426', 'https://openalex.org/W6655470396', 'https://openalex.org/W6712202099', 'https://openalex.org/W6676227212', 'https://openalex.org/W2157427027', 'https://openalex.org/W6712553779', 'https://openalex.org/W6677435873', 'https://openalex.org/W2044138293', 'https://openalex.org/W6602705600', 'https://openalex.org/W2067539019', 'https://openalex.org/W6602180557', 'https://openalex.org/W6645148572', 'https://openalex.org/W6602092770', 'https://openalex.org/W6675002571', 'https://openalex.org/W2126377586', 'https://openalex.org/W6658673440', 'https://openalex.org/W6712960331', 'https://openalex.org/W6656737381', 'https://openalex.org/W6641955892', 'https://openalex.org/W6664486393', 'https://openalex.org/W6632653590', 'https://openalex.org/W6640777149', 'https://openalex.org/W2295297373', 'https://openalex.org/W6649703416', 'https://openalex.org/W6687508285', 'https://openalex.org/W6675022971', 'https://openalex.org/W6638059883', 'https://openalex.org/W2030422732', 'https://openalex.org/W6665204316', 'https://openalex.org/W6634625101', 'https://openalex.org/W6691362072', 'https://openalex.org/W6713678193', 'https://openalex.org/W6696832885', 'https://openalex.org/W2058237037', 'https://openalex.org/W6680997062', 'https://openalex.org/W6684135220', 'https://openalex.org/W2114347655', 'https://openalex.org/W2145410271', 'https://openalex.org/W2010188467', 'https://openalex.org/W2398490608', 'https://openalex.org/W6638159135', 'https://openalex.org/W6677180724', 'https://openalex.org/W1539673959', 'https://openalex.org/W6719160716', 'https://openalex.org/W2078769636', 'https://openalex.org/W2032943813', 'https://openalex.org/W6663645435', 'https://openalex.org/W2220867547', 'https://openalex.org/W2404799143', 'https://openalex.org/W6677620606', 'https://openalex.org/W6704726871', 'https://openalex.org/W6973666849', 'https://openalex.org/W6655843320', 'https://openalex.org/W2507959295', 'https://openalex.org/W2516890051', 'https://openalex.org/W6712804684', 'https://openalex.org/W6659543308', 'https://openalex.org/W6670629611', 'https://openalex.org/W6682450205', 'https://openalex.org/W6607261905', 'https://openalex.org/W2099873701', 'https://openalex.org/W2401464865', 'https://openalex.org/W2915722758', 'https://openalex.org/W2251025892', 'https://openalex.org/W2612649659', 'https://openalex.org/W2400549570', 'https://openalex.org/W2407614114', 'https://openalex.org/W2107223151', 'https://openalex.org/W1967924372', 'https://openalex.org/W1503398984', 'https://openalex.org/W2116422968', 'https://openalex.org/W2116330964', 'https://openalex.org/W1942713348', 'https://openalex.org/W2166270474', 'https://openalex.org/W2140991203', 'https://openalex.org/W2057007397', 'https://openalex.org/W1796128977', 'https://openalex.org/W2022058071', 'https://openalex.org/W2396043527', 'https://openalex.org/W2154093685', 'https://openalex.org/W66167291', 'https://openalex.org/W3143835353', 'https://openalex.org/W1545920196', 'https://openalex.org/W1978741356', 'https://openalex.org/W2346964103', 'https://openalex.org/W2117041980', 'https://openalex.org/W2059652594', 'https://openalex.org/W52412328', 'https://openalex.org/W2025482506', 'https://openalex.org/W2805889152', 'https://openalex.org/W2020607164', 'https://openalex.org/W2033413759', 'https://openalex.org/W2190506272', 'https://openalex.org/W2035424729', 'https://openalex.org/W1997505733', 'https://openalex.org/W2291469555', 'https://openalex.org/W2395342389', 'https://openalex.org/W178496478', 'https://openalex.org/W2399576818', 'https://openalex.org/W2100768664', 'https://openalex.org/W2463237750', 'https://openalex.org/W1778492285', 'https://openalex.org/W2786608204', 'https://openalex.org/W1577418252', 'https://openalex.org/W2079460648', 'https://openalex.org/W2916018751', 'https://openalex.org/W51277926', 'https://openalex.org/W2052697931']",2017-05-18
https://openalex.org/W2748009955,https://doi.org/10.21437/interspeech.2017-339,Comparison of Non-Parametric Bayesian Mixture Models for Syllable Clustering and Zero-Resource Speech Processing,"Zero-resource speech processing (ZS) systems aim to learn structural representations of speech without access to labeled data. A starting point for these systems is the extraction of syllable tokens utilizing the rhythmic structure of a speech signal. Several recent ZS systems have therefore focused on clustering such syllable tokens into linguistically meaningful units. These systems have so far used heuristically set number of clusters, which can, however, be highly dataset dependent and cannot be optimized in actual unsupervised settings. This paper focuses on improving the flexibility of ZS systems using Bayesian non-parametric (BNP) mixture models that are capable of simultaneously learning the cluster models as well as their number based on the properties of the dataset. We also compare different model design choices, namely priors over the weights and the cluster component models, as the impact of these choices is rarely reported in the previous studies. Experiments are conducted using conversational speech from several languages. The models are first evaluated in a separate syllable clustering task and then as a part of a full ZS system in order to examine the potential of BNP methods and illuminate the relative importance of different model design choices.","['https://openalex.org/W2610013054', 'https://openalex.org/W2016155919', 'https://openalex.org/W2121464381', 'https://openalex.org/W2295297373', 'https://openalex.org/W1987971958', 'https://openalex.org/W2057007397', 'https://openalex.org/W2135537007', 'https://openalex.org/W2069429561', 'https://openalex.org/W2145001205', 'https://openalex.org/W2403962673', 'https://openalex.org/W2786608204', 'https://openalex.org/W2399576818', 'https://openalex.org/W2251025892', 'https://openalex.org/W2032943813', 'https://openalex.org/W2154099718', 'https://openalex.org/W2398490608', 'https://openalex.org/W1997505733', 'https://openalex.org/W2468716020', 'https://openalex.org/W2151967501', 'https://openalex.org/W2127498532', 'https://openalex.org/W2087309226', 'https://openalex.org/W2115870554', 'https://openalex.org/W2044138293', 'https://openalex.org/W2166637769', 'https://openalex.org/W2100768664', 'https://openalex.org/W1967687583', 'https://openalex.org/W2038101708']",2017-08-16
https://openalex.org/W2347098582,https://doi.org/10.1016/j.procs.2016.04.033,Variational Inference for Acoustic Unit Discovery,"Recently, several nonparametric Bayesian models have been proposed to automatically discover acoustic units in unlabeled data. Most of them are trained using various versions of the Gibbs Sampling (GS) method. In this work, we consider Variational Bayes (VB) as alternative inference process. Even though VB yields an approximate solution of the posterior distribution it can be easily parallelized which makes it more suitable for large database. Results show that, notwithstanding VB inference is an order of magnitude faster, it outperforms GS in terms of accuracy.","['https://openalex.org/W2170353620', 'https://openalex.org/W1796128977', 'https://openalex.org/W6959456255', 'https://openalex.org/W1967687583', 'https://openalex.org/W2127498532', 'https://openalex.org/W1635512741', 'https://openalex.org/W6624852173', 'https://openalex.org/W2040891197', 'https://openalex.org/W2154099718', 'https://openalex.org/W1506806321', 'https://openalex.org/W2619993508', 'https://openalex.org/W2120636621', 'https://openalex.org/W1516111018', 'https://openalex.org/W2100768664']",2016-01-01
https://openalex.org/W2972374322,https://doi.org/10.21437/interspeech.2019-3232,VQVAE Unsupervised Unit Discovery and Multi-Scale Code2Spec Inverter for Zerospeech Challenge 2019,"We describe our submitted system for the ZeroSpeech Challenge 2019.The current challenge theme addresses the difficulty of constructing a speech synthesizer without any text or phonetic labels and requires a system that can (1) discover subword units in an unsupervised way, and (2) synthesize the speech with a target speaker's voice.Moreover, the system should also balance the discrimination score ABX, the bit-rate compression rate, and the naturalness and the intelligibility of the constructed voice.To tackle these problems and achieve the best tradeoff, we utilize a vector quantized variational autoencoder (VQ-VAE) and a multi-scale codebook-tospectrogram (Code2Spec) inverter trained by mean square error and adversarial loss.The VQ-VAE extracts the speech to a latent space, forces itself to map it into the nearest codebook and produces compressed representation.Next, the inverter generates a magnitude spectrogram to the target voice, given the codebook vectors from VQ-VAE.In our experiments, we also investigated several other clustering algorithms, including K-Means and GMM, and compared them with the VQ-VAE result on ABX scores and bit rates.Our proposed approach significantly improved the intelligibility (in CER), the MOS, and discrimination ABX scores compared to the official ZeroSpeech 2019 baseline or even the topline.","['https://openalex.org/W2963971656', 'https://openalex.org/W2786608204', 'https://openalex.org/W2593414223', 'https://openalex.org/W2547039119', 'https://openalex.org/W2519091744', 'https://openalex.org/W2963799213', 'https://openalex.org/W2101234009', 'https://openalex.org/W2399576818', 'https://openalex.org/W1959608418', 'https://openalex.org/W2666408839', 'https://openalex.org/W2964069186', 'https://openalex.org/W2962699523', 'https://openalex.org/W4300047444', 'https://openalex.org/W2962896155', 'https://openalex.org/W2940544976', 'https://openalex.org/W2120847449', 'https://openalex.org/W1522301498', 'https://openalex.org/W4320013936', 'https://openalex.org/W2787447541', 'https://openalex.org/W2888858245', 'https://openalex.org/W2963796886', 'https://openalex.org/W4394670483', 'https://openalex.org/W2911340057', 'https://openalex.org/W1836465849', 'https://openalex.org/W2899771611', 'https://openalex.org/W3125709657', 'https://openalex.org/W2191779130']",2019-09-13
https://openalex.org/W2972964185,https://doi.org/10.21437/interspeech.2019-2336,Zero Resource Speech Synthesis Using Transcripts Derived from Perceptual Acoustic Units,"Zerospeech synthesis is the task of building vocabulary independent speech synthesis systems, where transcriptions are not available for training data. It is, therefore, necessary to convert training data into a sequence of fundamental acoustic units that can be used for synthesis during the test. This paper attempts to discover, and model perceptual acoustic units consisting of steady-state, and transient regions in speech. The transients roughly correspond to CV, VC units, while the steady-state corresponds to sonorants and fricatives. The speech signal is first preprocessed by segmenting the same into CVC-like units using a short-term energy-like contour. These CVC segments are clustered using a connected components-based graph clustering technique. The clustered CVC segments are initialized such that the onset (CV) and decays (VC) correspond to transients, and the rhyme corresponds to steady-states. Following this initialization, the units are allowed to re-organise on the continuous speech into a final set of AUs in an HMM-GMM framework. AU sequences thus obtained are used to train synthesis models. The performance of the proposed approach is evaluated on the Zerospeech 2019 challenge database. Subjective and objective scores show that reasonably good quality synthesis with low bit rate encoding can be achieved using the proposed AUs.","['https://openalex.org/W2347098582', 'https://openalex.org/W2406349064', 'https://openalex.org/W2547039119', 'https://openalex.org/W2786608204', 'https://openalex.org/W2097426397', 'https://openalex.org/W2100768664', 'https://openalex.org/W2470260127', 'https://openalex.org/W2963620343', 'https://openalex.org/W2117041980', 'https://openalex.org/W2029073757', 'https://openalex.org/W2395899413', 'https://openalex.org/W1967924372', 'https://openalex.org/W2126203737', 'https://openalex.org/W2598638573', 'https://openalex.org/W1524333225', 'https://openalex.org/W2028019270', 'https://openalex.org/W2121997342', 'https://openalex.org/W2154093685', 'https://openalex.org/W1975126845', 'https://openalex.org/W2940544976', 'https://openalex.org/W174715548', 'https://openalex.org/W2345811097', 'https://openalex.org/W1976985077', 'https://openalex.org/W2750248772']",2019-09-13
https://openalex.org/W2950414763,https://doi.org/10.21437/interspeech.2019-1337,Combining Adversarial Training and Disentangled Speech Representation for Robust Zero-Resource Subword Modeling,"This study addresses the problem of unsupervised subword unit discovery from untranscribed speech. It forms the basis of the ultimate goal of ZeroSpeech 2019, building text-to-speech systems without text labels. In this work, unit discovery is formulated as a pipeline of phonetically discriminative feature learning and unit inference. One major difficulty in robust unsupervised feature learning is dealing with speaker variation. Here the robustness towards speaker variation is achieved by applying adversarial training and FHVAE based disentangled speech representation learning. A comparison of the two approaches as well as their combination is studied in a DNN-bottleneck feature (DNN-BNF) architecture. Experiments are conducted on ZeroSpeech 2019 and 2017. Experimental results on ZeroSpeech 2017 show that both approaches are effective while the latter is more prominent, and that their combination brings further marginal improvement in across-speaker condition. Results on ZeroSpeech 2019 show that in the ABX discriminability task, our approaches significantly outperform the official baseline, and are competitive to or even outperform the official topline. The proposed unit sequence smoothing algorithm improves synthesis quality, at a cost of slight decrease in ABX discriminability.","['https://openalex.org/W2516890051', 'https://openalex.org/W1882958252', 'https://openalex.org/W2826003142', 'https://openalex.org/W2128032727', 'https://openalex.org/W2786608204', 'https://openalex.org/W1545920196', 'https://openalex.org/W2399576818', 'https://openalex.org/W2963620343', 'https://openalex.org/W2758785877', 'https://openalex.org/W2598638573', 'https://openalex.org/W2964121744', 'https://openalex.org/W2889228998', 'https://openalex.org/W2940544976', 'https://openalex.org/W1522301498', 'https://openalex.org/W2786902352', 'https://openalex.org/W4288107125', 'https://openalex.org/W2949510815', 'https://openalex.org/W2796339975', 'https://openalex.org/W4289564011', 'https://openalex.org/W2587088898', 'https://openalex.org/W2906459023', 'https://openalex.org/W2402144811', 'https://openalex.org/W1796128977', 'https://openalex.org/W2963618559', 'https://openalex.org/W3125709657', 'https://openalex.org/W2547039119', 'https://openalex.org/W2787426069', 'https://openalex.org/W1524333225', 'https://openalex.org/W2785860501', 'https://openalex.org/W2936120996', 'https://openalex.org/W2787447541', 'https://openalex.org/W2404799143', 'https://openalex.org/W2953384591', 'https://openalex.org/W4300047444', 'https://openalex.org/W2963826681']",2019-09-13
https://openalex.org/W2947445680,https://doi.org/10.21437/interspeech.2019-2048,Unsupervised End-to-End Learning of Discrete Linguistic Units for Voice Conversion,"We present an unsupervised end-to-end training scheme where we discover\ndiscrete subword units from speech without using any labels. The discrete\nsubword units are learned under an ASR-TTS autoencoder reconstruction setting,\nwhere an ASR-Encoder is trained to discover a set of common linguistic units\ngiven a variety of speakers, and a TTS-Decoder trained to project the\ndiscovered units back to the designated speech. We propose a discrete encoding\nmethod, Multilabel-Binary Vectors (MBV), to make the ASR-TTS autoencoder\ndifferentiable. We found that the proposed encoding method offers automatic\nextraction of speech content from speaker style, and is sufficient to cover\nfull linguistic content in a given language. Therefore, the TTS-Decoder can\nsynthesize speech with the same content as the input of ASR-Encoder but with\ndifferent speaker characteristics, which achieves voice conversion (VC). We\nfurther improve the quality of VC using adversarial training, where we train a\nTTS-Patcher that augments the output of TTS-Decoder. Objective and subjective\nevaluations show that the proposed approach offers strong VC results as it\neliminates speaker identity while preserving content within speech. In the\nZeroSpeech 2019 Challenge, we achieved outstanding performance in terms of low\nbitrate.\n","['https://openalex.org/W4295521014', 'https://openalex.org/W2547039119', 'https://openalex.org/W2963691546', 'https://openalex.org/W2899518769', 'https://openalex.org/W2963609956', 'https://openalex.org/W2550241133', 'https://openalex.org/W1522301498', 'https://openalex.org/W2792995953', 'https://openalex.org/W2020607164', 'https://openalex.org/W2767754137', 'https://openalex.org/W2940544976', 'https://openalex.org/W2963073614', 'https://openalex.org/W2963618559', 'https://openalex.org/W2964135678', 'https://openalex.org/W2962974898', 'https://openalex.org/W2532494225', 'https://openalex.org/W4320013936', 'https://openalex.org/W2964243274', 'https://openalex.org/W2347098582', 'https://openalex.org/W4394670483', 'https://openalex.org/W2598638573', 'https://openalex.org/W2099471712', 'https://openalex.org/W2950776302', 'https://openalex.org/W2963830550', 'https://openalex.org/W2963684067', 'https://openalex.org/W2395899413', 'https://openalex.org/W3125709657', 'https://openalex.org/W4288107125', 'https://openalex.org/W2962736743', 'https://openalex.org/W2608207374', 'https://openalex.org/W2476548250', 'https://openalex.org/W2547875792', 'https://openalex.org/W2548275288', 'https://openalex.org/W2963799213', 'https://openalex.org/W2951216052', 'https://openalex.org/W2962879692', 'https://openalex.org/W2758785877', 'https://openalex.org/W2059652594', 'https://openalex.org/W2963571336']",2019-09-13
https://openalex.org/W3003750857,https://doi.org/10.1109/globalsip45357.2019.8969412,Virtual Phone Discovery for Speech Synthesis Without Text,The objective of this work is to re-synthesize speech directly from the speech signals without using any text in a different speaker's voice. The speech signals are transformed into a sequence of acoustic subword units or virtual phones which are discovered automatically from the given speech signals in an unsupervised manner. The speech signal is initially segmented into acoustically homogeneous segments through kernel-Gram segmentation using MFCC and autoencoder bottleneck features. These segments are then clustered using different clustering techniques. The cluster labels thus obtained are considered as virtual phone units which are used to transcribe the speech signals. The virtual phones for the utterances to be resynthesized are encoded as one-hot vector sequences. Deep neural network based duration model and acoustic model are trained for synthesis using these sequences. A vocoder is used to synthesize speech in target speaker's voice from the features estimated by the acoustic model. The performance evaluation is done on ZeroSpeech 2019 challenge on English and Indonesian language. The bitrate and speaker similarity were found to be better than the challenge baseline with slightly lower intelligibility due to the compact encoding.,"['https://openalex.org/W2786608204', 'https://openalex.org/W2346964103', 'https://openalex.org/W6697293080', 'https://openalex.org/W6675022971', 'https://openalex.org/W2347098582', 'https://openalex.org/W2745710152', 'https://openalex.org/W2345811097', 'https://openalex.org/W1967924372', 'https://openalex.org/W2052697931', 'https://openalex.org/W1796128977', 'https://openalex.org/W2020607164', 'https://openalex.org/W2826003142', 'https://openalex.org/W1510007267', 'https://openalex.org/W2134202996', 'https://openalex.org/W2962699523', 'https://openalex.org/W2964135678', 'https://openalex.org/W2532494225', 'https://openalex.org/W2963830550', 'https://openalex.org/W2902070858', 'https://openalex.org/W2747192917', 'https://openalex.org/W2803005441', 'https://openalex.org/W2890718354', 'https://openalex.org/W2598638573', 'https://openalex.org/W2059652594', 'https://openalex.org/W6680735885', 'https://openalex.org/W1975728937', 'https://openalex.org/W2964169922', 'https://openalex.org/W2471520273', 'https://openalex.org/W2940544976', 'https://openalex.org/W2057007397', 'https://openalex.org/W2398490608', 'https://openalex.org/W2407614114', 'https://openalex.org/W6631362777', 'https://openalex.org/W2774848319', 'https://openalex.org/W2973026522', 'https://openalex.org/W2963620343', 'https://openalex.org/W1524333225', 'https://openalex.org/W2165874743', 'https://openalex.org/W2141465109', 'https://openalex.org/W2100768664']",2019-11-01
https://openalex.org/W2973013862,https://doi.org/10.21437/interspeech.2019-1430,Temporally-Aware Acoustic Unit Discovery for Zerospeech 2019 Challenge,,"['https://openalex.org/W2598638573', 'https://openalex.org/W2404799143', 'https://openalex.org/W2395899413', 'https://openalex.org/W2799046698', 'https://openalex.org/W1545920196', 'https://openalex.org/W2399576818', 'https://openalex.org/W2100768664', 'https://openalex.org/W2786608204', 'https://openalex.org/W2400549570', 'https://openalex.org/W1796128977', 'https://openalex.org/W2345811097', 'https://openalex.org/W2547039119', 'https://openalex.org/W2345968833', 'https://openalex.org/W1679913846', 'https://openalex.org/W2940544976', 'https://openalex.org/W2347098582']",2019-09-13
https://openalex.org/W3097056138,https://doi.org/10.21437/interspeech.2020-2765,Vector Quantized Temporally-Aware Correspondence Sparse Autoencoders for Zero-Resource Acoustic Unit Discovery,,"['https://openalex.org/W2400549570', 'https://openalex.org/W1796128977', 'https://openalex.org/W2598638573', 'https://openalex.org/W2395899413', 'https://openalex.org/W2972374322']",2020-10-25
https://openalex.org/W3161215977,https://doi.org/10.48550/arxiv.2011.03115,A Hierarchical Subspace Model for Language-Attuned Acoustic Unit\n Discovery,"In this work, we propose a hierarchical subspace model for acoustic unit\ndiscovery. In this approach, we frame the task as one of learning embeddings on\na low-dimensional phonetic subspace, and simultaneously specify the subspace\nitself as an embedding on a hyper-subspace. We train the hyper-subspace on a\nset of transcribed languages and transfer it to the target language. In the\ntarget language, we infer both the language and unit embeddings in an\nunsupervised manner, and in so doing, we simultaneously learn a subspace of\nunits specific to that language and the units that dwell on it. We conduct our\nexperiments on TIMIT and two low-resource languages: Mboshi and Yoruba. Results\nshow that our model outperforms major acoustic unit discovery techniques, both\nin terms of clustering quality and segmentation accuracy.\n","['https://openalex.org/W3092791109', 'https://openalex.org/W2084534958', 'https://openalex.org/W2963799213', 'https://openalex.org/W2195354', 'https://openalex.org/W1981706894', 'https://openalex.org/W2401396251', 'https://openalex.org/W2100768664', 'https://openalex.org/W3100270690', 'https://openalex.org/W2979476256', 'https://openalex.org/W1959608418', 'https://openalex.org/W2962693497', 'https://openalex.org/W2963620343', 'https://openalex.org/W2888911345', 'https://openalex.org/W2572097499', 'https://openalex.org/W2927191280', 'https://openalex.org/W2134670479', 'https://openalex.org/W2641832364', 'https://openalex.org/W2973026522', 'https://openalex.org/W2786608204', 'https://openalex.org/W2347098582', 'https://openalex.org/W2995680346', 'https://openalex.org/W4394867155', 'https://openalex.org/W2401271873', 'https://openalex.org/W2996383576', 'https://openalex.org/W2972574141', 'https://openalex.org/W2786902352', 'https://openalex.org/W2127498532', 'https://openalex.org/W1494198834', 'https://openalex.org/W2483390977', 'https://openalex.org/W2940544976', 'https://openalex.org/W1522301498', 'https://openalex.org/W3125709657', 'https://openalex.org/W2762715843']",2020-11-04
https://openalex.org/W3024040651,https://doi.org/10.21437/interspeech.2020-3127,Exploring TTS Without T Using Biologically/Psychologically Motivated Neural Network Modules (ZeroSpeech 2020),"In this study, we reported our exploration of Text-To-Speech without Text\n(TTS without T) in the Zero Resource Speech Challenge 2020, in which\nparticipants proposed an end-to-end, unsupervised system that learned speech\nrecognition and TTS together. We addressed the challenge using\nbiologically/psychologically motivated modules of Artificial Neural Networks\n(ANN), with a particular interest in unsupervised learning of human language as\na biological/psychological problem. The system first processes Mel Frequency\nCepstral Coefficient (MFCC) frames with an Echo-State Network (ESN), and\nsimulates computations in cortical microcircuits. The outcome is discretized by\nour original Variational Autoencoder (VAE) that implements the Dirichlet-based\nBayesian clustering widely accepted in computational linguistics and cognitive\nscience. The discretized signal is then reverted into sound waveform via a\nneural-network implementation of the source-filter model for speech production.\n","['https://openalex.org/W2964121744', 'https://openalex.org/W2598638573', 'https://openalex.org/W2972374322', 'https://openalex.org/W2547039119', 'https://openalex.org/W2547875792', 'https://openalex.org/W1959608418', 'https://openalex.org/W4288107125', 'https://openalex.org/W4391602018', 'https://openalex.org/W3125709657', 'https://openalex.org/W4385245566', 'https://openalex.org/W2092919341', 'https://openalex.org/W2347098582', 'https://openalex.org/W1586357756', 'https://openalex.org/W2963403868', 'https://openalex.org/W1993755070', 'https://openalex.org/W2016988675', 'https://openalex.org/W3185362781', 'https://openalex.org/W3023775752', 'https://openalex.org/W2133564696', 'https://openalex.org/W2964308564', 'https://openalex.org/W2947591107', 'https://openalex.org/W2468716020', 'https://openalex.org/W2158266063', 'https://openalex.org/W2963341956', 'https://openalex.org/W2048269309', 'https://openalex.org/W2963799213', 'https://openalex.org/W1522301498', 'https://openalex.org/W2118706537', 'https://openalex.org/W2126377586', 'https://openalex.org/W3048188704', 'https://openalex.org/W2990440871', 'https://openalex.org/W2896457183', 'https://openalex.org/W2940544976', 'https://openalex.org/W2118072362', 'https://openalex.org/W2103179919']",2020-10-25
https://openalex.org/W3096262326,https://doi.org/10.21437/interspeech.2020-2731,Exploration of End-to-End Synthesisers for Zero Resource Speech Challenge 2020,"A Spoken dialogue system for an unseen language is referred to as Zero resource speech. It is especially beneficial for developing applications for languages that have low digital resources. Zero resource speech synthesis is the task of building text-to-speech (TTS) models in the absence of transcriptions. In this work, speech is modelled as a sequence of transient and steady-state acoustic units, and a unique set of acoustic units is discovered by iterative training. Using the acoustic unit sequence, TTS models are trained. The main goal of this work is to improve the synthesis quality of zero resource TTS system. Four different systems are proposed. All the systems consist of three stages: unit discovery, followed by unit sequence to spectrogram mapping, and finally spectrogram to speech inversion. Modifications are proposed to the spectrogram mapping stage. These modifications include training the mapping on voice data, using x-vectors to improve the mapping, two-stage learning, and gender-specific modelling. Evaluation of the proposed systems in the Zerospeech 2020 challenge shows that quite good quality synthesis can be achieved.","['https://openalex.org/W2402146185', 'https://openalex.org/W1796128977', 'https://openalex.org/W2972964185', 'https://openalex.org/W2972867623', 'https://openalex.org/W2947445680', 'https://openalex.org/W2949382160', 'https://openalex.org/W2335906338', 'https://openalex.org/W2347098582', 'https://openalex.org/W2015876361', 'https://openalex.org/W1524333225', 'https://openalex.org/W2100768664', 'https://openalex.org/W2547039119', 'https://openalex.org/W1967924372', 'https://openalex.org/W2963300588', 'https://openalex.org/W2598638573']",2020-10-25
https://openalex.org/W3097692357,https://doi.org/10.21437/interspeech.2020-1785,Unsupervised Acoustic Unit Representation Learning for Voice Conversion Using WaveNet Auto-Encoders,This is a repository copy of Unsupervised acoustic unit representation learning for voice conversion using WaveNet auto-encoders.,"['https://openalex.org/W1959608418', 'https://openalex.org/W2005708641', 'https://openalex.org/W2786608204', 'https://openalex.org/W2963609956', 'https://openalex.org/W2964243274', 'https://openalex.org/W2972867623', 'https://openalex.org/W2963799213', 'https://openalex.org/W2603777577', 'https://openalex.org/W2785860501', 'https://openalex.org/W2972841524', 'https://openalex.org/W2519091744', 'https://openalex.org/W2395899413', 'https://openalex.org/W2758785877', 'https://openalex.org/W2346964103', 'https://openalex.org/W2963691546', 'https://openalex.org/W2972943112', 'https://openalex.org/W1665214252', 'https://openalex.org/W2787447541', 'https://openalex.org/W2402146185', 'https://openalex.org/W2128032727', 'https://openalex.org/W2598638573', 'https://openalex.org/W3095361818', 'https://openalex.org/W2963830550', 'https://openalex.org/W2502312327', 'https://openalex.org/W2789543585', 'https://openalex.org/W2972659941', 'https://openalex.org/W4288107125', 'https://openalex.org/W1522301498', 'https://openalex.org/W2547039119', 'https://openalex.org/W4295312788', 'https://openalex.org/W3125709657', 'https://openalex.org/W2952161038', 'https://openalex.org/W2514741789', 'https://openalex.org/W2242818861', 'https://openalex.org/W2972374322', 'https://openalex.org/W2979476256', 'https://openalex.org/W2786902352', 'https://openalex.org/W2950414763']",2020-10-25
https://openalex.org/W3096359985,https://doi.org/10.21437/interspeech.2020-2559,Cyclic Spectral Modeling for Unsupervised Unit Discovery into Voice Conversion with Excitation and Waveform Modeling,,"['https://openalex.org/W2346964103', 'https://openalex.org/W2347098582', 'https://openalex.org/W2787447541', 'https://openalex.org/W2946555236', 'https://openalex.org/W2547039119', 'https://openalex.org/W2972867623', 'https://openalex.org/W2940544976', 'https://openalex.org/W2532494225', 'https://openalex.org/W2972374322', 'https://openalex.org/W2963620343', 'https://openalex.org/W2025482506', 'https://openalex.org/W2786868129', 'https://openalex.org/W2134202996', 'https://openalex.org/W2964115348', 'https://openalex.org/W2471520273', 'https://openalex.org/W2749651610', 'https://openalex.org/W2055408826', 'https://openalex.org/W3015878662', 'https://openalex.org/W2406349064', 'https://openalex.org/W2964121744', 'https://openalex.org/W2972544500', 'https://openalex.org/W2395899413']",2020-10-25
https://openalex.org/W3096216486,https://doi.org/10.21437/interspeech.2020-3033,Transformer VQ-VAE for Unsupervised Unit Discovery and Speech Synthesis: ZeroSpeech 2020 Challenge,"In this paper, we report our submitted system for the ZeroSpeech 2020 challenge on Track 2019.The main theme in this challenge is to build a speech synthesizer without any textual information or phonetic labels.In order to tackle those challenges, we build a system that must address two major components such as 1) given speech audio, extract subword units in an unsupervised way and 2) resynthesize the audio from novel speakers.The system also needs to balance the codebook performance between the ABX error rate and the bitrate compression rate.Our main contribution here is we proposed Transformer-based VQ-VAE for unsupervised unit discovery and Transformerbased inverter for the speech synthesis given the extracted codebook.Additionally, we also explored several regularization methods to improve performance even further.","['https://openalex.org/W3125709657', 'https://openalex.org/W2979476256', 'https://openalex.org/W2963799213', 'https://openalex.org/W4288107125', 'https://openalex.org/W2120847449', 'https://openalex.org/W1522301498', 'https://openalex.org/W2191779130', 'https://openalex.org/W2789543585', 'https://openalex.org/W2547039119', 'https://openalex.org/W2972374322', 'https://openalex.org/W4385245566', 'https://openalex.org/W4394666973', 'https://openalex.org/W2972867623', 'https://openalex.org/W2940544976', 'https://openalex.org/W2906111771', 'https://openalex.org/W2025768430', 'https://openalex.org/W4295312788']",2020-10-25
https://openalex.org/W3197349023,https://doi.org/10.21437/interspeech.2021-1465,Information Retrieval for ZeroSpeech 2021: The Submission by University of Wroclaw,"We present a number of low-resource approaches to the tasks of the Zero Resource Speech Challenge 2021. We build on the unsupervised representations of speech proposed by the organizers as a baseline, derived from CPC and clustered with the k-means algorithm. We demonstrate that simple methods of refining those representations can narrow the gap, or even improve upon the solutions which use a high computational budget. The results lead to the conclusion that the CPC-derived representations are still too noisy for training language models, but stable enough for simpler forms of pattern matching and retrieval.","['https://openalex.org/W2142625445', 'https://openalex.org/W4385245566', 'https://openalex.org/W4362220304', 'https://openalex.org/W2053921957', 'https://openalex.org/W2963751529', 'https://openalex.org/W2996728628', 'https://openalex.org/W2252211741', 'https://openalex.org/W2965373594', 'https://openalex.org/W4287591426', 'https://openalex.org/W2995181338', 'https://openalex.org/W2786608204', 'https://openalex.org/W2251803266', 'https://openalex.org/W1494198834', 'https://openalex.org/W2741692265', 'https://openalex.org/W4297808394', 'https://openalex.org/W2963979492', 'https://openalex.org/W2963250244', 'https://openalex.org/W1614298861', 'https://openalex.org/W2128160875']",2021-06-22
https://openalex.org/W3204915839,https://doi.org/10.1109/taslp.2022.3180684,Unsupervised Speech Segmentation and Variable Rate Representation Learning Using Segmental Contrastive Predictive Coding,"Typically, unsupervised segmentation of speech into the phone- and word-like units are treated as separate tasks and are often done via different methods which do not fully leverage the inter-dependence of the two tasks. Here, we unify them and propose a technique that can jointly perform both, showing that these two tasks indeed benefit from each other. Recent attempts employ self-supervised learning, such as contrastive predictive coding (CPC), where the next frame is predicted given past context. However, CPC only looks at the audio signal's frame-level structure. We overcome this limitation with a segmental contrastive predictive coding (SCPC) framework to model the signal structure at a higher level, e.g., phone level. A convolutional neural network learns frame-level representation from the raw waveform via noise-contrastive estimation (NCE). A differentiable boundary detector finds variable-length segments, which are then used to optimize a segment encoder via NCE to learn segment representations. The differentiable boundary detector allows us to train frame-level and segment-level encoders jointly. Experiments show that our single model outperforms existing phone and word segmentation methods on TIMIT and Buckeye datasets. We analyze the impact of the threshold on boundary detector performance, and our results suggest that automatically learning the boundary threshold can be as effective as manually tuning that threshold. We discover that phone class impacts the boundary detection performance, and the boundaries between successive vowels or semivowels are the most difficult. Finally, we use SCPC to extract speech features at the segment level rather than at the uniformly spaced frame level (e.g., 10 ms) and produce variable rate representations that change according to the contents of the utterance. We can lower the feature extraction rate from the typical 100 Hz to as low as 14.5 Hz on average while still outperforming the hand-crafted features such as MFCC on the linear phone classification task.","['https://openalex.org/W6780218876', 'https://openalex.org/W6770506093', 'https://openalex.org/W2981857663', 'https://openalex.org/W2786608204', 'https://openalex.org/W2963620343', 'https://openalex.org/W2940544976', 'https://openalex.org/W2010188467', 'https://openalex.org/W2057007397', 'https://openalex.org/W2020607164', 'https://openalex.org/W2117041980', 'https://openalex.org/W2170659185', 'https://openalex.org/W6675022971', 'https://openalex.org/W2078769636', 'https://openalex.org/W2468716020', 'https://openalex.org/W2747192917', 'https://openalex.org/W2964169922', 'https://openalex.org/W2890718354', 'https://openalex.org/W2160815625', 'https://openalex.org/W2150769028', 'https://openalex.org/W4301204483', 'https://openalex.org/W6844194202', 'https://openalex.org/W2973049979', 'https://openalex.org/W3096656254', 'https://openalex.org/W6755207826', 'https://openalex.org/W6766673545', 'https://openalex.org/W6774314701', 'https://openalex.org/W6682948231', 'https://openalex.org/W3198782837', 'https://openalex.org/W2882319491', 'https://openalex.org/W2115867364', 'https://openalex.org/W2126377586', 'https://openalex.org/W2115197214', 'https://openalex.org/W6789826613', 'https://openalex.org/W2145410271', 'https://openalex.org/W2963137467', 'https://openalex.org/W2962799131', 'https://openalex.org/W3198134274', 'https://openalex.org/W3100270690', 'https://openalex.org/W6769196770', 'https://openalex.org/W2117126688', 'https://openalex.org/W2972794572', 'https://openalex.org/W1778492285', 'https://openalex.org/W6631526040', 'https://openalex.org/W2111732304', 'https://openalex.org/W2127141656', 'https://openalex.org/W6638749077', 'https://openalex.org/W2146444479', 'https://openalex.org/W6774456908', 'https://openalex.org/W2752796333', 'https://openalex.org/W6690026940', 'https://openalex.org/W130754613', 'https://openalex.org/W3095361818', 'https://openalex.org/W2890704021', 'https://openalex.org/W6795952400', 'https://openalex.org/W2719865699', 'https://openalex.org/W6790356757', 'https://openalex.org/W6786696081', 'https://openalex.org/W2949382160', 'https://openalex.org/W2152790380', 'https://openalex.org/W3169072315', 'https://openalex.org/W2100768664', 'https://openalex.org/W3027324582', 'https://openalex.org/W3034978746', 'https://openalex.org/W2963799213', 'https://openalex.org/W2963341956', 'https://openalex.org/W4287173589', 'https://openalex.org/W2991213871', 'https://openalex.org/W3008499099', 'https://openalex.org/W2242818861', 'https://openalex.org/W1525748279', 'https://openalex.org/W3125709657', 'https://openalex.org/W4394671563', 'https://openalex.org/W3036601975', 'https://openalex.org/W2996383576', 'https://openalex.org/W2973026522', 'https://openalex.org/W3099782249', 'https://openalex.org/W2965373594', 'https://openalex.org/W2601836666', 'https://openalex.org/W3110458199', 'https://openalex.org/W1828163288', 'https://openalex.org/W1994458317', 'https://openalex.org/W3098643042', 'https://openalex.org/W2842511635', 'https://openalex.org/W3112613336', 'https://openalex.org/W3127686677', 'https://openalex.org/W2478415332']",2022-01-01
https://openalex.org/W3209993061,https://doi.org/10.1109/icassp43922.2022.9746102,Contrastive Prediction Strategies for Unsupervised Segmentation and Categorization of Phonemes and Words,"We investigate the performance on phoneme categorization and phoneme and word segmentation of several self-supervised learning (SSL) methods based on Contrastive Predictive Coding (CPC). Our experiments show that with the existing algorithms there is a trade off between categorization and segmentation performance. We investigate the source of this conflict and conclude that the use of context building networks, albeit necessary for superior performance on categorization tasks, harms segmentation performance by causing a temporal shift on the learned representations. Aiming to bridge this gap, we take inspiration from the leading approach on segmentation, which simultaneously models the speech signal at the frame and phoneme level, and incorporate multi-level modelling into Aligned CPC (ACPC), a variation of CPC which exhibits the best performance on categorization tasks. Our multi-level ACPC (mACPC) improves in all categorization metrics and achieves state-of-the-art performance in word segmentation.","['https://openalex.org/W130754613', 'https://openalex.org/W2064675550', 'https://openalex.org/W6739901393', 'https://openalex.org/W6674330103', 'https://openalex.org/W6786696081', 'https://openalex.org/W2842511635', 'https://openalex.org/W6787178341', 'https://openalex.org/W2127141656', 'https://openalex.org/W3197974236', 'https://openalex.org/W6917638038', 'https://openalex.org/W1494198834', 'https://openalex.org/W3198782837', 'https://openalex.org/W3096656254', 'https://openalex.org/W2145410271', 'https://openalex.org/W4297808394', 'https://openalex.org/W3127686677', 'https://openalex.org/W3198134274', 'https://openalex.org/W3110458199', 'https://openalex.org/W4287591426', 'https://openalex.org/W2963403868', 'https://openalex.org/W3112613336', 'https://openalex.org/W4385245566', 'https://openalex.org/W2095705004']",2022-04-27
https://openalex.org/W2395899413,https://doi.org/10.21437/interspeech.2013-441,Evaluating speech features with the minimal-pair ABX task: analysis of the classical MFC/PLP pipeline,"We present a new framework for the evaluation of speech representations in zero-resource settings, that extends and complements previous work by Carlin, Jansen and Hermansky [1].In particular, we replace their Same/Different discrimination task by several Minimal-Pair ABX (MP-ABX) tasks.We explain the analytical advantages of this new framework and apply it to decompose the standard signal processing pipelines for computing PLP and MFC coefficients.This method enables us to confirm and quantify a variety of well-known and not-so-well-known results in a single framework.","['https://openalex.org/W2407151108', 'https://openalex.org/W2232131953', 'https://openalex.org/W2980286501', 'https://openalex.org/W2137075158', 'https://openalex.org/W2090861223', 'https://openalex.org/W4285719527', 'https://openalex.org/W2096765209', 'https://openalex.org/W2986535481', 'https://openalex.org/W4247807440', 'https://openalex.org/W2054139811', 'https://openalex.org/W168991039', 'https://openalex.org/W2406820985', 'https://openalex.org/W2089177488', 'https://openalex.org/W2025482506', 'https://openalex.org/W2160719354', 'https://openalex.org/W156237177', 'https://openalex.org/W48303286', 'https://openalex.org/W2400113920', 'https://openalex.org/W2117041980', 'https://openalex.org/W2100768664', 'https://openalex.org/W282666689', 'https://openalex.org/W1480485976']",2013-08-25
https://openalex.org/W2406349064,https://doi.org/10.21437/interspeech.2014-228,Evaluating speech features with the minimal-pair ABX task (II): resistance to noise,"The Minimal-Pair ABX (MP-ABX) paradigm has been proposed as a method for evaluating speech features for zeroresource/unsupervised speech technologies. We apply it in a phoneme discrimination task on the Articulation Index corpus to evaluate the resistance to noise of various speech features. In Experiment 1, we evaluate the robustness to additive noise at different signal-to-noise ratios, using car and babble noise from the Aurora-4 database and white noise. In Experiment 2, we examine the robustness to different kinds of convolutional noise. In both experiments we consider two classes of techniques to induce noise resistance: smoothing of the time-frequency representation and short-term adaptation in the time-domain. We consider smoothing along the spectral axis (as in PLP) and along the time axis (as in FDLP). For short-term adaptation in the time-domain, we compare the use of a static compressive non-linearity followed by RASTA filtering to an adaptive compression scheme.","['https://openalex.org/W2160719354', 'https://openalex.org/W2407151108', 'https://openalex.org/W1571339265', 'https://openalex.org/W1991163061', 'https://openalex.org/W2089177488', 'https://openalex.org/W2117041980', 'https://openalex.org/W2096765209', 'https://openalex.org/W2406820985', 'https://openalex.org/W2062164080', 'https://openalex.org/W2980286501', 'https://openalex.org/W2054139811', 'https://openalex.org/W2090861223', 'https://openalex.org/W2137075158', 'https://openalex.org/W2025482506', 'https://openalex.org/W2232131953', 'https://openalex.org/W2041777218', 'https://openalex.org/W156237177', 'https://openalex.org/W2046331056', 'https://openalex.org/W2055408826', 'https://openalex.org/W2100768664', 'https://openalex.org/W2395899413']",2014-09-14
https://openalex.org/W1993755070,https://doi.org/10.1037/a0034245,A role for the developing lexicon in phonetic category acquisition.,"Infants segment words from fluent speech during the same period when they are learning phonetic categories, yet accounts of phonetic category acquisition typically ignore information about the words in which sounds appear. We use a Bayesian model to illustrate how feedback from segmented words might constrain phonetic category learning by providing information about which sounds occur together in words. Simulations demonstrate that word-level information can successfully disambiguate overlapping English vowel categories. Learning patterns in the model are shown to parallel human behavior from artificial language learning tasks. These findings point to a central role for the developing lexicon in phonetic category acquisition and provide a framework for incorporating top-down constraints into models of category learning.","['https://openalex.org/W2140661818', 'https://openalex.org/W1579418186', 'https://openalex.org/W2063303346', 'https://openalex.org/W1584859531', 'https://openalex.org/W2128566521', 'https://openalex.org/W2097266862', 'https://openalex.org/W2010860035', 'https://openalex.org/W1598851216', 'https://openalex.org/W2082929796', 'https://openalex.org/W2401464865', 'https://openalex.org/W1990351858', 'https://openalex.org/W2071591642', 'https://openalex.org/W2158266063', 'https://openalex.org/W2131070395', 'https://openalex.org/W2081357278', 'https://openalex.org/W2075773844', 'https://openalex.org/W2129087637', 'https://openalex.org/W2170117014', 'https://openalex.org/W3021510377', 'https://openalex.org/W2095458199', 'https://openalex.org/W2107959623', 'https://openalex.org/W71962062', 'https://openalex.org/W2168266939', 'https://openalex.org/W2110627398', 'https://openalex.org/W2096736596', 'https://openalex.org/W2038056950', 'https://openalex.org/W2069429561', 'https://openalex.org/W2131314926', 'https://openalex.org/W2086880169', 'https://openalex.org/W2076343712', 'https://openalex.org/W2069201504', 'https://openalex.org/W2153450813', 'https://openalex.org/W1830076206', 'https://openalex.org/W2356024940', 'https://openalex.org/W1965307478', 'https://openalex.org/W2169991335', 'https://openalex.org/W1643858913', 'https://openalex.org/W2105000456', 'https://openalex.org/W2035122010', 'https://openalex.org/W2153592339', 'https://openalex.org/W2136445846', 'https://openalex.org/W2120321299', 'https://openalex.org/W1982490440', 'https://openalex.org/W2585464547', 'https://openalex.org/W2020999234', 'https://openalex.org/W2049633694', 'https://openalex.org/W1978567282', 'https://openalex.org/W2094008654', 'https://openalex.org/W2038407704', 'https://openalex.org/W2061656302', 'https://openalex.org/W2135563147', 'https://openalex.org/W2080972498', 'https://openalex.org/W2136766449', 'https://openalex.org/W1993006415', 'https://openalex.org/W1967307281', 'https://openalex.org/W2153767712', 'https://openalex.org/W2120636621', 'https://openalex.org/W2160464066', 'https://openalex.org/W2104752510', 'https://openalex.org/W2144283628', 'https://openalex.org/W2019922577', 'https://openalex.org/W2085373612', 'https://openalex.org/W2108145097', 'https://openalex.org/W2143022183', 'https://openalex.org/W1513896028', 'https://openalex.org/W2082853513', 'https://openalex.org/W2136653392', 'https://openalex.org/W1628323995', 'https://openalex.org/W2033177442', 'https://openalex.org/W2126377586', 'https://openalex.org/W1780831889', 'https://openalex.org/W2045656233', 'https://openalex.org/W1571895365', 'https://openalex.org/W1524454485', 'https://openalex.org/W2059824090', 'https://openalex.org/W1557379068', 'https://openalex.org/W2125477432', 'https://openalex.org/W2022150606', 'https://openalex.org/W2057227931', 'https://openalex.org/W2056133372', 'https://openalex.org/W2120459603', 'https://openalex.org/W2092919341', 'https://openalex.org/W1980862600', 'https://openalex.org/W1521255875', 'https://openalex.org/W1989847651', 'https://openalex.org/W2013588070', 'https://openalex.org/W2033012377', 'https://openalex.org/W2070696251', 'https://openalex.org/W2012380112', 'https://openalex.org/W2111942508', 'https://openalex.org/W2112911900', 'https://openalex.org/W2048269309', 'https://openalex.org/W2112906674', 'https://openalex.org/W2149784807', 'https://openalex.org/W2040137591', 'https://openalex.org/W2401823607', 'https://openalex.org/W2166851712', 'https://openalex.org/W2157305458', 'https://openalex.org/W2133514592', 'https://openalex.org/W2277764111', 'https://openalex.org/W2157427027', 'https://openalex.org/W2102480623', 'https://openalex.org/W2080180213', 'https://openalex.org/W2131924950', 'https://openalex.org/W2204691432', 'https://openalex.org/W2000781199', 'https://openalex.org/W2101509422', 'https://openalex.org/W2061445098', 'https://openalex.org/W2054948443', 'https://openalex.org/W2101736299', 'https://openalex.org/W1540332606', 'https://openalex.org/W2139948572', 'https://openalex.org/W2045213847', 'https://openalex.org/W2084088650', 'https://openalex.org/W2026709293', 'https://openalex.org/W1705861427', 'https://openalex.org/W1963729017', 'https://openalex.org/W2117126688']",2013-01-01
https://openalex.org/W2110627398,https://doi.org/10.1111/cogs.12008,A Single‐Stage Approach to Learning Phonological Categories: Insights From Inuktitut,"Abstract To acquire one’s native phonological system, language‐specific phonological categories and relationships must be extracted from the input. The acquisition of the categories and relationships has each in its own right been the focus of intense research. However, it is remarkable that research on the acquisition of categories and the relations between them has proceeded, for the most part, independently of one another. We argue that this has led to the implicit view that phonological acquisition is a “two‐stage” process: Phonetic categories are first acquired and then subsequently mapped onto abstract phoneme categories. We present simulations that suggest two problems with this view: First, the learner might mistake the phoneme‐level categories for phonetic‐level categories and thus be unable to learn the relationships between phonetic‐level categories; on the other hand, the learner might construct inaccurate phonetic‐level representations that prevent it from finding regular relations among them. We suggest an alternative conception of the phonological acquisition problem that sidesteps this apparent inevitability and acquires phonemic categories in a single stage. Using acoustic data from Inuktitut, we show that this model reliably converges on a set of phoneme‐level categories and phonetic‐level relations among subcategories, without making use of a lexicon.","['https://openalex.org/W2072240081', 'https://openalex.org/W1982707956', 'https://openalex.org/W2095458199', 'https://openalex.org/W2097609022', 'https://openalex.org/W2027003712', 'https://openalex.org/W153534061', 'https://openalex.org/W2006334572', 'https://openalex.org/W2025130480', 'https://openalex.org/W2131668296', 'https://openalex.org/W2049633694', 'https://openalex.org/W2134591615', 'https://openalex.org/W2050053276', 'https://openalex.org/W2024609061', 'https://openalex.org/W2091797506', 'https://openalex.org/W52412328', 'https://openalex.org/W4210416677', 'https://openalex.org/W2069429561', 'https://openalex.org/W2112606116', 'https://openalex.org/W2076867910', 'https://openalex.org/W1984198752', 'https://openalex.org/W1580018148', 'https://openalex.org/W346537747', 'https://openalex.org/W2182486909', 'https://openalex.org/W2038622214', 'https://openalex.org/W4299551239', 'https://openalex.org/W2141812712', 'https://openalex.org/W2994815856', 'https://openalex.org/W2121903946', 'https://openalex.org/W2150389998', 'https://openalex.org/W2140661818', 'https://openalex.org/W1978519615', 'https://openalex.org/W2084300416', 'https://openalex.org/W2167925143', 'https://openalex.org/W2104752510', 'https://openalex.org/W2488678869', 'https://openalex.org/W2169991335', 'https://openalex.org/W4237780050', 'https://openalex.org/W2990145359', 'https://openalex.org/W2098036909', 'https://openalex.org/W2112890390', 'https://openalex.org/W2120713167', 'https://openalex.org/W2113332115', 'https://openalex.org/W2067965259', 'https://openalex.org/W2990251282', 'https://openalex.org/W4210671811', 'https://openalex.org/W1980862600', 'https://openalex.org/W1993006415', 'https://openalex.org/W2334844141', 'https://openalex.org/W2990595833', 'https://openalex.org/W2108443500', 'https://openalex.org/W2153767712', 'https://openalex.org/W2019548241', 'https://openalex.org/W1988653157', 'https://openalex.org/W2101509422', 'https://openalex.org/W2036923909', 'https://openalex.org/W2010860035', 'https://openalex.org/W2134114503', 'https://openalex.org/W635861688', 'https://openalex.org/W1598851216', 'https://openalex.org/W1994381201', 'https://openalex.org/W2033178790', 'https://openalex.org/W2039455814', 'https://openalex.org/W2343272106', 'https://openalex.org/W2799061466', 'https://openalex.org/W2186780112', 'https://openalex.org/W2085788253', 'https://openalex.org/W2912889105', 'https://openalex.org/W2582743722', 'https://openalex.org/W2047056160', 'https://openalex.org/W1588069082', 'https://openalex.org/W605692607', 'https://openalex.org/W4235019020', 'https://openalex.org/W2074525598', 'https://openalex.org/W1972094032', 'https://openalex.org/W596450684', 'https://openalex.org/W2011832962', 'https://openalex.org/W1527996571', 'https://openalex.org/W2612166593', 'https://openalex.org/W562733482', 'https://openalex.org/W2315857866', 'https://openalex.org/W2129205580', 'https://openalex.org/W2890647168', 'https://openalex.org/W181056519', 'https://openalex.org/W4237595250', 'https://openalex.org/W2990173610', 'https://openalex.org/W1572134371', 'https://openalex.org/W1509562192', 'https://openalex.org/W1579271636', 'https://openalex.org/W1562911371', 'https://openalex.org/W2315366077', 'https://openalex.org/W1551770093', 'https://openalex.org/W2168266939', 'https://openalex.org/W2024745951', 'https://openalex.org/W2491143741', 'https://openalex.org/W4300465006', 'https://openalex.org/W1580230098', 'https://openalex.org/W1579838312', 'https://openalex.org/W2317117328', 'https://openalex.org/W624674337', 'https://openalex.org/W4244494905', 'https://openalex.org/W104739738', 'https://openalex.org/W1562629456', 'https://openalex.org/W1482316311', 'https://openalex.org/W2081484203', 'https://openalex.org/W2054571510', 'https://openalex.org/W2129087637', 'https://openalex.org/W2529284949', 'https://openalex.org/W1521566952', 'https://openalex.org/W2501460722', 'https://openalex.org/W2024246280', 'https://openalex.org/W2080972498', 'https://openalex.org/W1563907341', 'https://openalex.org/W2077629364', 'https://openalex.org/W4285719527', 'https://openalex.org/W2054726617', 'https://openalex.org/W1726487274', 'https://openalex.org/W1493022700']",2012-11-08
https://openalex.org/W3212943633,https://doi.org/10.18653/v1/2021.conll-1.51,Predicting non-native speech perception using the Perceptual Assimilation Model and state-of-the-art acoustic models,"Our native language influences the way we perceive speech sounds, affecting our ability to discriminate non-native sounds. We compare two ideas about the influence of the native language on speech perception: the Perceptual Assimilation Model, which appeals to a mental classification of sounds into native phoneme categories, versus the idea that rich, fine-grained phonetic representations tuned to the statistics of the native language, are sufficient. We operationalize this idea using representations from two state-of-the-art speech models, a Dirichlet process Gaussian mixture model and the more recent wav2vec 2.0 model. We present a new, open dataset of French- and English-speaking participants' speech perception behaviour for 61 vowel sounds from six languages. We show that phoneme assimilation is a better predictor than fine-grained phonetic modelling, both for the discrimination behaviour as a whole, and for predicting differences in discriminability associated with differences in native language background. We also show that wav2vec 2.0, while not good at capturing the effects of native language on speech perception, is complementary to information about native phoneme assimilation, and provides a good model of low-level phonetic representations, supporting the idea that both categorical and fine-grained perception are used during speech perception.","['https://openalex.org/W3099782249', 'https://openalex.org/W2747874407', 'https://openalex.org/W2127141656', 'https://openalex.org/W1978833308', 'https://openalex.org/W2145793103', 'https://openalex.org/W3093121832', 'https://openalex.org/W4300047444', 'https://openalex.org/W3160235762', 'https://openalex.org/W2084543000', 'https://openalex.org/W2019129540', 'https://openalex.org/W2092506294', 'https://openalex.org/W2481520443', 'https://openalex.org/W4288279357', 'https://openalex.org/W3023172065', 'https://openalex.org/W189186263', 'https://openalex.org/W2096563020', 'https://openalex.org/W2346964103', 'https://openalex.org/W2399576818', 'https://openalex.org/W4385773817', 'https://openalex.org/W2963620343', 'https://openalex.org/W3119308075', 'https://openalex.org/W1966395315', 'https://openalex.org/W2162711368', 'https://openalex.org/W2154095608', 'https://openalex.org/W1968703923', 'https://openalex.org/W3036601975', 'https://openalex.org/W1554887097', 'https://openalex.org/W3125087428']",2021-01-01
https://openalex.org/W4283332789,https://doi.org/10.18653/v1/2022.acl-long.523,Do self-supervised speech models develop human-like perception biases?,International audience,"['https://openalex.org/W3023172065', 'https://openalex.org/W2123355257', 'https://openalex.org/W3169320628', 'https://openalex.org/W2092506294', 'https://openalex.org/W3030437843', 'https://openalex.org/W3160525311', 'https://openalex.org/W3036601975', 'https://openalex.org/W3160799772', 'https://openalex.org/W3156899336', 'https://openalex.org/W3093579165', 'https://openalex.org/W3212943633', 'https://openalex.org/W4394671563', 'https://openalex.org/W2911249026', 'https://openalex.org/W4288279357', 'https://openalex.org/W3093121832', 'https://openalex.org/W3197259906', 'https://openalex.org/W2193413348', 'https://openalex.org/W2936774411', 'https://openalex.org/W3125087428', 'https://openalex.org/W4287692174', 'https://openalex.org/W3119308075', 'https://openalex.org/W4235199064', 'https://openalex.org/W2593779438', 'https://openalex.org/W2889500720', 'https://openalex.org/W2970540112', 'https://openalex.org/W3016181583', 'https://openalex.org/W2108582985', 'https://openalex.org/W2063525438', 'https://openalex.org/W3148101939', 'https://openalex.org/W189186263', 'https://openalex.org/W1494198834', 'https://openalex.org/W2002572909', 'https://openalex.org/W2963799213', 'https://openalex.org/W2593116425']",2022-01-01
https://openalex.org/W3156899336,https://doi.org/10.1101/2021.04.19.440438,The Psychometrics of Automatic Speech Recognition,"Deep neural networks have had considerable success in neuroscience as models of the visual system, and recent work has suggested this may also extend to the auditory system. We tested the behaviour of a range of state of the art deep learning-based automatic speech recognition systems on a wide collection of manipulated sounds used in standard human psychometric experiments. While some systems showed qualitative agreement with humans in certain tests, in others all tested systems diverged markedly from humans. In particular, all systems used spectral invariance, temporal fine structure and speech periodicity differently from humans. We conclude that despite some promising results, none of the tested automatic speech recognition systems can yet act as a strong proxy for human speech recognition. However, we note that the more recent systems with better performance also tend to better match human results, suggesting that continued cross-fertilisation of ideas between human and automatic speech recognition may be fruitful. Our open source toolbox allows researchers to assess future automatic speech recognition systems or add additional psychoacoustic measures.","['https://openalex.org/W1965213123', 'https://openalex.org/W3036601975', 'https://openalex.org/W2067187250', 'https://openalex.org/W2150769028', 'https://openalex.org/W1999686891', 'https://openalex.org/W2159373586', 'https://openalex.org/W2050758723', 'https://openalex.org/W2127141656', 'https://openalex.org/W2004777907', 'https://openalex.org/W2037976268', 'https://openalex.org/W2120847449', 'https://openalex.org/W1922655562', 'https://openalex.org/W2081236511', 'https://openalex.org/W2091098592', 'https://openalex.org/W2991315634', 'https://openalex.org/W4231807801', 'https://openalex.org/W3137888317', 'https://openalex.org/W2884225676', 'https://openalex.org/W1985226152', 'https://openalex.org/W2131062138', 'https://openalex.org/W2800311957', 'https://openalex.org/W2998566175', 'https://openalex.org/W2176287621', 'https://openalex.org/W1990157444', 'https://openalex.org/W66025329', 'https://openalex.org/W4254873021', 'https://openalex.org/W2022330547', 'https://openalex.org/W3004895274', 'https://openalex.org/W2143017621', 'https://openalex.org/W3094485987', 'https://openalex.org/W2512885752', 'https://openalex.org/W2157867825', 'https://openalex.org/W1494198834', 'https://openalex.org/W2936774411', 'https://openalex.org/W2402146185', 'https://openalex.org/W2748130992', 'https://openalex.org/W2888867175', 'https://openalex.org/W2514741789', 'https://openalex.org/W2408612323', 'https://openalex.org/W2978368159', 'https://openalex.org/W1998465740', 'https://openalex.org/W3120229981', 'https://openalex.org/W2801659857', 'https://openalex.org/W2747899975', 'https://openalex.org/W2189854523', 'https://openalex.org/W1983848225', 'https://openalex.org/W2726225402', 'https://openalex.org/W1985067545', 'https://openalex.org/W2029099045', 'https://openalex.org/W2035912487', 'https://openalex.org/W2058616551', 'https://openalex.org/W6931321145', 'https://openalex.org/W3141279762', 'https://openalex.org/W2990121692', 'https://openalex.org/W3099782249', 'https://openalex.org/W2126463549', 'https://openalex.org/W3216401400', 'https://openalex.org/W3163596720', 'https://openalex.org/W2091585309', 'https://openalex.org/W2963403868', 'https://openalex.org/W1980205575', 'https://openalex.org/W2963980299', 'https://openalex.org/W169745891', 'https://openalex.org/W3121914243', 'https://openalex.org/W2626778328']",2021-04-20
https://openalex.org/W4297841853,https://doi.org/10.21437/interspeech.2022-10961,MAE-AST: Masked Autoencoding Audio Spectrogram Transformer,"In this paper, we propose a simple yet powerful improvement over the recent Self-Supervised Audio Spectrogram Transformer (SSAST) model for speech and audio classification.Specifically, we leverage the insight that the SSAST uses a very high masking ratio (75%) during pretraining, meaning that the vast majority of self-attention compute is performed on mask tokens.We address this by integrating the encoder-decoder architecture from Masked Autoencoders are Scalable Vision Learners (MAE) into the SSAST, where a deep encoder operates on only unmasked input, and a shallow decoder operates on encoder outputs and mask tokens.We find that MAE-like pretraining can provide a 3× speedup and 2× memory usage reduction over the vanilla SSAST using current audio pretraining strategies with ordinary model and input sizes.When finetuning on downstream tasks, which only uses the encoder, we find that our approach outperforms the SSAST on a variety of downstream tasks.We further conduct comprehensive evaluations into different strategies of pretraining and explore differences in MAE-style pretraining between the visual and audio domains.","['https://openalex.org/W2146334809', 'https://openalex.org/W3036601975', 'https://openalex.org/W4398958419', 'https://openalex.org/W4297808394', 'https://openalex.org/W4313156423', 'https://openalex.org/W4287667694', 'https://openalex.org/W4385245566', 'https://openalex.org/W2981087920', 'https://openalex.org/W2896457183', 'https://openalex.org/W1494198834', 'https://openalex.org/W3138516171', 'https://openalex.org/W2933138175', 'https://openalex.org/W2593116425', 'https://openalex.org/W3196974791', 'https://openalex.org/W4292779060', 'https://openalex.org/W1522301498', 'https://openalex.org/W2797583228', 'https://openalex.org/W3160799772', 'https://openalex.org/W3094502228', 'https://openalex.org/W3197580070', 'https://openalex.org/W3206996142']",2022-09-16
https://openalex.org/W2114347655,https://doi.org/10.1109/tasl.2007.909282,Unsupervised Pattern Discovery in Speech,"We present a novel approach to speech processing based on the principle of pattern discovery. Our work represents a departure from traditional models of speech recognition, where the end goal is to classify speech into categories defined by a prespecified inventory of lexical units (i.e., phones or words). Instead, we attempt to discover such an inventory in an unsupervised manner by exploiting the structure of repeating patterns within the speech signal. We show how pattern discovery can be used to automatically acquire lexical entities directly from an untranscribed audio stream. Our approach to unsupervised word acquisition utilizes a segmental variant of a widely used dynamic programming technique, which allows us to find matching acoustic patterns between spoken utterances. By aggregating information about these matching patterns across audio streams, we demonstrate how to group similar acoustic sequences together to form clusters corresponding to lexical entities such as words and short multiword phrases. On a corpus of academic lecture material, we demonstrate that clusters found using this technique exhibit high purity and that many of the corresponding lexical identities are relevant to the underlying audio stream.","['https://openalex.org/W2111732304', 'https://openalex.org/W2095293504', 'https://openalex.org/W4251670979', 'https://openalex.org/W2086891622', 'https://openalex.org/W2089458547', 'https://openalex.org/W6635336695', 'https://openalex.org/W2099402246', 'https://openalex.org/W3021051756', 'https://openalex.org/W2143235280', 'https://openalex.org/W4237938692', 'https://openalex.org/W2074546930', 'https://openalex.org/W2161952424', 'https://openalex.org/W6678164431', 'https://openalex.org/W2112006116', 'https://openalex.org/W2028903194', 'https://openalex.org/W2114510609', 'https://openalex.org/W1980862600', 'https://openalex.org/W2103447044', 'https://openalex.org/W2121947440', 'https://openalex.org/W2009566340', 'https://openalex.org/W2074231493', 'https://openalex.org/W4245668478', 'https://openalex.org/W2054849588', 'https://openalex.org/W2016243284', 'https://openalex.org/W1610605641', 'https://openalex.org/W2138370049', 'https://openalex.org/W1964917299', 'https://openalex.org/W2140277151', 'https://openalex.org/W2118841860', 'https://openalex.org/W2128160875', 'https://openalex.org/W2164463707', 'https://openalex.org/W2009570821', 'https://openalex.org/W3036063182', 'https://openalex.org/W2122228338', 'https://openalex.org/W2999905431', 'https://openalex.org/W2165874743', 'https://openalex.org/W1589182518', 'https://openalex.org/W2107917162', 'https://openalex.org/W1499245496', 'https://openalex.org/W1483126227', 'https://openalex.org/W1978394996', 'https://openalex.org/W2171009857', 'https://openalex.org/W1530250655', 'https://openalex.org/W1207633162']",2007-12-20
https://openalex.org/W2079460648,https://doi.org/10.1109/icassp.2010.5495637,Towards multi-speaker unsupervised speech pattern discovery,"In this paper, we explore the use of a Gaussian posteriorgram based representation for unsupervised discovery of speech patterns. Compared with our previous work, the new approach provides significant improvement towards speaker independence. The framework consists of three main procedures: a Gaussian posteriorgram generation procedure which learns an unsupervised Gaussian mixture model and labels each speech frame with a Gaussian posteriorgram representation; a segmental dynamic time warping procedure which locates pairs of similar sequences of Gaussian posteriorgram vectors; and a graph clustering procedure which groups similar sequences into clusters. We demonstrate the viability of using the posteriorgram approach to handle many talkers by finding clusters of words in the TIMIT corpus.","['https://openalex.org/W2126203737', 'https://openalex.org/W2114510609', 'https://openalex.org/W2107076535', 'https://openalex.org/W2089458547', 'https://openalex.org/W2114347655', 'https://openalex.org/W2099415988', 'https://openalex.org/W159433267']",2010-01-01
https://openalex.org/W2049142189,https://doi.org/10.1109/tasl.2012.2194283,Unsupervised Motif Acquisition in Speech via Seeded Discovery and Template Matching Combination,International audience,"['https://openalex.org/W6680991293', 'https://openalex.org/W2083087666', 'https://openalex.org/W2028903194', 'https://openalex.org/W2118474530', 'https://openalex.org/W2149179203', 'https://openalex.org/W1988596541', 'https://openalex.org/W1507177964', 'https://openalex.org/W2403207842', 'https://openalex.org/W2112107221', 'https://openalex.org/W2144788278', 'https://openalex.org/W2407151108', 'https://openalex.org/W2125247927', 'https://openalex.org/W6601311673', 'https://openalex.org/W2089458547', 'https://openalex.org/W6632428362', 'https://openalex.org/W2079460648', 'https://openalex.org/W6602705600', 'https://openalex.org/W2161969291', 'https://openalex.org/W4211153864', 'https://openalex.org/W2025344845', 'https://openalex.org/W6633342350', 'https://openalex.org/W2097207027', 'https://openalex.org/W62023843', 'https://openalex.org/W4245668478', 'https://openalex.org/W2097128017', 'https://openalex.org/W66167291', 'https://openalex.org/W1499245496', 'https://openalex.org/W30845872', 'https://openalex.org/W1539935047', 'https://openalex.org/W20983465', 'https://openalex.org/W2045346852', 'https://openalex.org/W1556583247', 'https://openalex.org/W2141882396']",2012-04-09
https://openalex.org/W1967924372,https://doi.org/10.1109/icassp.2013.6639241,Weak top-down constraints for unsupervised acoustic model training,"Typical supervised acoustic model training relies on strong top-down constraints provided by dynamic programming alignment of the input observations to phonetic sequences derived from orthographic word transcripts and pronunciation dictionaries. This paper investigates a much weaker form of top-down supervision for use in place of transcripts and dictionaries in the zero resource setting. Our proposed constraints, which can be produced using recent spoken term discovery systems, come in the form of pairs of isolated word examples that share the same unknown type. For each pair, we perform a dynamic programming alignment of the acoustic observations of the two constituent examples, generating an inventory of cross-speaker frame pairs that each provide evidence that the same subword unit model should account for them. We find these weak top-down constraints are capable of improving model speaker independence by up to 57% relative over bottom-up training alone.","['https://openalex.org/W2128160875', 'https://openalex.org/W156237177', 'https://openalex.org/W2401464865', 'https://openalex.org/W6714100551', 'https://openalex.org/W6602705600', 'https://openalex.org/W2406820985', 'https://openalex.org/W2114478143', 'https://openalex.org/W6675022971', 'https://openalex.org/W2117041980', 'https://openalex.org/W2399869768', 'https://openalex.org/W3148201686', 'https://openalex.org/W2103933358', 'https://openalex.org/W2090861223', 'https://openalex.org/W1539935047', 'https://openalex.org/W2121947440', 'https://openalex.org/W1606268232', 'https://openalex.org/W2114347655', 'https://openalex.org/W2062914951', 'https://openalex.org/W2126203737', 'https://openalex.org/W2057007397', 'https://openalex.org/W30845872', 'https://openalex.org/W2079460648', 'https://openalex.org/W2407964052', 'https://openalex.org/W2100768664', 'https://openalex.org/W2407151108', 'https://openalex.org/W66167291']",2013-05-01
https://openalex.org/W2126377586,https://doi.org/10.1016/j.cognition.2009.03.008,A Bayesian framework for word segmentation: Exploring the effects of context,,"['https://openalex.org/W6609746230', 'https://openalex.org/W6982500881', 'https://openalex.org/W2154164802', 'https://openalex.org/W1975992139', 'https://openalex.org/W2115197214', 'https://openalex.org/W6602703493', 'https://openalex.org/W1971245457', 'https://openalex.org/W6791388132', 'https://openalex.org/W2089484716', 'https://openalex.org/W4231510805', 'https://openalex.org/W2132827946', 'https://openalex.org/W2074546930', 'https://openalex.org/W2029948425', 'https://openalex.org/W2071402670', 'https://openalex.org/W1997236510', 'https://openalex.org/W2064699871', 'https://openalex.org/W2166391802', 'https://openalex.org/W1526685788', 'https://openalex.org/W6679859123', 'https://openalex.org/W2117621558', 'https://openalex.org/W6727943367', 'https://openalex.org/W2126736494', 'https://openalex.org/W2025653016', 'https://openalex.org/W6606895322', 'https://openalex.org/W2110485445', 'https://openalex.org/W2091797506', 'https://openalex.org/W6682816277', 'https://openalex.org/W2069429561', 'https://openalex.org/W6677149852', 'https://openalex.org/W1500689260', 'https://openalex.org/W6677207036', 'https://openalex.org/W2786088222', 'https://openalex.org/W2130518563', 'https://openalex.org/W6677975208', 'https://openalex.org/W2020999234', 'https://openalex.org/W2101711363', 'https://openalex.org/W2111668269', 'https://openalex.org/W2172709584', 'https://openalex.org/W2122228338', 'https://openalex.org/W2159399018', 'https://openalex.org/W2604174198', 'https://openalex.org/W1990486914', 'https://openalex.org/W2882319491', 'https://openalex.org/W4251556668', 'https://openalex.org/W2138309709', 'https://openalex.org/W2117126688', 'https://openalex.org/W2157149948', 'https://openalex.org/W2105438133', 'https://openalex.org/W2061863127', 'https://openalex.org/W2059824090', 'https://openalex.org/W1934041838', 'https://openalex.org/W2049738347', 'https://openalex.org/W2157381218', 'https://openalex.org/W2065392216', 'https://openalex.org/W6679162469', 'https://openalex.org/W1995991622', 'https://openalex.org/W2135631383', 'https://openalex.org/W1993768374', 'https://openalex.org/W2056760934', 'https://openalex.org/W2111971553', 'https://openalex.org/W2118727822', 'https://openalex.org/W2149368642', 'https://openalex.org/W2080972498', 'https://openalex.org/W2003208764', 'https://openalex.org/W2149356016', 'https://openalex.org/W6678007500', 'https://openalex.org/W1980862600', 'https://openalex.org/W2115867364', 'https://openalex.org/W6638762797', 'https://openalex.org/W2154167968', 'https://openalex.org/W2136549906', 'https://openalex.org/W6683603713', 'https://openalex.org/W2142111485', 'https://openalex.org/W1991083510', 'https://openalex.org/W1994960488', 'https://openalex.org/W2161952424', 'https://openalex.org/W2121416338', 'https://openalex.org/W2016429292', 'https://openalex.org/W2147336195', 'https://openalex.org/W263845233', 'https://openalex.org/W1967465043', 'https://openalex.org/W2992985668', 'https://openalex.org/W1880262756', 'https://openalex.org/W167685538', 'https://openalex.org/W4232383088', 'https://openalex.org/W2111568643', 'https://openalex.org/W2154756108', 'https://openalex.org/W2123157758', 'https://openalex.org/W4237780050', 'https://openalex.org/W2130416410', 'https://openalex.org/W2122739034', 'https://openalex.org/W1985898923', 'https://openalex.org/W2045656233', 'https://openalex.org/W3136512150', 'https://openalex.org/W2528091958', 'https://openalex.org/W1487404635', 'https://openalex.org/W1982647060', 'https://openalex.org/W1483307070', 'https://openalex.org/W2009086942', 'https://openalex.org/W2005902041', 'https://openalex.org/W2070554026', 'https://openalex.org/W1779834323', 'https://openalex.org/W2132957691', 'https://openalex.org/W2117786207', 'https://openalex.org/W3150904112', 'https://openalex.org/W2131963099', 'https://openalex.org/W2540180329', 'https://openalex.org/W1663973292', 'https://openalex.org/W2703151831', 'https://openalex.org/W2158195707', 'https://openalex.org/W2760669695', 'https://openalex.org/W3147653952', 'https://openalex.org/W2120636621', 'https://openalex.org/W2158266063', 'https://openalex.org/W2420792277', 'https://openalex.org/W2004411856', 'https://openalex.org/W1842705192']",2009-05-06
https://openalex.org/W3044967013,https://doi.org/10.21437/interspeech.2020-2362,Evaluating the Reliability of Acoustic Speech Embeddings,"Speech embeddings are fixed-size acoustic representations of variable-length\nspeech sequences. They are increasingly used for a variety of tasks ranging\nfrom information retrieval to unsupervised term discovery and speech\nsegmentation. However, there is currently no clear methodology to compare or\noptimise the quality of these embeddings in a task-neutral way. Here, we\nsystematically compare two popular metrics, ABX discrimination and Mean Average\nPrecision (MAP), on 5 languages across 17 embedding methods, ranging from\nsupervised to fully unsupervised, and using different loss functions\n(autoencoders, correspondence autoencoders, siamese). Then we use the ABX and\nMAP to predict performances on a new downstream task: the unsupervised\nestimation of the frequencies of speech segments in a given corpus. We find\nthat overall, ABX and MAP correlate with one another and with frequency\nestimation. However, substantial discrepancies appear in the fine-grained\ndistinctions across languages and/or embedding methods. This makes it\nunrealistic at present to propose a task-independent silver bullet method for\ncomputing the intrinsic quality of speech embeddings. There is a need for more\ndetailed analysis of the metrics currently used to evaluate such embeddings.\n","['https://openalex.org/W2963620343', 'https://openalex.org/W2118020555', 'https://openalex.org/W2395899413', 'https://openalex.org/W1778492285', 'https://openalex.org/W2913062184', 'https://openalex.org/W2398490608', 'https://openalex.org/W2145410271', 'https://openalex.org/W2025482506', 'https://openalex.org/W2114347655', 'https://openalex.org/W1997505733', 'https://openalex.org/W2101234009', 'https://openalex.org/W2148154194', 'https://openalex.org/W2963340922', 'https://openalex.org/W2404799143', 'https://openalex.org/W2468716020', 'https://openalex.org/W1577418252', 'https://openalex.org/W1796128977', 'https://openalex.org/W2963720603', 'https://openalex.org/W2126377586', 'https://openalex.org/W2962736743', 'https://openalex.org/W2786608204', 'https://openalex.org/W4289564011', 'https://openalex.org/W3098361150', 'https://openalex.org/W2090861223', 'https://openalex.org/W2407151108', 'https://openalex.org/W2171019095', 'https://openalex.org/W2802557066', 'https://openalex.org/W2336585117', 'https://openalex.org/W2059652594', 'https://openalex.org/W2593864460', 'https://openalex.org/W2901751252']",2020-10-25
https://openalex.org/W2117126688,https://doi.org/10.7551/mitpress/7503.003.0085,Adaptor Grammars: A Framework for Specifying Compositional Nonparametric Bayesian Models,"This paper introduces adaptor grammars, a class of probabilistic models of language that generalize probabilistic context-free grammars (PCFGs).Adaptor grammars augment the probabilistic rules of PCFGs with ""adaptors"" that can induce dependencies among successive uses.With a particular choice of adaptor, based on the Pitman-Yor process, nonparametric Bayesian models of language using Dirichlet processes and hierarchical Dirichlet processes can be written as simple grammars.We present a general-purpose inference algorithm for adaptor grammars, making it easy to define and use such models, and illustrate how several existing nonparametric Bayesian models can be expressed within this framework.","['https://openalex.org/W2122228338', 'https://openalex.org/W2069429561', 'https://openalex.org/W2150507172', 'https://openalex.org/W2158266063', 'https://openalex.org/W2074546930', 'https://openalex.org/W2087309226', 'https://openalex.org/W2159399018', 'https://openalex.org/W1583697620', 'https://openalex.org/W2053218206', 'https://openalex.org/W2952343510']",2007-09-07
https://openalex.org/W2964115348,,"Linguistic unit discovery from multimodal inputs in unwritten languages: Summary of the ""Speaking Rosetta"" JSALT 2017 Workshop",We summarize the accomplishments of a multi-disciplinary workshop exploring the computational and scientific issues surrounding the discovery of linguistic units (subwords and words) in a language without orthography. We study the replacement of orthographic transcriptions by images and/or translated text in a well-resourced language to help unsupervised discovery from raw speech.,"['https://openalex.org/W2117041980', 'https://openalex.org/W2963620343', 'https://openalex.org/W2395052932', 'https://openalex.org/W2057007397', 'https://openalex.org/W1833498382', 'https://openalex.org/W2962862718', 'https://openalex.org/W2325972120', 'https://openalex.org/W2114347655', 'https://openalex.org/W4206864474', 'https://openalex.org/W2164505566', 'https://openalex.org/W2762715843', 'https://openalex.org/W2079460648', 'https://openalex.org/W2251025892', 'https://openalex.org/W1861492603', 'https://openalex.org/W2464234964', 'https://openalex.org/W2406349064', 'https://openalex.org/W1970890968', 'https://openalex.org/W2345799635', 'https://openalex.org/W2949328740', 'https://openalex.org/W1520968739', 'https://openalex.org/W2406324447', 'https://openalex.org/W1855892484', 'https://openalex.org/W2963819008', 'https://openalex.org/W2556930864', 'https://openalex.org/W2347098582', 'https://openalex.org/W2586148577', 'https://openalex.org/W4206865574', 'https://openalex.org/W2962832640', 'https://openalex.org/W3217769081']",2018-04-15
https://openalex.org/W2598638573,https://doi.org/10.21437/ssw.2016-33,Merlin: An Open Source Neural Network Speech Synthesis System,"We introduce the Merlin speech synthesis toolkit for neural network-based speech synthesis.The system takes linguistic features as input, and employs neural networks to predict acoustic features, which are then passed to a vocoder to produce the speech waveform.Various neural network architectures are implemented, including a standard feedforward neural network, mixture density neural network, recurrent neural network (RNN), long short-term memory (LSTM) recurrent neural network, amongst others.The toolkit is Open Source, written in Python, and is extensible.This paper briefly describes the system, and provides some benchmarking results on a freelyavailable corpus.","['https://openalex.org/W2402539796', 'https://openalex.org/W2100167690', 'https://openalex.org/W2129142580', 'https://openalex.org/W2399853303', 'https://openalex.org/W1924770834', 'https://openalex.org/W2406990556', 'https://openalex.org/W2049686551', 'https://openalex.org/W1990505856', 'https://openalex.org/W2402103843', 'https://openalex.org/W2045158511', 'https://openalex.org/W2111284386', 'https://openalex.org/W2134973740', 'https://openalex.org/W1888924187', 'https://openalex.org/W1571950845', 'https://openalex.org/W2397670047', 'https://openalex.org/W2102003408', 'https://openalex.org/W3123963976', 'https://openalex.org/W1613141907', 'https://openalex.org/W133102907', 'https://openalex.org/W2964060510', 'https://openalex.org/W1576227399', 'https://openalex.org/W2294797155', 'https://openalex.org/W2806733747', 'https://openalex.org/W2079735306', 'https://openalex.org/W1499332833', 'https://openalex.org/W2239904444', 'https://openalex.org/W1502723613', 'https://openalex.org/W1120805016', 'https://openalex.org/W2020024436', 'https://openalex.org/W2170980774', 'https://openalex.org/W31154030', 'https://openalex.org/W2395700867', 'https://openalex.org/W1544516254', 'https://openalex.org/W2404881427', 'https://openalex.org/W2043003570', 'https://openalex.org/W2471520273', 'https://openalex.org/W1543299179', 'https://openalex.org/W2136374105']",2016-09-13
https://openalex.org/W2995181338,https://doi.org/10.1109/icassp40776.2020.9052942,Libri-Light: A Benchmark for ASR with Limited or No Supervision,"We introduce a new collection of spoken English audio suitable for training\nspeech recognition systems under limited or no supervision. It is derived from\nopen-source audio books from the LibriVox project. It contains over 60K hours\nof audio, which is, to our knowledge, the largest freely-available corpus of\nspeech. The audio has been segmented using voice activity detection and is\ntagged with SNR, speaker ID and genre descriptions. Additionally, we provide\nbaseline systems and evaluation metrics working under three settings: (1) the\nzero resource/unsupervised setting (ABX), (2) the semi-supervised setting (PER,\nCER) and (3) the distant supervision setting (WER). Settings (2) and (3) use\nlimited textual resources (10 minutes to 10 hours) aligned with the speech.\nSetting (3) uses large amounts of unaligned text. They are evaluated on the\nstandard LibriSpeech dev and test sets for comparison with the supervised\nstate-of-the-art.\n","['https://openalex.org/W2963620343', 'https://openalex.org/W2940544976', 'https://openalex.org/W6629717138', 'https://openalex.org/W2937197076', 'https://openalex.org/W6712444837', 'https://openalex.org/W2592866267', 'https://openalex.org/W2953190524', 'https://openalex.org/W3005511757', 'https://openalex.org/W6751433836', 'https://openalex.org/W6770514103', 'https://openalex.org/W6756326128', 'https://openalex.org/W1970890968', 'https://openalex.org/W6656619859', 'https://openalex.org/W2127141656', 'https://openalex.org/W2973049979', 'https://openalex.org/W2842511635', 'https://openalex.org/W6775452034', 'https://openalex.org/W2346964103', 'https://openalex.org/W4234016251', 'https://openalex.org/W6747270024', 'https://openalex.org/W6679855610', 'https://openalex.org/W2944255943', 'https://openalex.org/W6748342566', 'https://openalex.org/W2972630480', 'https://openalex.org/W2963425185', 'https://openalex.org/W2161482971', 'https://openalex.org/W4288107125', 'https://openalex.org/W2979476256', 'https://openalex.org/W2963340922', 'https://openalex.org/W2899377381', 'https://openalex.org/W4297818305', 'https://openalex.org/W2134800885', 'https://openalex.org/W2593779438', 'https://openalex.org/W3103005696', 'https://openalex.org/W3016181583', 'https://openalex.org/W4297808394', 'https://openalex.org/W2988736778', 'https://openalex.org/W2804648901', 'https://openalex.org/W2025198378', 'https://openalex.org/W2161391345', 'https://openalex.org/W2787447541', 'https://openalex.org/W2926063217', 'https://openalex.org/W2794753807', 'https://openalex.org/W4300047444', 'https://openalex.org/W3015522062', 'https://openalex.org/W2395899413', 'https://openalex.org/W1494198834', 'https://openalex.org/W2996383576', 'https://openalex.org/W2973026522', 'https://openalex.org/W2781384251']",2020-04-09
https://openalex.org/W2014307400,https://doi.org/10.3758/brm.42.3.627,Wuggy: A multilingual pseudoword generator,,"['https://openalex.org/W2168979204', 'https://openalex.org/W2186780112', 'https://openalex.org/W2140255971', 'https://openalex.org/W1980082163', 'https://openalex.org/W1986788796', 'https://openalex.org/W2073556933', 'https://openalex.org/W2095845433', 'https://openalex.org/W2106558942', 'https://openalex.org/W4247667741', 'https://openalex.org/W2144710514', 'https://openalex.org/W2073441004', 'https://openalex.org/W2135314857', 'https://openalex.org/W2061625509', 'https://openalex.org/W2020220682', 'https://openalex.org/W4290377501', 'https://openalex.org/W2132193240']",2010-08-01
https://openalex.org/W2996728628,https://doi.org/10.1162/tacl_a_00321,BLiMP: The Benchmark of Linguistic Minimal Pairs for English (Electronic Resources),"We introduce The Benchmark of Linguistic Minimal Pairs (BLiMP),1 a challenge set for evaluating the linguistic knowledge of language models (LMs) on major grammatical phenomena in English. BLiMP consists of 67 individual datasets, each containing 1,000 minimal pairs—that is, pairs of minimally different sentences that contrast in grammatical acceptability and isolate specific phenomenon in syntax, morphology, or semantics. We generate the data according to linguist-crafted grammar templates, and human aggregate agreement with the labels is 96.4%. We evaluate n-gram, LSTM, and Transformer (GPT-2 and Transformer-XL) LMs by observing whether they assign a higher probability to the acceptable sentence in each minimal pair. We find that state-of-the-art models identify morphological contrasts related to agreement reliably, but they struggle with some subtle semantic and syntactic phenomena, such as negative polarity items and extraction islands.","['https://openalex.org/W2888922637', 'https://openalex.org/W2963025830', 'https://openalex.org/W1986120881', 'https://openalex.org/W2963403868', 'https://openalex.org/W2167723982', 'https://openalex.org/W2995181640', 'https://openalex.org/W2163730805', 'https://openalex.org/W2923014074', 'https://openalex.org/W2750779823', 'https://openalex.org/W2962961857', 'https://openalex.org/W2973957133', 'https://openalex.org/W2953369973', 'https://openalex.org/W2787560479', 'https://openalex.org/W2911109671', 'https://openalex.org/W2963494889', 'https://openalex.org/W3037191812', 'https://openalex.org/W2918996109', 'https://openalex.org/W2963026768', 'https://openalex.org/W1582487387', 'https://openalex.org/W2064675550', 'https://openalex.org/W2158195707', 'https://openalex.org/W2770232188', 'https://openalex.org/W4365799947', 'https://openalex.org/W2978670439', 'https://openalex.org/W2972351548', 'https://openalex.org/W2759181158', 'https://openalex.org/W2170716495', 'https://openalex.org/W4252209867', 'https://openalex.org/W2964117978', 'https://openalex.org/W179875071', 'https://openalex.org/W2730712696', 'https://openalex.org/W1502957213', 'https://openalex.org/W2549835527', 'https://openalex.org/W2971044268', 'https://openalex.org/W2531882892', 'https://openalex.org/W2994665957', 'https://openalex.org/W4388123003', 'https://openalex.org/W2964204621', 'https://openalex.org/W2891399254', 'https://openalex.org/W1984471812', 'https://openalex.org/W1974795422', 'https://openalex.org/W2963341956', 'https://openalex.org/W2599674900', 'https://openalex.org/W2612690371', 'https://openalex.org/W4245765565', 'https://openalex.org/W2864832950', 'https://openalex.org/W2563574619', 'https://openalex.org/W2124669395', 'https://openalex.org/W2515741950', 'https://openalex.org/W2141440284', 'https://openalex.org/W2972752636', 'https://openalex.org/W2981852735', 'https://openalex.org/W2902967615', 'https://openalex.org/W1586060904', 'https://openalex.org/W2962926715', 'https://openalex.org/W2251930319', 'https://openalex.org/W2024988999', 'https://openalex.org/W2990704537']",2020-07-29
https://openalex.org/W2963425185,https://doi.org/10.21437/interspeech.2018-2341,Speech2Vec: A Sequence-to-Sequence Framework for Learning Word Embeddings from Speech,"In this paper, we propose a novel deep neural network architecture, Speech2Vec, for learning fixed-length vector representations of audio segments excised from a speech corpus, where the vectors contain semantic information pertaining to the underlying spoken words, and are close to other vectors in the embedding space if their corresponding underlying spoken words are semantically similar.The proposed model can be viewed as a speech version of Word2Vec [1].Its design is based on a RNN Encoder-Decoder framework, and borrows the methodology of skipgrams or continuous bag-of-words for training.Learning word embeddings directly from speech enables Speech2Vec to make use of the semantic information carried by speech that does not exist in plain text.The learned word embeddings are evaluated and analyzed on 13 widely used word similarity benchmarks, and outperform word embeddings learned by Word2Vec from the transcriptions.","['https://openalex.org/W1494198834', 'https://openalex.org/W2132631284', 'https://openalex.org/W2103318667', 'https://openalex.org/W2187089797', 'https://openalex.org/W2556930864', 'https://openalex.org/W2133564696', 'https://openalex.org/W2611470828', 'https://openalex.org/W2139501017', 'https://openalex.org/W1854884267', 'https://openalex.org/W2964116568', 'https://openalex.org/W2951559648', 'https://openalex.org/W2962904995', 'https://openalex.org/W2493916176', 'https://openalex.org/W2962925243', 'https://openalex.org/W2251012068', 'https://openalex.org/W2059652594', 'https://openalex.org/W4294170691', 'https://openalex.org/W1860935423', 'https://openalex.org/W2130942839', 'https://openalex.org/W2137735870', 'https://openalex.org/W2176085882', 'https://openalex.org/W4300822525', 'https://openalex.org/W2142625445', 'https://openalex.org/W2296681920', 'https://openalex.org/W2468716020', 'https://openalex.org/W2252211741', 'https://openalex.org/W2170682101', 'https://openalex.org/W2190506272', 'https://openalex.org/W2951216052', 'https://openalex.org/W2137010615', 'https://openalex.org/W2296283641', 'https://openalex.org/W1902237438', 'https://openalex.org/W2964169922', 'https://openalex.org/W2963366649', 'https://openalex.org/W2767224889', 'https://openalex.org/W2251253014', 'https://openalex.org/W2963296402', 'https://openalex.org/W2157331557', 'https://openalex.org/W2962753610', 'https://openalex.org/W2080100102', 'https://openalex.org/W2891197287', 'https://openalex.org/W2250539671', 'https://openalex.org/W2963571336', 'https://openalex.org/W2899771611', 'https://openalex.org/W2550241133']",2018-08-28
https://openalex.org/W2170682101,https://doi.org/10.3115/1620754.1620758,A study on similarity and relatedness using distributional and WordNet-based approaches,"This paper presents and compares WordNet-based and distributional similarity approaches. The strengths and weaknesses of each approach regarding similarity and relatedness tasks are discussed, and a combination is presented. Each of our methods independently provide the best results in their class on the RG and WordSim353 datasets, and a supervised combination of them yields the best published results on all datasets. Finally, we pioneer cross-lingual similarity, showing that our methods are easily adapted for a cross-lingual task with minor losses.","['https://openalex.org/W2120779048', 'https://openalex.org/W1782572861', 'https://openalex.org/W2951798058', 'https://openalex.org/W4233775226', 'https://openalex.org/W192694488', 'https://openalex.org/W2166971953', 'https://openalex.org/W2096223431', 'https://openalex.org/W2161443453', 'https://openalex.org/W2100935296', 'https://openalex.org/W2136930489', 'https://openalex.org/W4255386104', 'https://openalex.org/W2103318667', 'https://openalex.org/W1959533457', 'https://openalex.org/W2136480620', 'https://openalex.org/W1567365482', 'https://openalex.org/W2170344111', 'https://openalex.org/W2166776180', 'https://openalex.org/W2055518963', 'https://openalex.org/W2534712034', 'https://openalex.org/W2149393279', 'https://openalex.org/W2149801387', 'https://openalex.org/W2117805756', 'https://openalex.org/W1517377188', 'https://openalex.org/W4300121351', 'https://openalex.org/W158057341', 'https://openalex.org/W1573498319', 'https://openalex.org/W2135207619', 'https://openalex.org/W4255198209', 'https://openalex.org/W1647729745', 'https://openalex.org/W1596967103', 'https://openalex.org/W2053921957', 'https://openalex.org/W2042160362', 'https://openalex.org/W4256347525', 'https://openalex.org/W2950225692', 'https://openalex.org/W2080100102', 'https://openalex.org/W2005181355']",2009-01-01
https://openalex.org/W2103318667,https://doi.org/10.1080/01690969108406936,Contextual correlates of semantic similarity,"Abstract The relationship between semantic and contextual similarity is investigated for pairs of nouns that vary from high to low semantic similarity. Semantic similarity is estimated by subjective ratings; contextual similarity is estimated by the method of sorting sentential contexts. The results show an inverse linear relationship between similarity of meaning and the discriminability of contexts. This relation, is obtained for two separate corpora of sentence contexts. It is concluded that, on average, for words in the same language drawn from the same syntactic and semantic categories, the more often two words can be substituted into the same contexts the more similar in meaning they are judged to be.","['https://openalex.org/W13823885', 'https://openalex.org/W2100322854', 'https://openalex.org/W2079194046', 'https://openalex.org/W2437277295', 'https://openalex.org/W2045553479', 'https://openalex.org/W4300703805', 'https://openalex.org/W4238944320', 'https://openalex.org/W4298351405', 'https://openalex.org/W1966153816', 'https://openalex.org/W2033716723', 'https://openalex.org/W4210560736', 'https://openalex.org/W1971220772', 'https://openalex.org/W2036895580', 'https://openalex.org/W1634667895', 'https://openalex.org/W2114826854', 'https://openalex.org/W2020159140', 'https://openalex.org/W1570047706', 'https://openalex.org/W1989415743', 'https://openalex.org/W2026442395', 'https://openalex.org/W4236556464', 'https://openalex.org/W2014735492', 'https://openalex.org/W2064332540', 'https://openalex.org/W2914326967', 'https://openalex.org/W2080100102', 'https://openalex.org/W1751175273', 'https://openalex.org/W1536719366', 'https://openalex.org/W2321575885', 'https://openalex.org/W2746118309', 'https://openalex.org/W4298028598', 'https://openalex.org/W1507401974', 'https://openalex.org/W4301847896', 'https://openalex.org/W1966680968', 'https://openalex.org/W2091384152', 'https://openalex.org/W2071094139', 'https://openalex.org/W1483126227', 'https://openalex.org/W2109334311', 'https://openalex.org/W1513522035', 'https://openalex.org/W2082766935', 'https://openalex.org/W2017580301', 'https://openalex.org/W1547269118', 'https://openalex.org/W4205256201', 'https://openalex.org/W3023045483']",1991-01-01
https://openalex.org/W2080100102,https://doi.org/10.1145/365628.365657,Contextual correlates of synonymy,"article Free AccessContextual correlates of synonymy Authors: Herbert Rubenstein Decision Sciences Lab, Bedford, MA Decision Sciences Lab, Bedford, MAView Profile , John B. Goodenough Decision Sciences Lab, Bedford, MA Decision Sciences Lab, Bedford, MAView Profile Authors Info & Claims Communications of the ACMVolume 8Issue 10Oct. 1965 pp 627–633https://doi.org/10.1145/365628.365657Published:01 October 1965Publication History 695citation3,459DownloadsMetricsTotal Citations695Total Downloads3,459Last 12 Months573Last 6 weeks59 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF","['https://openalex.org/W2882319491', 'https://openalex.org/W2015271197', 'https://openalex.org/W2087404238', 'https://openalex.org/W2033716723', 'https://openalex.org/W1738233868']",1965-10-01
https://openalex.org/W1854884267,https://doi.org/10.1162/coli_a_00237,SimLex-999: Evaluating Semantic Models With (Genuine) Similarity Estimation,"We present SimLex-999, a gold standard resource for evaluating distributional semantic models that improves on existing resources in several important ways. First, in contrast to gold standards such as WordSim-353 and MEN, it explicitly quantifies similarity rather than association or relatedness so that pairs of entities that are associated but not actually similar (Freud, psychology) have a low rating. We show that, via this focus on similarity, SimLex-999 incentivizes the development of models with a different, and arguably wider, range of applications than those which reflect conceptual association. Second, SimLex-999 contains a range of concrete and abstract adjective, noun, and verb pairs, together with an independent rating of concreteness and (free) association strength for each pair. This diversity enables fine-grained analyses of the performance of models on concepts of different types, and consequently greater insight into how architectures can be improved. Further, unlike existing gold standard evaluations, for which automatic approaches have reached or surpassed the inter-annotator agreement ceiling, state-of-the-art models perform well below this ceiling on SimLex-999. There is therefore plenty of scope for SimLex-999 to quantify future improvements to distributional semantic models, guiding the development of the next generation of representation-learning architectures.","['https://openalex.org/W2170682101', 'https://openalex.org/W2036931463', 'https://openalex.org/W2251874715', 'https://openalex.org/W2251803266', 'https://openalex.org/W2128870637', 'https://openalex.org/W2117865617', 'https://openalex.org/W2108530510', 'https://openalex.org/W2132339004', 'https://openalex.org/W21497345', 'https://openalex.org/W4251372957', 'https://openalex.org/W1979606348', 'https://openalex.org/W2136930489', 'https://openalex.org/W2123982464', 'https://openalex.org/W2117130368', 'https://openalex.org/W2067438047', 'https://openalex.org/W2000746239', 'https://openalex.org/W2482300836', 'https://openalex.org/W2078841894', 'https://openalex.org/W1984251878', 'https://openalex.org/W1788602', 'https://openalex.org/W2171802951', 'https://openalex.org/W2032964561', 'https://openalex.org/W2286410738', 'https://openalex.org/W2251117789', 'https://openalex.org/W2250676463', 'https://openalex.org/W1983578042', 'https://openalex.org/W2143413399', 'https://openalex.org/W2296076036', 'https://openalex.org/W2027267056', 'https://openalex.org/W2086039194', 'https://openalex.org/W2165979968', 'https://openalex.org/W2436001372', 'https://openalex.org/W2035726644', 'https://openalex.org/W1985953330', 'https://openalex.org/W2142120379', 'https://openalex.org/W2171836785', 'https://openalex.org/W2111258243', 'https://openalex.org/W1970476061', 'https://openalex.org/W1554804307', 'https://openalex.org/W2080834271', 'https://openalex.org/W2080100102', 'https://openalex.org/W2127002961', 'https://openalex.org/W1662133657', 'https://openalex.org/W2059975159', 'https://openalex.org/W1582344906', 'https://openalex.org/W2136480620', 'https://openalex.org/W2117805756', 'https://openalex.org/W2140406733', 'https://openalex.org/W1614298861', 'https://openalex.org/W181737412', 'https://openalex.org/W2158139315', 'https://openalex.org/W2135341569', 'https://openalex.org/W1541481035', 'https://openalex.org/W1565863475', 'https://openalex.org/W2251012068', 'https://openalex.org/W2098352331', 'https://openalex.org/W2164973920', 'https://openalex.org/W2129271949', 'https://openalex.org/W2290013849', 'https://openalex.org/W2137735870', 'https://openalex.org/W4285719527', 'https://openalex.org/W96809255', 'https://openalex.org/W2080902366', 'https://openalex.org/W3099386342', 'https://openalex.org/W2250742840', 'https://openalex.org/W191422183', 'https://openalex.org/W2506188197', 'https://openalex.org/W2126530744', 'https://openalex.org/W2154531419', 'https://openalex.org/W2150102617', 'https://openalex.org/W2251771443', 'https://openalex.org/W1868671693', 'https://openalex.org/W2164019165', 'https://openalex.org/W2250536421', 'https://openalex.org/W1566139570', 'https://openalex.org/W2143017621', 'https://openalex.org/W2153579005']",2015-12-01
https://openalex.org/W2176085882,https://doi.org/10.3115/v1/d14-1034,An Unsupervised Model for Instance Level Subcategorization Acquisition,"Most existing systems for subcategorization frame (SCF) acquisition rely on supervised parsing and infer SCF distributions at type, rather than instance level.These systems suffer from poor portability across domains and their benefit for NLP tasks that involve sentence-level processing is limited.We propose a new unsupervised, Markov Random Field-based model for SCF acquisition which is designed to address these problems.The system relies on supervised POS tagging rather than parsing, and is capable of learning SCFs at instance level.We perform evaluation against gold standard data which shows that our system outperforms several supervised and type-level SCF baselines.We also conduct task-based evaluation in the context of verb similarity prediction, demonstrating that a vector space model based on our SCFs substantially outperforms a lexical model and a model based on a supervised parser 1 .","['https://openalex.org/W2111024941', 'https://openalex.org/W1996430422', 'https://openalex.org/W2116410915', 'https://openalex.org/W2171116649', 'https://openalex.org/W2097606805', 'https://openalex.org/W1611318214', 'https://openalex.org/W2084774044', 'https://openalex.org/W1601035521', 'https://openalex.org/W1982827383', 'https://openalex.org/W2039217078', 'https://openalex.org/W32345482', 'https://openalex.org/W2068250380', 'https://openalex.org/W2757452186', 'https://openalex.org/W2607879133', 'https://openalex.org/W2099896133', 'https://openalex.org/W2250837944', 'https://openalex.org/W2121798597', 'https://openalex.org/W1511986666', 'https://openalex.org/W2119056510', 'https://openalex.org/W1662133657', 'https://openalex.org/W2250213987', 'https://openalex.org/W2029184000', 'https://openalex.org/W2129227538', 'https://openalex.org/W1508977358', 'https://openalex.org/W2153274216', 'https://openalex.org/W2005181355', 'https://openalex.org/W1585222170', 'https://openalex.org/W2081228205', 'https://openalex.org/W2250526231', 'https://openalex.org/W2053921957', 'https://openalex.org/W1945172732', 'https://openalex.org/W2144321756', 'https://openalex.org/W1818857488', 'https://openalex.org/W2107928532', 'https://openalex.org/W2083342361', 'https://openalex.org/W2251314312', 'https://openalex.org/W1490737687', 'https://openalex.org/W1855822899', 'https://openalex.org/W2135674549', 'https://openalex.org/W2076482515', 'https://openalex.org/W2121435899', 'https://openalex.org/W2074064986', 'https://openalex.org/W2088198454', 'https://openalex.org/W2078546664', 'https://openalex.org/W1972805353', 'https://openalex.org/W1502719479', 'https://openalex.org/W2138615112', 'https://openalex.org/W2130178369', 'https://openalex.org/W1564452174', 'https://openalex.org/W1909733559', 'https://openalex.org/W2130717590', 'https://openalex.org/W14067211', 'https://openalex.org/W1586407311', 'https://openalex.org/W1626542014', 'https://openalex.org/W81190909', 'https://openalex.org/W2052474702']",2014-01-01
https://openalex.org/W2026487812,https://doi.org/10.1145/1963405.1963455,A word at a time,"Computing the degree of semantic relatedness of words is a key functionality of many language applications such as search, clustering, and disambiguation. Previous approaches to computing semantic relatedness mostly used static language resources, while essentially ignoring their temporal aspects. We believe that a considerable amount of relatedness information can also be found in studying patterns of word usage over time. Consider, for instance, a newspaper archive spanning many years. Two words such as ""war"" and ""peace"" might rarely co-occur in the same articles, yet their patterns of use over time might be similar. In this paper, we propose a new semantic relatedness model, Temporal Semantic Analysis (TSA), which captures this temporal information. The previous state of the art method, Explicit Semantic Analysis (ESA), represented word semantics as a vector of concepts. TSA uses a more refined representation, where each concept is no longer scalar, but is instead represented as time series over a corpus of temporally-ordered documents. To the best of our knowledge, this is the first attempt to incorporate temporal evidence into models of semantic relatedness. Empirical evaluation shows that TSA provides consistent improvements over the state of the art ESA results on multiple benchmarks.","['https://openalex.org/W2918757710', 'https://openalex.org/W6637101025', 'https://openalex.org/W2127128140', 'https://openalex.org/W1963726077', 'https://openalex.org/W2091735588', 'https://openalex.org/W116902681', 'https://openalex.org/W2136930489', 'https://openalex.org/W2040546864', 'https://openalex.org/W1593239840', 'https://openalex.org/W2147152072', 'https://openalex.org/W1964365134', 'https://openalex.org/W2108280221', 'https://openalex.org/W4235505822', 'https://openalex.org/W3216404684', 'https://openalex.org/W2081798681', 'https://openalex.org/W2120779048', 'https://openalex.org/W2097766966', 'https://openalex.org/W2021314079', 'https://openalex.org/W2061986359', 'https://openalex.org/W2150739536', 'https://openalex.org/W2120084270', 'https://openalex.org/W2057714964', 'https://openalex.org/W2127536142', 'https://openalex.org/W3003709066', 'https://openalex.org/W2161443453', 'https://openalex.org/W2166008115', 'https://openalex.org/W2117065474', 'https://openalex.org/W2058602429', 'https://openalex.org/W2170907470', 'https://openalex.org/W2165299010', 'https://openalex.org/W2147880780', 'https://openalex.org/W1965495241', 'https://openalex.org/W1601068082', 'https://openalex.org/W2113889316', 'https://openalex.org/W2100935296', 'https://openalex.org/W2168621303', 'https://openalex.org/W2053921957', 'https://openalex.org/W1970381522', 'https://openalex.org/W1782572861', 'https://openalex.org/W1659833910', 'https://openalex.org/W2038721957', 'https://openalex.org/W158057341', 'https://openalex.org/W1647729745', 'https://openalex.org/W1984558542', 'https://openalex.org/W1521908097', 'https://openalex.org/W1660390307', 'https://openalex.org/W1646006088', 'https://openalex.org/W1992914835', 'https://openalex.org/W2022122406']",2011-03-28
https://openalex.org/W2142625445,https://doi.org/10.1145/2339530.2339751,Large-scale learning of word relatedness with constraints,"Prior work on computing semantic relatedness of words focused on representing their meaning in isolation, effectively disregarding inter-word affinities. We propose a large-scale data mining approach to learning word-word relatedness, where known pairs of related words impose constraints on the learning process. We learn for each word a low-dimensional representation, which strives to maximize the likelihood of a word given the contexts in which it appears. Our method, called CLEAR, is shown to significantly outperform previously published approaches. The proposed method is based on first principles, and is generic enough to exploit diverse types of text corpora, while having the flexibility to impose constraints on the derived word similarities. We also make publicly available a new labeled dataset for evaluating word relatedness algorithms, which we believe to be the largest such dataset to date.","['https://openalex.org/W2155870214', 'https://openalex.org/W1880262756', 'https://openalex.org/W2136930489', 'https://openalex.org/W1593239840', 'https://openalex.org/W2147152072', 'https://openalex.org/W4235505822', 'https://openalex.org/W1993509040', 'https://openalex.org/W3216404684', 'https://openalex.org/W3001753394', 'https://openalex.org/W2787894218', 'https://openalex.org/W6678578999', 'https://openalex.org/W588052932', 'https://openalex.org/W2120084270', 'https://openalex.org/W2026487812', 'https://openalex.org/W1994616650', 'https://openalex.org/W1557757161', 'https://openalex.org/W203276351', 'https://openalex.org/W1974595223', 'https://openalex.org/W2059975159', 'https://openalex.org/W1974406477', 'https://openalex.org/W2058602429', 'https://openalex.org/W2117065474', 'https://openalex.org/W2053921957', 'https://openalex.org/W1992914835', 'https://openalex.org/W2099938389', 'https://openalex.org/W1558797106', 'https://openalex.org/W1480376833', 'https://openalex.org/W2038721957', 'https://openalex.org/W2125972432', 'https://openalex.org/W2166490638', 'https://openalex.org/W1521908097', 'https://openalex.org/W1970381522']",2012-08-12
https://openalex.org/W1494198834,https://doi.org/10.1109/icassp.2015.7178964,Librispeech: An ASR corpus based on public domain audio books,"This paper introduces a new corpus of read English speech, suitable for training and evaluating speech recognition systems. The LibriSpeech corpus is derived from audiobooks that are part of the LibriVox project, and contains 1000 hours of speech sampled at 16 kHz. We have made the corpus freely available for download, along with separately prepared language-model training data and pre-built language models. We show that acoustic models trained on LibriSpeech give lower error rate on the Wall Street Journal (WSJ) test sets than models trained on WSJ itself. We are also releasing Kaldi scripts that make it easy to build these systems.","['https://openalex.org/W2113641473', 'https://openalex.org/W2090755665', 'https://openalex.org/W2148154194', 'https://openalex.org/W2106554350', 'https://openalex.org/W2087064593', 'https://openalex.org/W1647671624', 'https://openalex.org/W1517939602', 'https://openalex.org/W2037740282', 'https://openalex.org/W1599512239', 'https://openalex.org/W6631362777', 'https://openalex.org/W6603477829', 'https://openalex.org/W2024490156', 'https://openalex.org/W2164107060', 'https://openalex.org/W6712802073', 'https://openalex.org/W6677973343', 'https://openalex.org/W6636811518', 'https://openalex.org/W6738902873', 'https://openalex.org/W2097927681', 'https://openalex.org/W2026369565', 'https://openalex.org/W2330075180', 'https://openalex.org/W2950186769', 'https://openalex.org/W2125234026', 'https://openalex.org/W1524333225', 'https://openalex.org/W1934041838', 'https://openalex.org/W1631260214', 'https://openalex.org/W2397159106', 'https://openalex.org/W2620757702', 'https://openalex.org/W85707815', 'https://openalex.org/W2916535084']",2015-04-01
https://openalex.org/W2619697695,https://doi.org/10.1109/iccv.2017.73,"Look, Listen and Learn","We consider the question: what can be learnt by looking at and listening to a large number of unlabelled videos? There is a valuable, but so far untapped, source of information contained in the video itself - the correspondence between the visual and the audio streams, and we introduce a novel ""Audio-Visual Correspondence"" learning task that makes use of this. Training visual and audio networks from scratch, without any additional supervision other than the raw unconstrained videos themselves, is shown to successfully solve this task, and, more interestingly, result in good visual and audio representations. These features set the new state-of-the-art on two sound classification benchmarks, and perform on par with the state-of-the-art selfsupervised approaches on ImageNet classification. We also demonstrate that the network is able to localize objects in both modalities, as well as perform fine-grained recognition tasks.","['https://openalex.org/W2086384421', 'https://openalex.org/W6678360021', 'https://openalex.org/W6637373629', 'https://openalex.org/W2117539524', 'https://openalex.org/W6701655646', 'https://openalex.org/W219040644', 'https://openalex.org/W2183341477', 'https://openalex.org/W6678470764', 'https://openalex.org/W2593116425', 'https://openalex.org/W6729977899', 'https://openalex.org/W6638667902', 'https://openalex.org/W2105582566', 'https://openalex.org/W6631190155', 'https://openalex.org/W2287334441', 'https://openalex.org/W6684191040', 'https://openalex.org/W870084106', 'https://openalex.org/W2043045839', 'https://openalex.org/W2052666245', 'https://openalex.org/W6729831399', 'https://openalex.org/W6735927292', 'https://openalex.org/W2157498370', 'https://openalex.org/W2048679005', 'https://openalex.org/W6715501732', 'https://openalex.org/W343636949', 'https://openalex.org/W6682250724', 'https://openalex.org/W1520997877', 'https://openalex.org/W6700872662', 'https://openalex.org/W6722416126', 'https://openalex.org/W6725104640', 'https://openalex.org/W2964345931', 'https://openalex.org/W6643326691', 'https://openalex.org/W2963420272', 'https://openalex.org/W2487442924', 'https://openalex.org/W2321533354', 'https://openalex.org/W2962835968', 'https://openalex.org/W2163605009', 'https://openalex.org/W2095147901', 'https://openalex.org/W2963074118', 'https://openalex.org/W4294568686', 'https://openalex.org/W2962756039', 'https://openalex.org/W2148349024', 'https://openalex.org/W2123024445', 'https://openalex.org/W2326925005', 'https://openalex.org/W2124033848', 'https://openalex.org/W2964121744', 'https://openalex.org/W1836465849', 'https://openalex.org/W4293665662', 'https://openalex.org/W2604379605', 'https://openalex.org/W2556930864', 'https://openalex.org/W1522301498', 'https://openalex.org/W2962714319', 'https://openalex.org/W1972567154', 'https://openalex.org/W2619947201', 'https://openalex.org/W2963265008', 'https://openalex.org/W1686810756', 'https://openalex.org/W2511428026', 'https://openalex.org/W2963192800']",2017-10-01
https://openalex.org/W2586148577,https://doi.org/10.18653/v1/p17-1057,Representations of language in a model of visually grounded speech signal,"We present a visually grounded model of speech perception which projects spoken utterances and images to a joint semantic space. We use a multi-layer recurrent highway network to model the temporal nature of spoken speech, and show that it learns to extract both form and meaning-based linguistic knowledge from the input signal. We carry out an in-depth analysis of the representations used by different components of the trained model and show that encoding of semantic aspects tends to become richer as we go up the hierarchy of layers, whereas encoding of form-related aspects of the language input tends to initially increase and then plateau or decrease.","['https://openalex.org/W3213502289', 'https://openalex.org/W2155889433', 'https://openalex.org/W2282219577', 'https://openalex.org/W2292919134', 'https://openalex.org/W2953318193', 'https://openalex.org/W2123815913', 'https://openalex.org/W2531381952', 'https://openalex.org/W2471839888', 'https://openalex.org/W2194775991', 'https://openalex.org/W2172888184', 'https://openalex.org/W4245833664', 'https://openalex.org/W68733909', 'https://openalex.org/W1522301498', 'https://openalex.org/W2964121744', 'https://openalex.org/W2962776659', 'https://openalex.org/W2962835968', 'https://openalex.org/W2143623448', 'https://openalex.org/W4299801216', 'https://openalex.org/W2524611247', 'https://openalex.org/W385555557', 'https://openalex.org/W1905882502', 'https://openalex.org/W2580178245', 'https://openalex.org/W2515741950', 'https://openalex.org/W4394453761', 'https://openalex.org/W2951674897', 'https://openalex.org/W2952020226', 'https://openalex.org/W2251861449', 'https://openalex.org/W2962753610', 'https://openalex.org/W2953177656', 'https://openalex.org/W2953188482', 'https://openalex.org/W4294555862', 'https://openalex.org/W2160783091', 'https://openalex.org/W2963899908', 'https://openalex.org/W2134670479', 'https://openalex.org/W2562979205', 'https://openalex.org/W1686810756', 'https://openalex.org/W2396384435', 'https://openalex.org/W2107917162', 'https://openalex.org/W2556930864', 'https://openalex.org/W4237938692', 'https://openalex.org/W4297826211', 'https://openalex.org/W1861492603', 'https://openalex.org/W2127438782', 'https://openalex.org/W2962862718', 'https://openalex.org/W2250790822', 'https://openalex.org/W2117539524', 'https://openalex.org/W2137010615', 'https://openalex.org/W2473934411']",2017-01-01
https://openalex.org/W2949387496,https://doi.org/10.1523/jneurosci.0065-18.2018,"In Spoken Word Recognition, the Future Predicts the Past","Speech is an inherently noisy and ambiguous signal. To fluently derive meaning, a listener must integrate contextual information to guide interpretations of the sensory input. Although many studies have demonstrated the influence of prior context on speech perception, the neural mechanisms supporting the integration of subsequent context remain unknown. Using MEG to record from human auditory cortex, we analyzed responses to spoken words with a varyingly ambiguous onset phoneme, the identity of which is later disambiguated at the lexical uniqueness point. Fifty participants (both male and female) were recruited across two MEG experiments. Our findings suggest that primary auditory cortex is sensitive to phonological ambiguity very early during processing at just 50 ms after onset. Subphonemic detail is preserved in auditory cortex over long timescales and re-evoked at subsequent phoneme positions. Commitments to phonological categories occur in parallel, resolving on the shorter timescale of ∼450 ms. These findings provide evidence that future input determines the perception of earlier speech sounds by maintaining sensory features until they can be integrated with top-down lexical information.","['https://openalex.org/W3147793219', 'https://openalex.org/W4231913388', 'https://openalex.org/W2582743722', 'https://openalex.org/W2135894974', 'https://openalex.org/W2120025651', 'https://openalex.org/W2088738817', 'https://openalex.org/W2085027819', 'https://openalex.org/W4299687266', 'https://openalex.org/W2085460877', 'https://openalex.org/W1951724000', 'https://openalex.org/W1986008769', 'https://openalex.org/W2071912321', 'https://openalex.org/W2043090466', 'https://openalex.org/W1996259186', 'https://openalex.org/W2162711368', 'https://openalex.org/W2135704565', 'https://openalex.org/W1990211450', 'https://openalex.org/W2084209890', 'https://openalex.org/W4246695671', 'https://openalex.org/W2528189865', 'https://openalex.org/W2011627227', 'https://openalex.org/W1976359583', 'https://openalex.org/W1965349238', 'https://openalex.org/W2048471469', 'https://openalex.org/W1875231349', 'https://openalex.org/W4301512201', 'https://openalex.org/W2081794212', 'https://openalex.org/W2563866812', 'https://openalex.org/W2015272368', 'https://openalex.org/W2013875934', 'https://openalex.org/W2068981233', 'https://openalex.org/W2135280482', 'https://openalex.org/W2079951026', 'https://openalex.org/W2140789293', 'https://openalex.org/W1965248225', 'https://openalex.org/W2131062138', 'https://openalex.org/W2156899532', 'https://openalex.org/W2002114312', 'https://openalex.org/W2034498217', 'https://openalex.org/W2582721013', 'https://openalex.org/W2169134378', 'https://openalex.org/W2013150886', 'https://openalex.org/W2079207700', 'https://openalex.org/W4254127581', 'https://openalex.org/W2146924077', 'https://openalex.org/W2113545763', 'https://openalex.org/W2131140847', 'https://openalex.org/W2054168569', 'https://openalex.org/W2802373946', 'https://openalex.org/W2168979204', 'https://openalex.org/W2053681687', 'https://openalex.org/W2134952451', 'https://openalex.org/W1518285299', 'https://openalex.org/W2147723409', 'https://openalex.org/W2030351702', 'https://openalex.org/W2137172783', 'https://openalex.org/W1977531436', 'https://openalex.org/W1979330310', 'https://openalex.org/W2032625358', 'https://openalex.org/W2963446970', 'https://openalex.org/W4248963734', 'https://openalex.org/W2285151101', 'https://openalex.org/W2135595031', 'https://openalex.org/W2100941255', 'https://openalex.org/W2603968080', 'https://openalex.org/W2154649497', 'https://openalex.org/W2690777458', 'https://openalex.org/W1987188408', 'https://openalex.org/W2018338408', 'https://openalex.org/W2148345678', 'https://openalex.org/W346503201', 'https://openalex.org/W1773398849', 'https://openalex.org/W2365553918', 'https://openalex.org/W2125633255', 'https://openalex.org/W2110920486']",2018-07-16
https://openalex.org/W3160251434,https://doi.org/10.1111/cogs.12943,Probing Lexical Ambiguity: Word Vectors Encode Number and Relatedness of Senses,"Abstract Lexical ambiguity—the phenomenon of a single word having multiple, distinguishable senses—is pervasive in language. Both the degree of ambiguity of a word (roughly, its number of senses) and the relatedness of those senses have been found to have widespread effects on language acquisition and processing. Recently, distributional approaches to semantics, in which a word's meaning is determined by its contexts, have led to successful research quantifying the degree of ambiguity, but these measures have not distinguished between the ambiguity of words with multiple related senses versus multiple unrelated meanings. In this work, we present the first assessment of whether distributional meaning representations can capture the ambiguity structure of a word, including both the number and relatedness of senses. On a very large sample of English words, we find that some, but not all, distributional semantic representations that we test exhibit detectable differences between sets of monosemes (unambiguous words; N = 964), polysemes (with multiple related senses; N = 4,096), and homonyms (with multiple unrelated senses; N = 355). Our findings begin to answer open questions from earlier work regarding whether distributional semantic representations of words, which successfully capture various semantic relationships, also reflect fine‐grained aspects of meaning structure that influence human behavior. Our findings emphasize the importance of measuring whether proposed lexical representations capture such distinctions: In addition to standard benchmarks that test the similarity structure of distributional semantic models, we need to also consider whether they have cognitively plausible ambiguity structure.","['https://openalex.org/W2111267834', 'https://openalex.org/W2399777503', 'https://openalex.org/W2056763217', 'https://openalex.org/W2037493627', 'https://openalex.org/W2295508206', 'https://openalex.org/W2963639656', 'https://openalex.org/W2053362255', 'https://openalex.org/W2251803266', 'https://openalex.org/W2092723833', 'https://openalex.org/W2979247533', 'https://openalex.org/W7002254874', 'https://openalex.org/W360559091', 'https://openalex.org/W1481333559', 'https://openalex.org/W2477496173', 'https://openalex.org/W2334841817', 'https://openalex.org/W1997161938', 'https://openalex.org/W2025075790', 'https://openalex.org/W2014440992', 'https://openalex.org/W2482447406', 'https://openalex.org/W1989376754', 'https://openalex.org/W1985587054', 'https://openalex.org/W1597195725', 'https://openalex.org/W2736989307', 'https://openalex.org/W6769430610', 'https://openalex.org/W1984866353', 'https://openalex.org/W4236522562', 'https://openalex.org/W6650698052', 'https://openalex.org/W2031497137', 'https://openalex.org/W2005665919', 'https://openalex.org/W2151482304', 'https://openalex.org/W2106872048', 'https://openalex.org/W2345836734', 'https://openalex.org/W2884872018', 'https://openalex.org/W6753935773', 'https://openalex.org/W6736035027', 'https://openalex.org/W2156526064', 'https://openalex.org/W6683275052', 'https://openalex.org/W1986707196', 'https://openalex.org/W3191219186', 'https://openalex.org/W6799424760', 'https://openalex.org/W2099584159', 'https://openalex.org/W6674872719', 'https://openalex.org/W1975593115', 'https://openalex.org/W2100313834', 'https://openalex.org/W1983578042', 'https://openalex.org/W1615991656', 'https://openalex.org/W1010415138', 'https://openalex.org/W2037387434', 'https://openalex.org/W2078894097', 'https://openalex.org/W1614298861', 'https://openalex.org/W2153579005', 'https://openalex.org/W6729126190', 'https://openalex.org/W810147176', 'https://openalex.org/W4247487857', 'https://openalex.org/W2250539671', 'https://openalex.org/W6691431627', 'https://openalex.org/W2507274780', 'https://openalex.org/W2004841825', 'https://openalex.org/W2288693139', 'https://openalex.org/W2118004980', 'https://openalex.org/W2153501447', 'https://openalex.org/W2790612928', 'https://openalex.org/W6749168449', 'https://openalex.org/W2164973920', 'https://openalex.org/W6602245285', 'https://openalex.org/W2046121397', 'https://openalex.org/W2146158822', 'https://openalex.org/W4246716965', 'https://openalex.org/W6604617241', 'https://openalex.org/W2767253414', 'https://openalex.org/W2252211741', 'https://openalex.org/W2130337399', 'https://openalex.org/W2080149055', 'https://openalex.org/W6670618154', 'https://openalex.org/W2065278061', 'https://openalex.org/W2132193240', 'https://openalex.org/W2140452151', 'https://openalex.org/W6681099935', 'https://openalex.org/W2599276130', 'https://openalex.org/W2605063145', 'https://openalex.org/W2001949459', 'https://openalex.org/W2604272474', 'https://openalex.org/W2891553961', 'https://openalex.org/W2760669695', 'https://openalex.org/W392761142', 'https://openalex.org/W113586804', 'https://openalex.org/W2613000335']",2021-05-01
https://openalex.org/W2332013542,https://doi.org/10.2307/538001,Course in General Linguistics,,[],1960-07-01
https://openalex.org/W2069857264,https://doi.org/10.1007/s11525-014-9242-z,Word and the Americanist perspective,,"['https://openalex.org/W7056981767', 'https://openalex.org/W596964094', 'https://openalex.org/W4301878799', 'https://openalex.org/W2575217003', 'https://openalex.org/W7070480813', 'https://openalex.org/W214730478', 'https://openalex.org/W6702132775', 'https://openalex.org/W6632514605', 'https://openalex.org/W4213126324', 'https://openalex.org/W6824492111', 'https://openalex.org/W6630149844', 'https://openalex.org/W7006751849', 'https://openalex.org/W4242438765', 'https://openalex.org/W55132463', 'https://openalex.org/W625445412', 'https://openalex.org/W2495920857', 'https://openalex.org/W6658051190', 'https://openalex.org/W2038542953', 'https://openalex.org/W6677807142', 'https://openalex.org/W6628808731', 'https://openalex.org/W127049220', 'https://openalex.org/W1594938058', 'https://openalex.org/W4256395818', 'https://openalex.org/W6807628732', 'https://openalex.org/W2092516186', 'https://openalex.org/W6617080431', 'https://openalex.org/W2488330084', 'https://openalex.org/W1562911371', 'https://openalex.org/W2345719788', 'https://openalex.org/W2111042112', 'https://openalex.org/W2148917251', 'https://openalex.org/W1504955803', 'https://openalex.org/W6635731811', 'https://openalex.org/W4214610173', 'https://openalex.org/W3131162924', 'https://openalex.org/W4231609280', 'https://openalex.org/W7009098526', 'https://openalex.org/W2035869314', 'https://openalex.org/W2343181265', 'https://openalex.org/W7034063146', 'https://openalex.org/W6731719308', 'https://openalex.org/W2320048127', 'https://openalex.org/W2021385925', 'https://openalex.org/W2119872545', 'https://openalex.org/W1504127138', 'https://openalex.org/W2156940641', 'https://openalex.org/W587375785', 'https://openalex.org/W1885856807', 'https://openalex.org/W584075463', 'https://openalex.org/W1595210733', 'https://openalex.org/W20815070', 'https://openalex.org/W2571528555', 'https://openalex.org/W301902852', 'https://openalex.org/W1492117853', 'https://openalex.org/W2507048821', 'https://openalex.org/W2096883086', 'https://openalex.org/W427940727', 'https://openalex.org/W77797504', 'https://openalex.org/W4387627350', 'https://openalex.org/W1534300969', 'https://openalex.org/W2676700929', 'https://openalex.org/W2029928670', 'https://openalex.org/W1479664672', 'https://openalex.org/W4211111292', 'https://openalex.org/W803770162', 'https://openalex.org/W1540550292', 'https://openalex.org/W1516286893', 'https://openalex.org/W4249702653', 'https://openalex.org/W4285719527', 'https://openalex.org/W778446758', 'https://openalex.org/W1545698603', 'https://openalex.org/W2954868721']",2014-09-01
https://openalex.org/W3209984917,https://doi.org/10.1109/jstsp.2022.3188113,WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing,"Self-supervised learning (SSL) achieves great success in speech recognition,\nwhile limited exploration has been attempted for other speech processing tasks.\nAs speech signal contains multi-faceted information including speaker identity,\nparalinguistics, spoken content, etc., learning universal representations for\nall speech tasks is challenging. To tackle the problem, we propose a new\npre-trained model, WavLM, to solve full-stack downstream speech tasks. WavLM\njointly learns masked speech prediction and denoising in pre-training. By this\nmeans, WavLM does not only keep the speech content modeling capability by the\nmasked speech prediction, but also improves the potential to non-ASR tasks by\nthe speech denoising. In addition, WavLM employs gated relative position bias\nfor the Transformer structure to better capture the sequence ordering of input\nspeech. We also scale up the training dataset from 60k hours to 94k hours.\nWavLM Large achieves state-of-the-art performance on the SUPERB benchmark, and\nbrings significant improvements for various speech processing tasks on their\nrepresentative benchmarks. The code and pre-trained models are available at\nhttps://aka.ms/wavlm.\n","['https://openalex.org/W2896457183', 'https://openalex.org/W6763701032', 'https://openalex.org/W6769627184', 'https://openalex.org/W6844194202', 'https://openalex.org/W6780218876', 'https://openalex.org/W3209059054', 'https://openalex.org/W6788335241', 'https://openalex.org/W3197580070', 'https://openalex.org/W2995181338', 'https://openalex.org/W6791904447', 'https://openalex.org/W3198270883', 'https://openalex.org/W2963122170', 'https://openalex.org/W3008181812', 'https://openalex.org/W3198771897', 'https://openalex.org/W3175898847', 'https://openalex.org/W3198694222', 'https://openalex.org/W3119308075', 'https://openalex.org/W3024869864', 'https://openalex.org/W2981087920', 'https://openalex.org/W3016232124', 'https://openalex.org/W3163842642', 'https://openalex.org/W3212886388', 'https://openalex.org/W4225661121', 'https://openalex.org/W2951974815', 'https://openalex.org/W2962850167', 'https://openalex.org/W6745117592', 'https://openalex.org/W3100270690', 'https://openalex.org/W3097286738', 'https://openalex.org/W2972943112', 'https://openalex.org/W3016011332', 'https://openalex.org/W3035202887', 'https://openalex.org/W3198858531', 'https://openalex.org/W3041561163', 'https://openalex.org/W2982223350', 'https://openalex.org/W3015265920', 'https://openalex.org/W3206996142', 'https://openalex.org/W2973049979', 'https://openalex.org/W6769196770', 'https://openalex.org/W3015356564', 'https://openalex.org/W4226033575', 'https://openalex.org/W2973157397', 'https://openalex.org/W3015213852', 'https://openalex.org/W3212799896', 'https://openalex.org/W3206252155', 'https://openalex.org/W3204696009', 'https://openalex.org/W6739901393', 'https://openalex.org/W3197042120', 'https://openalex.org/W3194687854', 'https://openalex.org/W1494198834', 'https://openalex.org/W6796242362', 'https://openalex.org/W3016181583', 'https://openalex.org/W2808631503', 'https://openalex.org/W6688816777', 'https://openalex.org/W2969985801', 'https://openalex.org/W6801723603', 'https://openalex.org/W3094374485', 'https://openalex.org/W2157161740', 'https://openalex.org/W125553504', 'https://openalex.org/W3095212884', 'https://openalex.org/W6779069803', 'https://openalex.org/W3178462146', 'https://openalex.org/W4220731890', 'https://openalex.org/W3196857193', 'https://openalex.org/W2696967604', 'https://openalex.org/W2972949456', 'https://openalex.org/W123007118', 'https://openalex.org/W3095189764', 'https://openalex.org/W2069681747', 'https://openalex.org/W2765425905', 'https://openalex.org/W2803322398', 'https://openalex.org/W2117678320', 'https://openalex.org/W2030486566', 'https://openalex.org/W6757817989', 'https://openalex.org/W3160936850', 'https://openalex.org/W3193846000', 'https://openalex.org/W3205495812', 'https://openalex.org/W6770506093', 'https://openalex.org/W3016010032', 'https://openalex.org/W3095173472', 'https://openalex.org/W3097777922', 'https://openalex.org/W2127141656', 'https://openalex.org/W2936774411', 'https://openalex.org/W6768080748', 'https://openalex.org/W2331143823', 'https://openalex.org/W2953190524', 'https://openalex.org/W3205644108', 'https://openalex.org/W2963618559', 'https://openalex.org/W3026868282', 'https://openalex.org/W2963341956', 'https://openalex.org/W2996383576', 'https://openalex.org/W2950813464', 'https://openalex.org/W3004728855', 'https://openalex.org/W3125709657', 'https://openalex.org/W3099782249', 'https://openalex.org/W4287120025', 'https://openalex.org/W3178296206', 'https://openalex.org/W2219249508', 'https://openalex.org/W2758785877', 'https://openalex.org/W4385245566', 'https://openalex.org/W4297808394', 'https://openalex.org/W3169688220', 'https://openalex.org/W4300427991', 'https://openalex.org/W3125596972', 'https://openalex.org/W2975381464', 'https://openalex.org/W4308349017', 'https://openalex.org/W4287374065', 'https://openalex.org/W2991213871', 'https://openalex.org/W3095292526', 'https://openalex.org/W3112034174', 'https://openalex.org/W3082274269', 'https://openalex.org/W2972712416', 'https://openalex.org/W3157923770', 'https://openalex.org/W3144173820', 'https://openalex.org/W3169320628', 'https://openalex.org/W4288089799', 'https://openalex.org/W3198698812', 'https://openalex.org/W4307023467', 'https://openalex.org/W2970597249', 'https://openalex.org/W2963403868', 'https://openalex.org/W3174648740', 'https://openalex.org/W3139918052', 'https://openalex.org/W4285250921', 'https://openalex.org/W2726515241', 'https://openalex.org/W4294796045', 'https://openalex.org/W4306169301', 'https://openalex.org/W3165647589', 'https://openalex.org/W2979476256', 'https://openalex.org/W3033627755', 'https://openalex.org/W2842511635', 'https://openalex.org/W2908510526', 'https://openalex.org/W3002741552', 'https://openalex.org/W3036601975', 'https://openalex.org/W3162648834']",2022-07-04
https://openalex.org/W3198217962,https://doi.org/10.18653/v1/2022.acl-long.593,Text-Free Prosody-Aware Generative Spoken Language Modeling,"Eugene Kharitonov, Ann Lee, Adam Polyak, Yossi Adi, Jade Copet, Kushal Lakhotia, Tu Anh Nguyen, Morgane Riviere, Abdelrahman Mohamed, Emmanuel Dupoux, Wei-Ning Hsu. Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2022.","['https://openalex.org/W2107740512', 'https://openalex.org/W2141885148', 'https://openalex.org/W1524333225', 'https://openalex.org/W3169320628', 'https://openalex.org/W2151083697', 'https://openalex.org/W2130086727', 'https://openalex.org/W3157923770', 'https://openalex.org/W2810914326', 'https://openalex.org/W2160473997', 'https://openalex.org/W3098403858', 'https://openalex.org/W3099782249', 'https://openalex.org/W3036601975', 'https://openalex.org/W2112078429', 'https://openalex.org/W2972943112', 'https://openalex.org/W2608207374', 'https://openalex.org/W2426479676', 'https://openalex.org/W2973049979', 'https://openalex.org/W3095948607', 'https://openalex.org/W3098903812', 'https://openalex.org/W2527729766', 'https://openalex.org/W1597422500', 'https://openalex.org/W3150572638', 'https://openalex.org/W2123409957', 'https://openalex.org/W2950349262', 'https://openalex.org/W2949382160', 'https://openalex.org/W2982223350', 'https://openalex.org/W1522301498', 'https://openalex.org/W2143827132', 'https://openalex.org/W3112034174', 'https://openalex.org/W359161088', 'https://openalex.org/W2963799213', 'https://openalex.org/W2118748593', 'https://openalex.org/W3039910566', 'https://openalex.org/W2842511635', 'https://openalex.org/W3094247854', 'https://openalex.org/W2913151434', 'https://openalex.org/W3210177631', 'https://openalex.org/W1494198834', 'https://openalex.org/W2093585241', 'https://openalex.org/W3033411150', 'https://openalex.org/W3148101939', 'https://openalex.org/W2995181338', 'https://openalex.org/W3140429000']",2022-01-01
https://openalex.org/W4225726571,https://doi.org/10.21437/interspeech.2022-373,"Probing phoneme, language and speaker information in unsupervised speech representations","Unsupervised models of representations based on Contrastive Predictive Coding\n(CPC)[1] are primarily used in spoken language modelling in that they encode\nphonetic information. In this study, we ask what other types of information are\npresent in CPC speech representations. We focus on three categories: phone\nclass, gender and language, and compare monolingual and bilingual models. Using\nqualitative and quantitative tools, we find that both gender and phone class\ninformation are present in both types of models. Language information, however,\nis very salient in the bilingual model only, suggesting CPC models learn to\ndiscriminate languages when trained on multiple languages. Some language\ninformation can also be retrieved from monolingual models, but it is more\ndiffused across all features. These patterns hold when analyses are carried on\nthe discrete units from a downstream clustering model. However, although there\nis no effect of the number of target clusters on phone class and language\ninformation, more gender information is encoded with more clusters. Finally, we\nfind that there is some cost to being exposed to two languages on a downstream\nphoneme discrimination task.\n","['https://openalex.org/W1728842521', 'https://openalex.org/W3140429000', 'https://openalex.org/W3036601975', 'https://openalex.org/W2973049979', 'https://openalex.org/W4287591426', 'https://openalex.org/W4287854499', 'https://openalex.org/W2979476256', 'https://openalex.org/W3102342027', 'https://openalex.org/W4283332789', 'https://openalex.org/W4297808394', 'https://openalex.org/W2395899413', 'https://openalex.org/W3169320628', 'https://openalex.org/W3125709657', 'https://openalex.org/W3198815374', 'https://openalex.org/W3031133340', 'https://openalex.org/W3030437843', 'https://openalex.org/W4301785137', 'https://openalex.org/W4295312788', 'https://openalex.org/W2542768043', 'https://openalex.org/W4300047444', 'https://openalex.org/W1524333225', 'https://openalex.org/W4287887366', 'https://openalex.org/W2187089797', 'https://openalex.org/W3016181583']",2022-09-16
https://openalex.org/W3093121832,https://doi.org/10.21437/interspeech.2020-1671,Perceptimatic: A Human Speech Perception Benchmark for Unsupervised Subword Modelling,"In this paper, we present a data set and methods to compare speech processing models and human behaviour on a phone discrimination task. We provide Perceptimatic, an open data set which consists of French and English speech stimuli, as well as the results of 91 English- and 93 French-speaking listeners. The stimuli test a wide range of French and English contrasts, and are extracted directly from corpora of natural running read speech, used for the 2017 Zero Resource Speech Challenge. We provide a method to compare humans' perceptual space with models' representational space, and we apply it to models previously submitted to the Challenge. We show that, unlike unsupervised models and supervised multilingual models, a standard supervised monolingual HMM-GMM phone recognition system, while good at discriminating phones, yields a representational space very different from that of human native listeners.","['https://openalex.org/W1524333225', 'https://openalex.org/W2785415724', 'https://openalex.org/W2963620343', 'https://openalex.org/W2786902352', 'https://openalex.org/W2787223168', 'https://openalex.org/W2911249026', 'https://openalex.org/W2940544976', 'https://openalex.org/W2963980299', 'https://openalex.org/W4288279357', 'https://openalex.org/W1568183767', 'https://openalex.org/W2787426069', 'https://openalex.org/W3023172065', 'https://openalex.org/W2730658205', 'https://openalex.org/W2517346207', 'https://openalex.org/W2759889345', 'https://openalex.org/W2399576818', 'https://openalex.org/W2786337938', 'https://openalex.org/W4288107125', 'https://openalex.org/W2786608204', 'https://openalex.org/W2325526696', 'https://openalex.org/W2787447541', 'https://openalex.org/W4300047444', 'https://openalex.org/W2889500720', 'https://openalex.org/W2768352418']",2020-10-25
https://openalex.org/W3148101939,https://doi.org/10.1109/slt48900.2021.9383461,Towards Unsupervised Learning of Speech Features in the Wild,"Recent work on unsupervised contrastive learning of speech representation has shown promising results, but so far has mostly been applied to clean, curated speech datasets. Can it also be used with unprepared audio data ""in the wild""? Here, we explore three potential problems in this setting: (i) presence of non-speech data, (ii) noisy or low quality speech data, and (iii) imbalance in speaker distribution. We show that on the Libri-light train set, which is itself a relatively clean speech-only dataset, these problems combined can already have a performance cost of up to 30% relative for the ABX score. We show that the first two problems can be alleviated by data filtering, with voice activity detection selecting speech segments, while perplexity of a model trained with clean data helping to discard entire files. We show that the third problem can be alleviated by learning a speaker embedding in the predictive branch of the model. We show that these techniques build more robust speech features that can be transferred to an ASR task in the low resource setting.","['https://openalex.org/W6743986254', 'https://openalex.org/W2127141656', 'https://openalex.org/W6769455919', 'https://openalex.org/W3015213852', 'https://openalex.org/W6770514103', 'https://openalex.org/W6714100551', 'https://openalex.org/W3015783745', 'https://openalex.org/W1494198834', 'https://openalex.org/W6739901393', 'https://openalex.org/W2842511635', 'https://openalex.org/W2983785920', 'https://openalex.org/W6780483730', 'https://openalex.org/W6761553608', 'https://openalex.org/W2111702745', 'https://openalex.org/W2124558353', 'https://openalex.org/W2147590749', 'https://openalex.org/W2430252546', 'https://openalex.org/W2079623482', 'https://openalex.org/W2889374926', 'https://openalex.org/W2963381607', 'https://openalex.org/W3015501067', 'https://openalex.org/W6712444837', 'https://openalex.org/W2973049979', 'https://openalex.org/W3093096176', 'https://openalex.org/W6697293080', 'https://openalex.org/W3016181583', 'https://openalex.org/W6771812881', 'https://openalex.org/W3003875258', 'https://openalex.org/W3102342027', 'https://openalex.org/W2346964103', 'https://openalex.org/W6844194202', 'https://openalex.org/W2940544976', 'https://openalex.org/W2796339975', 'https://openalex.org/W2133223948', 'https://openalex.org/W6750523955', 'https://openalex.org/W2787447541', 'https://openalex.org/W6780218876', 'https://openalex.org/W2950414763', 'https://openalex.org/W2055408826', 'https://openalex.org/W2962850179', 'https://openalex.org/W2973026522', 'https://openalex.org/W4289564011', 'https://openalex.org/W3036601975', 'https://openalex.org/W2995181338', 'https://openalex.org/W2988736778', 'https://openalex.org/W2795282075', 'https://openalex.org/W3093427098', 'https://openalex.org/W2407151108', 'https://openalex.org/W2963403868', 'https://openalex.org/W3144810982', 'https://openalex.org/W3099782249', 'https://openalex.org/W3016011332', 'https://openalex.org/W2963620343', 'https://openalex.org/W4385245566', 'https://openalex.org/W2990583358', 'https://openalex.org/W2593779438', 'https://openalex.org/W4297808394', 'https://openalex.org/W2963371670', 'https://openalex.org/W2753008876', 'https://openalex.org/W2786608204', 'https://openalex.org/W2395899413', 'https://openalex.org/W2930682606', 'https://openalex.org/W2953190524']",2021-01-19
https://openalex.org/W3007068036,https://doi.org/10.1109/asru46091.2019.9003853,Speech-to-Speech Translation Between Untranscribed Unknown Languages,"In this paper, we explore a method for training speech-to-speech translation tasks without any transcription or linguistic supervision. Our proposed method consists of two steps: First, we train and generate discrete representation with unsupervised term discovery with a discrete quantized autoencoder. Second, we train a sequence-to-sequence model that directly maps the source language speech to the target languages discrete representation. Our proposed method can directly generate target speech without any auxiliary or pre-training steps with a source or target transcription. To the best of our knowledge, this is the first work that performed pure speech-to-speech translation between untranscribed unknown languages.","['https://openalex.org/W2963581463', 'https://openalex.org/W2963796886', 'https://openalex.org/W2962699523', 'https://openalex.org/W6681644459', 'https://openalex.org/W6678262379', 'https://openalex.org/W6898505805', 'https://openalex.org/W2963620343', 'https://openalex.org/W2940544976', 'https://openalex.org/W2947445680', 'https://openalex.org/W6763445112', 'https://openalex.org/W2752796333', 'https://openalex.org/W2025768430', 'https://openalex.org/W6748381668', 'https://openalex.org/W6757152577', 'https://openalex.org/W6608432165', 'https://openalex.org/W2466918907', 'https://openalex.org/W2120847449', 'https://openalex.org/W6736180185', 'https://openalex.org/W2161742089', 'https://openalex.org/W6732953234', 'https://openalex.org/W2962680099', 'https://openalex.org/W6679434410', 'https://openalex.org/W6973666849', 'https://openalex.org/W6623517193', 'https://openalex.org/W1902237438', 'https://openalex.org/W6679436768', 'https://openalex.org/W2064675550', 'https://openalex.org/W2884852625', 'https://openalex.org/W2949328740', 'https://openalex.org/W206967138', 'https://openalex.org/W1836465849', 'https://openalex.org/W2605131327', 'https://openalex.org/W2130942839', 'https://openalex.org/W2972495969', 'https://openalex.org/W2123301721', 'https://openalex.org/W2963609956', 'https://openalex.org/W2144600658', 'https://openalex.org/W2964121744', 'https://openalex.org/W2964308564', 'https://openalex.org/W2133564696', 'https://openalex.org/W2949117887', 'https://openalex.org/W1921523184', 'https://openalex.org/W2101105183', 'https://openalex.org/W1522301498', 'https://openalex.org/W2789543585', 'https://openalex.org/W2963799213', 'https://openalex.org/W2964026424', 'https://openalex.org/W2786608204', 'https://openalex.org/W2972374322', 'https://openalex.org/W2906111771', 'https://openalex.org/W2191779130', 'https://openalex.org/W2973026522', 'https://openalex.org/W854541894']",2019-12-01
https://openalex.org/W2972495969,https://doi.org/10.21437/interspeech.2019-1951,Direct Speech-to-Speech Translation with a Sequence-to-Sequence Model,"We present an attention-based sequence-to-sequence neural network which can directly translate speech from one language into speech in another language, without relying on an intermediate text representation.The network is trained end-to-end, learning to map speech spectrograms into target spectrograms in another language, corresponding to the translated content (in a different canonical voice).We further demonstrate the ability to synthesize translated speech using the voice of the source speaker.We conduct experiments on two Spanish-to-English speech translation datasets, and find that the proposed model slightly underperforms a baseline cascade of a direct speech-to-text translation model and a text-to-speech synthesis model, demonstrating the feasibility of the approach on this very challenging task.","['https://openalex.org/W2963609956', 'https://openalex.org/W2133564696', 'https://openalex.org/W4298174729', 'https://openalex.org/W2747920239', 'https://openalex.org/W2972970915', 'https://openalex.org/W2892620417', 'https://openalex.org/W4293569541', 'https://openalex.org/W2133300417', 'https://openalex.org/W2964138190', 'https://openalex.org/W2963779652', 'https://openalex.org/W2097203679', 'https://openalex.org/W4293714597', 'https://openalex.org/W4385245566', 'https://openalex.org/W2113106066', 'https://openalex.org/W2963011080', 'https://openalex.org/W2964243274', 'https://openalex.org/W2962824709', 'https://openalex.org/W2139647714', 'https://openalex.org/W2525778437', 'https://openalex.org/W2120847449', 'https://openalex.org/W1962947832', 'https://openalex.org/W2896538040', 'https://openalex.org/W2928941594', 'https://openalex.org/W1494198834', 'https://openalex.org/W2011783148', 'https://openalex.org/W2808706139', 'https://openalex.org/W2795581297', 'https://openalex.org/W2912492482', 'https://openalex.org/W3012492057', 'https://openalex.org/W1538023239', 'https://openalex.org/W2605131327', 'https://openalex.org/W2152834109', 'https://openalex.org/W4289383906', 'https://openalex.org/W1537859740', 'https://openalex.org/W2136545725', 'https://openalex.org/W4294619240', 'https://openalex.org/W2788357188', 'https://openalex.org/W2949328740', 'https://openalex.org/W4298580827', 'https://openalex.org/W2941115821', 'https://openalex.org/W2794490148', 'https://openalex.org/W4300558631']",2019-09-13
https://openalex.org/W3180374548,https://doi.org/10.18653/v1/2022.acl-long.235,Direct Speech-to-Speech Translation With Discrete Units,"Ann Lee, Peng-Jen Chen, Changhan Wang, Jiatao Gu, Sravya Popuri, Xutai Ma, Adam Polyak, Yossi Adi, Qing He, Yun Tang, Juan Pino, Wei-Ning Hsu. Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2022.","['https://openalex.org/W2933138175', 'https://openalex.org/W3007068036', 'https://openalex.org/W3197580070', 'https://openalex.org/W3157923770', 'https://openalex.org/W3210177631', 'https://openalex.org/W2605131327', 'https://openalex.org/W2995181338', 'https://openalex.org/W3112092703', 'https://openalex.org/W3007142233', 'https://openalex.org/W3173767661', 'https://openalex.org/W3098403858', 'https://openalex.org/W3169320628', 'https://openalex.org/W2152834109', 'https://openalex.org/W2035108931', 'https://openalex.org/W3033411150', 'https://openalex.org/W4394671563', 'https://openalex.org/W2963609956', 'https://openalex.org/W4385245566', 'https://openalex.org/W2963532001', 'https://openalex.org/W3140429000', 'https://openalex.org/W2963979492', 'https://openalex.org/W4287553982', 'https://openalex.org/W2949328740', 'https://openalex.org/W3160525311', 'https://openalex.org/W3112616666', 'https://openalex.org/W2936774411', 'https://openalex.org/W2991213871', 'https://openalex.org/W2963403868', 'https://openalex.org/W2998353611', 'https://openalex.org/W3118578889', 'https://openalex.org/W1494198834', 'https://openalex.org/W1537859740', 'https://openalex.org/W2136545725', 'https://openalex.org/W3142316150', 'https://openalex.org/W2127141656', 'https://openalex.org/W3175871055', 'https://openalex.org/W2903739847', 'https://openalex.org/W2972495969', 'https://openalex.org/W2973157397', 'https://openalex.org/W3186843219', 'https://openalex.org/W3119308075', 'https://openalex.org/W2097203679', 'https://openalex.org/W2747920239', 'https://openalex.org/W3130016944', 'https://openalex.org/W3099782249', 'https://openalex.org/W3092424727', 'https://openalex.org/W3036601975', 'https://openalex.org/W3092028330']",2022-01-01
https://openalex.org/W4287854499,https://doi.org/10.18653/v1/2022.naacl-main.63,Textless Speech-to-Speech Translation on Real Data,"Ann Lee, Hongyu Gong, Paul-Ambroise Duquenne, Holger Schwenk, Peng-Jen Chen, Changhan Wang, Sravya Popuri, Yossi Adi, Juan Pino, Jiatao Gu, Wei-Ning Hsu. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2022.","['https://openalex.org/W2933138175', 'https://openalex.org/W3092424727', 'https://openalex.org/W2514828952', 'https://openalex.org/W1494198834', 'https://openalex.org/W3142316150', 'https://openalex.org/W3175301726', 'https://openalex.org/W2972495969', 'https://openalex.org/W2963979492', 'https://openalex.org/W3015698636', 'https://openalex.org/W4301980136', 'https://openalex.org/W4287079508', 'https://openalex.org/W3007068036', 'https://openalex.org/W2963341956', 'https://openalex.org/W2963609956', 'https://openalex.org/W620750443', 'https://openalex.org/W2946200149', 'https://openalex.org/W3213873715', 'https://openalex.org/W2903739847', 'https://openalex.org/W3140429000', 'https://openalex.org/W3134644026', 'https://openalex.org/W2808631503', 'https://openalex.org/W3016160783', 'https://openalex.org/W3186843219', 'https://openalex.org/W2991213871', 'https://openalex.org/W2963799213', 'https://openalex.org/W3213018012', 'https://openalex.org/W3118578889', 'https://openalex.org/W2972466499', 'https://openalex.org/W2964243274', 'https://openalex.org/W3033411150', 'https://openalex.org/W2972802841', 'https://openalex.org/W4286984129', 'https://openalex.org/W3043665049', 'https://openalex.org/W2949328740', 'https://openalex.org/W2046056978', 'https://openalex.org/W3092028330', 'https://openalex.org/W3119308075', 'https://openalex.org/W3175871055', 'https://openalex.org/W3169320628', 'https://openalex.org/W2988736778', 'https://openalex.org/W2963532001', 'https://openalex.org/W3201257124', 'https://openalex.org/W2136545725', 'https://openalex.org/W2619368999', 'https://openalex.org/W4385245566', 'https://openalex.org/W3030437843', 'https://openalex.org/W4394671563']",2022-01-01
https://openalex.org/W4287591426,https://doi.org/10.48550/arxiv.2011.11588,The Zero Resource Speech Benchmark 2021: Metrics and baselines for unsupervised spoken language modeling,"We introduce a new unsupervised task, spoken language modeling: the learning of linguistic representations from raw audio signals without any labels, along with the Zero Resource Speech Benchmark 2021: a suite of 4 black-box, zero-shot metrics probing for the quality of the learned models at 4 linguistic levels: phonetics, lexicon, syntax and semantics. We present the results and analyses of a composite baseline made of the concatenation of three unsupervised systems: self-supervised contrastive representation learning (CPC), clustering (k-means) and language modeling (LSTM or BERT). The language models learn on the basis of the pseudo-text derived from clustering the learned representations. This simple pipeline shows better than chance performance on all four metrics, demonstrating the feasibility of spoken language modeling from raw speech. It also yields worse performance compared to text-based 'topline' systems trained on the same data, delineating the space to be explored by more sophisticated end-to-end models.",[],2020-11-23
https://openalex.org/W4307680525,https://doi.org/10.1162/tacl_a_00545,Generative Spoken Dialogue Language Modeling,"Abstract We introduce dGSLM, the first “textless” model able to generate audio samples of naturalistic spoken dialogues. It uses recent work on unsupervised spoken unit discovery coupled with a dual-tower transformer architecture with cross-attention trained on 2000 hours of two-channel raw conversational audio (Fisher dataset) without any text or labels. We show that our model is able to generate speech, laughter, and other paralinguistic signals in the two channels simultaneously and reproduces more naturalistic and fluid turn taking compared to a text-based cascaded model.1,2","['https://openalex.org/W6772715161', 'https://openalex.org/W6630821413', 'https://openalex.org/W6780218876', 'https://openalex.org/W6811170316', 'https://openalex.org/W6843330092', 'https://openalex.org/W2102722370', 'https://openalex.org/W3015783745', 'https://openalex.org/W3016011332', 'https://openalex.org/W6603931906', 'https://openalex.org/W6791299810', 'https://openalex.org/W1964725106', 'https://openalex.org/W3094393093', 'https://openalex.org/W6805110637', 'https://openalex.org/W3197934793', 'https://openalex.org/W2008741806', 'https://openalex.org/W2001292406', 'https://openalex.org/W6796554684', 'https://openalex.org/W3198771897', 'https://openalex.org/W2995181338', 'https://openalex.org/W3198217962', 'https://openalex.org/W6631190155', 'https://openalex.org/W6798616804', 'https://openalex.org/W6783867762', 'https://openalex.org/W6803066952', 'https://openalex.org/W6767671539', 'https://openalex.org/W6790356757', 'https://openalex.org/W1608166496', 'https://openalex.org/W3034999214', 'https://openalex.org/W6777615688', 'https://openalex.org/W6640842352', 'https://openalex.org/W2982223350', 'https://openalex.org/W2889231094', 'https://openalex.org/W2087762538', 'https://openalex.org/W4220690942', 'https://openalex.org/W6794898703', 'https://openalex.org/W6704752648', 'https://openalex.org/W2933138175', 'https://openalex.org/W3140429000', 'https://openalex.org/W2067097374', 'https://openalex.org/W2160473997', 'https://openalex.org/W3148101939', 'https://openalex.org/W2963747517', 'https://openalex.org/W6776750061', 'https://openalex.org/W4248634141', 'https://openalex.org/W6628172081', 'https://openalex.org/W2161345458', 'https://openalex.org/W2057563799', 'https://openalex.org/W2962784628', 'https://openalex.org/W6729983166', 'https://openalex.org/W4385573862', 'https://openalex.org/W2786387151', 'https://openalex.org/W3112188842', 'https://openalex.org/W2162634167', 'https://openalex.org/W1986450839', 'https://openalex.org/W792814583', 'https://openalex.org/W2842511635', 'https://openalex.org/W2752796333', 'https://openalex.org/W6635590879', 'https://openalex.org/W2921495256', 'https://openalex.org/W3186804217', 'https://openalex.org/W3197580070', 'https://openalex.org/W6641025798', 'https://openalex.org/W6769690604', 'https://openalex.org/W3134881075', 'https://openalex.org/W3213873715', 'https://openalex.org/W3155584966', 'https://openalex.org/W4394671563', 'https://openalex.org/W2988937804', 'https://openalex.org/W2963799213', 'https://openalex.org/W4287900772', 'https://openalex.org/W3102393842', 'https://openalex.org/W4297809080', 'https://openalex.org/W2963206148', 'https://openalex.org/W4237772098', 'https://openalex.org/W4381786045', 'https://openalex.org/W3161207330', 'https://openalex.org/W4297808394', 'https://openalex.org/W1219741494', 'https://openalex.org/W3186138538', 'https://openalex.org/W4226199158', 'https://openalex.org/W1591706642', 'https://openalex.org/W3027879771', 'https://openalex.org/W2974231335', 'https://openalex.org/W3036601975', 'https://openalex.org/W3169320628', 'https://openalex.org/W4200113972']",2023-01-01
https://openalex.org/W4285483774,https://doi.org/10.48550/arxiv.2207.06405,Masked Autoencoders that Listen,"This paper studies a simple extension of image-based Masked Autoencoders (MAE) to self-supervised representation learning from audio spectrograms. Following the Transformer encoder-decoder design in MAE, our Audio-MAE first encodes audio spectrogram patches with a high masking ratio, feeding only the non-masked tokens through encoder layers. The decoder then re-orders and decodes the encoded context padded with mask tokens, in order to reconstruct the input spectrogram. We find it beneficial to incorporate local window attention in the decoder, as audio spectrograms are highly correlated in local time and frequency bands. We then fine-tune the encoder with a lower masking ratio on target datasets. Empirically, Audio-MAE sets new state-of-the-art performance on six audio and speech classification tasks, outperforming other recent models that use external supervised pre-training. The code and models will be at https://github.com/facebookresearch/AudioMAE.",[],2022-07-13
https://openalex.org/W1973746598,https://doi.org/10.1001/archotol.1977.00780290081022,Introduction to the Psychology of Hearing,"The author's stated general approach is to relate the psychological and perceptual aspects of sound to the underlying physiological mechanisms of hearing in a way that the material can be used as a text to accompany an advanced undergraduate- or graduate-level course in auditory perception. The attempt is to provide an account of current trends in auditory research on a level not too technical for the novice. Psychoacoustic studies on humans and physiological studies on animals serve as the primary bases for subject matter presentation, and many practical applications are offered. Among the chapters are the following: the nature of sound and the structure of the auditory system; loudness, adaptation, and fatigue; frequency analysis, masking, and critical bands; pitch perception and auditory pattern perception; space perception; and speech perception. Within these chapter headings special attention is given to a number of topics, including signal detection theory, monaural and binaural hearing,",[],1977-12-01
https://openalex.org/W3186843219,,Translatotron 2: Robust direct speech-to-speech translation.,"We present Translatotron 2, a neural direct speech-to-speech translation model that can be trained end-to-end. Translatotron 2 consists of a speech encoder, a phoneme decoder, a mel-spectrogram synthesizer, and an attention module that connects all the previous three components. Experimental results suggest that Translatotron 2 outperforms the original Translatotron by a large margin in terms of translation quality and predicted speech naturalness, and drastically improves the robustness of the predicted speech by mitigating over-generation, such as babbling or long pause. We also propose a new method for retaining the source speaker's voice in the translated speech. The trained model is restricted to retain the source speaker's voice, and unlike the original Translatotron, it is not able to generate speech in a different speaker's voice, making the model more robust for production deployment, by mitigating potential misuse for creating spoofing audio artifacts. When the new method is used together with a simple concatenation-based data augmentation, the trained Translatotron 2 model is able to retain each speaker's voice for input with speaker turns.","['https://openalex.org/W2972702018', 'https://openalex.org/W3012492057', 'https://openalex.org/W3130016944', 'https://openalex.org/W3097777922', 'https://openalex.org/W3007068036', 'https://openalex.org/W2097203679', 'https://openalex.org/W2963432880', 'https://openalex.org/W2963403868', 'https://openalex.org/W2964243274', 'https://openalex.org/W1494198834', 'https://openalex.org/W3142316150', 'https://openalex.org/W2972495969', 'https://openalex.org/W3008181812', 'https://openalex.org/W2936774411', 'https://openalex.org/W2605131327', 'https://openalex.org/W3015440307', 'https://openalex.org/W2928941594', 'https://openalex.org/W3026041220', 'https://openalex.org/W2963590452', 'https://openalex.org/W2136545725', 'https://openalex.org/W2973212992', 'https://openalex.org/W2970730223', 'https://openalex.org/W3082130377', 'https://openalex.org/W3197324626', 'https://openalex.org/W3043665049', 'https://openalex.org/W3180374548', 'https://openalex.org/W3054645415', 'https://openalex.org/W2973084242', 'https://openalex.org/W2972359262', 'https://openalex.org/W2963799213', 'https://openalex.org/W2962788625', 'https://openalex.org/W3175871055', 'https://openalex.org/W2964161387', 'https://openalex.org/W3163793923', 'https://openalex.org/W2120847449', 'https://openalex.org/W2964307104', 'https://openalex.org/W3015922793', 'https://openalex.org/W2972473628', 'https://openalex.org/W3011535310', 'https://openalex.org/W3026777299', 'https://openalex.org/W3091928890', 'https://openalex.org/W3161296985', 'https://openalex.org/W3008125272', 'https://openalex.org/W3099782249', 'https://openalex.org/W3153287399', 'https://openalex.org/W3161436426', 'https://openalex.org/W3197294703']",2021-07-19
https://openalex.org/W4297808394,https://doi.org/10.48550/arxiv.1807.03748,Representation Learning with Contrastive Predictive Coding,"While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.",[],2018-07-10
https://openalex.org/W2132631284,,Verb similarity on the taxonomy of WordNet,"In this paper, we introduce two kinds of word similarity algorithms, SHE and RHE, to investigate the capability of WordNet in measuring verb similarity. In the absence of a standard verb set we have proposed two new verb similarity","['https://openalex.org/W2003240077', 'https://openalex.org/W1950936596', 'https://openalex.org/W2117753247', 'https://openalex.org/W2038721957', 'https://openalex.org/W2140887277', 'https://openalex.org/W1971220772', 'https://openalex.org/W1573498319', 'https://openalex.org/W2136480620', 'https://openalex.org/W1567365482', 'https://openalex.org/W2117805756', 'https://openalex.org/W4285719527', 'https://openalex.org/W2123489126', 'https://openalex.org/W1983578042', 'https://openalex.org/W2100935296', 'https://openalex.org/W3088601333', 'https://openalex.org/W2149671658', 'https://openalex.org/W2087739686', 'https://openalex.org/W2534712034', 'https://openalex.org/W136846643', 'https://openalex.org/W2962689487', 'https://openalex.org/W2080100102', 'https://openalex.org/W2081580037', 'https://openalex.org/W2160482687', 'https://openalex.org/W2117149238']",2006-01-01
https://openalex.org/W4221161768,https://doi.org/10.48550/arxiv.2202.03543,Self-Supervised Representation Learning for Speech Using Visual Grounding and Masked Language Modeling,"In this paper, we describe our submissions to the ZeroSpeech 2021 Challenge and SUPERB benchmark. Our submissions are based on the recently proposed FaST-VGS model, which is a Transformer-based model that learns to associate raw speech waveforms with semantically related images, all without the use of any transcriptions of the speech. Additionally, we introduce a novel extension of this model, FaST-VGS+, which is learned in a multi-task fashion with a masked language modeling objective in addition to the visual grounding objective. On ZeroSpeech 2021, we show that our models perform competitively on the ABX task, outperform all other concurrent submissions on the Syntactic and Semantic tasks, and nearly match the best system on the Lexical task. On the SUPERB benchmark, we show that our models also achieve strong performance, in some cases even outperforming the popular wav2vec2.0 model.",[],2022-02-07
https://openalex.org/W4226199158,https://doi.org/10.48550/arxiv.2203.01829,A Brief Overview of Unsupervised Neural Speech Representation Learning,"Unsupervised representation learning for speech processing has matured greatly in the last few years. Work in computer vision and natural language processing has paved the way, but speech data offers unique challenges. As a result, methods from other domains rarely translate directly. We review the development of unsupervised representation learning for speech over the last decade. We identify two primary model categories: self-supervised methods and probabilistic latent variable models. We describe the models and develop a comprehensive taxonomy. Finally, we discuss and compare models from the two categories.","['https://openalex.org/W3016181583', 'https://openalex.org/W2107789863', 'https://openalex.org/W2963137467', 'https://openalex.org/W2963925452', 'https://openalex.org/W1686810756', 'https://openalex.org/W3197259906', 'https://openalex.org/W3146777637', 'https://openalex.org/W4237840503', 'https://openalex.org/W2988736778', 'https://openalex.org/W3198782837', 'https://openalex.org/W3093427098', 'https://openalex.org/W4297808394', 'https://openalex.org/W3041561163', 'https://openalex.org/W2786608204', 'https://openalex.org/W2122538988', 'https://openalex.org/W1945356021', 'https://openalex.org/W2587284713', 'https://openalex.org/W2750248772', 'https://openalex.org/W2981991061', 'https://openalex.org/W3134881075', 'https://openalex.org/W3097777922', 'https://openalex.org/W3035202887', 'https://openalex.org/W2937090315', 'https://openalex.org/W44815768', 'https://openalex.org/W343636949', 'https://openalex.org/W2746710273', 'https://openalex.org/W2020607164', 'https://openalex.org/W3033038061', 'https://openalex.org/W2888911345', 'https://openalex.org/W3160345865', 'https://openalex.org/W2395899413', 'https://openalex.org/W3204915839', 'https://openalex.org/W4287374065', 'https://openalex.org/W2767754137', 'https://openalex.org/W1959608418', 'https://openalex.org/W2979476256', 'https://openalex.org/W2963420272', 'https://openalex.org/W3209993061', 'https://openalex.org/W2896457183', 'https://openalex.org/W2973157397', 'https://openalex.org/W2396566817', 'https://openalex.org/W3209984917', 'https://openalex.org/W179875071', 'https://openalex.org/W2972943112', 'https://openalex.org/W3015265920', 'https://openalex.org/W2788991015', 'https://openalex.org/W2963317665', 'https://openalex.org/W3016011332', 'https://openalex.org/W2519091744', 'https://openalex.org/W2242818861', 'https://openalex.org/W3036622477', 'https://openalex.org/W3096656254', 'https://openalex.org/W1967924372', 'https://openalex.org/W138345131', 'https://openalex.org/W3112034174', 'https://openalex.org/W2889313720', 'https://openalex.org/W2108598243', 'https://openalex.org/W3198858531', 'https://openalex.org/W4286849919', 'https://openalex.org/W3162875390', 'https://openalex.org/W2059652594', 'https://openalex.org/W4226103796', 'https://openalex.org/W4214784181', 'https://openalex.org/W1545920196', 'https://openalex.org/W1909320841', 'https://openalex.org/W2018168021', 'https://openalex.org/W1796128977', 'https://openalex.org/W2146444479', 'https://openalex.org/W3102342027', 'https://openalex.org/W2548228487', 'https://openalex.org/W3160303932', 'https://openalex.org/W3160235762', 'https://openalex.org/W4287173589', 'https://openalex.org/W4288310870', 'https://openalex.org/W4295177495', 'https://openalex.org/W2347098582', 'https://openalex.org/W3034749675', 'https://openalex.org/W2787447541', 'https://openalex.org/W2327501763', 'https://openalex.org/W3125709657', 'https://openalex.org/W3161223924', 'https://openalex.org/W2758785877', 'https://openalex.org/W2973049979', 'https://openalex.org/W2962799131', 'https://openalex.org/W4294170691', 'https://openalex.org/W2767224889', 'https://openalex.org/W3015949486', 'https://openalex.org/W3008499099', 'https://openalex.org/W2136922672', 'https://openalex.org/W2963720603', 'https://openalex.org/W3148040514', 'https://openalex.org/W2097012520', 'https://openalex.org/W2950151997', 'https://openalex.org/W3198134274', 'https://openalex.org/W3202710890', 'https://openalex.org/W3097286738', 'https://openalex.org/W4287887773', 'https://openalex.org/W3148001440', 'https://openalex.org/W4300047444', 'https://openalex.org/W2593011301', 'https://openalex.org/W4385245566', 'https://openalex.org/W592244745', 'https://openalex.org/W2963571336', 'https://openalex.org/W2076878942', 'https://openalex.org/W2936774411', 'https://openalex.org/W2097117768', 'https://openalex.org/W2963799213', 'https://openalex.org/W4297786395', 'https://openalex.org/W4287824654', 'https://openalex.org/W3198429080', 'https://openalex.org/W4288574863', 'https://openalex.org/W2100768664', 'https://openalex.org/W2163922914', 'https://openalex.org/W3197580070', 'https://openalex.org/W2152790380', 'https://openalex.org/W2168013545', 'https://openalex.org/W2406349064', 'https://openalex.org/W3015213852', 'https://openalex.org/W2194775991', 'https://openalex.org/W3209059054', 'https://openalex.org/W3036601975', 'https://openalex.org/W2962850167', 'https://openalex.org/W3095361818', 'https://openalex.org/W2963223306', 'https://openalex.org/W2982223350', 'https://openalex.org/W3203098807']",2022-03-01
https://openalex.org/W4287887366,https://doi.org/10.18653/v1/2022.naacl-demo.1,textless-lib: a Library for Textless Spoken Language Processing,"Eugene Kharitonov, Jade Copet, Kushal Lakhotia, Tu Anh Nguyen, Paden Tomasello, Ann Lee, Ali Elkahky, Wei-Ning Hsu, Abdelrahman Mohamed, Emmanuel Dupoux, Yossi Adi. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: System Demonstrations. 2022.","['https://openalex.org/W2964243274', 'https://openalex.org/W2946200149', 'https://openalex.org/W3015338123', 'https://openalex.org/W3148101939', 'https://openalex.org/W3209984917', 'https://openalex.org/W3093096176', 'https://openalex.org/W3033411150', 'https://openalex.org/W2250539671', 'https://openalex.org/W2965373594', 'https://openalex.org/W4226033575', 'https://openalex.org/W4287591426', 'https://openalex.org/W4297808394', 'https://openalex.org/W3036601975', 'https://openalex.org/W3169320628', 'https://openalex.org/W4287854499', 'https://openalex.org/W3140429000', 'https://openalex.org/W4286984129', 'https://openalex.org/W2893425640', 'https://openalex.org/W3092028330', 'https://openalex.org/W2752177116', 'https://openalex.org/W2516090925', 'https://openalex.org/W3180374548', 'https://openalex.org/W4292779060', 'https://openalex.org/W4200635400', 'https://openalex.org/W4394671563', 'https://openalex.org/W3197974236', 'https://openalex.org/W2973026522', 'https://openalex.org/W2950018712', 'https://openalex.org/W3141523618', 'https://openalex.org/W4307680525', 'https://openalex.org/W3144810982', 'https://openalex.org/W2963821905', 'https://openalex.org/W3198815374', 'https://openalex.org/W1494198834', 'https://openalex.org/W2962739339', 'https://openalex.org/W2799124508', 'https://openalex.org/W2995181338', 'https://openalex.org/W2970006822', 'https://openalex.org/W2896457183', 'https://openalex.org/W3161348170', 'https://openalex.org/W4308349017', 'https://openalex.org/W4286899907', 'https://openalex.org/W4287374065', 'https://openalex.org/W3213873715', 'https://openalex.org/W2962866891', 'https://openalex.org/W2973049979', 'https://openalex.org/W2515741950', 'https://openalex.org/W2963300588']",2022-01-01
https://openalex.org/W2964243274,https://doi.org/10.1109/icassp.2018.8461368,Natural TTS Synthesis by Conditioning Wavenet on MEL Spectrogram Predictions,"This paper describes Tacotron 2, a neural network architecture for speech synthesis directly from text. The system is composed of a recurrent sequence-to-sequence feature prediction network that maps character embeddings to mel-scale spectrograms, followed by a modified WaveNet model acting as a vocoder to synthesize time-domain waveforms from those spectrograms. Our model achieves a mean opinion score (MOS) of 4.53 comparable to a MOS of 4.58 for professionally recorded speech. To validate our design choices, we present ablation studies of key components of our system and evaluate the impact of using mel spectrograms as the conditioning input to WaveNet instead of linguistic, duration, and F0 features. We further show that using this compact acoustic intermediate representation allows for a significant reduction in the size of the WaveNet architecture.","['https://openalex.org/W2964301388', 'https://openalex.org/W2507771204', 'https://openalex.org/W6738277540', 'https://openalex.org/W6745697700', 'https://openalex.org/W2963609956', 'https://openalex.org/W6679436768', 'https://openalex.org/W2120847449', 'https://openalex.org/W2749651610', 'https://openalex.org/W6756197946', 'https://openalex.org/W2148154194', 'https://openalex.org/W6638667902', 'https://openalex.org/W2131774270', 'https://openalex.org/W2769810959', 'https://openalex.org/W2154920538', 'https://openalex.org/W6635953567', 'https://openalex.org/W6675380101', 'https://openalex.org/W6631190155', 'https://openalex.org/W2129142580', 'https://openalex.org/W2111284386', 'https://openalex.org/W2150658333', 'https://openalex.org/W6734815144', 'https://openalex.org/W1570629387', 'https://openalex.org/W2064675550', 'https://openalex.org/W6679434410', 'https://openalex.org/W6623517193', 'https://openalex.org/W6634817459', 'https://openalex.org/W6714142977', 'https://openalex.org/W6674330103', 'https://openalex.org/W2095705004', 'https://openalex.org/W1836465849', 'https://openalex.org/W2591927543', 'https://openalex.org/W4293714597', 'https://openalex.org/W2519091744', 'https://openalex.org/W2619368999', 'https://openalex.org/W854541894', 'https://openalex.org/W2102003408', 'https://openalex.org/W1579853615', 'https://openalex.org/W2766812927', 'https://openalex.org/W2901997113', 'https://openalex.org/W4294619240', 'https://openalex.org/W1599623585', 'https://openalex.org/W1522301498', 'https://openalex.org/W2133564696', 'https://openalex.org/W2130942839']",2018-04-01
https://openalex.org/W1967005434,https://doi.org/10.1145/116873.116880,Voronoi diagrams—a survey of a fundamental geometric data structure,"article Free Access Share on Voronoi diagrams—a survey of a fundamental geometric data structure Author: Franz Aurenhammer Technische Univ. Graz, Schiebbstattgasse, Austria Technische Univ. Graz, Schiebbstattgasse, AustriaView Profile Authors Info & Claims ACM Computing SurveysVolume 23Issue 3Sept. 1991 pp 345–405https://doi.org/10.1145/116873.116880Published:01 September 1991Publication History 2,817citation20,462DownloadsMetricsTotal Citations2,817Total Downloads20,462Last 12 Months1,262Last 6 weeks220 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF","['https://openalex.org/W2074863496', 'https://openalex.org/W2042607215', 'https://openalex.org/W2037026877', 'https://openalex.org/W2324172568', 'https://openalex.org/W2167940250', 'https://openalex.org/W1988887029', 'https://openalex.org/W1986496961', 'https://openalex.org/W1999823999', 'https://openalex.org/W6661567786', 'https://openalex.org/W2002558490', 'https://openalex.org/W2061053015', 'https://openalex.org/W2048475323', 'https://openalex.org/W2010649646', 'https://openalex.org/W1993481043', 'https://openalex.org/W1982777080', 'https://openalex.org/W2026347293', 'https://openalex.org/W2162918363', 'https://openalex.org/W2054736321', 'https://openalex.org/W2001099600', 'https://openalex.org/W1493266518', 'https://openalex.org/W1595094456', 'https://openalex.org/W205046867', 'https://openalex.org/W2329938184', 'https://openalex.org/W2067305605', 'https://openalex.org/W2024766881', 'https://openalex.org/W2114220616', 'https://openalex.org/W96629785', 'https://openalex.org/W2109324451', 'https://openalex.org/W2042418193', 'https://openalex.org/W6699504334', 'https://openalex.org/W2046053182', 'https://openalex.org/W2019079424', 'https://openalex.org/W4235309799', 'https://openalex.org/W2089082307', 'https://openalex.org/W2054351230', 'https://openalex.org/W1984406695', 'https://openalex.org/W1958385715', 'https://openalex.org/W1965701485', 'https://openalex.org/W1990617091', 'https://openalex.org/W4299512672', 'https://openalex.org/W2044734157', 'https://openalex.org/W2039849774', 'https://openalex.org/W1996570135', 'https://openalex.org/W2007986693', 'https://openalex.org/W2079093471', 'https://openalex.org/W2128865241', 'https://openalex.org/W1976125024', 'https://openalex.org/W2014843742', 'https://openalex.org/W1909076809', 'https://openalex.org/W2000744043', 'https://openalex.org/W2011573873', 'https://openalex.org/W2067631433', 'https://openalex.org/W2075773495', 'https://openalex.org/W2102902634', 'https://openalex.org/W4254977685', 'https://openalex.org/W1843774033', 'https://openalex.org/W2029495080', 'https://openalex.org/W2059343005', 'https://openalex.org/W7043684968', 'https://openalex.org/W4247168971', 'https://openalex.org/W2066297387', 'https://openalex.org/W2040791319', 'https://openalex.org/W2092005146', 'https://openalex.org/W2334687819', 'https://openalex.org/W2050895339', 'https://openalex.org/W1996236086', 'https://openalex.org/W2080742301', 'https://openalex.org/W2067994867', 'https://openalex.org/W2031874971', 'https://openalex.org/W1991064236', 'https://openalex.org/W2057476951', 'https://openalex.org/W1974821267', 'https://openalex.org/W4300640952', 'https://openalex.org/W2016852342', 'https://openalex.org/W2035774625', 'https://openalex.org/W1974343573', 'https://openalex.org/W1973073235', 'https://openalex.org/W2132026455', 'https://openalex.org/W2151631165', 'https://openalex.org/W2120934134', 'https://openalex.org/W1503088215', 'https://openalex.org/W2053333600', 'https://openalex.org/W1989849514', 'https://openalex.org/W2073977387', 'https://openalex.org/W2030464285', 'https://openalex.org/W1606650340', 'https://openalex.org/W2070164574', 'https://openalex.org/W2011404269', 'https://openalex.org/W1970754929', 'https://openalex.org/W2568002389', 'https://openalex.org/W2014754855', 'https://openalex.org/W1536913299', 'https://openalex.org/W2142337286', 'https://openalex.org/W1982483258', 'https://openalex.org/W2083032883', 'https://openalex.org/W2052165970', 'https://openalex.org/W1788997585', 'https://openalex.org/W2024332608', 'https://openalex.org/W1995056576', 'https://openalex.org/W2084300309', 'https://openalex.org/W2116030341', 'https://openalex.org/W2035622528', 'https://openalex.org/W1993581977', 'https://openalex.org/W2978212472', 'https://openalex.org/W1986590274', 'https://openalex.org/W1687392666', 'https://openalex.org/W188972168', 'https://openalex.org/W2075616065', 'https://openalex.org/W2126876121', 'https://openalex.org/W2332151900', 'https://openalex.org/W4210881201', 'https://openalex.org/W6634790685', 'https://openalex.org/W4236645106', 'https://openalex.org/W2163733435', 'https://openalex.org/W1965680834', 'https://openalex.org/W1993559042', 'https://openalex.org/W1542085343', 'https://openalex.org/W2048422125', 'https://openalex.org/W6676263039', 'https://openalex.org/W1993391455', 'https://openalex.org/W2015751084', 'https://openalex.org/W2004988621', 'https://openalex.org/W1981233261', 'https://openalex.org/W2002827932', 'https://openalex.org/W2091757707', 'https://openalex.org/W1968591755', 'https://openalex.org/W4251077095', 'https://openalex.org/W1975114110', 'https://openalex.org/W2111409442', 'https://openalex.org/W2009835586', 'https://openalex.org/W2047635660', 'https://openalex.org/W2332079086', 'https://openalex.org/W2006858491', 'https://openalex.org/W1964316024', 'https://openalex.org/W2113174871', 'https://openalex.org/W2004138302', 'https://openalex.org/W43500862', 'https://openalex.org/W2030407339', 'https://openalex.org/W2107423006', 'https://openalex.org/W6664395802', 'https://openalex.org/W2055593169', 'https://openalex.org/W2108567935', 'https://openalex.org/W76152643', 'https://openalex.org/W2016924518', 'https://openalex.org/W2312522318', 'https://openalex.org/W2316901299', 'https://openalex.org/W1599333084', 'https://openalex.org/W1998692689', 'https://openalex.org/W2051217487', 'https://openalex.org/W2024559808', 'https://openalex.org/W2094650250', 'https://openalex.org/W2141807666', 'https://openalex.org/W2323877013', 'https://openalex.org/W6699748111', 'https://openalex.org/W2314001243', 'https://openalex.org/W1965440866', 'https://openalex.org/W2130300980', 'https://openalex.org/W2025475855', 'https://openalex.org/W2065973215', 'https://openalex.org/W2733827376', 'https://openalex.org/W1995202710', 'https://openalex.org/W2160549424', 'https://openalex.org/W2045561895', 'https://openalex.org/W2055569927', 'https://openalex.org/W2041775009', 'https://openalex.org/W2911302472', 'https://openalex.org/W2017927472', 'https://openalex.org/W1977649561', 'https://openalex.org/W1990095504', 'https://openalex.org/W2085550119', 'https://openalex.org/W6631157930', 'https://openalex.org/W1994286847', 'https://openalex.org/W2022179164', 'https://openalex.org/W1824254661', 'https://openalex.org/W149513471', 'https://openalex.org/W1786647412', 'https://openalex.org/W1932005101', 'https://openalex.org/W2054621199', 'https://openalex.org/W1993441504', 'https://openalex.org/W1983020550', 'https://openalex.org/W2077374034', 'https://openalex.org/W1988065338', 'https://openalex.org/W1968721698', 'https://openalex.org/W2187726933', 'https://openalex.org/W1989373517', 'https://openalex.org/W1553142094', 'https://openalex.org/W1984823613', 'https://openalex.org/W2063295648', 'https://openalex.org/W1992843866', 'https://openalex.org/W1520127302', 'https://openalex.org/W2128672663', 'https://openalex.org/W2007551675', 'https://openalex.org/W2146919520', 'https://openalex.org/W2098765871', 'https://openalex.org/W2085415559', 'https://openalex.org/W1973942323', 'https://openalex.org/W2031671531', 'https://openalex.org/W2011124327', 'https://openalex.org/W1583421438', 'https://openalex.org/W2041059091', 'https://openalex.org/W654974866', 'https://openalex.org/W2086165124', 'https://openalex.org/W1552760089', 'https://openalex.org/W4285719527', 'https://openalex.org/W2588612699', 'https://openalex.org/W282228223', 'https://openalex.org/W2083686972', 'https://openalex.org/W2913066018', 'https://openalex.org/W1977183350', 'https://openalex.org/W2073906119', 'https://openalex.org/W2070060000', 'https://openalex.org/W2005774001', 'https://openalex.org/W2066194644', 'https://openalex.org/W180118279', 'https://openalex.org/W2086676524', 'https://openalex.org/W2956015669', 'https://openalex.org/W2093241092', 'https://openalex.org/W2055893639', 'https://openalex.org/W2083198723', 'https://openalex.org/W2045293233', 'https://openalex.org/W2000521645', 'https://openalex.org/W2111732445', 'https://openalex.org/W2027484351', 'https://openalex.org/W1554127434', 'https://openalex.org/W2036254524', 'https://openalex.org/W2147961665', 'https://openalex.org/W2061344951', 'https://openalex.org/W2060513624', 'https://openalex.org/W2019252445', 'https://openalex.org/W2782706474', 'https://openalex.org/W1995997000', 'https://openalex.org/W1594625131', 'https://openalex.org/W1526295984', 'https://openalex.org/W1994621439', 'https://openalex.org/W2318725026', 'https://openalex.org/W4255770412', 'https://openalex.org/W2007610503', 'https://openalex.org/W3149705110', 'https://openalex.org/W2074907599', 'https://openalex.org/W2145277585', 'https://openalex.org/W2005314985', 'https://openalex.org/W2067033286', 'https://openalex.org/W3159914786', 'https://openalex.org/W2109067131', 'https://openalex.org/W2094418873', 'https://openalex.org/W2009218627', 'https://openalex.org/W2031806265', 'https://openalex.org/W2032985147', 'https://openalex.org/W2318592595', 'https://openalex.org/W2002507856', 'https://openalex.org/W1981140310', 'https://openalex.org/W110556279', 'https://openalex.org/W2064761827', 'https://openalex.org/W1968045065', 'https://openalex.org/W2058432138', 'https://openalex.org/W2022266599', 'https://openalex.org/W1523349020', 'https://openalex.org/W1980348369', 'https://openalex.org/W2145935370', 'https://openalex.org/W2294603245', 'https://openalex.org/W2317860351', 'https://openalex.org/W2026763406', 'https://openalex.org/W2022465905', 'https://openalex.org/W2057512681', 'https://openalex.org/W1589700598', 'https://openalex.org/W1969165241', 'https://openalex.org/W2037855401', 'https://openalex.org/W2053348213', 'https://openalex.org/W1966568196', 'https://openalex.org/W1979194821', 'https://openalex.org/W2139594840', 'https://openalex.org/W2046227217', 'https://openalex.org/W2120018535']",1991-09-01
https://openalex.org/W4297841405,https://doi.org/10.21437/interspeech.2022-10884,Phonetic Analysis of Self-supervised Representations of English Speech,"We present an analysis of discrete units discovered via selfsupervised representation learning on English speech.We focus on units produced by a pre-trained HuBERT model due to its wide adoption in ASR, speech synthesis, and many other tasks.Whereas previous work has evaluated the quality of such quantization models in aggregate over all phones for a given language, we break our analysis down into broad phonetic classes, taking into account specific aspects of their articulation when considering their alignment to discrete units.We find that these units correspond to sub-phonetic events, and that fine dynamics such as the distinct closure and release portions of plosives tend to be represented by sequences of discrete units.Our work provides a reference for the phonetic properties of discrete units discovered by HuBERT, facilitating analyses of many speech applications based on this model.","['https://openalex.org/W1494198834', 'https://openalex.org/W4288107125', 'https://openalex.org/W1524333225', 'https://openalex.org/W3160200310', 'https://openalex.org/W3140429000', 'https://openalex.org/W3036601975', 'https://openalex.org/W3197580070', 'https://openalex.org/W2896457183', 'https://openalex.org/W3095361818', 'https://openalex.org/W3160799772', 'https://openalex.org/W2998572311', 'https://openalex.org/W4206711328', 'https://openalex.org/W2748598007', 'https://openalex.org/W3169320628', 'https://openalex.org/W4394671563', 'https://openalex.org/W2395899413']",2022-09-16
https://openalex.org/W3140429000,https://doi.org/10.21437/interspeech.2021-475,Speech Resynthesis from Discrete Disentangled Self-Supervised Representations,"We propose using self-supervised discrete representations for the task of\nspeech resynthesis. To generate disentangled representation, we separately\nextract low-bitrate representations for speech content, prosodic information,\nand speaker identity. This allows to synthesize speech in a controllable\nmanner. We analyze various state-of-the-art, self-supervised representation\nlearning methods and shed light on the advantages of each method while\nconsidering reconstruction quality and disentanglement properties.\nSpecifically, we evaluate the F0 reconstruction, speaker identification\nperformance (for both resynthesis and voice conversion), recordings'\nintelligibility, and overall quality using subjective human evaluation. Lastly,\nwe demonstrate how these representations can be used for an ultra-lightweight\nspeech codec. Using the obtained representations, we can get to a rate of 365\nbits per second while providing better speech quality than the baseline\nmethods. Audio samples can be found under the following link:\nspeechbot.github.io/resynthesis.\n","['https://openalex.org/W2963618559', 'https://openalex.org/W2890983311', 'https://openalex.org/W2963403868', 'https://openalex.org/W2963799213', 'https://openalex.org/W2973049979', 'https://openalex.org/W2963300588', 'https://openalex.org/W2097645910', 'https://openalex.org/W3095948607', 'https://openalex.org/W2944079609', 'https://openalex.org/W2995181338', 'https://openalex.org/W2292235217', 'https://openalex.org/W3096216486', 'https://openalex.org/W2972867623', 'https://openalex.org/W2964167449', 'https://openalex.org/W2935711438', 'https://openalex.org/W2940544976', 'https://openalex.org/W1494198834', 'https://openalex.org/W3210177631', 'https://openalex.org/W2808631503', 'https://openalex.org/W2120847449', 'https://openalex.org/W3021164770', 'https://openalex.org/W3096656254', 'https://openalex.org/W3148101939', 'https://openalex.org/W1885680957', 'https://openalex.org/W2115098197', 'https://openalex.org/W1498609987', 'https://openalex.org/W3093427098', 'https://openalex.org/W3016098186', 'https://openalex.org/W3099782249', 'https://openalex.org/W3095361818', 'https://openalex.org/W2130086727', 'https://openalex.org/W2527729766', 'https://openalex.org/W2842511635', 'https://openalex.org/W3025878903', 'https://openalex.org/W2924551963', 'https://openalex.org/W3096323553', 'https://openalex.org/W2949382160', 'https://openalex.org/W2750248772', 'https://openalex.org/W3163296124', 'https://openalex.org/W3098403858', 'https://openalex.org/W2963341956', 'https://openalex.org/W2775336875', 'https://openalex.org/W1959608418', 'https://openalex.org/W3160799772', 'https://openalex.org/W2114925438', 'https://openalex.org/W2963091184', 'https://openalex.org/W2107740512']",2021-08-27
https://openalex.org/W4297841865,https://doi.org/10.21437/interspeech.2022-777,Self-supervised Speaker Diarization,"Over the last few years, deep learning has grown in popularity for speaker verification, identification, and diarization.Inarguably, a significant part of this success is due to the demonstrated effectiveness of their speaker representations.These, however, are heavily dependent on large amounts of annotated data and can be sensitive to new domains.This study proposes an entirely unsupervised deep-learning model for speaker diarization.Specifically, the study focuses on generating highquality neural speaker representations without any annotated data, as well as on estimating secondary hyperparameters of the model without annotations.The speaker embeddings are represented by an encoder trained in a self-supervised fashion using pairs of adjacent segments assumed to be of the same speaker.The trained encoder model is then used to self-generate pseudo-labels to subsequently train a similarity score between different segments of the same call using probabilistic linear discriminant analysis (PLDA) and further to learn a clustering stopping threshold.We compared our model to state-of-the-art unsupervised as well as supervised baselines on the CallHome benchmarks.According to empirical results, our approach outperforms unsupervised methods when only two speakers are present in the call, and is only slightly worse than recent supervised models.","['https://openalex.org/W2972949456', 'https://openalex.org/W4286695273', 'https://openalex.org/W2166637769', 'https://openalex.org/W2088234478', 'https://openalex.org/W3008357631', 'https://openalex.org/W2890964092', 'https://openalex.org/W2962788625', 'https://openalex.org/W3095212884', 'https://openalex.org/W3134652006', 'https://openalex.org/W2963263347', 'https://openalex.org/W3010196324', 'https://openalex.org/W1524333225', 'https://openalex.org/W3096656254', 'https://openalex.org/W2757910899', 'https://openalex.org/W2038101708', 'https://openalex.org/W2765122878', 'https://openalex.org/W2035890032', 'https://openalex.org/W1589137271', 'https://openalex.org/W2963745998', 'https://openalex.org/W2896538040', 'https://openalex.org/W3163019736', 'https://openalex.org/W2150769028', 'https://openalex.org/W2125642021', 'https://openalex.org/W4287164729', 'https://openalex.org/W2396834488']",2022-09-16
https://openalex.org/W2187089797,,Visualizing Data using t-SNE,"We present a new technique called “t-SNE” that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images of objects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large datasets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence the way in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of datasets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualizations produced by t-SNE are significantly better than those produced by the other techniques on almost all of the datasets.","['https://openalex.org/W2072128103', 'https://openalex.org/W101236918', 'https://openalex.org/W2120481923', 'https://openalex.org/W1988464212', 'https://openalex.org/W2156287497', 'https://openalex.org/W2134312057', 'https://openalex.org/W2158307450', 'https://openalex.org/W2167064216', 'https://openalex.org/W2100495367', 'https://openalex.org/W2001141328', 'https://openalex.org/W2065281378', 'https://openalex.org/W2117684310', 'https://openalex.org/W2160208155', 'https://openalex.org/W2137570937', 'https://openalex.org/W2126415191', 'https://openalex.org/W2139823104', 'https://openalex.org/W2156718197', 'https://openalex.org/W1515707356', 'https://openalex.org/W2157444450', 'https://openalex.org/W2053186076', 'https://openalex.org/W1993436046', 'https://openalex.org/W1587720067', 'https://openalex.org/W2107039700', 'https://openalex.org/W2169507824', 'https://openalex.org/W1697082725', 'https://openalex.org/W1742512077', 'https://openalex.org/W2119111481', 'https://openalex.org/W2076137473', 'https://openalex.org/W2017588182', 'https://openalex.org/W2104780023', 'https://openalex.org/W2155161883', 'https://openalex.org/W2122837498', 'https://openalex.org/W2125637308', 'https://openalex.org/W1539175566', 'https://openalex.org/W2071128523']",2008-01-01
https://openalex.org/W4381786045,https://doi.org/10.1109/taslp.2023.3288409,AudioLM: A Language Modeling Approach to Audio Generation,"We introduce AudioLM, a framework for high-quality audio generation with long-term consistency. AudioLM maps the input audio to a sequence of discrete tokens and casts audio generation as a language modeling task in this representation space. We show how existing audio tokenizers provide different trade-offs between reconstruction quality and long-term structure, and we propose a hybrid tokenization scheme to achieve both objectives. Namely, we leverage the discretized activations of a masked language model pre-trained on audio to capture long-term structure and the discrete codes produced by a neural audio codec to achieve high-quality synthesis. By training on large corpora of raw audio waveforms, AudioLM learns to generate natural and coherent continuations given short prompts. When trained on speech, and without any transcript or annotation, AudioLM generates syntactically and semantically plausible speech continuations while also maintaining speaker identity and prosody for unseen speakers. Furthermore, we demonstrate how our approach extends beyond speech by generating coherent piano music continuations, despite being trained without any symbolic representation of music.","['https://openalex.org/W3197259906', 'https://openalex.org/W6840487619', 'https://openalex.org/W6839643428', 'https://openalex.org/W3160799772', 'https://openalex.org/W6739901393', 'https://openalex.org/W6809593508', 'https://openalex.org/W6790356757', 'https://openalex.org/W4292825791', 'https://openalex.org/W2995181338', 'https://openalex.org/W6734901337', 'https://openalex.org/W6802517614', 'https://openalex.org/W3148101939', 'https://openalex.org/W6810081322', 'https://openalex.org/W1494198834', 'https://openalex.org/W4226033575', 'https://openalex.org/W3215615641', 'https://openalex.org/W6755207826', 'https://openalex.org/W2395899413', 'https://openalex.org/W3037038648', 'https://openalex.org/W4287887366', 'https://openalex.org/W3198217962', 'https://openalex.org/W4296068815', 'https://openalex.org/W3097777922', 'https://openalex.org/W3180355996', 'https://openalex.org/W6810311916', 'https://openalex.org/W6776218486', 'https://openalex.org/W4312633146', 'https://openalex.org/W1728888090', 'https://openalex.org/W6778883912', 'https://openalex.org/W6782760101', 'https://openalex.org/W6783867762', 'https://openalex.org/W6767111847', 'https://openalex.org/W6783182287', 'https://openalex.org/W3095095816', 'https://openalex.org/W6783944145', 'https://openalex.org/W4226380987', 'https://openalex.org/W6771324808', 'https://openalex.org/W6798182279', 'https://openalex.org/W3144810982', 'https://openalex.org/W3162391496', 'https://openalex.org/W3209059054', 'https://openalex.org/W6769196770', 'https://openalex.org/W6748409065', 'https://openalex.org/W3131922516', 'https://openalex.org/W6769627184', 'https://openalex.org/W6735849998', 'https://openalex.org/W6762931180', 'https://openalex.org/W2972354707', 'https://openalex.org/W2963182577', 'https://openalex.org/W6843673214', 'https://openalex.org/W6805710207', 'https://openalex.org/W6800767084', 'https://openalex.org/W2752796333', 'https://openalex.org/W6768435317', 'https://openalex.org/W6844194202', 'https://openalex.org/W3186609711', 'https://openalex.org/W6780218876', 'https://openalex.org/W6755182157', 'https://openalex.org/W3198815374', 'https://openalex.org/W4292779060', 'https://openalex.org/W4283388932', 'https://openalex.org/W2604231067', 'https://openalex.org/W4221161768', 'https://openalex.org/W2896457183', 'https://openalex.org/W2996286887', 'https://openalex.org/W2519091744', 'https://openalex.org/W4224308101', 'https://openalex.org/W2995359496', 'https://openalex.org/W4288348042', 'https://openalex.org/W3123097577', 'https://openalex.org/W2963799213', 'https://openalex.org/W4287802874', 'https://openalex.org/W2950547518', 'https://openalex.org/W3129651364', 'https://openalex.org/W4385245566', 'https://openalex.org/W3092028330', 'https://openalex.org/W3177813494', 'https://openalex.org/W2979476256', 'https://openalex.org/W3206395542', 'https://openalex.org/W2593779438', 'https://openalex.org/W4226275767', 'https://openalex.org/W2970006822', 'https://openalex.org/W4309793872', 'https://openalex.org/W3036601975', 'https://openalex.org/W4225680573', 'https://openalex.org/W4394671563', 'https://openalex.org/W4288089799', 'https://openalex.org/W3198123200', 'https://openalex.org/W4294619240', 'https://openalex.org/W4298580827', 'https://openalex.org/W2971074500', 'https://openalex.org/W4297808394']",2023-01-01
https://openalex.org/W2138615112,,V-Measure: A Conditional Entropy-Based External Cluster Evaluation Measure,"We present V-measure, an external entropybased cluster evaluation measure. Vmeasure provides an elegant solution to many problems that affect previously defined cluster evaluation measures including 1) dependence on clustering algorithm or data set, 2) the “problem of matching”, where the clustering of only a portion of data points are evaluated and 3) accurate evaluation and combination of two desirable aspects of clustering, homogeneity and completeness. We compare V-measure to a number of popular cluster evaluation measures and demonstrate that it satisfies several desirable properties of clustering solutions, using simulated clustering results. Finally, we use V-measure to evaluate two clustering tasks: document clustering and pitch accent type clustering.","['https://openalex.org/W2434205482', 'https://openalex.org/W1875231349', 'https://openalex.org/W2098162425', 'https://openalex.org/W2152144380', 'https://openalex.org/W2100399036', 'https://openalex.org/W2100958137', 'https://openalex.org/W1546703457', 'https://openalex.org/W125573836', 'https://openalex.org/W1915179267', 'https://openalex.org/W2054658115', 'https://openalex.org/W1501095784', 'https://openalex.org/W2070412788', 'https://openalex.org/W2127218421', 'https://openalex.org/W3139328003', 'https://openalex.org/W2127042504', 'https://openalex.org/W2033403400', 'https://openalex.org/W2133249310', 'https://openalex.org/W2137692354', 'https://openalex.org/W2030644393', 'https://openalex.org/W2037744768', 'https://openalex.org/W2171964404', 'https://openalex.org/W2145036943', 'https://openalex.org/W2106009717', 'https://openalex.org/W1533169541', 'https://openalex.org/W162654330', 'https://openalex.org/W1996764654', 'https://openalex.org/W1963678392', 'https://openalex.org/W1998871699', 'https://openalex.org/W2157305458', 'https://openalex.org/W2963673689']",2007-06-01
https://openalex.org/W3127686677,https://doi.org/10.57702/3vf2hii4,TIMIT Acoustic-Phonetic Continuous Speech Corpus,"<h3>Introduction</h3><br> The TIMIT corpus of read speech is designed to provide speech data for acoustic-phonetic studies and for the development and evaluation of automatic speech recognition systems. TIMIT contains broadband recordings of 630 speakers of eight major dialects of American English, each reading ten phonetically rich sentences. The TIMIT corpus includes time-aligned orthographic, phonetic and word transcriptions as well as a 16-bit, 16kHz speech waveform file for each utterance. Corpus design was a joint effort among the Massachusetts Institute of Technology (MIT), SRI International (SRI) and Texas Instruments, Inc. (TI). The speech was recorded at TI, transcribed at MIT and verified and prepared for CD-ROM production by the National Institute of Standards and Technology (NIST). <br> The TIMIT corpus transcriptions have been hand verified. Test and training subsets, balanced for phonetic and dialectal coverage, are specified. Tabular computer-searchable information is included as well as written documentation. <br> <h3>Samples</h3><br> <ul><br> <li><a href=""desc/addenda/LDC93S1.phn"" rel=""nofollow"">phonemes</a></li><br> <li><a href=""desc/addenda/LDC93S1.txt"" rel=""nofollow"">transcripts</a></li><br> <li><a href=""desc/addenda/LDC93S1.wav"" rel=""nofollow"">audio</a></li><br> <li><a href=""desc/addenda/LDC93S1.wrd"" rel=""nofollow"">word list</a></li><br> </ul></br> Portions © 1993 Trustees of the University of Pennsylvania",[],2024-01-01
https://openalex.org/W3036601975,https://doi.org/10.48550/arxiv.2006.11477,wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations,"We show for the first time that learning powerful representations from speech audio alone followed by fine-tuning on transcribed speech can outperform the best semi-supervised methods while being conceptually simpler. wav2vec 2.0 masks the speech input in the latent space and solves a contrastive task defined over a quantization of the latent representations which are jointly learned. Experiments using all labeled data of Librispeech achieve 1.8/3.3 WER on the clean/other test sets. When lowering the amount of labeled data to one hour, wav2vec 2.0 outperforms the previous state of the art on the 100 hour subset while using 100 times less labeled data. Using just ten minutes of labeled data and pre-training on 53k hours of unlabeled data still achieves 4.8/8.2 WER. This demonstrates the feasibility of speech recognition with limited amounts of labeled data.","['https://openalex.org/W273093436', 'https://openalex.org/W3005680577', 'https://openalex.org/W3107298252', 'https://openalex.org/W3016181583', 'https://openalex.org/W2908336025', 'https://openalex.org/W2936295285', 'https://openalex.org/W2973049979', 'https://openalex.org/W2953190524', 'https://openalex.org/W2941814890', 'https://openalex.org/W2962901777', 'https://openalex.org/W2971155163', 'https://openalex.org/W2936774411', 'https://openalex.org/W3025165719', 'https://openalex.org/W2127141656', 'https://openalex.org/W2996383576', 'https://openalex.org/W2995181338', 'https://openalex.org/W2996159613', 'https://openalex.org/W3004728855', 'https://openalex.org/W2124509324', 'https://openalex.org/W2995680346', 'https://openalex.org/W10548402', 'https://openalex.org/W3026041220', 'https://openalex.org/W2896457183', 'https://openalex.org/W3103005696', 'https://openalex.org/W2121879602', 'https://openalex.org/W2794209590', 'https://openalex.org/W2991213871', 'https://openalex.org/W2944828972', 'https://openalex.org/W2949892913', 'https://openalex.org/W2994536315', 'https://openalex.org/W3021469861', 'https://openalex.org/W2152790380', 'https://openalex.org/W2964121744', 'https://openalex.org/W2547875792', 'https://openalex.org/W2962942158', 'https://openalex.org/W3127686677', 'https://openalex.org/W2963799213', 'https://openalex.org/W3003875258', 'https://openalex.org/W2963807318', 'https://openalex.org/W3027083471', 'https://openalex.org/W2899663614', 'https://openalex.org/W2296701362', 'https://openalex.org/W2965373594', 'https://openalex.org/W2963403868', 'https://openalex.org/W3002741552', 'https://openalex.org/W2981991061', 'https://openalex.org/W2962739339', 'https://openalex.org/W2952509486', 'https://openalex.org/W2988736778', 'https://openalex.org/W3035524453', 'https://openalex.org/W3037932933', 'https://openalex.org/W2963631907', 'https://openalex.org/W2842511635', 'https://openalex.org/W1494198834', 'https://openalex.org/W3015419784', 'https://openalex.org/W2972943112', 'https://openalex.org/W2972374322']",2020-06-20
https://openalex.org/W3196820367,https://doi.org/10.21437/interspeech.2021-994,Human-to-Human Conversation Dataset for Learning Fine-Grained Turn-Taking Action,,"['https://openalex.org/W2973172454', 'https://openalex.org/W2973137193', 'https://openalex.org/W2972156721', 'https://openalex.org/W2803914087', 'https://openalex.org/W2067097374', 'https://openalex.org/W2787693967', 'https://openalex.org/W1503312748', 'https://openalex.org/W2889445100', 'https://openalex.org/W3102393842', 'https://openalex.org/W253869686', 'https://openalex.org/W2578390274', 'https://openalex.org/W2980823180', 'https://openalex.org/W2515585303', 'https://openalex.org/W2402762749']",2021-08-27
https://openalex.org/W3173691672,https://doi.org/10.18653/v1/2021.acl-short.111,"Preview, Attend and Review: Schema-Aware Curriculum Learning for Multi-Domain Dialogue State Tracking","Yinpei Dai, Hangyu Li, Yongbin Li, Jian Sun, Fei Huang, Luo Si, Xiaodan Zhu. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers). 2021.","['https://openalex.org/W3034284249', 'https://openalex.org/W2296073425', 'https://openalex.org/W2963797754', 'https://openalex.org/W3175095351', 'https://openalex.org/W3015974317', 'https://openalex.org/W3175678722', 'https://openalex.org/W1527783480', 'https://openalex.org/W2899628936', 'https://openalex.org/W4288288848', 'https://openalex.org/W3142849873', 'https://openalex.org/W2468710617', 'https://openalex.org/W2963096017', 'https://openalex.org/W2998572029', 'https://openalex.org/W2998228050', 'https://openalex.org/W2950695840', 'https://openalex.org/W3034938700', 'https://openalex.org/W3034573951', 'https://openalex.org/W3034201598', 'https://openalex.org/W3035633461', 'https://openalex.org/W3126918322', 'https://openalex.org/W3021096583', 'https://openalex.org/W2962739339', 'https://openalex.org/W3091355780', 'https://openalex.org/W2979400990', 'https://openalex.org/W3094479119', 'https://openalex.org/W2997657234', 'https://openalex.org/W2798367796', 'https://openalex.org/W2945475330', 'https://openalex.org/W4287749601', 'https://openalex.org/W3103753314', 'https://openalex.org/W3040352674', 'https://openalex.org/W4287659415', 'https://openalex.org/W3106495716', 'https://openalex.org/W1522301498', 'https://openalex.org/W3099231098', 'https://openalex.org/W4288094254', 'https://openalex.org/W2962831269', 'https://openalex.org/W4285719527', 'https://openalex.org/W3101131512', 'https://openalex.org/W2964121744', 'https://openalex.org/W2963341956', 'https://openalex.org/W3094024803', 'https://openalex.org/W3035470414', 'https://openalex.org/W3034623328', 'https://openalex.org/W4287795696', 'https://openalex.org/W2962721878', 'https://openalex.org/W3119649668']",2021-01-01
https://openalex.org/W3034879520,https://doi.org/10.18653/v1/2020.acl-main.57,Learning Low-Resource End-To-End Goal-Oriented Dialog for Fast and Reliable System Deployment,"Existing end-to-end dialog systems perform less effectively when data is scarce. To obtain an acceptable success in real-life online services with only a handful of training examples, both fast adaptability and reliable performance are highly desirable for dialog systems. In this paper, we propose the Meta-Dialog System (MDS), which combines the advantages of both meta-learning approaches and human-machine collaboration. We evaluate our methods on a new extended-bAbI dataset and a transformed MultiWOZ dataset for low-resource goal-oriented dialog learning. Experimental results show that MDS significantly outperforms non-meta-learning baselines and can achieve more than 90% per-turn accuracies with only 10 dialogs on the extended-bAbI dataset.","['https://openalex.org/W2970678056', 'https://openalex.org/W2954465950', 'https://openalex.org/W2759104452', 'https://openalex.org/W2962898354', 'https://openalex.org/W2963567240', 'https://openalex.org/W2594726847', 'https://openalex.org/W2964588180', 'https://openalex.org/W2951980657', 'https://openalex.org/W2891732163', 'https://openalex.org/W2958341373', 'https://openalex.org/W2889502429', 'https://openalex.org/W2951008357', 'https://openalex.org/W2952409498', 'https://openalex.org/W2964210218', 'https://openalex.org/W2971048662', 'https://openalex.org/W2964105864', 'https://openalex.org/W2951650631', 'https://openalex.org/W2900227126', 'https://openalex.org/W2604763608']",2020-01-01
https://openalex.org/W1964725106,https://doi.org/10.1037/h0033031,Some signals and rules for taking speaking turns in conversations.,"Studied the turn-taking mechanism, whereby participants manage the smooth and appropriate exchange of speaking turns in face-to-face interaction in 2 videotapes showing a therapist-patient interview and a discussion between 2 therapists. 3 basic signals were noted: (a) turn-yielding signals by the s","['https://openalex.org/W2414468490', 'https://openalex.org/W2137409775', 'https://openalex.org/W1488926664', 'https://openalex.org/W2034407437', 'https://openalex.org/W258661234', 'https://openalex.org/W2078226637', 'https://openalex.org/W2073468232', 'https://openalex.org/W2050532715', 'https://openalex.org/W1520341977', 'https://openalex.org/W2244616636', 'https://openalex.org/W1985479696', 'https://openalex.org/W2044818951', 'https://openalex.org/W2111527257', 'https://openalex.org/W1983248018', 'https://openalex.org/W2795708771', 'https://openalex.org/W99247495', 'https://openalex.org/W313132781', 'https://openalex.org/W607201541', 'https://openalex.org/W2024503781', 'https://openalex.org/W2341461363', 'https://openalex.org/W2765325901']",1972-08-01
https://openalex.org/W2161296357,https://doi.org/10.1016/0022-1031(74)90070-5,On signalling that it's your turn to speak,,"['https://openalex.org/W2020314745', 'https://openalex.org/W2034407437', 'https://openalex.org/W1964725106', 'https://openalex.org/W2795708771', 'https://openalex.org/W2244616636', 'https://openalex.org/W2137409775', 'https://openalex.org/W2414468490', 'https://openalex.org/W6606446938', 'https://openalex.org/W1985479696', 'https://openalex.org/W2024503781', 'https://openalex.org/W2044818951', 'https://openalex.org/W6745790466', 'https://openalex.org/W6641025798', 'https://openalex.org/W258661234', 'https://openalex.org/W2773068894', 'https://openalex.org/W2038733313', 'https://openalex.org/W2325218811', 'https://openalex.org/W1488926664', 'https://openalex.org/W2324129272', 'https://openalex.org/W1963080254', 'https://openalex.org/W313132781', 'https://openalex.org/W2035863871', 'https://openalex.org/W2317018373', 'https://openalex.org/W2765325901', 'https://openalex.org/W4300469004']",1974-05-01
https://openalex.org/W3094393093,https://doi.org/10.18653/v1/2020.findings-emnlp.268,TurnGPT: a Transformer-based Language Model for Predicting Turn-taking in Spoken Dialog,"Syntactic and pragmatic completeness is known to be important for turn-taking\nprediction, but so far machine learning models of turn-taking have used such\nlinguistic information in a limited way. In this paper, we introduce TurnGPT, a\ntransformer-based language model for predicting turn-shifts in spoken dialog.\nThe model has been trained and evaluated on a variety of written and spoken\ndialog datasets. We show that the model outperforms two baselines used in prior\nwork. We also report on an ablation study, as well as attention and gradient\nanalyses, which show that the model is able to utilize the dialog context and\npragmatic completeness for turn-taking prediction. Finally, we explore the\nmodel's potential in not only detecting, but also projecting, turn-completions.\n",['https://openalex.org/W2970971581'],2020-01-01
https://openalex.org/W3034445880,https://doi.org/10.18653/v1/2020.acl-main.102,Dynamic Memory Induction Networks for Few-Shot Text Classification,"This paper proposes Dynamic Memory Induction Networks (DMIN) for few-short text classification. The model develops a dynamic routing mechanism over static memory, enabling it to better adapt to unseen classes, a critical capability for few-short classification. The model also expands the induction process with supervised learning weights and query information to enhance the generalization ability of meta-learning. The proposed model brings forward the state-of-the-art performance significantly by 2~4% improvement on the miniRCV1 and ODIC datasets. Detailed analysis is further performed to show how the proposed network achieves the new performance.","['https://openalex.org/W2753160622', 'https://openalex.org/W2921156067', 'https://openalex.org/W4297733977', 'https://openalex.org/W2964022985', 'https://openalex.org/W2796346823', 'https://openalex.org/W2962739339', 'https://openalex.org/W2601450892', 'https://openalex.org/W2963403868', 'https://openalex.org/W2896457183', 'https://openalex.org/W2472819217', 'https://openalex.org/W2964059756', 'https://openalex.org/W2963680240', 'https://openalex.org/W2187089797', 'https://openalex.org/W2971167006', 'https://openalex.org/W4288593364', 'https://openalex.org/W2787501667', 'https://openalex.org/W3102507836', 'https://openalex.org/W2968250601', 'https://openalex.org/W2963341956', 'https://openalex.org/W2888541716', 'https://openalex.org/W3146079624', 'https://openalex.org/W3098357269', 'https://openalex.org/W2535697732', 'https://openalex.org/W2962849793', 'https://openalex.org/W2047209146', 'https://openalex.org/W2162708558', 'https://openalex.org/W2963341924', 'https://openalex.org/W2963943197', 'https://openalex.org/W2953111196', 'https://openalex.org/W2963703618', 'https://openalex.org/W2964316912', 'https://openalex.org/W2963789888', 'https://openalex.org/W2911504222', 'https://openalex.org/W2889577585', 'https://openalex.org/W2905471643', 'https://openalex.org/W2971048662', 'https://openalex.org/W2115733720', 'https://openalex.org/W2971330564', 'https://openalex.org/W2995322030', 'https://openalex.org/W2953044442', 'https://openalex.org/W2892122929', 'https://openalex.org/W2798836702', 'https://openalex.org/W2963168371', 'https://openalex.org/W3037856073', 'https://openalex.org/W2604763608', 'https://openalex.org/W4385245566', 'https://openalex.org/W2964105864', 'https://openalex.org/W2970678056', 'https://openalex.org/W3104770333', 'https://openalex.org/W2951615109']",2020-01-01
https://openalex.org/W2971048662,https://doi.org/10.18653/v1/d19-1403,Induction Networks for Few-Shot Text Classification,"Ruiying Geng, Binhua Li, Yongbin Li, Xiaodan Zhu, Ping Jian, Jian Sun. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019.","['https://openalex.org/W2162708558', 'https://openalex.org/W2948974578', 'https://openalex.org/W2963270153', 'https://openalex.org/W2963053846', 'https://openalex.org/W2597655663', 'https://openalex.org/W2963341924', 'https://openalex.org/W2250539671', 'https://openalex.org/W2966661', 'https://openalex.org/W2115733720', 'https://openalex.org/W2889577585', 'https://openalex.org/W2962853356', 'https://openalex.org/W3104770333', 'https://openalex.org/W2962886257', 'https://openalex.org/W2265289447', 'https://openalex.org/W2792334966', 'https://openalex.org/W2604763608', 'https://openalex.org/W2187089797', 'https://openalex.org/W2964071174', 'https://openalex.org/W3098357269', 'https://openalex.org/W2156387975', 'https://openalex.org/W2964316912', 'https://openalex.org/W2951422922', 'https://openalex.org/W2796346823', 'https://openalex.org/W2146502635', 'https://openalex.org/W2163302275', 'https://openalex.org/W2770468159', 'https://openalex.org/W2127426251', 'https://openalex.org/W3146079624', 'https://openalex.org/W2601450892', 'https://openalex.org/W4293412117', 'https://openalex.org/W2963703618', 'https://openalex.org/W2804580284', 'https://openalex.org/W2787501667', 'https://openalex.org/W2964105864']",2019-01-01
https://openalex.org/W2889445100,https://doi.org/10.21437/interspeech.2018-1442,Prediction of Turn-taking Using Multitask Learning with Prediction of Backchannels and Fillers,,"['https://openalex.org/W2748416658', 'https://openalex.org/W2097799523', 'https://openalex.org/W2975596361', 'https://openalex.org/W68208136', 'https://openalex.org/W2746424190', 'https://openalex.org/W50922381', 'https://openalex.org/W2149653219', 'https://openalex.org/W1566669007', 'https://openalex.org/W1833445864', 'https://openalex.org/W2786387151', 'https://openalex.org/W2513669042', 'https://openalex.org/W2513322895', 'https://openalex.org/W2170983113', 'https://openalex.org/W2515585303']",2018-08-28
https://openalex.org/W2973172454,https://doi.org/10.21437/interspeech.2019-1537,Turn-Taking Prediction Based on Detection of Transition Relevance Place,,"['https://openalex.org/W2889231094', 'https://openalex.org/W2153190547', 'https://openalex.org/W3105974384', 'https://openalex.org/W2748406667', 'https://openalex.org/W2889265484', 'https://openalex.org/W2116906536', 'https://openalex.org/W1547057154', 'https://openalex.org/W2404128211', 'https://openalex.org/W2975911382', 'https://openalex.org/W2810525233', 'https://openalex.org/W50922381', 'https://openalex.org/W2252053380', 'https://openalex.org/W2116985048', 'https://openalex.org/W253869686', 'https://openalex.org/W2798405286', 'https://openalex.org/W2803914087', 'https://openalex.org/W2013987183', 'https://openalex.org/W2950577311', 'https://openalex.org/W2087762538', 'https://openalex.org/W2746424190', 'https://openalex.org/W1566669007', 'https://openalex.org/W2547390253', 'https://openalex.org/W2513322895', 'https://openalex.org/W2402762749', 'https://openalex.org/W2102759648']",2019-09-13
https://openalex.org/W3093051361,https://doi.org/10.1145/3394171.3413678,MISA,"Multimodal Sentiment Analysis is an active area of research that leverages multimodal signals for affective understanding of user-generated videos. The predominant approach, addressing this task, has been to develop sophisticated fusion techniques. However, the heterogeneous nature of the signals creates distributional modality gaps that pose significant challenges. In this paper, we aim to learn effective modality representations to aid the process of fusion. We propose a novel framework, MISA, which projects each modality to two distinct subspaces. The first subspace is modality-invariant, where the representations across modalities learn their commonalities and reduce the modality gap. The second subspace is modality-specific, which is private to each modality and captures their characteristic features. These representations provide a holistic view of the multimodal data, which is used for fusion that leads to task predictions. Our experiments on popular sentiment analysis benchmarks, MOSI and MOSEI, demonstrate significant gains over state-of-the-art models. We also consider the task of Multimodal Humor Detection and experiment on the recently proposed UR_FUNNY dataset. Here too, our model fares better than strong baselines, establishing MISA as a useful multimodal framework.","['https://openalex.org/W2395639500', 'https://openalex.org/W2971050617', 'https://openalex.org/W2767249564', 'https://openalex.org/W2095176743', 'https://openalex.org/W2016730668', 'https://openalex.org/W4388330068', 'https://openalex.org/W2963383024', 'https://openalex.org/W2899197626', 'https://openalex.org/W2896463661', 'https://openalex.org/W2946165673', 'https://openalex.org/W2937328183', 'https://openalex.org/W2064675550', 'https://openalex.org/W2886193235', 'https://openalex.org/W2962897020', 'https://openalex.org/W2964346351', 'https://openalex.org/W2949391930', 'https://openalex.org/W2997573100', 'https://openalex.org/W2958722525', 'https://openalex.org/W2963702064', 'https://openalex.org/W1679826675', 'https://openalex.org/W2964216321', 'https://openalex.org/W2250539671', 'https://openalex.org/W2962931510', 'https://openalex.org/W2963032608', 'https://openalex.org/W2584561145', 'https://openalex.org/W2251394420', 'https://openalex.org/W2740550900', 'https://openalex.org/W2963326042', 'https://openalex.org/W2964051877', 'https://openalex.org/W2214409633', 'https://openalex.org/W3009260245', 'https://openalex.org/W2964010806', 'https://openalex.org/W2787581402', 'https://openalex.org/W2963710346', 'https://openalex.org/W2556418146', 'https://openalex.org/W2530846021', 'https://openalex.org/W3104536742', 'https://openalex.org/W2985862548', 'https://openalex.org/W2187089797', 'https://openalex.org/W2562630055', 'https://openalex.org/W2750779823', 'https://openalex.org/W1595126664', 'https://openalex.org/W4299527668', 'https://openalex.org/W3021173516', 'https://openalex.org/W3014390292', 'https://openalex.org/W2968124245']",2020-10-12
https://openalex.org/W3173964589,https://doi.org/10.1609/aaai.v35i14.17550,Dynamic Hybrid Relation Exploration Network for Cross-Domain Context-Dependent Semantic Parsing,"Semantic parsing has long been a fundamental problem in natural language processing. Recently, cross-domain context-dependent semantic parsing has become a new focus of research. Central to the problem is the challenge of leveraging contextual information of both natural language queries and database schemas in the interaction history. In this paper, we present a dynamic graph framework that is capable of effectively modelling contextual utterances, tokens, database schemas, and their complicated interaction as the conversation proceeds. The framework employs a dynamic memory decay mechanism that incorporates inductive bias to integrate enriched contextual relation representation, which is further enhanced with a powerful reranking model. At the time of writing, we demonstrate that the proposed framework outperforms all existing models by large margins, achieving new state-of-the-art performance on two large-scale benchmarks, the SParC and CoSQL datasets. Specifically, the model attains a 55.8% question-match and 30.8% interaction-match accuracy on SParC, and a 46.8% question-match and 17.0% interaction-match accuracy on CoSQL.","['https://openalex.org/W2950304420', 'https://openalex.org/W6690953369', 'https://openalex.org/W2896457183', 'https://openalex.org/W6755714500', 'https://openalex.org/W2768660351', 'https://openalex.org/W2945102109', 'https://openalex.org/W2610403318', 'https://openalex.org/W6669997747', 'https://openalex.org/W6666761814', 'https://openalex.org/W2896342318', 'https://openalex.org/W2912624765', 'https://openalex.org/W6737850504', 'https://openalex.org/W2612228435', 'https://openalex.org/W6631190155', 'https://openalex.org/W2269738476', 'https://openalex.org/W3004379681', 'https://openalex.org/W2420948438', 'https://openalex.org/W2809324505', 'https://openalex.org/W2162455891', 'https://openalex.org/W2925436546', 'https://openalex.org/W2970971581', 'https://openalex.org/W6691431627', 'https://openalex.org/W2798391112', 'https://openalex.org/W2796979813', 'https://openalex.org/W6739901393', 'https://openalex.org/W2985377636', 'https://openalex.org/W2121465811', 'https://openalex.org/W6744893907', 'https://openalex.org/W2605887895', 'https://openalex.org/W6763643681', 'https://openalex.org/W2891691255', 'https://openalex.org/W6763164710', 'https://openalex.org/W2163274265', 'https://openalex.org/W1496189301', 'https://openalex.org/W2111742432', 'https://openalex.org/W2142898321', 'https://openalex.org/W2970172141', 'https://openalex.org/W2751448157', 'https://openalex.org/W2963868320', 'https://openalex.org/W4295312788', 'https://openalex.org/W2963617989', 'https://openalex.org/W2250539671', 'https://openalex.org/W2949215742', 'https://openalex.org/W4289406345', 'https://openalex.org/W4288109580', 'https://openalex.org/W2964224049', 'https://openalex.org/W2952230306', 'https://openalex.org/W2952032096', 'https://openalex.org/W2963372003', 'https://openalex.org/W4288601872', 'https://openalex.org/W2998313947', 'https://openalex.org/W4293350112', 'https://openalex.org/W1522301498', 'https://openalex.org/W4288335742', 'https://openalex.org/W2762513422', 'https://openalex.org/W648786980', 'https://openalex.org/W2962846267', 'https://openalex.org/W2077302143', 'https://openalex.org/W2964271186', 'https://openalex.org/W4288025992', 'https://openalex.org/W3034196295', 'https://openalex.org/W2964081539', 'https://openalex.org/W2963357517', 'https://openalex.org/W4385245566', 'https://openalex.org/W2250225488']",2021-05-18
https://openalex.org/W3034366140,https://doi.org/10.18653/v1/2020.sigdial-1.15,An Attentive Listening System with Android ERICA: Comparison of Autonomous and WOZ Interactions,"We describe an attentive listening system for the autonomous android robot ERICA. The proposed system generates several types of listener responses: backchannels, repeats, elaborating questions, assessments, generic sentimental responses, and generic responses. In this paper, we report a subjective experiment with 20 elderly people. First, we evaluated each system utterance excluding backchannels and generic responses, in an offline manner. It was found that most of the system utterances were linguistically appropriate, and they elicited positive reactions from the subjects. Furthermore, 58.2% of the responses were acknowledged as being appropriate listener responses. We also compared the proposed system with a WOZ system where a human operator was operating the robot. From the subjective evaluation, the proposed system achieved comparable scores in basic skills of attentive listening such as encouragement to talk, focused on the talk, and actively listening. It was also found that there is still a gap between the system and the WOZ for more sophisticated skills such as dialogue understanding, showing interest, and empathy towards the user.","['https://openalex.org/W2118748593', 'https://openalex.org/W2250645263', 'https://openalex.org/W1932345741', 'https://openalex.org/W2900365780', 'https://openalex.org/W2109636054', 'https://openalex.org/W2067097374', 'https://openalex.org/W2560913262', 'https://openalex.org/W2975911382', 'https://openalex.org/W2554972835', 'https://openalex.org/W2097799523', 'https://openalex.org/W3133764549', 'https://openalex.org/W4299566536', 'https://openalex.org/W2042170119', 'https://openalex.org/W2399149746', 'https://openalex.org/W2886370553', 'https://openalex.org/W95879096', 'https://openalex.org/W2895434601', 'https://openalex.org/W2565542385', 'https://openalex.org/W2980823180', 'https://openalex.org/W2527766749', 'https://openalex.org/W1876206866', 'https://openalex.org/W2105422377', 'https://openalex.org/W2787693967', 'https://openalex.org/W2513669042']",2020-01-01
https://openalex.org/W1832693441,https://doi.org/10.3115/v1/d14-1181,Convolutional Neural Networks for Sentence Classification,"We report on a series of experiments with convolutional neural networks (CNN) trained on top of pre-trained word vectors for sentence-level classification tasks.We show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks.Learning task-specific vectors through fine-tuning offers further gains in performance.We additionally propose a simple modification to the architecture to allow for the use of both task-specific and static vectors.The CNN models discussed herein improve upon the state of the art on 4 out of 7 tasks, which include sentiment analysis and question classification.","['https://openalex.org/W2146502635', 'https://openalex.org/W2251738400', 'https://openalex.org/W71795751', 'https://openalex.org/W2186845332', 'https://openalex.org/W2112796928', 'https://openalex.org/W2132166724', 'https://openalex.org/W2618530766', 'https://openalex.org/W2163605009', 'https://openalex.org/W1904365287', 'https://openalex.org/W4294170691', 'https://openalex.org/W35527955', 'https://openalex.org/W2949380545', 'https://openalex.org/W6908809', 'https://openalex.org/W2153579005', 'https://openalex.org/W2120615054', 'https://openalex.org/W2143612262', 'https://openalex.org/W2014902591', 'https://openalex.org/W1610356397', 'https://openalex.org/W2952230511', 'https://openalex.org/W2250981850', 'https://openalex.org/W2119408773', 'https://openalex.org/W2952186591', 'https://openalex.org/W2251939518', 'https://openalex.org/W2251143283', 'https://openalex.org/W1889268436', 'https://openalex.org/W2125573226', 'https://openalex.org/W4285719527', 'https://openalex.org/W2061495585', 'https://openalex.org/W2070246124', 'https://openalex.org/W2154359981', 'https://openalex.org/W2114524997', 'https://openalex.org/W2062118960', 'https://openalex.org/W2160660844', 'https://openalex.org/W2163455955', 'https://openalex.org/W2158899491']",2014-01-01
https://openalex.org/W2980823180,https://doi.org/10.1145/3340555.3353727,Smooth Turn-taking by a Robot Using an Online Continuous Model to Generate Turn-taking Cues,"Turn-taking in human-robot interaction is a crucial part of spoken dialogue systems, but current models do not allow for human-like turn-taking speed seen in natural conversation. In this work we propose combining two independent prediction models. A continuous model predicts the upcoming end of the turn in order to generate gaze aversion and fillers as turn-taking cues. This prediction is done while the user is speaking, so turn-taking can be done with little silence between turns, or even overlap. Once a speech recognition result has been received at a later time, a second model uses the lexical information to decide if or when the turn should actually be taken. We constructed the continuous model using the speaker's prosodic features as inputs and evaluated its online performance. We then conducted a subjective experiment in which we implemented our model in an android robot and asked participants to compare it to one without turn-taking cues, which produces a response when a speech recognition result is received. We found that using both gaze aversion and a filler was preferred when the continuous model correctly predicted the upcoming end of turn, while using only gaze aversion was better if the prediction was wrong.","['https://openalex.org/W2748604175', 'https://openalex.org/W2056257735', 'https://openalex.org/W2554972835', 'https://openalex.org/W2889445100', 'https://openalex.org/W2074996852', 'https://openalex.org/W2746424190', 'https://openalex.org/W2141666434', 'https://openalex.org/W1985479696', 'https://openalex.org/W4252407247', 'https://openalex.org/W2895434601', 'https://openalex.org/W2972977904', 'https://openalex.org/W1903378096', 'https://openalex.org/W2748416658', 'https://openalex.org/W2745949735', 'https://openalex.org/W2748406667', 'https://openalex.org/W2889231094', 'https://openalex.org/W2020587327', 'https://openalex.org/W2170584777', 'https://openalex.org/W2137279659', 'https://openalex.org/W2888997666', 'https://openalex.org/W2056973084', 'https://openalex.org/W2786387151', 'https://openalex.org/W2293392332', 'https://openalex.org/W2162634167', 'https://openalex.org/W2890197052', 'https://openalex.org/W2884001105', 'https://openalex.org/W2561031991', 'https://openalex.org/W3105974384', 'https://openalex.org/W2002069029', 'https://openalex.org/W2975596361', 'https://openalex.org/W2344694625', 'https://openalex.org/W1833445864', 'https://openalex.org/W2153190547']",2019-10-14
https://openalex.org/W2787693967,https://doi.org/10.18653/v1/w17-5516,"Attentive listening system with backchanneling, response generation and flexible turn-taking","Attentive listening systems are designed to let people, especially senior people, keep talking to maintain communication ability and mental health. This paper addresses key components of an attentive listening system which encourages users to talk smoothly. First, we introduce continuous prediction of end-of-utterances and generation of backchannels, rather than generating backchannels after end-point detection of utterances. This improves subjective evaluations of backchannels. Second, we propose an effective statement response mechanism which detects focus words and responds in the form of a question or partial repeat. This can be applied to any statement. Moreover, a flexible turn-taking mechanism is designed which uses backchannels or fillers when the turn-switch is ambiguous. These techniques are integrated into a humanoid robot to conduct attentive listening. We test the feasibility of the system in a pilot experiment and show that it can produce coherent dialogues during conversation.","['https://openalex.org/W2946961698', 'https://openalex.org/W1876206866', 'https://openalex.org/W4248634141', 'https://openalex.org/W3034729383', 'https://openalex.org/W2104300420', 'https://openalex.org/W108570142', 'https://openalex.org/W2111673230', 'https://openalex.org/W3151580377', 'https://openalex.org/W2527766749', 'https://openalex.org/W2140797606', 'https://openalex.org/W1977500051', 'https://openalex.org/W2140615673', 'https://openalex.org/W2097799523', 'https://openalex.org/W1502984613', 'https://openalex.org/W2042170119', 'https://openalex.org/W1921786749', 'https://openalex.org/W2093822404', 'https://openalex.org/W2105422377', 'https://openalex.org/W2153190547', 'https://openalex.org/W2067097374', 'https://openalex.org/W2109636054', 'https://openalex.org/W50922381', 'https://openalex.org/W2118748593']",2017-01-01
https://openalex.org/W2952409498,https://doi.org/10.18653/v1/p19-1548,Deep Unknown Intent Detection with Margin Loss,"Identifying the unknown (novel) user intents that have never appeared in the training set is a challenging task in the dialogue system. In this paper, we present a two-stage method for detecting unknown intents. We use bidirectional long short-term memory (BiLSTM) network with the margin loss as the feature extractor. With margin loss, we can learn discriminative deep features by forcing the network to maximize inter-class variance and to minimize intra-class variance. Then, we feed the feature vectors to the density-based novelty detection algorithm, local outlier factor (LOF), to detect unknown intents. Experiments on two benchmark datasets show that our method can yield consistent improvements compared with the baseline methods.","['https://openalex.org/W2583461040', 'https://openalex.org/W2963149653', 'https://openalex.org/W2803392141', 'https://openalex.org/W2272331516', 'https://openalex.org/W2531327146', 'https://openalex.org/W2962898354', 'https://openalex.org/W2600537992', 'https://openalex.org/W2804945011', 'https://openalex.org/W2250539671', 'https://openalex.org/W2137871902', 'https://openalex.org/W2963546708', 'https://openalex.org/W2963924212', 'https://openalex.org/W2475167333', 'https://openalex.org/W2964201905', 'https://openalex.org/W2963466847', 'https://openalex.org/W2119880843', 'https://openalex.org/W4293478066', 'https://openalex.org/W2962914604', 'https://openalex.org/W2963656735', 'https://openalex.org/W2097550833', 'https://openalex.org/W2811255692', 'https://openalex.org/W2187089797', 'https://openalex.org/W3103152812']",2019-01-01
https://openalex.org/W2969394406,https://doi.org/10.1016/j.knosys.2019.104979,A post-processing method for detecting unknown intent of dialogue system via pre-trained deep neural network classifier,,"['https://openalex.org/W6763425312', 'https://openalex.org/W1000500997', 'https://openalex.org/W2806416578', 'https://openalex.org/W2899555336', 'https://openalex.org/W2964201905', 'https://openalex.org/W2962914604', 'https://openalex.org/W2583461040', 'https://openalex.org/W2119880843', 'https://openalex.org/W2475167333', 'https://openalex.org/W2963924212', 'https://openalex.org/W6680007464', 'https://openalex.org/W2963149653', 'https://openalex.org/W6608287133', 'https://openalex.org/W2951748425', 'https://openalex.org/W6636501900', 'https://openalex.org/W2803392141', 'https://openalex.org/W2804945011', 'https://openalex.org/W2079735306', 'https://openalex.org/W2757599232', 'https://openalex.org/W6638523607', 'https://openalex.org/W2123099218', 'https://openalex.org/W2077302143', 'https://openalex.org/W6635733909', 'https://openalex.org/W2250539671', 'https://openalex.org/W2964331270', 'https://openalex.org/W6702248584', 'https://openalex.org/W2626967530', 'https://openalex.org/W1566256432', 'https://openalex.org/W2964212410', 'https://openalex.org/W2963693742', 'https://openalex.org/W2952409498', 'https://openalex.org/W1618905105', 'https://openalex.org/W1599263113', 'https://openalex.org/W2963546708', 'https://openalex.org/W2767414122', 'https://openalex.org/W3014813097', 'https://openalex.org/W2963341956', 'https://openalex.org/W2599674900', 'https://openalex.org/W3000506106', 'https://openalex.org/W2896457183', 'https://openalex.org/W2144182447', 'https://openalex.org/W1821462560', 'https://openalex.org/W2952677200', 'https://openalex.org/W2133864802']",2019-08-22
https://openalex.org/W2998721586,https://doi.org/10.1609/aaai.v34i05.6353,Discovering New Intents via Constrained Deep Adaptive Clustering with Cluster Refinement,"Identifying new user intents is an essential task in the dialogue system. However, it is hard to get satisfying clustering results since the definition of intents is strongly guided by prior knowledge. Existing methods incorporate prior knowledge by intensive feature engineering, which not only leads to overfitting but also makes it sensitive to the number of clusters. In this paper, we propose constrained deep adaptive clustering with cluster refinement (CDAC+), an end-to-end clustering method that can naturally incorporate pairwise constraints as prior knowledge to guide the clustering process. Moreover, we refine the clusters by forcing the model to learn from the high confidence assignments. After eliminating low confidence assignments, our approach is surprisingly insensitive to the number of clusters. Experimental results on the three benchmark datasets show that our method can yield significant improvements over strong baselines. 1","['https://openalex.org/W2153839362', 'https://openalex.org/W2096100960', 'https://openalex.org/W2883725317', 'https://openalex.org/W6747233776', 'https://openalex.org/W2896457183', 'https://openalex.org/W2020735245', 'https://openalex.org/W2408412675', 'https://openalex.org/W2890950904', 'https://openalex.org/W2769159728', 'https://openalex.org/W6689029123', 'https://openalex.org/W6763425312', 'https://openalex.org/W6753624237', 'https://openalex.org/W6684207430', 'https://openalex.org/W6691431627', 'https://openalex.org/W2925841463', 'https://openalex.org/W2889636191', 'https://openalex.org/W6735236233', 'https://openalex.org/W2134089414', 'https://openalex.org/W2284936106', 'https://openalex.org/W2980282514', 'https://openalex.org/W6685380521', 'https://openalex.org/W2251410829', 'https://openalex.org/W2533545350', 'https://openalex.org/W1775434803', 'https://openalex.org/W2888939716', 'https://openalex.org/W2187089797', 'https://openalex.org/W2222512263', 'https://openalex.org/W2964343354', 'https://openalex.org/W2165698076', 'https://openalex.org/W2779692282', 'https://openalex.org/W2601450892', 'https://openalex.org/W2952409498', 'https://openalex.org/W2964074409', 'https://openalex.org/W2250539671', 'https://openalex.org/W2963325132', 'https://openalex.org/W2950180292', 'https://openalex.org/W2127218421', 'https://openalex.org/W1552847225']",2020-04-03
https://openalex.org/W3080879265,https://doi.org/10.1145/3394486.3403390,Towards Building an Intelligent Chatbot for Customer Service,"In recent years, intelligent chatbots have been widely used in the field of customer service. One of the key challenges for chatbots to maintain fluent dialogues with customers is how to respond at the appropriate time. However, most of the state-of-the-art chatbots follow the turn-by-turn interaction scheme. Such chatbots respond after each time when a customer sends an utterance, which in some cases leads to inappropriate responses and misleads the process of the dialogues. In this paper, we propose a multi-turn response triggering model (MRTM) to address this problem. MRTM is learned from large-scale human-human dialogues between the customers and the agents with a self-supervised learning scheme. It leverages the semantic matching relationships between the context and the response to train a semantic matching model and obtains the weights of the co-occurring utterances in the context through an asymmetrical self-attention mechanism. The weights are then used to determine whether the given context should be responded to. We conduct extensive experiments on two dialogue datasets collected from the real-world online customer service systems. Results show that MRTM outperforms the baselines by a large margin. Furthermore, we incorporate MRTM into DiDi's customer service chatbot. Based on the ability to identify the appropriate time to respond, the chatbot can incrementally aggregate the information across multiple utterances and make more intelligent responses at the appropriate time.","['https://openalex.org/W2972438655', 'https://openalex.org/W1986532700', 'https://openalex.org/W343636949', 'https://openalex.org/W2972916088', 'https://openalex.org/W2373570000', 'https://openalex.org/W2964092386', 'https://openalex.org/W1518951372', 'https://openalex.org/W2952813980', 'https://openalex.org/W2096145771', 'https://openalex.org/W2539095851', 'https://openalex.org/W219040644', 'https://openalex.org/W4236521339', 'https://openalex.org/W1598178035', 'https://openalex.org/W2964046296', 'https://openalex.org/W2891416139', 'https://openalex.org/W2339852062', 'https://openalex.org/W2251818205', 'https://openalex.org/W2798456655', 'https://openalex.org/W2949888546', 'https://openalex.org/W2963403868', 'https://openalex.org/W2153579005']",2020-08-20
https://openalex.org/W2952890017,https://doi.org/10.1145/3292500.3330683,Automatic Dialogue Summary Generation for Customer Service,"Dialogue summarization extracts useful information from a dialogue. It helps people quickly capture the highlights of a dialogue without going through long and sometimes twisted utterances. For customer service, it saves human resources currently required to write dialogue summaries. A main challenge of dialogue summarization is to design a mechanism to ensure the logic, integrity, and correctness of the summaries. In this paper, we introduce auxiliary key point sequences to solve this problem. A key point sequence describes the logic of the summary. In our training procedure, a key point sequence acts as an auxiliary label. It helps the model learn the logic of the summary. In the prediction procedure, our model predicts the key point sequence first and then uses it to guide the prediction of the summary. Along with the auxiliary key point sequence, we propose a novel Leader-Writer network. The Leader net predicts the key point sequence, and the Writer net predicts the summary based on the decoded key point sequence. The Leader net ensures the summary is logical and integral. The Writer net focuses on generating fluent sentences. We test our model on customer service scenarios. The results show that our model outperforms other models not only on BLEU and ROUGE-L score but also on logic and integrity.","['https://openalex.org/W2028339364', 'https://openalex.org/W2157331557', 'https://openalex.org/W2467173223', 'https://openalex.org/W2798240283', 'https://openalex.org/W2251654079', 'https://openalex.org/W2964165364', 'https://openalex.org/W2962944953', 'https://openalex.org/W2194775991', 'https://openalex.org/W2118119027', 'https://openalex.org/W2526471240', 'https://openalex.org/W2963929190', 'https://openalex.org/W2250595592', 'https://openalex.org/W2101105183', 'https://openalex.org/W2963084599', 'https://openalex.org/W2740747242', 'https://openalex.org/W2016589492', 'https://openalex.org/W2462831000', 'https://openalex.org/W2962808855', 'https://openalex.org/W2122311631', 'https://openalex.org/W2507756961', 'https://openalex.org/W2606974598', 'https://openalex.org/W2137161909', 'https://openalex.org/W2962965405', 'https://openalex.org/W2899270155', 'https://openalex.org/W4297564112', 'https://openalex.org/W2133564696', 'https://openalex.org/W2239203031', 'https://openalex.org/W2095705004', 'https://openalex.org/W2176263492', 'https://openalex.org/W1513168555', 'https://openalex.org/W2626778328']",2019-07-25
https://openalex.org/W3202125623,https://doi.org/10.18653/v1/2021.emnlp-main.185,DialogueCSE: Dialogue-based Contrastive Learning of Sentence Embeddings,"Learning sentence embeddings from dialogues has drawn increasing attention due to its low annotation cost and high domain adaptability. Conventional approaches employ the siamese-network for this task, which obtains the sentence embeddings through modeling the context-response semantic relevance by applying a feed-forward network on top of the sentence encoders. However, as the semantic textual similarity is commonly measured through the element-wise distance metrics (e.g. cosine and L2 distance), such architecture yields a large gap between training and evaluating. In this paper, we propose DialogueCSE, a dialogue-based contrastive learning approach to tackle this issue. DialogueCSE first introduces a novel matching-guided embedding (MGE) mechanism, which generates a context-aware embedding for each candidate response embedding (i.e. the context-free embedding) according to the guidance of the multi-turn context-response matching matrices. Then it pairs each context-aware embedding with its corresponding context-free embedding and finally minimizes the contrastive loss across all pairs. We evaluate our model on three multi-turn dialogue datasets: the Microsoft Dialogue Corpus, the Jing Dong Dialogue Corpus, and the E-commerce Dialogue Corpus. Evaluation results show that our approach significantly outperforms the baselines across all three datasets in terms of MAP and Spearman’s correlation measures, demonstrating its effectiveness. Further quantitative experiments show that our approach achieves better performance when leveraging more dialogue context and remains robust when less training data is provided.","['https://openalex.org/W3100652389', 'https://openalex.org/W2949446780', 'https://openalex.org/W2970641574', 'https://openalex.org/W3105816068', 'https://openalex.org/W2891177506', 'https://openalex.org/W2611029872', 'https://openalex.org/W2790235966', 'https://openalex.org/W3154229486', 'https://openalex.org/W2949433733', 'https://openalex.org/W2953384591', 'https://openalex.org/W3104033643', 'https://openalex.org/W2413533759', 'https://openalex.org/W2963149412', 'https://openalex.org/W2896457183', 'https://openalex.org/W2963918774', 'https://openalex.org/W3175362188', 'https://openalex.org/W2963846996', 'https://openalex.org/W2786464815', 'https://openalex.org/W2963804993', 'https://openalex.org/W3033406728', 'https://openalex.org/W1486649854', 'https://openalex.org/W3034238904', 'https://openalex.org/W2250539671', 'https://openalex.org/W3115295967', 'https://openalex.org/W4313908941', 'https://openalex.org/W3031414376', 'https://openalex.org/W3131870090', 'https://openalex.org/W1665214252', 'https://openalex.org/W3104078590', 'https://openalex.org/W2842511635', 'https://openalex.org/W3164054899', 'https://openalex.org/W4297785815', 'https://openalex.org/W2923014074', 'https://openalex.org/W2963310665', 'https://openalex.org/W2798583685', 'https://openalex.org/W3156636935', 'https://openalex.org/W4252076394', 'https://openalex.org/W1566289585', 'https://openalex.org/W2963644595', 'https://openalex.org/W1840435438', 'https://openalex.org/W2963341956', 'https://openalex.org/W4297808394', 'https://openalex.org/W2155482025', 'https://openalex.org/W3173783447', 'https://openalex.org/W2250790822', 'https://openalex.org/W4298443704', 'https://openalex.org/W2884814595']",2021-01-01
https://openalex.org/W3182074706,https://doi.org/10.1016/j.csl.2021.101255,Spoken language interaction with robots: Recommendations for future research,"With robotics rapidly advancing, more effective human–robot interaction is increasingly needed to realize the full potential of robots for society. While spoken language must be part of the solution, our ability to provide spoken language interaction capabilities is still very limited. In this article, based on the report of an interdisciplinary workshop convened by the National Science Foundation, we identify key scientific and engineering advances needed to enable effective spoken language interaction with robotics. We make 25 recommendations, involving eight general themes: putting human needs first, better modeling the social and interactive aspects of language, improving robustness, creating new methods for rapid adaptation, better integrating speech and language with other communication modalities, giving speech and language components access to rich representations of the robot’s current knowledge and state, making all components operate in real time, and improving research infrastructure and resources. Research and development that prioritizes these topics will, we believe, provide a solid foundation for the creation of speech-capable robots that are easy and effective for humans to work with.","['https://openalex.org/W2617211984', 'https://openalex.org/W1542318638', 'https://openalex.org/W2916904544', 'https://openalex.org/W2127241481', 'https://openalex.org/W2902010772', 'https://openalex.org/W2767825081', 'https://openalex.org/W2190734921', 'https://openalex.org/W2189066119', 'https://openalex.org/W2054989962', 'https://openalex.org/W1927421023', 'https://openalex.org/W2048435059', 'https://openalex.org/W3103741966', 'https://openalex.org/W2109636054', 'https://openalex.org/W2150692719', 'https://openalex.org/W1580807540', 'https://openalex.org/W2057065084', 'https://openalex.org/W2604799547', 'https://openalex.org/W2136902017', 'https://openalex.org/W83250750', 'https://openalex.org/W6768351464', 'https://openalex.org/W3082732381', 'https://openalex.org/W1985639699', 'https://openalex.org/W6713246390', 'https://openalex.org/W2915579687', 'https://openalex.org/W1975096659', 'https://openalex.org/W2122238029', 'https://openalex.org/W6723770088', 'https://openalex.org/W6788119825', 'https://openalex.org/W2007465845', 'https://openalex.org/W6662950808', 'https://openalex.org/W6631234443', 'https://openalex.org/W2014994704', 'https://openalex.org/W2339027962', 'https://openalex.org/W3112188842', 'https://openalex.org/W2955277818', 'https://openalex.org/W3003205975', 'https://openalex.org/W2794490148', 'https://openalex.org/W2026237990', 'https://openalex.org/W2787690100', 'https://openalex.org/W2251375560', 'https://openalex.org/W4241420860', 'https://openalex.org/W2784006305', 'https://openalex.org/W3094833381', 'https://openalex.org/W2975911382', 'https://openalex.org/W3105075819', 'https://openalex.org/W2583914620', 'https://openalex.org/W1539115757', 'https://openalex.org/W2964030743', 'https://openalex.org/W2478830319', 'https://openalex.org/W2913542295', 'https://openalex.org/W3037092552', 'https://openalex.org/W4287600736', 'https://openalex.org/W3035391471', 'https://openalex.org/W2966781877', 'https://openalex.org/W2237891656', 'https://openalex.org/W2562615954', 'https://openalex.org/W2405187948', 'https://openalex.org/W2049851402', 'https://openalex.org/W3114284325', 'https://openalex.org/W1546025391', 'https://openalex.org/W1522654972', 'https://openalex.org/W2964916315']",2021-07-02
https://openalex.org/W2191779130,https://doi.org/10.25080/majora-7b98e3ed-003,librosa: Audio and Music Signal Analysis in Python,"This document describes version 0.4.0 of librosa: a Python package for audio and music signal processing. At a high level, librosa provides implementations of a variety of common functions used throughout the field of music information retrieval. In this document, a brief overview of the library's functionality is provided, along with explanations of the design goals, software development practices, and notational conventions.","['https://openalex.org/W6675354045', 'https://openalex.org/W6691839725', 'https://openalex.org/W2146292423', 'https://openalex.org/W1916910924', 'https://openalex.org/W2103869314', 'https://openalex.org/W6603616073', 'https://openalex.org/W1975929202', 'https://openalex.org/W2125324924', 'https://openalex.org/W129413713', 'https://openalex.org/W2915624731', 'https://openalex.org/W2397818963', 'https://openalex.org/W78743328', 'https://openalex.org/W1902027874', 'https://openalex.org/W1561135842', 'https://openalex.org/W2016885049', 'https://openalex.org/W6697202309', 'https://openalex.org/W2385545', 'https://openalex.org/W2285540944', 'https://openalex.org/W2053347927', 'https://openalex.org/W2294459443', 'https://openalex.org/W2052872069', 'https://openalex.org/W2101234009', 'https://openalex.org/W4232336823', 'https://openalex.org/W4245436919', 'https://openalex.org/W2254715784', 'https://openalex.org/W2407685581', 'https://openalex.org/W3005347330', 'https://openalex.org/W2011301426', 'https://openalex.org/W2016381774']",2015-01-01
https://openalex.org/W2250539671,https://doi.org/10.3115/v1/d14-1162,Glove: Global Vectors for Word Representation,"Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.","['https://openalex.org/W2251012068', 'https://openalex.org/W4285719527', 'https://openalex.org/W2155169782', 'https://openalex.org/W2118020653', 'https://openalex.org/W2141599568', 'https://openalex.org/W2117130368', 'https://openalex.org/W1614298861', 'https://openalex.org/W2103318667', 'https://openalex.org/W2144578941', 'https://openalex.org/W2167510172', 'https://openalex.org/W2164019165', 'https://openalex.org/W2251803266', 'https://openalex.org/W1978400666', 'https://openalex.org/W2158139315', 'https://openalex.org/W2158899491', 'https://openalex.org/W2147152072', 'https://openalex.org/W2080100102', 'https://openalex.org/W2072128103', 'https://openalex.org/W2153579005', 'https://openalex.org/W2133280805', 'https://openalex.org/W2097732278', 'https://openalex.org/W2077428231', 'https://openalex.org/W2250189634', 'https://openalex.org/W1981617416', 'https://openalex.org/W2146502635', 'https://openalex.org/W1495550473', 'https://openalex.org/W2067438047', 'https://openalex.org/W1499253590']",2014-01-01
https://openalex.org/W2973137193,https://doi.org/10.21437/interspeech.2019-3152,Investigating Linguistic and Semantic Features for Turn-Taking Prediction in Open-Domain Human-Computer Conversation,,"['https://openalex.org/W2786387151', 'https://openalex.org/W1608166496', 'https://openalex.org/W2889445100', 'https://openalex.org/W1518863056', 'https://openalex.org/W2803914087', 'https://openalex.org/W2889231094', 'https://openalex.org/W2745404607', 'https://openalex.org/W2091861733', 'https://openalex.org/W2515585303', 'https://openalex.org/W2008741806', 'https://openalex.org/W2748406667', 'https://openalex.org/W2593140731', 'https://openalex.org/W1998677696', 'https://openalex.org/W1830940278', 'https://openalex.org/W2748416658', 'https://openalex.org/W2566066744', 'https://openalex.org/W2895434601', 'https://openalex.org/W2745949735', 'https://openalex.org/W2087762538']",2019-09-13
https://openalex.org/W3112188842,https://doi.org/10.1016/j.csl.2020.101178,Turn-taking in Conversational Systems and Human-Robot Interaction: A Review,"The taking of turns is a fundamental aspect of dialogue. Since it is difficult to speak and listen at the same time, the participants need to coordinate who is currently speaking and when the next person can start to speak. Humans are very good at this coordination, and typically achieve fluent turn-taking with very small gaps and little overlap. Conversational systems (including voice assistants and social robots), on the other hand, typically have problems with frequent interruptions and long response delays, which has called for a substantial body of research on how to improve turn-taking in conversational systems. In this review article, we provide an overview of this research and give directions for future research. First, we provide a theoretical background of the linguistic research tradition on turn-taking and some of the fundamental concepts in theories of turn-taking. We also provide an extensive review of multi-modal cues (including verbal cues, prosody, breathing, gaze and gestures) that have been found to facilitate the coordination of turn-taking in human-human interaction, and which can be utilised for turn-taking in conversational systems. After this, we review work that has been done on modelling turn-taking, including end-of-turn detection, handling of user interruptions, generation of turn-taking cues, and multi-party human-robot interaction. Finally, we identify key areas where more research is needed to achieve fluent turn-taking in spoken interaction between man and machine.","['https://openalex.org/W2093364769', 'https://openalex.org/W46927895', 'https://openalex.org/W2118142207', 'https://openalex.org/W2033704812', 'https://openalex.org/W2057768007', 'https://openalex.org/W6744710442', 'https://openalex.org/W2097369932', 'https://openalex.org/W2028624421', 'https://openalex.org/W2086568921', 'https://openalex.org/W6629661887', 'https://openalex.org/W2028495596', 'https://openalex.org/W316215934', 'https://openalex.org/W6682247640', 'https://openalex.org/W2026813018', 'https://openalex.org/W2102722370', 'https://openalex.org/W6653227793', 'https://openalex.org/W6635529589', 'https://openalex.org/W2007889078', 'https://openalex.org/W1987920017', 'https://openalex.org/W2140615673', 'https://openalex.org/W1967691260', 'https://openalex.org/W2116985048', 'https://openalex.org/W2204195844', 'https://openalex.org/W2020314745', 'https://openalex.org/W1964725106', 'https://openalex.org/W2161296357', 'https://openalex.org/W2091660985', 'https://openalex.org/W2008986570', 'https://openalex.org/W6785556276', 'https://openalex.org/W6600696423', 'https://openalex.org/W7073743773', 'https://openalex.org/W6602761387', 'https://openalex.org/W6689979588', 'https://openalex.org/W2024034741', 'https://openalex.org/W6775318448', 'https://openalex.org/W2142227642', 'https://openalex.org/W6779782438', 'https://openalex.org/W6684440257', 'https://openalex.org/W4256058489', 'https://openalex.org/W2008741806', 'https://openalex.org/W6711991620', 'https://openalex.org/W1999133084', 'https://openalex.org/W2001292406', 'https://openalex.org/W6669997747', 'https://openalex.org/W2044196055', 'https://openalex.org/W6619003279', 'https://openalex.org/W2752741953', 'https://openalex.org/W6728501297', 'https://openalex.org/W6766227590', 'https://openalex.org/W6653903801', 'https://openalex.org/W6712705134', 'https://openalex.org/W6727946854', 'https://openalex.org/W6691645846', 'https://openalex.org/W6674517602', 'https://openalex.org/W2141666434', 'https://openalex.org/W6680560982', 'https://openalex.org/W6682498442', 'https://openalex.org/W6633341269', 'https://openalex.org/W6681266627', 'https://openalex.org/W6712740397', 'https://openalex.org/W1985479696', 'https://openalex.org/W6691527086', 'https://openalex.org/W1566669007', 'https://openalex.org/W2008103726', 'https://openalex.org/W6769987251', 'https://openalex.org/W6675097140', 'https://openalex.org/W6636323409', 'https://openalex.org/W6712640476', 'https://openalex.org/W2162060208', 'https://openalex.org/W6742567220', 'https://openalex.org/W2083682764', 'https://openalex.org/W6754421245', 'https://openalex.org/W2107357210', 'https://openalex.org/W2087762538', 'https://openalex.org/W2134165242', 'https://openalex.org/W6675758204', 'https://openalex.org/W2063688338', 'https://openalex.org/W2201256059', 'https://openalex.org/W6675368168', 'https://openalex.org/W2087147962', 'https://openalex.org/W2014566497', 'https://openalex.org/W2029644462', 'https://openalex.org/W6603354570', 'https://openalex.org/W6680110485', 'https://openalex.org/W2086875012', 'https://openalex.org/W6659215615', 'https://openalex.org/W6630446755', 'https://openalex.org/W6649804639', 'https://openalex.org/W6667011525', 'https://openalex.org/W2317015831', 'https://openalex.org/W6777454688', 'https://openalex.org/W6752515662', 'https://openalex.org/W6785857042', 'https://openalex.org/W2624415404', 'https://openalex.org/W2129090275', 'https://openalex.org/W6682996943', 'https://openalex.org/W6635109089', 'https://openalex.org/W2161345458', 'https://openalex.org/W6632002277', 'https://openalex.org/W6643471007', 'https://openalex.org/W2078226637', 'https://openalex.org/W6626257203', 'https://openalex.org/W6675697699', 'https://openalex.org/W2083186017', 'https://openalex.org/W2326426091', 'https://openalex.org/W6608148995', 'https://openalex.org/W2056953935', 'https://openalex.org/W2736179957', 'https://openalex.org/W6748491412', 'https://openalex.org/W6644208342', 'https://openalex.org/W1992506508', 'https://openalex.org/W2102759648', 'https://openalex.org/W6697365223', 'https://openalex.org/W6662199808', 'https://openalex.org/W2118924889', 'https://openalex.org/W2162634167', 'https://openalex.org/W6600804670', 'https://openalex.org/W6691739522', 'https://openalex.org/W28861688', 'https://openalex.org/W648734790', 'https://openalex.org/W1986450839', 'https://openalex.org/W2073912734', 'https://openalex.org/W2117866272', 'https://openalex.org/W1993055580', 'https://openalex.org/W6607202079', 'https://openalex.org/W6650147065', 'https://openalex.org/W6675389440', 'https://openalex.org/W6674631038', 'https://openalex.org/W6676002167', 'https://openalex.org/W2000101173', 'https://openalex.org/W6656257995', 'https://openalex.org/W2159005166', 'https://openalex.org/W6685214704', 'https://openalex.org/W6860387310', 'https://openalex.org/W6758743442', 'https://openalex.org/W6675629716', 'https://openalex.org/W2807877245', 'https://openalex.org/W6683502084', 'https://openalex.org/W2165275111', 'https://openalex.org/W2144312014', 'https://openalex.org/W2507738869', 'https://openalex.org/W6785974838', 'https://openalex.org/W6641025798', 'https://openalex.org/W6722969988', 'https://openalex.org/W2903611517', 'https://openalex.org/W1524418473', 'https://openalex.org/W2591798388', 'https://openalex.org/W1499881690', 'https://openalex.org/W68208136', 'https://openalex.org/W1608166496', 'https://openalex.org/W2980823180', 'https://openalex.org/W83540058', 'https://openalex.org/W2615322227', 'https://openalex.org/W2293392332', 'https://openalex.org/W2100835029', 'https://openalex.org/W2154524549', 'https://openalex.org/W3093291353', 'https://openalex.org/W1563178652', 'https://openalex.org/W1554401341', 'https://openalex.org/W3102886993', 'https://openalex.org/W2399858921', 'https://openalex.org/W17927053', 'https://openalex.org/W2011518224', 'https://openalex.org/W2106078370', 'https://openalex.org/W2105422377', 'https://openalex.org/W2071029309', 'https://openalex.org/W2915722758', 'https://openalex.org/W2761289309', 'https://openalex.org/W2150609911', 'https://openalex.org/W1589781773', 'https://openalex.org/W1977647663', 'https://openalex.org/W4231332890', 'https://openalex.org/W2150610356', 'https://openalex.org/W2604292070', 'https://openalex.org/W2144155486', 'https://openalex.org/W4205177836', 'https://openalex.org/W1533504578', 'https://openalex.org/W2153190547', 'https://openalex.org/W2527766749', 'https://openalex.org/W2045804781', 'https://openalex.org/W2104489958', 'https://openalex.org/W2100844198', 'https://openalex.org/W1963080254', 'https://openalex.org/W2133497422', 'https://openalex.org/W2596035415', 'https://openalex.org/W657599939', 'https://openalex.org/W2011652428', 'https://openalex.org/W1975856388', 'https://openalex.org/W2972320372', 'https://openalex.org/W175385064', 'https://openalex.org/W1986532700', 'https://openalex.org/W4248634141', 'https://openalex.org/W4230956878', 'https://openalex.org/W2786387151', 'https://openalex.org/W2000343728', 'https://openalex.org/W2085662862', 'https://openalex.org/W2067097374', 'https://openalex.org/W4299379707', 'https://openalex.org/W3105974384', 'https://openalex.org/W2398156266', 'https://openalex.org/W3035599013', 'https://openalex.org/W201747637', 'https://openalex.org/W1974052916', 'https://openalex.org/W4253732063', 'https://openalex.org/W3143835353', 'https://openalex.org/W2492441051', 'https://openalex.org/W2166637769', 'https://openalex.org/W3027013254', 'https://openalex.org/W1998677696', 'https://openalex.org/W2810525233', 'https://openalex.org/W2011685492', 'https://openalex.org/W4236521339', 'https://openalex.org/W2035500771', 'https://openalex.org/W3102393842', 'https://openalex.org/W2077302143', 'https://openalex.org/W2097799523', 'https://openalex.org/W19064539', 'https://openalex.org/W2161466446', 'https://openalex.org/W2896753156', 'https://openalex.org/W2396571640', 'https://openalex.org/W2250275257', 'https://openalex.org/W2532841597', 'https://openalex.org/W2141061570', 'https://openalex.org/W2104300420', 'https://openalex.org/W2096598450', 'https://openalex.org/W2237495196', 'https://openalex.org/W2914243039', 'https://openalex.org/W2921495256', 'https://openalex.org/W2004415003', 'https://openalex.org/W1010839910', 'https://openalex.org/W1583748115', 'https://openalex.org/W1977089878', 'https://openalex.org/W20116688', 'https://openalex.org/W2745949735', 'https://openalex.org/W2889231094', 'https://openalex.org/W1595229305', 'https://openalex.org/W2100919116', 'https://openalex.org/W2252053380', 'https://openalex.org/W2250891614', 'https://openalex.org/W3141239769', 'https://openalex.org/W1973933596', 'https://openalex.org/W2031375782', 'https://openalex.org/W216945601', 'https://openalex.org/W1508665521', 'https://openalex.org/W2401047175', 'https://openalex.org/W2024714067', 'https://openalex.org/W2013987183', 'https://openalex.org/W2591973297']",2020-12-16
https://openalex.org/W3001197829,https://doi.org/10.48550/arxiv.2001.07685,FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence,"Semi-supervised learning (SSL) provides an effective means of leveraging unlabeled data to improve a model's performance. In this paper, we demonstrate the power of a simple combination of two common SSL methods: consistency regularization and pseudo-labeling. Our algorithm, FixMatch, first generates pseudo-labels using the model's predictions on weakly-augmented unlabeled images. For a given image, the pseudo-label is only retained if the model produces a high-confidence prediction. The model is then trained to predict the pseudo-label when fed a strongly-augmented version of the same image. Despite its simplicity, we show that FixMatch achieves state-of-the-art performance across a variety of standard semi-supervised learning benchmarks, including 94.93% accuracy on CIFAR-10 with 250 labels and 88.61% accuracy with 40 -- just 4 labels per class. Since FixMatch bears many similarities to existing SSL methods that achieve worse performance, we carry out an extensive ablation study to tease apart the experimental factors that are most important to FixMatch's success. We make our code available at https://github.com/google-research/fixmatch.","['https://openalex.org/W2981952041', 'https://openalex.org/W2746314669', 'https://openalex.org/W2808042107', 'https://openalex.org/W2981852735', 'https://openalex.org/W2079057609', 'https://openalex.org/W1988720110', 'https://openalex.org/W2998987396', 'https://openalex.org/W2964137095', 'https://openalex.org/W2129068307', 'https://openalex.org/W104184427', 'https://openalex.org/W2949736877', 'https://openalex.org/W2963208657', 'https://openalex.org/W2335728318', 'https://openalex.org/W2118858186', 'https://openalex.org/W2095705004', 'https://openalex.org/W2908510526', 'https://openalex.org/W2996501936', 'https://openalex.org/W3118608800', 'https://openalex.org/W2964121744', 'https://openalex.org/W2145494108', 'https://openalex.org/W2962369866', 'https://openalex.org/W2898564876', 'https://openalex.org/W2592691248', 'https://openalex.org/W2963435192', 'https://openalex.org/W2982467521', 'https://openalex.org/W2530816535', 'https://openalex.org/W2921087533', 'https://openalex.org/W2978426779', 'https://openalex.org/W2867167548', 'https://openalex.org/W2767414122', 'https://openalex.org/W2964159205', 'https://openalex.org/W2622263826', 'https://openalex.org/W2963956526', 'https://openalex.org/W2964677000', 'https://openalex.org/W2963170156', 'https://openalex.org/W1975165783', 'https://openalex.org/W2136504847', 'https://openalex.org/W2963703197', 'https://openalex.org/W2108598243', 'https://openalex.org/W2936774411', 'https://openalex.org/W2163568299', 'https://openalex.org/W2994088087', 'https://openalex.org/W2962723986', 'https://openalex.org/W2259472270', 'https://openalex.org/W1990334093', 'https://openalex.org/W2284660317', 'https://openalex.org/W2952053192', 'https://openalex.org/W2895281799', 'https://openalex.org/W3035160371', 'https://openalex.org/W2765407302', 'https://openalex.org/W2111316763', 'https://openalex.org/W1479807131', 'https://openalex.org/W830076066', 'https://openalex.org/W2775461895', 'https://openalex.org/W2993466051', 'https://openalex.org/W2963263347', 'https://openalex.org/W2980149079', 'https://openalex.org/W2963449430', 'https://openalex.org/W2963930099', 'https://openalex.org/W2946856970']",2020-01-21
https://openalex.org/W2962369866,https://doi.org/10.48550/arxiv.1904.12848,Unsupervised Data Augmentation for Consistency Training,"Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods such as RandAugment and back-translation, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 5.43 with only 250 examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used. Code is available at https://github.com/google-research/uda.","['https://openalex.org/W2129068307', 'https://openalex.org/W2903105043', 'https://openalex.org/W2911603976', 'https://openalex.org/W2943865428', 'https://openalex.org/W2422843715', 'https://openalex.org/W2963247666', 'https://openalex.org/W2947294642', 'https://openalex.org/W2315403234', 'https://openalex.org/W2626778328', 'https://openalex.org/W2335728318', 'https://openalex.org/W2947099774', 'https://openalex.org/W2885724687', 'https://openalex.org/W2556096924', 'https://openalex.org/W2950513705', 'https://openalex.org/W2170973209', 'https://openalex.org/W2909869271', 'https://openalex.org/W2250539671', 'https://openalex.org/W2785885246', 'https://openalex.org/W2798858969', 'https://openalex.org/W2592691248', 'https://openalex.org/W2963170156', 'https://openalex.org/W2804047946', 'https://openalex.org/W2787560479', 'https://openalex.org/W2280377497', 'https://openalex.org/W2948433173', 'https://openalex.org/W2194775991', 'https://openalex.org/W2993466051', 'https://openalex.org/W2027731328', 'https://openalex.org/W2979579363', 'https://openalex.org/W2963341956', 'https://openalex.org/W2963216553', 'https://openalex.org/W2896011495', 'https://openalex.org/W3118608800', 'https://openalex.org/W2593814746', 'https://openalex.org/W2531409750', 'https://openalex.org/W2947775933', 'https://openalex.org/W2964159205', 'https://openalex.org/W2619184049', 'https://openalex.org/W2963373786', 'https://openalex.org/W2963012544', 'https://openalex.org/W2947188859', 'https://openalex.org/W1983320747', 'https://openalex.org/W2734426634', 'https://openalex.org/W2586581008', 'https://openalex.org/W2740721704', 'https://openalex.org/W2951970475', 'https://openalex.org/W1821462560', 'https://openalex.org/W2117130368', 'https://openalex.org/W830076066', 'https://openalex.org/W2963956526', 'https://openalex.org/W2952444318', 'https://openalex.org/W2145494108', 'https://openalex.org/W3103900065', 'https://openalex.org/W2153579005', 'https://openalex.org/W2746314669', 'https://openalex.org/W2944828972', 'https://openalex.org/W2108501770', 'https://openalex.org/W2953291403', 'https://openalex.org/W2519887557', 'https://openalex.org/W2952148143', 'https://openalex.org/W3089856963', 'https://openalex.org/W2975761646', 'https://openalex.org/W2936774411', 'https://openalex.org/W2113459411', 'https://openalex.org/W2946856970', 'https://openalex.org/W2921087533', 'https://openalex.org/W2963026768', 'https://openalex.org/W2963558289', 'https://openalex.org/W2401231614', 'https://openalex.org/W2765407302', 'https://openalex.org/W2108598243', 'https://openalex.org/W1922655562', 'https://openalex.org/W2963435192', 'https://openalex.org/W1600737329']",2019-04-29
https://openalex.org/W2809210859,https://doi.org/10.1145/3219819.3220045,Coupled Context Modeling for Deep Chit-Chat,"To have automatic conversations between human and computer is regarded as one of the most hardcore problems in computer science. Conversational systems are of growing importance due to their promising potentials and commercial values as virtual assistants and chatbots. To build such systems with adequate intelligence is challenging, and requires abundant resources including an acquisition of big conversational data and interdisciplinary techniques, such as content analysis, text mining, and retrieval. The arrival of big data era reveals the feasibility to create a conversational system empowered by data-driven approaches. Now we are able to collect an extremely large number of human-human conversations on Web, and organize them to launch human-computer conversational systems. Given a human issued utterance, i.e., a query, a conversational system will search for appropriate responses, conduct relevance ranking using contexts information, and then output the highly relevant result. In this paper, we propose a novel context modeling framework with end-to-end neural networks for human-computer conversational systems. The proposed model is general and unified. In the experiments, we demonstrate the effectiveness of the proposed model for human-computer conversations using [email protected], MAP, nDCG, and MRR metrics.","['https://openalex.org/W4231109964', 'https://openalex.org/W3149154678', 'https://openalex.org/W2069870183', 'https://openalex.org/W2109814494', 'https://openalex.org/W1505802906', 'https://openalex.org/W4206827264', 'https://openalex.org/W2142920810', 'https://openalex.org/W1518951372', 'https://openalex.org/W2807880213', 'https://openalex.org/W2096145771', 'https://openalex.org/W2102531443', 'https://openalex.org/W2964217331', 'https://openalex.org/W2339852062', 'https://openalex.org/W2538399326', 'https://openalex.org/W2739634080', 'https://openalex.org/W2962883855', 'https://openalex.org/W2787911506', 'https://openalex.org/W2335981466', 'https://openalex.org/W2964178377', 'https://openalex.org/W2772564276', 'https://openalex.org/W4231934124', 'https://openalex.org/W2757121784', 'https://openalex.org/W2808293489', 'https://openalex.org/W2821503932', 'https://openalex.org/W2891416139', 'https://openalex.org/W2170245882', 'https://openalex.org/W2786983967', 'https://openalex.org/W71795751', 'https://openalex.org/W2808440041', 'https://openalex.org/W2098697179', 'https://openalex.org/W2251241778', 'https://openalex.org/W2963035145', 'https://openalex.org/W1750263989', 'https://openalex.org/W2962958286', 'https://openalex.org/W2123031745', 'https://openalex.org/W2561368124', 'https://openalex.org/W10957333', 'https://openalex.org/W2251235149', 'https://openalex.org/W2963206148', 'https://openalex.org/W1532325895', 'https://openalex.org/W295828404', 'https://openalex.org/W2170738476', 'https://openalex.org/W3122775348', 'https://openalex.org/W2072128103', 'https://openalex.org/W2251494832', 'https://openalex.org/W2130942839', 'https://openalex.org/W2740258984', 'https://openalex.org/W2548091406', 'https://openalex.org/W1921650316', 'https://openalex.org/W2120615054', 'https://openalex.org/W2963963856', 'https://openalex.org/W2128892113', 'https://openalex.org/W2741363662', 'https://openalex.org/W2963625079', 'https://openalex.org/W2963986868']",2018-07-19
https://openalex.org/W3128412859,https://doi.org/10.1609/aaai.v35i12.17289,Learning Modality-Specific Representations with Self-Supervised Multi-Task Learning for Multimodal Sentiment Analysis,"Representation Learning is a significant and challenging task in multimodal learning. Effective modality representations should contain two parts of characteristics: the consistency and the difference. Due to the unified multimodal annota- tion, existing methods are restricted in capturing differenti- ated information. However, additional unimodal annotations are high time- and labor-cost. In this paper, we design a la- bel generation module based on the self-supervised learning strategy to acquire independent unimodal supervisions. Then, joint training the multimodal and uni-modal tasks to learn the consistency and difference, respectively. Moreover, dur- ing the training stage, we design a weight-adjustment strat- egy to balance the learning progress among different sub- tasks. That is to guide the subtasks to focus on samples with the larger difference between modality supervisions. Last, we conduct extensive experiments on three public multimodal baseline datasets. The experimental results validate the re- liability and stability of auto-generated unimodal supervi- sions. On MOSI and MOSEI datasets, our method surpasses the current state-of-the-art methods. On the SIMS dataset, our method achieves comparable performance than human- annotated unimodal labels. The full codes are available at https://github.com/thuiar/Self-MM.","['https://openalex.org/W2946218857', 'https://openalex.org/W2619383789', 'https://openalex.org/W3022398031', 'https://openalex.org/W6666761814', 'https://openalex.org/W1958932515', 'https://openalex.org/W2798965674', 'https://openalex.org/W3034266838', 'https://openalex.org/W2985862548', 'https://openalex.org/W2947476638', 'https://openalex.org/W6752724743', 'https://openalex.org/W2901272442', 'https://openalex.org/W3034849760', 'https://openalex.org/W2883409523', 'https://openalex.org/W2051464482', 'https://openalex.org/W6742058293', 'https://openalex.org/W4385245566', 'https://openalex.org/W2964346351', 'https://openalex.org/W3093051361', 'https://openalex.org/W2963685106', 'https://openalex.org/W4287780442', 'https://openalex.org/W2964216663', 'https://openalex.org/W2896457183', 'https://openalex.org/W2964051877', 'https://openalex.org/W3037572520', 'https://openalex.org/W2465534249', 'https://openalex.org/W2963403868', 'https://openalex.org/W2577325523', 'https://openalex.org/W2742079690', 'https://openalex.org/W3021173516', 'https://openalex.org/W2964010806', 'https://openalex.org/W2963341956', 'https://openalex.org/W2808359495', 'https://openalex.org/W3098042509', 'https://openalex.org/W2787581402', 'https://openalex.org/W2738581557', 'https://openalex.org/W2064675550']",2021-05-18
https://openalex.org/W3174620475,https://doi.org/10.18653/v1/2021.acl-demo.20,TEXTOIR: An Integrated and Visualized Platform for Text Open Intent Recognition,"TEXTOIR is the first integrated and visualized platform for text open intent\nrecognition. It is composed of two main modules: open intent detection and open\nintent discovery. Each module integrates most of the state-of-the-art\nalgorithms and benchmark intent datasets. It also contains an overall framework\nconnecting the two modules in a pipeline scheme. In addition, this platform has\nvisualized tools for data and model management, training, evaluation and\nanalysis of the performance from different aspects. TEXTOIR provides useful\ntoolkits and convenient visualized interfaces for each sub-module (Toolkit\ncode: https://github.com/thuiar/TEXTOIR), and designs a framework to implement\na complete process to both identify known intents and discover open intents\n(Demo code: https://github.com/thuiar/TEXTOIR-DEMO).\n","['https://openalex.org/W3045492832', 'https://openalex.org/W2964295685', 'https://openalex.org/W2986193249', 'https://openalex.org/W2963149653', 'https://openalex.org/W2127218421', 'https://openalex.org/W2187089797', 'https://openalex.org/W2531327146', 'https://openalex.org/W4297683418', 'https://openalex.org/W2963924212', 'https://openalex.org/W2963341956', 'https://openalex.org/W2963693742', 'https://openalex.org/W2020735245', 'https://openalex.org/W2962852342', 'https://openalex.org/W2988964532', 'https://openalex.org/W2251410829', 'https://openalex.org/W1673310716', 'https://openalex.org/W2250539671', 'https://openalex.org/W3174821200', 'https://openalex.org/W2963877826', 'https://openalex.org/W2533545350', 'https://openalex.org/W2998721586', 'https://openalex.org/W2896457183', 'https://openalex.org/W2952409498', 'https://openalex.org/W3035371495', 'https://openalex.org/W2964074409', 'https://openalex.org/W3023027202', 'https://openalex.org/W3173488222', 'https://openalex.org/W2769159728', 'https://openalex.org/W2990604239', 'https://openalex.org/W2767414122', 'https://openalex.org/W4386265460']",2021-01-01
https://openalex.org/W3173488222,https://doi.org/10.1609/aaai.v35i16.17690,Deep Open Intent Classification with Adaptive Decision Boundary,"Open intent classification is a challenging task in dialogue systems. On the one hand, it should ensure the quality of known intent identification. On the other hand, it needs to detect the open (unknown) intent without prior knowledge. Current models are limited in finding the appropriate decision boundary to balance the performances of both known intents and the open intent. In this paper, we propose a post-processing method to learn the adaptive decision boundary (ADB) for open intent classification. We first utilize the labeled known intent samples to pre-train the model. Then, we automatically learn the adaptive spherical decision boundary for each known class with the aid of well-trained features. Specifically, we propose a new loss function to balance both the empirical risk and the open space risk. Our method does not need open intent samples and is free from modifying the model architecture. Moreover, our approach is surprisingly insensitive with less labeled data and fewer known intents. Extensive experiments on three benchmark datasets show that our method yields significant improvements compared with the state-of-the-art methods.","['https://openalex.org/W6785458781', 'https://openalex.org/W6694286045', 'https://openalex.org/W2583461040', 'https://openalex.org/W3012396850', 'https://openalex.org/W2896457183', 'https://openalex.org/W2949325756', 'https://openalex.org/W2475167333', 'https://openalex.org/W2997140799', 'https://openalex.org/W2531327146', 'https://openalex.org/W1032927584', 'https://openalex.org/W2811255692', 'https://openalex.org/W2971418622', 'https://openalex.org/W2767414122', 'https://openalex.org/W6763425312', 'https://openalex.org/W2969394406', 'https://openalex.org/W2989993260', 'https://openalex.org/W3035472542', 'https://openalex.org/W1932198206', 'https://openalex.org/W2997075693', 'https://openalex.org/W2971167298', 'https://openalex.org/W6680007464', 'https://openalex.org/W6678038612', 'https://openalex.org/W6655096051', 'https://openalex.org/W2132870739', 'https://openalex.org/W6744934105', 'https://openalex.org/W2886829407', 'https://openalex.org/W6766799949', 'https://openalex.org/W6642885627', 'https://openalex.org/W2251410829', 'https://openalex.org/W3035371495', 'https://openalex.org/W2618146408', 'https://openalex.org/W2905730339', 'https://openalex.org/W2964201905', 'https://openalex.org/W1522301498', 'https://openalex.org/W1970088130', 'https://openalex.org/W2986193249', 'https://openalex.org/W2963924212', 'https://openalex.org/W3014813097', 'https://openalex.org/W2963149653', 'https://openalex.org/W2018459374', 'https://openalex.org/W2119880843', 'https://openalex.org/W2992671401', 'https://openalex.org/W2952409498', 'https://openalex.org/W2962914604', 'https://openalex.org/W3045492832', 'https://openalex.org/W2987802279', 'https://openalex.org/W2963546708', 'https://openalex.org/W3102616566', 'https://openalex.org/W2963033987', 'https://openalex.org/W4386266007', 'https://openalex.org/W2963066655', 'https://openalex.org/W2980282514']",2021-05-18
https://openalex.org/W3112240880,https://doi.org/10.1609/aaai.v35i16.17689,Discovering New Intents with Deep Aligned Clustering,"Discovering new intents is a crucial task in dialogue systems. Most existing methods are limited in transferring the prior knowledge from known intents to new intents. These methods also have difficulties in providing high-quality supervised signals to learn clustering-friendly features for grouping unlabeled intents. In this work, we propose an effective method (Deep Aligned Clustering) to discover new intents with the aid of limited known intent data. Firstly, we leverage a few labeled known intent samples as prior knowledge to pre-train the model. Then, we perform k-means to produce cluster assignments as pseudo-labels. Moreover, we propose an alignment strategy to tackle the label inconsistency problem during clustering assignments. Finally, we learn the intent representations under the supervision of the aligned pseudo-labels. With an unknown number of new intents, we predict the number of intent categories by eliminating low-confidence intent-wise clusters. Extensive experiments on two benchmark datasets show that our method is more robust and achieves substantial improvements over the state-of-the-art methods.","['https://openalex.org/W2153839362', 'https://openalex.org/W2096100960', 'https://openalex.org/W2583461040', 'https://openalex.org/W2883725317', 'https://openalex.org/W3012396850', 'https://openalex.org/W6747233776', 'https://openalex.org/W2896457183', 'https://openalex.org/W2803392141', 'https://openalex.org/W2005852173', 'https://openalex.org/W2020735245', 'https://openalex.org/W2408412675', 'https://openalex.org/W2403246281', 'https://openalex.org/W2970941071', 'https://openalex.org/W2890950904', 'https://openalex.org/W2769159728', 'https://openalex.org/W2908345757', 'https://openalex.org/W6689029123', 'https://openalex.org/W2971418622', 'https://openalex.org/W6763425312', 'https://openalex.org/W2989993260', 'https://openalex.org/W3035472542', 'https://openalex.org/W2888939716', 'https://openalex.org/W2971104760', 'https://openalex.org/W2997075693', 'https://openalex.org/W2971167298', 'https://openalex.org/W1987971958', 'https://openalex.org/W2889636191', 'https://openalex.org/W3023027202', 'https://openalex.org/W2134089414', 'https://openalex.org/W2804945011', 'https://openalex.org/W6673114980', 'https://openalex.org/W6685380521', 'https://openalex.org/W2533545350', 'https://openalex.org/W2337374958', 'https://openalex.org/W3034576826', 'https://openalex.org/W2222512263', 'https://openalex.org/W4253156077', 'https://openalex.org/W4292692470', 'https://openalex.org/W2963877826', 'https://openalex.org/W4386266007', 'https://openalex.org/W2964295685', 'https://openalex.org/W2127218421', 'https://openalex.org/W1618905105', 'https://openalex.org/W2963341956', 'https://openalex.org/W2980282514', 'https://openalex.org/W2089468765', 'https://openalex.org/W2986193249', 'https://openalex.org/W2250539671', 'https://openalex.org/W2990604239', 'https://openalex.org/W3045492832', 'https://openalex.org/W2998721586', 'https://openalex.org/W2952409498', 'https://openalex.org/W2988964532', 'https://openalex.org/W2779692282', 'https://openalex.org/W2964074409', 'https://openalex.org/W1673310716', 'https://openalex.org/W2962852342']",2021-05-18
https://openalex.org/W3099890447,https://doi.org/10.18653/v1/2020.emnlp-main.277,Dialogue Distillation: Open-Domain Dialogue Augmentation Using Unpaired Data,"Recent advances in open-domain dialogue systems rely on the success of neural models that are trained on large-scale data. However, collecting large-scale dialogue data is usually time-consuming and labor-intensive. To address this data dilemma, we propose a novel data augmentation method for training open-domain dialogue models by utilizing unpaired data. Specifically, a data-level distillation process is first proposed to construct augmented dialogues where both post and response are retrieved from the unpaired data. A ranking module is employed to filter out low-quality dialogues. Further, a model-level distillation process is employed to distill a teacher model trained on high-quality paired data to augmented dialogue pairs, thereby preventing dialogue models from being affected by the noise in the augmented data. Automatic and manual evaluation indicates that our method can produce high-quality dialogue pairs with diverse contents, and the proposed data-level and model-level dialogue distillation can improve the performance of competitive baselines.","['https://openalex.org/W2963206148', 'https://openalex.org/W2950902819', 'https://openalex.org/W4295727797', 'https://openalex.org/W2963691849', 'https://openalex.org/W3035148359', 'https://openalex.org/W2889681790', 'https://openalex.org/W2911994530', 'https://openalex.org/W1821462560', 'https://openalex.org/W2611029872', 'https://openalex.org/W2963521540', 'https://openalex.org/W2128892113', 'https://openalex.org/W2804047946', 'https://openalex.org/W2130942839', 'https://openalex.org/W3014773921', 'https://openalex.org/W4295253143', 'https://openalex.org/W2904444765', 'https://openalex.org/W2808437126', 'https://openalex.org/W2963825865', 'https://openalex.org/W2971296908', 'https://openalex.org/W3104078590', 'https://openalex.org/W112197792', 'https://openalex.org/W2963403868', 'https://openalex.org/W2963216553', 'https://openalex.org/W2896457183', 'https://openalex.org/W2997892440', 'https://openalex.org/W2807873315', 'https://openalex.org/W1591706642', 'https://openalex.org/W2963341956', 'https://openalex.org/W3097517997', 'https://openalex.org/W3093956460', 'https://openalex.org/W4385245566', 'https://openalex.org/W2962796276', 'https://openalex.org/W2963564796', 'https://openalex.org/W222053410', 'https://openalex.org/W2964309167', 'https://openalex.org/W3035282664', 'https://openalex.org/W2963736842', 'https://openalex.org/W2586847566', 'https://openalex.org/W3015322406', 'https://openalex.org/W2963201498', 'https://openalex.org/W3035072597', 'https://openalex.org/W2963371754', 'https://openalex.org/W2953039584', 'https://openalex.org/W2963544700']",2020-01-01
https://openalex.org/W4221141243,https://doi.org/10.18653/v1/2022.findings-acl.27,A Slot Is Not Built in One Utterance: Spoken Language Dialogs with Sub-Slots,"A slot value might be provided segment by segment over multiple-turn interactions in a dialog, especially for some important information such as phone numbers and names. It is a common phenomenon in daily life, but little attention has been paid to it in previous work. To fill the gap, this paper defines a new task named Sub-Slot based Task-Oriented Dialog (SSTOD) and builds a Chinese dialog dataset SSD for boosting research on SSTOD. The dataset includes a total of 40K dialogs and 500K utterances from four different domains: Chinese names, phone numbers, ID numbers and license plate numbers. The data is well annotated with sub-slot values, slot values, dialog states and actions. We find some new linguistic phenomena and interactive manners in SSTOD which raise critical challenges of building dialog agents for the task. We test three state-of-the-art dialog models on SSTOD and find they cannot handle the task well on any of the four domains. We also investigate an improved model by involving slot knowledge in a plug-in manner. More work should be done to meet the new challenges raised from SSTOD which widely exists in real-life applications. The dataset and code are publicly available via https://github.com/shunjiu/SSTOD.","['https://openalex.org/W6858769235', 'https://openalex.org/W2997108628', 'https://openalex.org/W3112180926', 'https://openalex.org/W2251058040', 'https://openalex.org/W2097136395', 'https://openalex.org/W178897730', 'https://openalex.org/W2997771882', 'https://openalex.org/W4297783677', 'https://openalex.org/W3034879520', 'https://openalex.org/W4287795696', 'https://openalex.org/W2964006684', 'https://openalex.org/W4287829318', 'https://openalex.org/W3104546989', 'https://openalex.org/W3036362489', 'https://openalex.org/W2250297846', 'https://openalex.org/W3011899608', 'https://openalex.org/W2144211451', 'https://openalex.org/W2945475330', 'https://openalex.org/W3173691672', 'https://openalex.org/W2127270678', 'https://openalex.org/W2251235149', 'https://openalex.org/W3034533785', 'https://openalex.org/W2998704965', 'https://openalex.org/W2604698497', 'https://openalex.org/W2768282280', 'https://openalex.org/W2464790259', 'https://openalex.org/W2949252816', 'https://openalex.org/W3024509506', 'https://openalex.org/W2784070054', 'https://openalex.org/W2077302143']",2022-01-01
https://openalex.org/W2252276958,https://doi.org/10.18653/v1/w15-4606,An Incremental Turn-Taking Model with Active System Barge-in for Spoken Dialog Systems,"This paper deals with an incremental turntaking model that provides a novel solution for end-of-turn detection.It includes a flexible framework that enables active system barge-in.In order to accomplish this, a systematic procedure of teaching a dialog system to produce meaningful system barge-in is presented.This procedure improves system robustness and success rate.It includes constructing cost models and learning optimal policy using reinforcement learning.Results show that our model reduces false cut-in rate by 37.1% and response delay by 32.5% compared to the baseline system.Also the learned system barge-in strategy yields a 27.7% increase in average reward from user responses.","['https://openalex.org/W1502481855', 'https://openalex.org/W2067097374', 'https://openalex.org/W1574292571', 'https://openalex.org/W2085662862', 'https://openalex.org/W1484777458', 'https://openalex.org/W1010839910', 'https://openalex.org/W2109943925', 'https://openalex.org/W1990517552', 'https://openalex.org/W1986532700', 'https://openalex.org/W2399301052', 'https://openalex.org/W1515851193', 'https://openalex.org/W2134289401', 'https://openalex.org/W178897730', 'https://openalex.org/W2013887137', 'https://openalex.org/W2278865652', 'https://openalex.org/W1998677696', 'https://openalex.org/W2127838323', 'https://openalex.org/W2251235149']",2015-01-01
https://openalex.org/W2997892440,https://doi.org/10.1609/aaai.v34i05.6518,A Pre-Training Based Personalized Dialogue Generation Model with Persona-Sparse Data,"Endowing dialogue systems with personas is essential to deliver more human-like conversations. However, this problem is still far from well explored due to the difficulties of both embodying personalities in natural languages and the persona sparsity issue observed in most dialogue corpora. This paper proposes a pre-training based personalized dialogue model that can generate coherent responses using persona-sparse dialogue data. In this method, a pre-trained language model is used to initialize an encoder and decoder, and personal attribute embeddings are devised to model richer dialogue contexts by encoding speakers' personas together with dialogue histories. Further, to incorporate the target persona in the decoding process and to balance its contribution, an attention routing structure is devised in the decoder to merge features extracted from the target persona and dialogue contexts using dynamically predicted weights. Our model can utilize persona-sparse dialogues in a unified manner during the training process, and can also control the amount of persona-related features to exhibit during the inference process. Both automatic and manual evaluation demonstrates that the proposed model outperforms state-of-the-art methods for generating more coherent and persona consistent responses with persona-sparse data.","['https://openalex.org/W2250895046', 'https://openalex.org/W2956901422', 'https://openalex.org/W2896457183', 'https://openalex.org/W2913443447', 'https://openalex.org/W2953039584', 'https://openalex.org/W2945397504', 'https://openalex.org/W2740919303', 'https://openalex.org/W1958706068', 'https://openalex.org/W6698480918', 'https://openalex.org/W2765617518', 'https://openalex.org/W6755879163', 'https://openalex.org/W6677154328', 'https://openalex.org/W2890394457', 'https://openalex.org/W2947972709', 'https://openalex.org/W6898505805', 'https://openalex.org/W6748634344', 'https://openalex.org/W2625977873', 'https://openalex.org/W112197792', 'https://openalex.org/W2962883855', 'https://openalex.org/W2947375732', 'https://openalex.org/W2938830017', 'https://openalex.org/W6679436768', 'https://openalex.org/W2914204778', 'https://openalex.org/W2578354947', 'https://openalex.org/W2911994530', 'https://openalex.org/W2605133118', 'https://openalex.org/W2807873315', 'https://openalex.org/W2900227126', 'https://openalex.org/W2115648139', 'https://openalex.org/W2964309167', 'https://openalex.org/W2963206148', 'https://openalex.org/W4385245566', 'https://openalex.org/W2951216772', 'https://openalex.org/W2962739339', 'https://openalex.org/W2962796276', 'https://openalex.org/W2130942839', 'https://openalex.org/W2963825865', 'https://openalex.org/W2965718149', 'https://openalex.org/W2988647680', 'https://openalex.org/W2983772459', 'https://openalex.org/W4288624561', 'https://openalex.org/W3015322406', 'https://openalex.org/W2964352131']",2020-04-03
https://openalex.org/W2578390274,,Reinforcement learning for turn-taking management in incremental spoken dialogue systems,"In this article, reinforcement learning is used to learn an optimal turn-taking strategy for vocal human-machine dialogue. The Orange Labs' Majordomo dialogue system, which allows the users to have conversations within a smart home, has been upgraded to an incremental version. First, a user simulator is built in order to generate a dialogue corpus which thereafter is used to optimise the turn-taking strategy from delayed rewards with the Fitted-Q reinforcement learning algorithm. Real users test and evaluate the new learnt strategy, versus a non-incremental and a handcrafted incremental strategies. The data-driven strategy is shown to significantly improve the task completion ratio and to be preferred by the users according to subjective metrics.","['https://openalex.org/W2020755048', 'https://openalex.org/W2119631826', 'https://openalex.org/W200223693', 'https://openalex.org/W2104300420', 'https://openalex.org/W2095271936', 'https://openalex.org/W2110633879', 'https://openalex.org/W2026431544', 'https://openalex.org/W2106017103', 'https://openalex.org/W2476025067', 'https://openalex.org/W1524333225', 'https://openalex.org/W2250707538', 'https://openalex.org/W2399301052', 'https://openalex.org/W2250891614', 'https://openalex.org/W86954431', 'https://openalex.org/W1515851193', 'https://openalex.org/W2251587124', 'https://openalex.org/W2250736710', 'https://openalex.org/W2109038907', 'https://openalex.org/W2067097374', 'https://openalex.org/W2252276958', 'https://openalex.org/W2105252562', 'https://openalex.org/W2168490009', 'https://openalex.org/W2045804781', 'https://openalex.org/W2394671344', 'https://openalex.org/W2251527109', 'https://openalex.org/W2153190547', 'https://openalex.org/W2106547558', 'https://openalex.org/W2062175565', 'https://openalex.org/W2150609911', 'https://openalex.org/W9230629', 'https://openalex.org/W2563711641', 'https://openalex.org/W2067348796', 'https://openalex.org/W1975244201', 'https://openalex.org/W121610373', 'https://openalex.org/W2251062710']",2016-07-09
https://openalex.org/W3197781433,https://doi.org/10.1007/978-3-030-82196-8_57,A Survey on the Semi Supervised Learning Paradigm in the Context of Speech Emotion Recognition,,"['https://openalex.org/W1549066977', 'https://openalex.org/W4243223219', 'https://openalex.org/W2977979692', 'https://openalex.org/W2969889150', 'https://openalex.org/W2561184891', 'https://openalex.org/W2105594594', 'https://openalex.org/W1615454278', 'https://openalex.org/W13034104', 'https://openalex.org/W2074788634', 'https://openalex.org/W3035043463', 'https://openalex.org/W2893051100', 'https://openalex.org/W2761514455', 'https://openalex.org/W3086923691', 'https://openalex.org/W3096831136', 'https://openalex.org/W2964159205', 'https://openalex.org/W2146334809', 'https://openalex.org/W175750906', 'https://openalex.org/W2342475039', 'https://openalex.org/W1501669607', 'https://openalex.org/W2963199341', 'https://openalex.org/W1494198834', 'https://openalex.org/W2145487065', 'https://openalex.org/W2607400660', 'https://openalex.org/W2025768430', 'https://openalex.org/W3161810785', 'https://openalex.org/W3089639627', 'https://openalex.org/W2100495367', 'https://openalex.org/W2564725949', 'https://openalex.org/W2018549299', 'https://openalex.org/W179777611', 'https://openalex.org/W2147062276', 'https://openalex.org/W2401417847', 'https://openalex.org/W2144005487', 'https://openalex.org/W2194775991', 'https://openalex.org/W2113087918', 'https://openalex.org/W1581984155', 'https://openalex.org/W2648194195', 'https://openalex.org/W2085662862', 'https://openalex.org/W3015141382', 'https://openalex.org/W820669328', 'https://openalex.org/W2504119555', 'https://openalex.org/W1521803737']",2021-08-02
https://openalex.org/W2610815425,,Proceedings of the SIGDIAL 2013 Conference,,[],2013-01-01
https://openalex.org/W4386265460,https://doi.org/10.1007/978-981-99-3885-8_9,Discovering New Intents with Deep Aligned Clustering,,"['https://openalex.org/W2988964532', 'https://openalex.org/W3035472542', 'https://openalex.org/W3023027202', 'https://openalex.org/W2896457183', 'https://openalex.org/W2990604239', 'https://openalex.org/W2883725317', 'https://openalex.org/W3034576826', 'https://openalex.org/W2222512263', 'https://openalex.org/W1987971958', 'https://openalex.org/W2986193249', 'https://openalex.org/W3045492832', 'https://openalex.org/W2127218421', 'https://openalex.org/W2020735245', 'https://openalex.org/W2132870739', 'https://openalex.org/W2779692282', 'https://openalex.org/W2250539671', 'https://openalex.org/W2153839362', 'https://openalex.org/W2602856279', 'https://openalex.org/W2952409498', 'https://openalex.org/W2979826702', 'https://openalex.org/W3106333467']",2023-01-01
https://openalex.org/W3173941845,https://doi.org/10.18653/v1/2021.acl-long.272,Diversifying Dialog Generation via Adaptive Label Smoothing,"Yida Wang, Yinhe Zheng, Yong Jiang, Minlie Huang. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2021.","['https://openalex.org/W2995460523', 'https://openalex.org/W3135335819', 'https://openalex.org/W2916898195', 'https://openalex.org/W2952988558', 'https://openalex.org/W2951883832', 'https://openalex.org/W3015322406', 'https://openalex.org/W3035282664', 'https://openalex.org/W3088677288', 'https://openalex.org/W4288482469', 'https://openalex.org/W2884561390', 'https://openalex.org/W2761590056', 'https://openalex.org/W2970206392', 'https://openalex.org/W2905933322', 'https://openalex.org/W2101105183', 'https://openalex.org/W2626967530', 'https://openalex.org/W2963403868', 'https://openalex.org/W2183341477', 'https://openalex.org/W2918914336', 'https://openalex.org/W2890969459', 'https://openalex.org/W2964121744', 'https://openalex.org/W2803985397', 'https://openalex.org/W2952650870', 'https://openalex.org/W3175570311', 'https://openalex.org/W2788932366', 'https://openalex.org/W2963736842', 'https://openalex.org/W3035317912', 'https://openalex.org/W1522301498', 'https://openalex.org/W2963544536', 'https://openalex.org/W3093956460', 'https://openalex.org/W2948210185', 'https://openalex.org/W3100737666', 'https://openalex.org/W4297798436', 'https://openalex.org/W2996287690', 'https://openalex.org/W4385245566', 'https://openalex.org/W2890940245', 'https://openalex.org/W2962717182', 'https://openalex.org/W2963206148', 'https://openalex.org/W3098774588', 'https://openalex.org/W1821462560', 'https://openalex.org/W2962814079', 'https://openalex.org/W2581377246', 'https://openalex.org/W2963212250', 'https://openalex.org/W3099890447', 'https://openalex.org/W2995969307', 'https://openalex.org/W2997892440', 'https://openalex.org/W1975879668', 'https://openalex.org/W3104668038', 'https://openalex.org/W2995404354', 'https://openalex.org/W2968297680', 'https://openalex.org/W2964212410', 'https://openalex.org/W3103182178', 'https://openalex.org/W3099180151', 'https://openalex.org/W3035239386', 'https://openalex.org/W3004809259', 'https://openalex.org/W2963351448', 'https://openalex.org/W4287865413', 'https://openalex.org/W2938704169', 'https://openalex.org/W3125507956', 'https://openalex.org/W3035068109', 'https://openalex.org/W2963341956']",2021-01-01
https://openalex.org/W3193915594,https://doi.org/10.48550/arxiv.2108.07154,MMChat: Multi-Modal Chat Dataset on Social Media,"Incorporating multi-modal contexts in conversation is important for developing more engaging dialogue systems. In this work, we explore this direction by introducing MMChat: a large-scale Chinese multi-modal dialogue corpus (32.4M raw dialogues and 120.84K filtered dialogues). Unlike previous corpora that are crowd-sourced or collected from fictitious movies, MMChat contains image-grounded dialogues collected from real conversations on social media, in which the sparsity issue is observed. Specifically, image-initiated dialogues in common communications may deviate to some non-image-grounded topics as the conversation proceeds. To better investigate this issue, we manually annotate 100K dialogues from MMChat and further filter the corpus accordingly, which yields MMChat-hf. We develop a benchmark model to address the sparsity issue in dialogue generation tasks by adapting the attention routing mechanism on image features. Experiments demonstrate the usefulness of incorporating image features and the effectiveness of handling the sparsity of image features.","['https://openalex.org/W2973159684', 'https://openalex.org/W2897182555', 'https://openalex.org/W2963789888', 'https://openalex.org/W2745461083', 'https://openalex.org/W3113547664', 'https://openalex.org/W2889226596', 'https://openalex.org/W2951883832', 'https://openalex.org/W2963825865', 'https://openalex.org/W2277195237', 'https://openalex.org/W2997892440', 'https://openalex.org/W2911994530', 'https://openalex.org/W3103639864', 'https://openalex.org/W2970608575', 'https://openalex.org/W3133702157', 'https://openalex.org/W2101105183', 'https://openalex.org/W3095351420', 'https://openalex.org/W2963177331', 'https://openalex.org/W3090998540', 'https://openalex.org/W2613718673', 'https://openalex.org/W2963919731', 'https://openalex.org/W2997517419']",2021-08-16
https://openalex.org/W4301104990,,Multimodal Machine Learning: A Survey and Taxonomy,"Our experience of the world is multimodal - we see objects, hear sounds, feel texture, smell odors, and taste flavors. Modality refers to the way in which something happens or is experienced and a research problem is characterized as multimodal when it includes multiple such modalities. In order for Artificial Intelligence to make progress in understanding the world around us, it needs to be able to interpret such multimodal signals together. Multimodal machine learning aims to build models that can process and relate information from multiple modalities. It is a vibrant multi-disciplinary field of increasing importance and with extraordinary potential. Instead of focusing on specific multimodal applications, this paper surveys the recent advances in multimodal machine learning itself and presents them in a common taxonomy. We go beyond the typical early and late fusion categorization and identify broader challenges that are faced by multimodal machine learning, namely: representation, translation, alignment, fusion, and co-learning. This new taxonomy will enable researchers to better understand the state of the field and identify directions for future research.",[],2017-05-26
https://openalex.org/W4297783677,https://doi.org/10.48550/arxiv.2111.14592,GALAXY: A Generative Pre-trained Model for Task-Oriented Dialog with Semi-Supervised Learning and Explicit Policy Injection,"Pre-trained models have proved to be powerful in enhancing task-oriented dialog systems. However, current pre-training methods mainly focus on enhancing dialog understanding and generation tasks while neglecting the exploitation of dialog policy. In this paper, we propose GALAXY, a novel pre-trained dialog model that explicitly learns dialog policy from limited labeled dialogs and large-scale unlabeled dialog corpora via semi-supervised learning. Specifically, we introduce a dialog act prediction task for policy optimization during pre-training and employ a consistency regularization term to refine the learned representation with the help of unlabeled dialogs. We also implement a gating mechanism to weigh suitable unlabeled dialog samples. Empirical results show that GALAXY substantially improves the performance of task-oriented dialog systems, and achieves new state-of-the-art results on benchmark datasets: In-Car, MultiWOZ2.0 and MultiWOZ2.1, improving their end-to-end combined scores by 2.5, 5.3 and 5.5 points, respectively. We also show that GALAXY has a stronger few-shot ability than existing models under various low-resource settings.",[],2021-11-29
https://openalex.org/W3188553726,https://doi.org/10.48550/arxiv.2108.01547,EVA: An Open-Domain Chinese Dialogue System with Large-Scale Generative Pre-Training,"Although pre-trained language models have remarkably enhanced the generation ability of dialogue systems, open-domain Chinese dialogue systems are still limited by the dialogue data and the model size compared with English ones. In this paper, we propose EVA, a Chinese dialogue system that contains the largest Chinese pre-trained dialogue model with 2.8B parameters. To build this model, we collect the largest Chinese dialogue dataset named WDC-Dialogue from various public social media. This dataset contains 1.4B context-response pairs and is used as the pre-training corpus of EVA. Extensive experiments on automatic and human evaluation show that EVA outperforms other Chinese pre-trained dialogue models especially in the multi-turn interaction of human-bot conversations.","['https://openalex.org/W3000779003', 'https://openalex.org/W2328886022', 'https://openalex.org/W2101105183', 'https://openalex.org/W2891416139', 'https://openalex.org/W2102531443', 'https://openalex.org/W2982399380', 'https://openalex.org/W2963206148', 'https://openalex.org/W2963250244', 'https://openalex.org/W2154652894', 'https://openalex.org/W2626778328', 'https://openalex.org/W3155584966', 'https://openalex.org/W2911994530', 'https://openalex.org/W3040352674', 'https://openalex.org/W2963963856', 'https://openalex.org/W2963112338', 'https://openalex.org/W3129831491', 'https://openalex.org/W3082274269', 'https://openalex.org/W2963475460', 'https://openalex.org/W2949888546', 'https://openalex.org/W3093956460', 'https://openalex.org/W1591706642']",2021-08-03
https://openalex.org/W4241891521,https://doi.org/10.17323/1728-192x-2015-1-142-202,A Simplest Systematics for the Organization of Turn-Taking for Conversation,"The article is the first Russian translation of the most well-known piece in conversation analysis (CA), written by the founders of CA Harvey Sacks, Emanuel Schegloff and Gail Jefferson. It has become a milestone in the development of the discipline. The authors offer a comprehensive approach to the study of conversational interactions. The approach is based on the analysis of detailed transcripts of the records of natural conversations. The authors show that in the course of the conversation co-conversationalists use a number of techniques to organize the turn-taking. These techniques are combined in four rules: (1) the first option is the transfer of speakership via allocation of the next speaker by the current speaker; (2) if this first option is not realized, turn-taking may happen via the self-selection by one of the participants; (3) if the second option remains unrealized too, the current speaker continues speaking, (4) with all three options being recurrently provided at all next transition relevant places. The result of the operation of these rules is an orderly conversation based on the principle “one speaker at a time.” According to the authors, this model is compatible with obvious observations concerning conversational practices that they make. The authors show that in every conversation there is a turn-taking system in operation, which provides for a flexible adaptation of the every conversation’s structure to any possible topics and any possible speakers’ identities. Such approach considers how the participants in social interactions order their communication with each other, achieving a sense of normally occurring interaction.","['https://openalex.org/W1985479696', 'https://openalex.org/W1651898646', 'https://openalex.org/W250657125', 'https://openalex.org/W2240306122', 'https://openalex.org/W2097814956', 'https://openalex.org/W1900064238', 'https://openalex.org/W4254353056', 'https://openalex.org/W2989964977', 'https://openalex.org/W6667986835', 'https://openalex.org/W2323552962', 'https://openalex.org/W1964725106', 'https://openalex.org/W4244054825', 'https://openalex.org/W4214817013', 'https://openalex.org/W2027563576', 'https://openalex.org/W2076010014', 'https://openalex.org/W2026073919', 'https://openalex.org/W2073092450', 'https://openalex.org/W2008211236', 'https://openalex.org/W143125967', 'https://openalex.org/W4300505196', 'https://openalex.org/W2005336371', 'https://openalex.org/W4293377111', 'https://openalex.org/W2574304980', 'https://openalex.org/W3149175452', 'https://openalex.org/W2314403306', 'https://openalex.org/W2024642405']",2015-01-01
https://openalex.org/W4288020585,https://doi.org/10.48550/arxiv.1911.09785,ReMixMatch: Semi-Supervised Learning with Distribution Alignment and\n Augmentation Anchoring,"We improve the recently-proposed ""MixMatch"" semi-supervised learning\nalgorithm by introducing two new techniques: distribution alignment and\naugmentation anchoring. Distribution alignment encourages the marginal\ndistribution of predictions on unlabeled data to be close to the marginal\ndistribution of ground-truth labels. Augmentation anchoring feeds multiple\nstrongly augmented versions of an input into the model and encourages each\noutput to be close to the prediction for a weakly-augmented version of the same\ninput. To produce strong augmentations, we propose a variant of AutoAugment\nwhich learns the augmentation policy while the model is being trained. Our new\nalgorithm, dubbed ReMixMatch, is significantly more data-efficient than prior\nwork, requiring between $5\\times$ and $16\\times$ less data to reach the same\naccuracy. For example, on CIFAR-10 with 250 labeled examples we reach $93.73\\%$\naccuracy (compared to MixMatch's accuracy of $93.58\\%$ with $4{,}000$ examples)\nand a median accuracy of $84.92\\%$ with just four labels per class. We make our\ncode and data open-source at https://github.com/google-research/remixmatch.\n",[],2019-11-21
https://openalex.org/W4200113972,https://doi.org/10.1162/coli_a_00430,Revisiting the Boundary between ASR and NLU in the Age of Conversational Dialog Systems,"Abstract As more users across the world are interacting with dialog agents in their daily life, there is a need for better speech understanding that calls for renewed attention to the dynamics between research in automatic speech recognition (ASR) and natural language understanding (NLU). We briefly review these research areas and lay out the current relationship between them. In light of the observations we make in this article, we argue that (1) NLU should be cognizant of the presence of ASR models being used upstream in a dialog system’s pipeline, (2) ASR should be able to learn from errors found in NLU, (3) there is a need for end-to-end data sets that provide semantic annotations on spoken input, (4) there should be stronger collaboration between ASR and NLU research communities.","['https://openalex.org/W1602389404', 'https://openalex.org/W6691329670', 'https://openalex.org/W2110037758', 'https://openalex.org/W6677618753', 'https://openalex.org/W2891229414', 'https://openalex.org/W2120375264', 'https://openalex.org/W14656806', 'https://openalex.org/W6774832990', 'https://openalex.org/W6769847149', 'https://openalex.org/W2963691697', 'https://openalex.org/W6737185339', 'https://openalex.org/W2894164357', 'https://openalex.org/W2007261869', 'https://openalex.org/W2114483840', 'https://openalex.org/W2251058040', 'https://openalex.org/W3093050310', 'https://openalex.org/W6756315458', 'https://openalex.org/W3097964672', 'https://openalex.org/W2511962886', 'https://openalex.org/W2885485938', 'https://openalex.org/W6750372648', 'https://openalex.org/W3095311338', 'https://openalex.org/W6772693987', 'https://openalex.org/W2936597270', 'https://openalex.org/W3176683285', 'https://openalex.org/W2161274063', 'https://openalex.org/W2803193013', 'https://openalex.org/W2972584841', 'https://openalex.org/W2158960817', 'https://openalex.org/W2103196492', 'https://openalex.org/W2096389830', 'https://openalex.org/W3173154122', 'https://openalex.org/W2091671846', 'https://openalex.org/W2963748441', 'https://openalex.org/W1998677696', 'https://openalex.org/W3153592532', 'https://openalex.org/W2964223283', 'https://openalex.org/W2963288440', 'https://openalex.org/W2973056893', 'https://openalex.org/W6752148829', 'https://openalex.org/W1968101325', 'https://openalex.org/W2169842528', 'https://openalex.org/W2791808303', 'https://openalex.org/W2592224602', 'https://openalex.org/W1649407914', 'https://openalex.org/W2189256702', 'https://openalex.org/W2888975141', 'https://openalex.org/W3046040002', 'https://openalex.org/W3015747801', 'https://openalex.org/W3196863408', 'https://openalex.org/W2079694211', 'https://openalex.org/W2806081754', 'https://openalex.org/W2738658885', 'https://openalex.org/W2962804563', 'https://openalex.org/W2999245659', 'https://openalex.org/W2984020609', 'https://openalex.org/W2915722758', 'https://openalex.org/W3011487811', 'https://openalex.org/W2618735189']",2021-12-22
https://openalex.org/W3170536409,https://doi.org/10.1145/3447548.3467107,MeLL: Large-scale Extensible User Intent Classification for Dialogue Systems with Meta Lifelong Learning,"User intent detection is vital for understanding their demands in dialogue systems. Although the User Intent Classification (UIC) task has been widely studied, for large-scale industrial applications, the task is still challenging. This is because user inputs in distinct domains may have different text distributions and target intent sets. When the underlying application evolves, new UIC tasks continuously emerge in a large quantity. Hence, it is crucial to develop a framework for large-scale extensible UIC that continuously fits new tasks and avoids catastrophic forgetting with an acceptable parameter growth rate. In this paper, we introduce the Meta Lifelong Learning (MeLL) framework to address this task. In MeLL, a BERT-based text encoder is employed to learn robust text representations across tasks, which is slowly updated for lifelong learning. We design global and local memory networks to capture the cross-task prototype representations of different classes, treated as the meta-learner quickly adapted to different tasks. Additionally, the Least Recently Used replacement policy is applied to manage the global memory such that the model size does not explode through time. Finally, each UIC task has its own task-specific output layer, with the attentive summarization of various features. We have conducted extensive experiments on both open-source and real industry datasets. Results show that MeLL improves the performance compared with strong baselines and also reduces the number of total parameters. We have also deployed MeLL on a real-world e-commerce dialogue system AliMe and observed significant improvements in terms of both F1 and the resources usage.","['https://openalex.org/W3034828204', 'https://openalex.org/W3099543642', 'https://openalex.org/W3034974675', 'https://openalex.org/W2946085385', 'https://openalex.org/W3110926867', 'https://openalex.org/W2964048876', 'https://openalex.org/W2510315076', 'https://openalex.org/W1832693441', 'https://openalex.org/W2473930607', 'https://openalex.org/W3118093735', 'https://openalex.org/W2965607502', 'https://openalex.org/W3104820280', 'https://openalex.org/W2953111196', 'https://openalex.org/W2788388592', 'https://openalex.org/W2951980657', 'https://openalex.org/W3098800734', 'https://openalex.org/W3011574394', 'https://openalex.org/W2981852735', 'https://openalex.org/W2991537901', 'https://openalex.org/W2911300548', 'https://openalex.org/W2980708516', 'https://openalex.org/W3094554104', 'https://openalex.org/W3099382298', 'https://openalex.org/W2896457183', 'https://openalex.org/W2972300333', 'https://openalex.org/W4288089799', 'https://openalex.org/W2601450892', 'https://openalex.org/W3109287115', 'https://openalex.org/W2965373594', 'https://openalex.org/W3082274269', 'https://openalex.org/W2902625698', 'https://openalex.org/W3034417115', 'https://openalex.org/W3003352860', 'https://openalex.org/W2963390791', 'https://openalex.org/W4322588812', 'https://openalex.org/W2799195065', 'https://openalex.org/W2803609229', 'https://openalex.org/W2906141031', 'https://openalex.org/W2950813464', 'https://openalex.org/W2996428491', 'https://openalex.org/W3088409176', 'https://openalex.org/W2922368466', 'https://openalex.org/W3210120707', 'https://openalex.org/W3084189447', 'https://openalex.org/W2964092386', 'https://openalex.org/W2963854351', 'https://openalex.org/W2971339032']",2021-08-12
https://openalex.org/W1010839910,,Continuously Predicting and Processing Barge-in During a Live Spoken Dialogue Task,"Barge-in enables the user to provide input during system speech, facilitating a more natural and efficient interaction. Standard methods generally focus on singlestage barge-in detection, applying the dialogue policy irrespective of the barge-in context. Unfortunately, this approach performs poorly when used in challenging environments. We propose and evaluate a barge-in processing method that uses a prediction strategy to continuously decide whether to pause, continue, or resume the prompt. This model has greater task success and efficiency than the standard approach when evaluated in a public spoken dialogue system. Index Terms: spoken dialogue systems, barge-in 1","['https://openalex.org/W2166350486', 'https://openalex.org/W178897730', 'https://openalex.org/W2394671344', 'https://openalex.org/W28861688', 'https://openalex.org/W2084142050', 'https://openalex.org/W2165861304', 'https://openalex.org/W2104300420', 'https://openalex.org/W1991646969', 'https://openalex.org/W2119631826', 'https://openalex.org/W1691659217', 'https://openalex.org/W1972491067', 'https://openalex.org/W2048008777']",2013-08-01
https://openalex.org/W2162556815,https://doi.org/10.21437/interspeech.2009-88,Enabling a user to specify an item at any time during system enumeration - item identification for barge-in-able conversational dialogue systems,"In conversational dialogue systems, users prefer to speak at any time and to use natural expressions. We have developed an Independent Component Analysis (ICA) based semi-blind source separation method, which allows users to barge-in over system utterances at any time. We created a novel method from timing information derived from barge-in utterances to identify one item that a user indicates during system enumeration. First, we determine the timing distribution of user utterances containing referential expressions and then approximate it using a gamma distribution. Second, we represent both the utterance timing and automatic speech recognition (ASR) results as probabilities of the desired selection from the system’s enumeration. We then integrate these two probabilities to identify the item having the maximum likelihood of selection. Experimental results using 400 utterances indicated that our method outperformed two methods used as a baseline (one of ASR results only and one of utterance timing only) in identification accuracy. Index Terms: spoken dialogue system, conversational interaction, barge-in, utterance timing","['https://openalex.org/W2151742940', 'https://openalex.org/W1489972948', 'https://openalex.org/W2166350486', 'https://openalex.org/W65340009', 'https://openalex.org/W1570542661', 'https://openalex.org/W2077378466', 'https://openalex.org/W28861688', 'https://openalex.org/W2116870703', 'https://openalex.org/W1972626400', 'https://openalex.org/W2117488952', 'https://openalex.org/W2100291405']",2009-09-06
https://openalex.org/W2002069029,https://doi.org/10.1016/c2013-0-11461-4,Studies in the Organization of Conversational Interaction,,[],1978-01-01
https://openalex.org/W4284683546,https://doi.org/10.1145/3477495.3532069,Unified Dialog Model Pre-training for Task-Oriented Dialog Understanding and Generation,"Recently, pre-training methods have shown remarkable success in task-oriented dialog (TOD) systems. However, most existing pre-trained models for TOD focus on either dialog understanding or dialog generation, but not both. In this paper, we propose SPACE, a novel unified pre-trained dialog model learning from large-scale dialog corpora with limited annotations, which can be effectively fine-tuned on a wide range of downstream dialog tasks. Specifically, SPACE consists of four successive components in a single transformer to maintain a task-flow in TOD systems: (i) a dialog encoding module to encode dialog history, (ii) a dialog understanding module to extract semantic vectors from either user queries or system responses, (iii) a dialog policy module to generate a policy vector that contains high-level semantics of the response, and (iv) a dialog generation module to produce appropriate responses. We design a dedicated pre-training objective for each component. Concretely, we pre-train the dialog encoding module with span mask language modeling to learn contextualized dialog information. To capture the structured dialog semantics, we pre-train the dialog understanding module via a novel tree-induced semi-supervised contrastive learning objective with the help of extra dialog annotations. In addition, we pre-train the dialog policy module by minimizing the ℒ2 distance between its output policy vector and the semantic vector of the response for policy optimization. Finally, the dialog generation model is pre-trained by language modeling. Results show that SPACE achieves state-of-the-art performance on eight downstream dialog benchmarks, including intent prediction, dialog state tracking, and end-to-end dialog modeling. We also show that SPACE has a stronger few-shot ability than existing models under the low-resource setting.","['https://openalex.org/W3035451444', 'https://openalex.org/W2964006684', 'https://openalex.org/W2985067290', 'https://openalex.org/W3034284249', 'https://openalex.org/W3045492832', 'https://openalex.org/W2972324944', 'https://openalex.org/W3034861927', 'https://openalex.org/W3034879520', 'https://openalex.org/W2963491014', 'https://openalex.org/W3099590177', 'https://openalex.org/W3174076858', 'https://openalex.org/W2971048662', 'https://openalex.org/W2972664115', 'https://openalex.org/W2892248135', 'https://openalex.org/W3117925982', 'https://openalex.org/W3112388682', 'https://openalex.org/W3102445752', 'https://openalex.org/W2889448364', 'https://openalex.org/W3011411500', 'https://openalex.org/W3154271556', 'https://openalex.org/W2798914047', 'https://openalex.org/W4205991051', 'https://openalex.org/W3109620645', 'https://openalex.org/W3114038149', 'https://openalex.org/W3167376363', 'https://openalex.org/W2979520138', 'https://openalex.org/W2101105183', 'https://openalex.org/W3189817881', 'https://openalex.org/W2985891764', 'https://openalex.org/W2972156721', 'https://openalex.org/W2981852735', 'https://openalex.org/W2963748441', 'https://openalex.org/W2997771882', 'https://openalex.org/W2964223283', 'https://openalex.org/W3155584966', 'https://openalex.org/W2786472750', 'https://openalex.org/W2898856000', 'https://openalex.org/W2806600904', 'https://openalex.org/W3015217416', 'https://openalex.org/W2128970689', 'https://openalex.org/W4205633461', 'https://openalex.org/W3088059392', 'https://openalex.org/W2923014074', 'https://openalex.org/W2952607215', 'https://openalex.org/W2891704263', 'https://openalex.org/W2963797754', 'https://openalex.org/W2468710617', 'https://openalex.org/W3100110884', 'https://openalex.org/W3161101519', 'https://openalex.org/W2970442801', 'https://openalex.org/W3045703328', 'https://openalex.org/W3101223450', 'https://openalex.org/W3176740717', 'https://openalex.org/W2963825865', 'https://openalex.org/W3098807778', 'https://openalex.org/W2988937804', 'https://openalex.org/W2891826200', 'https://openalex.org/W4214567023', 'https://openalex.org/W4255386139', 'https://openalex.org/W2769692274', 'https://openalex.org/W2750779823', 'https://openalex.org/W4239019441', 'https://openalex.org/W4288089799', 'https://openalex.org/W4238846128', 'https://openalex.org/W3121492439', 'https://openalex.org/W4210896998']",2022-07-06
https://openalex.org/W4238846128,https://doi.org/10.18653/v1/2021.acl-long,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),,[],2021-01-01
https://openalex.org/W2619383789,https://doi.org/10.1109/tpami.2018.2798607,Multimodal Machine Learning: A Survey and Taxonomy,"Our experience of the world is multimodal - we see objects, hear sounds, feel texture, smell odors, and taste flavors. Modality refers to the way in which something happens or is experienced and a research problem is characterized as multimodal when it includes multiple such modalities. In order for Artificial Intelligence to make progress in understanding the world around us, it needs to be able to interpret such multimodal signals together. Multimodal machine learning aims to build models that can process and relate information from multiple modalities. It is a vibrant multi-disciplinary field of increasing importance and with extraordinary potential. Instead of focusing on specific multimodal applications, this paper surveys the recent advances in multimodal machine learning itself and presents them in a common taxonomy. We go beyond the typical early and late fusion categorization and identify broader challenges that are faced by multimodal machine learning, namely: representation, translation, alignment, fusion, and co-learning. This new taxonomy will enable researchers to better understand the state of the field and identify directions for future research.","['https://openalex.org/W2096391593', 'https://openalex.org/W2101534792', 'https://openalex.org/W6683277684', 'https://openalex.org/W6687672932', 'https://openalex.org/W6726977916', 'https://openalex.org/W2106277773', 'https://openalex.org/W2113507809', 'https://openalex.org/W6713645886', 'https://openalex.org/W6687543112', 'https://openalex.org/W1773149199', 'https://openalex.org/W2251394420', 'https://openalex.org/W2062632672', 'https://openalex.org/W2012237712', 'https://openalex.org/W2388114291', 'https://openalex.org/W2112019442', 'https://openalex.org/W2112184938', 'https://openalex.org/W6680094886', 'https://openalex.org/W2118714046', 'https://openalex.org/W2327501763', 'https://openalex.org/W1555767263', 'https://openalex.org/W6678809451', 'https://openalex.org/W1893116441', 'https://openalex.org/W2167103782', 'https://openalex.org/W2137806537', 'https://openalex.org/W2042608483', 'https://openalex.org/W6607775107', 'https://openalex.org/W2914699769', 'https://openalex.org/W2143492886', 'https://openalex.org/W2470413457', 'https://openalex.org/W2148298736', 'https://openalex.org/W2130162821', 'https://openalex.org/W1970055505', 'https://openalex.org/W2147885303', 'https://openalex.org/W2111078031', 'https://openalex.org/W6652311901', 'https://openalex.org/W2282219577', 'https://openalex.org/W2048679005', 'https://openalex.org/W2090048052', 'https://openalex.org/W262578090', 'https://openalex.org/W6676380891', 'https://openalex.org/W2152239535', 'https://openalex.org/W6845679800', 'https://openalex.org/W2133459682', 'https://openalex.org/W2105103432', 'https://openalex.org/W2163108352', 'https://openalex.org/W6605295763', 'https://openalex.org/W2963192057', 'https://openalex.org/W6684209796', 'https://openalex.org/W1503933356', 'https://openalex.org/W2296613712', 'https://openalex.org/W4240592325', 'https://openalex.org/W6682691769', 'https://openalex.org/W6600334730', 'https://openalex.org/W6712426025', 'https://openalex.org/W22229905', 'https://openalex.org/W2342662179', 'https://openalex.org/W1897761818', 'https://openalex.org/W2098411764', 'https://openalex.org/W6696843773', 'https://openalex.org/W2026012689', 'https://openalex.org/W2128856065', 'https://openalex.org/W6681184217', 'https://openalex.org/W1985867508', 'https://openalex.org/W6639432524', 'https://openalex.org/W6898505805', 'https://openalex.org/W1573040851', 'https://openalex.org/W6682222085', 'https://openalex.org/W2964345931', 'https://openalex.org/W1996478295', 'https://openalex.org/W6676497082', 'https://openalex.org/W1971791733', 'https://openalex.org/W2080576537', 'https://openalex.org/W2963260436', 'https://openalex.org/W2964118342', 'https://openalex.org/W2129360799', 'https://openalex.org/W6712802073', 'https://openalex.org/W2546919788', 'https://openalex.org/W6631216910', 'https://openalex.org/W1822526425', 'https://openalex.org/W6686207219', 'https://openalex.org/W1933349210', 'https://openalex.org/W2164186291', 'https://openalex.org/W6639434097', 'https://openalex.org/W2129382193', 'https://openalex.org/W4211232216', 'https://openalex.org/W2068676460', 'https://openalex.org/W2120776756', 'https://openalex.org/W6623517193', 'https://openalex.org/W6727336983', 'https://openalex.org/W6639358663', 'https://openalex.org/W2109743529', 'https://openalex.org/W6631943919', 'https://openalex.org/W6636942303', 'https://openalex.org/W4245655784', 'https://openalex.org/W2142900973', 'https://openalex.org/W6625044600', 'https://openalex.org/W2143612262', 'https://openalex.org/W2098562545', 'https://openalex.org/W2100235303', 'https://openalex.org/W2041288440', 'https://openalex.org/W6606327593', 'https://openalex.org/W1964073652', 'https://openalex.org/W6678470764', 'https://openalex.org/W2963383024', 'https://openalex.org/W6629203210', 'https://openalex.org/W2125366733', 'https://openalex.org/W2316138215', 'https://openalex.org/W2124372976', 'https://openalex.org/W2062955551', 'https://openalex.org/W6678360021', 'https://openalex.org/W2149557440', 'https://openalex.org/W6637373629', 'https://openalex.org/W59175527', 'https://openalex.org/W6675048546', 'https://openalex.org/W2119288237', 'https://openalex.org/W2220981600', 'https://openalex.org/W6691647468', 'https://openalex.org/W2066667210', 'https://openalex.org/W2250742840', 'https://openalex.org/W6638667902', 'https://openalex.org/W6682864246', 'https://openalex.org/W2150658333', 'https://openalex.org/W3087871082', 'https://openalex.org/W2411037331', 'https://openalex.org/W4252331534', 'https://openalex.org/W2266728343', 'https://openalex.org/W2063330527', 'https://openalex.org/W2160815625', 'https://openalex.org/W2173180041', 'https://openalex.org/W2136922672', 'https://openalex.org/W2015412875', 'https://openalex.org/W2022799064', 'https://openalex.org/W2064675550', 'https://openalex.org/W68733909', 'https://openalex.org/W2025341678', 'https://openalex.org/W2963735856', 'https://openalex.org/W2164699598', 'https://openalex.org/W6637698695', 'https://openalex.org/W1480583224', 'https://openalex.org/W6637989529', 'https://openalex.org/W6732843983', 'https://openalex.org/W6674330103', 'https://openalex.org/W6676709516', 'https://openalex.org/W2143926884', 'https://openalex.org/W2126598020', 'https://openalex.org/W6679436768', 'https://openalex.org/W6730042849', 'https://openalex.org/W6606244218', 'https://openalex.org/W1906515132', 'https://openalex.org/W1986451414', 'https://openalex.org/W6650605322', 'https://openalex.org/W6691419566', 'https://openalex.org/W6634126550', 'https://openalex.org/W2434537049', 'https://openalex.org/W2399733683', 'https://openalex.org/W1976066595', 'https://openalex.org/W1956340063', 'https://openalex.org/W6685183736', 'https://openalex.org/W2964241990', 'https://openalex.org/W2963410018', 'https://openalex.org/W2102765684', 'https://openalex.org/W6639103823', 'https://openalex.org/W2963389687', 'https://openalex.org/W6639283537', 'https://openalex.org/W6685527872', 'https://openalex.org/W2038698865', 'https://openalex.org/W1895577753', 'https://openalex.org/W1966811077', 'https://openalex.org/W6637306801', 'https://openalex.org/W2153927146', 'https://openalex.org/W6638549007', 'https://openalex.org/W2150824314', 'https://openalex.org/W2061781940', 'https://openalex.org/W2019024625', 'https://openalex.org/W6717487601', 'https://openalex.org/W2462496837', 'https://openalex.org/W1664311846', 'https://openalex.org/W2151103935', 'https://openalex.org/W2149940198', 'https://openalex.org/W2051721233', 'https://openalex.org/W6600827882', 'https://openalex.org/W2026243162', 'https://openalex.org/W6623995992', 'https://openalex.org/W6630875275', 'https://openalex.org/W2069682406', 'https://openalex.org/W1540429825', 'https://openalex.org/W6692004142', 'https://openalex.org/W6697449767', 'https://openalex.org/W2142192571', 'https://openalex.org/W2963109634', 'https://openalex.org/W6683074461', 'https://openalex.org/W6638742206', 'https://openalex.org/W2131179926', 'https://openalex.org/W2141477623', 'https://openalex.org/W6636447180', 'https://openalex.org/W2015394094', 'https://openalex.org/W2135776491', 'https://openalex.org/W6640296258', 'https://openalex.org/W6639118148', 'https://openalex.org/W2963954913', 'https://openalex.org/W1987835821', 'https://openalex.org/W1586939924', 'https://openalex.org/W2250842428', 'https://openalex.org/W6680336390', 'https://openalex.org/W6628794645', 'https://openalex.org/W2185175083', 'https://openalex.org/W1977547683', 'https://openalex.org/W2963576560', 'https://openalex.org/W6631190155', 'https://openalex.org/W2009059481', 'https://openalex.org/W2251885125', 'https://openalex.org/W2252122141', 'https://openalex.org/W2145056192', 'https://openalex.org/W6637971603', 'https://openalex.org/W6676647902', 'https://openalex.org/W1905882502', 'https://openalex.org/W6640257717', 'https://openalex.org/W1601567445', 'https://openalex.org/W6631516269', 'https://openalex.org/W2489434015', 'https://openalex.org/W2151096985', 'https://openalex.org/W6730666313', 'https://openalex.org/W2156503193', 'https://openalex.org/W2025638820', 'https://openalex.org/W2129142580', 'https://openalex.org/W2963605190', 'https://openalex.org/W6688143368', 'https://openalex.org/W6682511423', 'https://openalex.org/W2063036810', 'https://openalex.org/W6640764460', 'https://openalex.org/W2053101950', 'https://openalex.org/W6729831399', 'https://openalex.org/W6679434410', 'https://openalex.org/W2058616948', 'https://openalex.org/W6683167905', 'https://openalex.org/W7011438494', 'https://openalex.org/W6608183366', 'https://openalex.org/W2291822808', 'https://openalex.org/W1969616664', 'https://openalex.org/W4212844288', 'https://openalex.org/W2163922914', 'https://openalex.org/W6682086108', 'https://openalex.org/W6684191040', 'https://openalex.org/W2048343491', 'https://openalex.org/W2057568625', 'https://openalex.org/W2083885588', 'https://openalex.org/W6682082992', 'https://openalex.org/W2130055251', 'https://openalex.org/W2077395415', 'https://openalex.org/W2252238675', 'https://openalex.org/W1566289585', 'https://openalex.org/W1996418862', 'https://openalex.org/W2251970440', 'https://openalex.org/W1883346539', 'https://openalex.org/W2101105183', 'https://openalex.org/W4285719527', 'https://openalex.org/W3125032682', 'https://openalex.org/W1933065844', 'https://openalex.org/W1572567476', 'https://openalex.org/W2111645492', 'https://openalex.org/W1762503104', 'https://openalex.org/W4320013936', 'https://openalex.org/W2953318193', 'https://openalex.org/W2949465329', 'https://openalex.org/W2267126114', 'https://openalex.org/W1858383477', 'https://openalex.org/W1753482797', 'https://openalex.org/W2963579811', 'https://openalex.org/W2397159106', 'https://openalex.org/W1481820510', 'https://openalex.org/W2136985729', 'https://openalex.org/W2109586012', 'https://openalex.org/W2112912048', 'https://openalex.org/W189596042', 'https://openalex.org/W1872883209', 'https://openalex.org/W1870428314', 'https://openalex.org/W877909479', 'https://openalex.org/W2402955625', 'https://openalex.org/W2203543769', 'https://openalex.org/W2184045248', 'https://openalex.org/W2963899908', 'https://openalex.org/W2164587673', 'https://openalex.org/W21006490', 'https://openalex.org/W2123024445', 'https://openalex.org/W1527575280', 'https://openalex.org/W1766290689', 'https://openalex.org/W2000911139', 'https://openalex.org/W1514535095', 'https://openalex.org/W2557865186', 'https://openalex.org/W1686810756', 'https://openalex.org/W2003333103', 'https://openalex.org/W956551720', 'https://openalex.org/W2251353663', 'https://openalex.org/W4244018879', 'https://openalex.org/W1922557984', 'https://openalex.org/W854541894', 'https://openalex.org/W2963656855', 'https://openalex.org/W2108710284', 'https://openalex.org/W2519656895', 'https://openalex.org/W2133564696', 'https://openalex.org/W1836465849', 'https://openalex.org/W4293665662', 'https://openalex.org/W2181691731', 'https://openalex.org/W1651753422', 'https://openalex.org/W1123427201', 'https://openalex.org/W2293453011', 'https://openalex.org/W1488163396', 'https://openalex.org/W4302613066', 'https://openalex.org/W1522301498', 'https://openalex.org/W1889081078', 'https://openalex.org/W199018803', 'https://openalex.org/W2150696241', 'https://openalex.org/W1828348983', 'https://openalex.org/W4299801216', 'https://openalex.org/W155596317', 'https://openalex.org/W1687846465', 'https://openalex.org/W3000384245', 'https://openalex.org/W2143449221', 'https://openalex.org/W2147880316', 'https://openalex.org/W1811254738', 'https://openalex.org/W3023993913', 'https://openalex.org/W2006969979', 'https://openalex.org/W1931795219', 'https://openalex.org/W1889038981', 'https://openalex.org/W2962835968', 'https://openalex.org/W1628307106', 'https://openalex.org/W2963811219', 'https://openalex.org/W2405756170', 'https://openalex.org/W2964217371', 'https://openalex.org/W1523385540', 'https://openalex.org/W129606432', 'https://openalex.org/W1528056001', 'https://openalex.org/W2963082528', 'https://openalex.org/W2963324994', 'https://openalex.org/W2125336414', 'https://openalex.org/W2964040984', 'https://openalex.org/W2153579005', 'https://openalex.org/W2964308564', 'https://openalex.org/W2095705004', 'https://openalex.org/W2963143316', 'https://openalex.org/W2100561338', 'https://openalex.org/W2418349398', 'https://openalex.org/W2099471712', 'https://openalex.org/W2399507222', 'https://openalex.org/W4297813007', 'https://openalex.org/W2519091744', 'https://openalex.org/W2579317665', 'https://openalex.org/W2201007611', 'https://openalex.org/W2520160253', 'https://openalex.org/W2164450870', 'https://openalex.org/W2962706528', 'https://openalex.org/W2184188583', 'https://openalex.org/W4294170691', 'https://openalex.org/W2124033848', 'https://openalex.org/W2494980014', 'https://openalex.org/W2130942839', 'https://openalex.org/W2156303437', 'https://openalex.org/W8316075', 'https://openalex.org/W2294797155', 'https://openalex.org/W1963540633', 'https://openalex.org/W1533861849', 'https://openalex.org/W2159973364', 'https://openalex.org/W2137735870', 'https://openalex.org/W2180844455', 'https://openalex.org/W2149172860', 'https://openalex.org/W2964121744', 'https://openalex.org/W2962756039', 'https://openalex.org/W2163605009', 'https://openalex.org/W2150295085']",2018-01-25
https://openalex.org/W2067097374,https://doi.org/10.3115/1620754.1620846,A finite-state turn-taking model for spoken dialog systems,"This paper introduces the Finite-State Turn-Taking Machine (FSTTM), a new model to control the turn-taking behavior of conversational agents. Based on a non-deterministic finite-state machine, the FSTTM uses a cost matrix and decision theoretic principles to select a turn-taking action at any time. We show how the model can be applied to the problem of end-of-turn detection. Evaluation results on a deployed spoken dialog system show that the FSTTM provides significantly higher responsiveness than previous approaches.","['https://openalex.org/W1998677696', 'https://openalex.org/W1903951673', 'https://openalex.org/W2161345458', 'https://openalex.org/W2099529102', 'https://openalex.org/W1583748115', 'https://openalex.org/W1934807246', 'https://openalex.org/W2156597615', 'https://openalex.org/W80222165', 'https://openalex.org/W1964725106', 'https://openalex.org/W2159117246', 'https://openalex.org/W1518023928', 'https://openalex.org/W116569011', 'https://openalex.org/W2153190547', 'https://openalex.org/W792814583', 'https://openalex.org/W1518863056', 'https://openalex.org/W258661234', 'https://openalex.org/W4248634141', 'https://openalex.org/W2100844198', 'https://openalex.org/W2157986953']",2009-01-01
https://openalex.org/W4287780442,https://doi.org/10.48550/arxiv.2005.03545,MISA: Modality-Invariant and -Specific Representations for Multimodal\n Sentiment Analysis,"Multimodal Sentiment Analysis is an active area of research that leverages\nmultimodal signals for affective understanding of user-generated videos. The\npredominant approach, addressing this task, has been to develop sophisticated\nfusion techniques. However, the heterogeneous nature of the signals creates\ndistributional modality gaps that pose significant challenges. In this paper,\nwe aim to learn effective modality representations to aid the process of\nfusion. We propose a novel framework, MISA, which projects each modality to two\ndistinct subspaces. The first subspace is modality-invariant, where the\nrepresentations across modalities learn their commonalities and reduce the\nmodality gap. The second subspace is modality-specific, which is private to\neach modality and captures their characteristic features. These representations\nprovide a holistic view of the multimodal data, which is used for fusion that\nleads to task predictions. Our experiments on popular sentiment analysis\nbenchmarks, MOSI and MOSEI, demonstrate significant gains over state-of-the-art\nmodels. We also consider the task of Multimodal Humor Detection and experiment\non the recently proposed UR_FUNNY dataset. Here too, our model fares better\nthan strong baselines, establishing MISA as a useful multimodal framework.\n",[],2020-05-07
https://openalex.org/W3167098825,https://doi.org/10.18653/v1/2021.naacl-main.79,MTAG: Modal-Temporal Attention Graph for Unaligned Human Multimodal Language Sequences,"Jianing Yang, Yongxin Wang, Ruitao Yi, Yuying Zhu, Azaan Rehman, Amir Zadeh, Soujanya Poria, Louis-Philippe Morency. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021.","['https://openalex.org/W2740550900', 'https://openalex.org/W1501856433', 'https://openalex.org/W2964216663', 'https://openalex.org/W2886193235', 'https://openalex.org/W2982108874', 'https://openalex.org/W2970990666', 'https://openalex.org/W3084283759', 'https://openalex.org/W2962931510', 'https://openalex.org/W2911286998', 'https://openalex.org/W4294558607', 'https://openalex.org/W2116341502', 'https://openalex.org/W2964051877', 'https://openalex.org/W2939208918', 'https://openalex.org/W3093400813', 'https://openalex.org/W2963858333', 'https://openalex.org/W2127141656', 'https://openalex.org/W2989619960', 'https://openalex.org/W4210993929', 'https://openalex.org/W2964015378', 'https://openalex.org/W2964266095', 'https://openalex.org/W2556418146', 'https://openalex.org/W2963685106', 'https://openalex.org/W2250539671', 'https://openalex.org/W2963919031', 'https://openalex.org/W3034871396', 'https://openalex.org/W3034649151', 'https://openalex.org/W3096690837', 'https://openalex.org/W4288358813', 'https://openalex.org/W3034472388', 'https://openalex.org/W2808359495', 'https://openalex.org/W2955233641', 'https://openalex.org/W2184188583', 'https://openalex.org/W2095176743', 'https://openalex.org/W2963871344', 'https://openalex.org/W2604314403', 'https://openalex.org/W2146334809', 'https://openalex.org/W2962767366', 'https://openalex.org/W4297733535']",2021-01-01
https://openalex.org/W2219249508,https://doi.org/10.48550/arxiv.1510.08484,"MUSAN: A Music, Speech, and Noise Corpus","This report introduces a new corpus of music, speech, and noise. This dataset is suitable for training models for voice activity detection (VAD) and music/speech discrimination. Our corpus is released under a flexible Creative Commons license. The dataset consists of music from several genres, speech from twelve languages, and a wide assortment of technical and non-technical noises. We demonstrate use of this corpus for music/speech discrimination on Broadcast news and VAD for speaker identification.","['https://openalex.org/W1556219185', 'https://openalex.org/W2290689761', 'https://openalex.org/W1980993072', 'https://openalex.org/W1524333225', 'https://openalex.org/W2942177450']",2015-10-28
https://openalex.org/W4226174273,https://doi.org/10.18653/v1/2022.acl-long.44,Improving Meta-learning for Low-resource Text Classification and Generation via Memory Imitation,"Building models of natural language processing (NLP) is challenging in low-resource scenarios where only limited data are available. Optimization-based meta-learning algorithms achieve promising results in low-resource scenarios by adapting a well-generalized model initialization to handle new tasks. Nonetheless, these approaches suffer from the memorization overfitting issue, where the model tends to memorize the meta-training tasks while ignoring support sets when adapting to new tasks. To address this issue, we propose a memory imitation meta-learning (MemIML) method that enhances the model’s reliance on support sets for task adaptation. Specifically, we introduce a task-specific memory module to store support set information and construct an imitation module to force query sets to imitate the behaviors of some representative supportset samples stored in the memory. A theoretical analysis is provided to prove the effectiveness of our method, and empirical results also demonstrate that our method outperforms competitive baselines on both text classification and generation tasks.","['https://openalex.org/W2964105864', 'https://openalex.org/W2787035179', 'https://openalex.org/W3195298899', 'https://openalex.org/W2601450892', 'https://openalex.org/W4385245566', 'https://openalex.org/W2964588180', 'https://openalex.org/W2472819217', 'https://openalex.org/W3163781021', 'https://openalex.org/W2866343820', 'https://openalex.org/W2997197207', 'https://openalex.org/W2971048662', 'https://openalex.org/W3166523474', 'https://openalex.org/W2951980657', 'https://openalex.org/W1522301498', 'https://openalex.org/W2945978556', 'https://openalex.org/W2992306696', 'https://openalex.org/W3035094063', 'https://openalex.org/W2963267363', 'https://openalex.org/W2953044442', 'https://openalex.org/W1956340063', 'https://openalex.org/W1542791059', 'https://openalex.org/W2896457183', 'https://openalex.org/W4327656064', 'https://openalex.org/W2963680240', 'https://openalex.org/W2604763608', 'https://openalex.org/W4297663362', 'https://openalex.org/W2154652894', 'https://openalex.org/W2970971561', 'https://openalex.org/W3025611493', 'https://openalex.org/W3040863728', 'https://openalex.org/W3163842339', 'https://openalex.org/W2963341924', 'https://openalex.org/W3156104344', 'https://openalex.org/W2963106996', 'https://openalex.org/W2064675550', 'https://openalex.org/W3100609281', 'https://openalex.org/W3015078597', 'https://openalex.org/W2888541716', 'https://openalex.org/W2980708516', 'https://openalex.org/W2250539671', 'https://openalex.org/W2963206148', 'https://openalex.org/W3034942609', 'https://openalex.org/W2964316912', 'https://openalex.org/W2092961325']",2022-01-01
https://openalex.org/W4220770602,https://doi.org/10.31234/osf.io/5tmgy,Statistical learning models of early phonetic acquisition struggle with child-centered audio data,"Infants learn their native language(s) at an amazing speed. Before they even talk, their perception adapts to the language(s) they hear. However, the mechanisms responsible for this perceptual attunement still remain unclear. A long tradition in linguistics points to the importance of specialized language mechanisms that would allow us to quickly and effortlessly learn from the language(s) we are exposed to. However, the currently dominant explanation for perceptual attunement posits that infants apply a domain-general learning mechanism consisting in learning statistical regularities from the speech stream they hear, and which may be found in learning across domains and across species. Critically, the feasibility of employing purely domain-general statistical learning mechanisms has only been demonstrated with computational models on unrealistic and simplified input. This paper presents the first attempt to study perceptual attunement with 2,000 hours of ecological child-centered recordings in American English and Metropolitan French. We show that, when applied on ecologically-valid data, generic learning mechanisms develop a language-relevant perceptual space but fail to show evidence for perceptual attunement. It is only when supplemented with domain-specific audio filtering and augmentation mechanisms that computational models show a significant attunement to the language they have been exposed to. Hence, we conclude that, when learning from ecological audio, domain-specific mechanisms may be necessary to guide early language learning in the wild even if the learning itself is done through generic mechanisms. We anticipate our work to be a starting point for ecologically-valid computational models of perceptual attunement in other domains and species.",[],2022-03-08
https://openalex.org/W4225079082,https://doi.org/10.1177/01427237211066405,How diverse is child language acquisition research?,"A comprehensive theory of child language acquisition requires an evidential base that is representative of the typological diversity present in the world’s 7000 or so languages. However, languages are dying at an alarming rate, and the next 50 years represents the last chance we have to document acquisition in many of them. Here, we take stock of the last 45 years of research published in the four main child language acquisition journals: Journal of Child Language, First Language, Language Acquisition and Language Learning and Development. We coded each article for several variables, including (1) participant group (mono vs multilingual), (2) language(s), (3) topic(s) and (4) country of author affiliation, from each journal’s inception until the end of 2020. We found that we have at least one article published on around 103 languages, representing approximately 1.5% of the world’s languages. The distribution of articles was highly skewed towards English and other well-studied Indo-European languages, with the majority of non-Indo-European languages having just one paper. A majority of the papers focused on studies of monolingual children, although papers did not always explicitly report participant group status. The distribution of topics across language categories was more even. The number of articles published on non-Indo-European languages from countries outside of North America and Europe is increasing; however, this increase is driven by research conducted in relatively wealthy countries. Overall, the vast majority of the research was produced in the Global North. We conclude that, despite a proud history of crosslinguistic research, the goals of the discipline need to be recalibrated before we can lay claim to truly a representative account of child language acquisition.","['https://openalex.org/W2115193559', 'https://openalex.org/W1951724000', 'https://openalex.org/W2180289676', 'https://openalex.org/W266785474', 'https://openalex.org/W2098649695', 'https://openalex.org/W2088785393', 'https://openalex.org/W1492445845', 'https://openalex.org/W2997253105', 'https://openalex.org/W2944539396', 'https://openalex.org/W2626688023', 'https://openalex.org/W3134837539', 'https://openalex.org/W2419499857', 'https://openalex.org/W825113776', 'https://openalex.org/W2114019212', 'https://openalex.org/W2325267572', 'https://openalex.org/W2917038132', 'https://openalex.org/W2000196122', 'https://openalex.org/W3206596900', 'https://openalex.org/W3185943521', 'https://openalex.org/W3090053190', 'https://openalex.org/W3214101907', 'https://openalex.org/W3213054052', 'https://openalex.org/W1531752105', 'https://openalex.org/W2166462447', 'https://openalex.org/W2943599806', 'https://openalex.org/W2128629493', 'https://openalex.org/W2151136874', 'https://openalex.org/W1562809004', 'https://openalex.org/W2085876742', 'https://openalex.org/W6980538191', 'https://openalex.org/W4285488353', 'https://openalex.org/W2014840417', 'https://openalex.org/W2152974526', 'https://openalex.org/W2138464179', 'https://openalex.org/W1995710972', 'https://openalex.org/W2326473355', 'https://openalex.org/W1591962818', 'https://openalex.org/W2980810716', 'https://openalex.org/W3145901247', 'https://openalex.org/W1690765785', 'https://openalex.org/W2575495090', 'https://openalex.org/W2096944735', 'https://openalex.org/W2063598038', 'https://openalex.org/W2385415323', 'https://openalex.org/W2133486974', 'https://openalex.org/W2129355607', 'https://openalex.org/W2618478924', 'https://openalex.org/W2146804814', 'https://openalex.org/W2950195977', 'https://openalex.org/W2166858542', 'https://openalex.org/W2023648418', 'https://openalex.org/W2064567363', 'https://openalex.org/W3033031683', 'https://openalex.org/W2582743722', 'https://openalex.org/W4214541243', 'https://openalex.org/W3047390821', 'https://openalex.org/W2905961459', 'https://openalex.org/W2306053304', 'https://openalex.org/W2032543155', 'https://openalex.org/W2096494428', 'https://openalex.org/W2011135529', 'https://openalex.org/W2237428880', 'https://openalex.org/W4376475523', 'https://openalex.org/W4246293254', 'https://openalex.org/W2964911375', 'https://openalex.org/W2984637106', 'https://openalex.org/W1487861877', 'https://openalex.org/W3044664353', 'https://openalex.org/W367997690', 'https://openalex.org/W614158856', 'https://openalex.org/W1580585489', 'https://openalex.org/W1506887983', 'https://openalex.org/W4206256985', 'https://openalex.org/W1553508775', 'https://openalex.org/W2063718015', 'https://openalex.org/W2551535154', 'https://openalex.org/W4256449073', 'https://openalex.org/W1994381201', 'https://openalex.org/W1507098069', 'https://openalex.org/W2771442381', 'https://openalex.org/W2398326651', 'https://openalex.org/W2005867571', 'https://openalex.org/W2333916262', 'https://openalex.org/W2328091329']",2022-01-28
https://openalex.org/W2895356663,https://doi.org/10.1111/desc.12724,What Do North American Babies Hear? A large‐scale cross‐corpus analysis,"Abstract A range of demographic variables influences how much speech young children hear. However, because studies have used vastly different sampling methods, quantitative comparison of interlocking demographic effects has been nearly impossible, across or within studies. We harnessed a unique collection of existing naturalistic, day‐long recordings from 61 homes across four North American cities to examine language input as a function of age, gender, and maternal education. We analyzed adult speech heard by 3‐ to 20‐month‐olds who wore audio recorders for an entire day. We annotated speaker gender and speech register (child‐directed or adult‐directed) for 10,861 utterances from female and male adults in these recordings. Examining age, gender, and maternal education collectively in this ecologically valid dataset, we find several key results. First, the speaker gender imbalance in the input is striking: children heard 2–3× more speech from females than males. Second, children in higher‐maternal education homes heard more child‐directed speech than those in lower‐maternal education homes. Finally, our analyses revealed a previously unreported effect: the proportion of child‐directed speech in the input increases with age, due to a decrease in adult‐directed speech with age. This large‐scale analysis is an important step forward in collectively examining demographic variables that influence early development, made possible by pooled, comparable, day‐long recordings of children's language environments. The audio recordings, annotations, and annotation software are readily available for reuse and reanalysis by other researchers.","['https://openalex.org/W2103289704', 'https://openalex.org/W2169759015', 'https://openalex.org/W2141845152', 'https://openalex.org/W6945130725', 'https://openalex.org/W2885156775', 'https://openalex.org/W2768701474', 'https://openalex.org/W2063303346', 'https://openalex.org/W2700463282', 'https://openalex.org/W2088377333', 'https://openalex.org/W1988670119', 'https://openalex.org/W1981826156', 'https://openalex.org/W1945005118', 'https://openalex.org/W2765364385', 'https://openalex.org/W2131168675', 'https://openalex.org/W4240067879', 'https://openalex.org/W2074916712', 'https://openalex.org/W2787076719', 'https://openalex.org/W2736646379', 'https://openalex.org/W2191828469', 'https://openalex.org/W2108946139', 'https://openalex.org/W1894419856', 'https://openalex.org/W2106640230', 'https://openalex.org/W2921069930', 'https://openalex.org/W2113941258', 'https://openalex.org/W2021548302', 'https://openalex.org/W2045495963', 'https://openalex.org/W2048843925', 'https://openalex.org/W2133414707', 'https://openalex.org/W1983855165', 'https://openalex.org/W1974714315', 'https://openalex.org/W1966536015', 'https://openalex.org/W2784408816', 'https://openalex.org/W2911442201', 'https://openalex.org/W2086115904', 'https://openalex.org/W2782905495', 'https://openalex.org/W2113153226', 'https://openalex.org/W6907393280', 'https://openalex.org/W2132566726', 'https://openalex.org/W2011578660', 'https://openalex.org/W1975419617', 'https://openalex.org/W2061594239', 'https://openalex.org/W2030365182', 'https://openalex.org/W1974425872', 'https://openalex.org/W1977979148', 'https://openalex.org/W2662400371', 'https://openalex.org/W2156639694', 'https://openalex.org/W2125766564', 'https://openalex.org/W1980760525', 'https://openalex.org/W2064135025', 'https://openalex.org/W2028919945', 'https://openalex.org/W4247708919', 'https://openalex.org/W2131273696', 'https://openalex.org/W2097515925', 'https://openalex.org/W2001339108', 'https://openalex.org/W2154600605', 'https://openalex.org/W2078678039', 'https://openalex.org/W2145503173', 'https://openalex.org/W2167290899', 'https://openalex.org/W2576562787', 'https://openalex.org/W2115099665', 'https://openalex.org/W4232614171', 'https://openalex.org/W2513468056', 'https://openalex.org/W2343593471', 'https://openalex.org/W1511187197', 'https://openalex.org/W6964162247', 'https://openalex.org/W2162994165', 'https://openalex.org/W2566861030', 'https://openalex.org/W2102040782', 'https://openalex.org/W2079602445', 'https://openalex.org/W2052955028', 'https://openalex.org/W3165064679', 'https://openalex.org/W4251965084', 'https://openalex.org/W4241482853', 'https://openalex.org/W2068866377', 'https://openalex.org/W1993425853', 'https://openalex.org/W2259559558', 'https://openalex.org/W4298742451', 'https://openalex.org/W1485588222', 'https://openalex.org/W2064182530']",2018-10-12
https://openalex.org/W3135131435,,Predicting Age of Acquisition in Early Word Learning Using Recurrent Neural Networks.,"Vocabulary growth and syntactic development are known tobe highly correlated in early child language. What determineswhen words are acquired and how can this help us understandwhat drives early language development? We train an LSTMlanguage model, known to detect syntactic regularities that arerelevant for predicting the difficulty of words, on child-directedspeech. We use the average surprisal of words for the model,which encodes sequential predictability, as a predictor for theage of acquisition of words in early child language. We com-pare this predictor to word frequency and others and find thataverage surprisal is a good predictor for the age of acquisitionof function words and predicates beyond frequency, but notfor nouns. Our approach provides insight into what makes agood model of early word learning, especially for words whosemeanings rely heavily on linguistic context.","['https://openalex.org/W2151834591', 'https://openalex.org/W2910821810', 'https://openalex.org/W2110485445', 'https://openalex.org/W2131424651', 'https://openalex.org/W2888209919', 'https://openalex.org/W2064675550', 'https://openalex.org/W2095689128', 'https://openalex.org/W2164418233', 'https://openalex.org/W2549835527', 'https://openalex.org/W2402268235', 'https://openalex.org/W2512700785', 'https://openalex.org/W1971747668', 'https://openalex.org/W2105495317', 'https://openalex.org/W2061626640', 'https://openalex.org/W2102554574', 'https://openalex.org/W1552207970', 'https://openalex.org/W2963403868', 'https://openalex.org/W1974991592', 'https://openalex.org/W2082137931', 'https://openalex.org/W2138356889', 'https://openalex.org/W2052262800', 'https://openalex.org/W1979532929', 'https://openalex.org/W2120292361', 'https://openalex.org/W2971016963', 'https://openalex.org/W2123090910', 'https://openalex.org/W2087372020', 'https://openalex.org/W2139450036', 'https://openalex.org/W36920265', 'https://openalex.org/W3137537418', 'https://openalex.org/W2943456001', 'https://openalex.org/W2137105200', 'https://openalex.org/W2131536386', 'https://openalex.org/W2078834097']",2020-01-01
https://openalex.org/W4320013820,https://doi.org/10.5260/chara.24.3.41,Linguistic Data Consortium,"The Linguistic Data Consortium (LDC) creates, stores, and distributes language resources, in particular language corpora, for educational, governmental, and commercial purposes. At this time, the number of corpora available on the LDC platform exceeds 900, and new ones are added on a monthly basis. Since its founding in 1992, LDC has had thousands of members such as universities, libraries, government research laboratories, and corporations. While there is a plethora of language resources available to researchers these days, LDC continues to stand out by offering an unparalleled selection of carefully curated corpora combined with a variety of linguistic tools.",[],2023-01-01
https://openalex.org/W4253576984,https://doi.org/10.1111/b.9781405132534.2006.00010.x,Blackwell Handbook of Language Development,,[],2006-01-01
https://openalex.org/W1995991622,https://doi.org/10.1017/s0305000900006449,The child language data exchange system,"ABSTRACT The study of language acquisition underwent a major revolution in the late 1950s as a result of the dissemination of technology permitting high-quality tape-recording of children in the family setting. This new technology led to major breakthroughs in the quality of both data and theory. The field is now at the threshold of a possible second major breakthrough stimulated by the dissemination of personal computing. Researchers are now able to transcribe tape-recorded data into computer files. With this new medium it is easy to conduct global searches for word combinations across collections of files. It is also possible to enter new codings of the basic text line. Because of the speed and accuracy with which computer files can be copied, it is now much easier to share data between researchers. To foster this sharing of computerized data, a group of child language researchers has established the Child Language Data Exchange System (CHILDES). This article details the formation of the CHILDES, the governance of the system, the nature of the database, the shape of the coding conventions, and the types of computer programs being developed.","['https://openalex.org/W6683645029', 'https://openalex.org/W4239427658', 'https://openalex.org/W6662829803', 'https://openalex.org/W2093099215', 'https://openalex.org/W6654629360', 'https://openalex.org/W6607497268', 'https://openalex.org/W4387937121', 'https://openalex.org/W4249308669', 'https://openalex.org/W3036876884', 'https://openalex.org/W2017633082', 'https://openalex.org/W1483126227', 'https://openalex.org/W2049108250', 'https://openalex.org/W1979654885', 'https://openalex.org/W1980757728', 'https://openalex.org/W2086426947', 'https://openalex.org/W2564295779', 'https://openalex.org/W1983248018', 'https://openalex.org/W1999665130', 'https://openalex.org/W2160657639', 'https://openalex.org/W2061741899', 'https://openalex.org/W2017580301', 'https://openalex.org/W184808789', 'https://openalex.org/W2056156314', 'https://openalex.org/W1995991622', 'https://openalex.org/W4231712578']",1985-06-01
https://openalex.org/W4309419356,https://doi.org/10.1201/9781003205388-2,What Artificial Neural Networks Can Tell Us about Human Language Acquisition,"Rapid progress in machine learning for natural language processing has the potential to transform debates about how humans learn language.However, the learning environments and biases of current artificial learners and humans diverge in ways that weaken the impact of the evidence obtained from learning simulations.For example, today's most effective neural language models are trained on roughly one thousand times the amount of linguistic data available to a typical child.To increase the relevance of learnability results from computational models, we need to train model learners without significant advantages over humans.If an appropriate model successfully acquires some target linguistic knowledge, it can provide a proof of concept that the target is learnable in a hypothesized human learning scenario.Plausible model learners will enable us to carry out experimental manipulations to make causal inferences about variables in the learning environment, and to rigorously test poverty-of-the-stimulus-style claims arguing for innate linguistic knowledge in humans on the basis of speculations about learnability.Comparable experiments will never be possible with human subjects due to practical and ethical considerations, making model learners an indispensable resource.So far, attempts to deprive current models of unfair advantages obtain sub-human results for key grammatical behaviors such as acceptability judgments.But before we can justifiably conclude that language learning requires more prior domainspecific knowledge than current models possess, we must first explore non-linguistic inputs in the form of multimodal stimuli and multi-agent interaction as ways to make our learners more efficient at learning from limited linguistic input.","['https://openalex.org/W2435103813', 'https://openalex.org/W2515741950', 'https://openalex.org/W2906152891', 'https://openalex.org/W2888912391', 'https://openalex.org/W3030163527', 'https://openalex.org/W2947748865', 'https://openalex.org/W3207937903', 'https://openalex.org/W1889081078', 'https://openalex.org/W3020257313', 'https://openalex.org/W2041459597', 'https://openalex.org/W1911662473', 'https://openalex.org/W2864832950', 'https://openalex.org/W2580123087', 'https://openalex.org/W72959365', 'https://openalex.org/W2087327436', 'https://openalex.org/W2765364385', 'https://openalex.org/W2896457183', 'https://openalex.org/W2797498228', 'https://openalex.org/W2483390977', 'https://openalex.org/W3127227595', 'https://openalex.org/W3111367603', 'https://openalex.org/W2516090925', 'https://openalex.org/W3176751053', 'https://openalex.org/W2118373646', 'https://openalex.org/W3083146265', 'https://openalex.org/W3037115370', 'https://openalex.org/W2605959375', 'https://openalex.org/W2795355797', 'https://openalex.org/W2132730112', 'https://openalex.org/W2232699035', 'https://openalex.org/W1998674455', 'https://openalex.org/W3033187248', 'https://openalex.org/W2970862333', 'https://openalex.org/W2798812533', 'https://openalex.org/W3022853932', 'https://openalex.org/W2970780738', 'https://openalex.org/W3211156350', 'https://openalex.org/W3199674690', 'https://openalex.org/W3159619744', 'https://openalex.org/W3104739822', 'https://openalex.org/W2277195237', 'https://openalex.org/W2789352267', 'https://openalex.org/W2908662516', 'https://openalex.org/W1983578042', 'https://openalex.org/W2531882892', 'https://openalex.org/W2963871344', 'https://openalex.org/W2564324149', 'https://openalex.org/W2787615430', 'https://openalex.org/W3034611340', 'https://openalex.org/W2113069506', 'https://openalex.org/W2164418233', 'https://openalex.org/W2948539192', 'https://openalex.org/W2549835527', 'https://openalex.org/W2419539795', 'https://openalex.org/W2966715458', 'https://openalex.org/W4200526505', 'https://openalex.org/W3031914912', 'https://openalex.org/W2888922637', 'https://openalex.org/W2788924045', 'https://openalex.org/W3105478389', 'https://openalex.org/W3156194904', 'https://openalex.org/W2154346509', 'https://openalex.org/W2962739339', 'https://openalex.org/W2970476646', 'https://openalex.org/W3035305735', 'https://openalex.org/W3112408862', 'https://openalex.org/W2922091957', 'https://openalex.org/W2163730805', 'https://openalex.org/W2995186722', 'https://openalex.org/W2981641565', 'https://openalex.org/W3091406101', 'https://openalex.org/W3006881356', 'https://openalex.org/W2996908057', 'https://openalex.org/W3034775979', 'https://openalex.org/W2024988999', 'https://openalex.org/W1983149072', 'https://openalex.org/W2072364373', 'https://openalex.org/W2969876226', 'https://openalex.org/W2931316642', 'https://openalex.org/W2908854766', 'https://openalex.org/W4238893454', 'https://openalex.org/W4293354654', 'https://openalex.org/W3104142662', 'https://openalex.org/W3013891696', 'https://openalex.org/W3088059392', 'https://openalex.org/W2996728628', 'https://openalex.org/W3093002075', 'https://openalex.org/W3006861283', 'https://openalex.org/W4207085713', 'https://openalex.org/W2963159690', 'https://openalex.org/W3034510440', 'https://openalex.org/W4252434862', 'https://openalex.org/W2996132992', 'https://openalex.org/W2963026768', 'https://openalex.org/W2949674892', 'https://openalex.org/W3166396011', 'https://openalex.org/W4212995409', 'https://openalex.org/W2152496361', 'https://openalex.org/W4301259831', 'https://openalex.org/W3200434522', 'https://openalex.org/W2014009760', 'https://openalex.org/W2730712696', 'https://openalex.org/W3035241006', 'https://openalex.org/W4254816979', 'https://openalex.org/W2962961857', 'https://openalex.org/W2396361046', 'https://openalex.org/W2965373594', 'https://openalex.org/W2970231061', 'https://openalex.org/W4226146865', 'https://openalex.org/W2333916262', 'https://openalex.org/W4295846245', 'https://openalex.org/W4238907713', 'https://openalex.org/W2981851019', 'https://openalex.org/W2006132921', 'https://openalex.org/W1969005071', 'https://openalex.org/W3202908475', 'https://openalex.org/W4287765185', 'https://openalex.org/W3122890974', 'https://openalex.org/W4287118015', 'https://openalex.org/W4288633968', 'https://openalex.org/W2147682057', 'https://openalex.org/W2963751529', 'https://openalex.org/W2994665957', 'https://openalex.org/W2102320628', 'https://openalex.org/W3159900299', 'https://openalex.org/W2964289358', 'https://openalex.org/W2023723978', 'https://openalex.org/W4288351520', 'https://openalex.org/W2484448352', 'https://openalex.org/W3103536442', 'https://openalex.org/W2120159535', 'https://openalex.org/W3176357828', 'https://openalex.org/W2971016963', 'https://openalex.org/W4224308101', 'https://openalex.org/W4312910992', 'https://openalex.org/W36434594', 'https://openalex.org/W2134237567', 'https://openalex.org/W3202712981', 'https://openalex.org/W2159772141', 'https://openalex.org/W4229673855', 'https://openalex.org/W4298090669', 'https://openalex.org/W1573042291', 'https://openalex.org/W4394671563', 'https://openalex.org/W4292779060', 'https://openalex.org/W3046535886', 'https://openalex.org/W3199373335', 'https://openalex.org/W3104235057', 'https://openalex.org/W2279843799', 'https://openalex.org/W4385245566', 'https://openalex.org/W3042795397', 'https://openalex.org/W2143971272', 'https://openalex.org/W2745407705', 'https://openalex.org/W1924770834', 'https://openalex.org/W3176198948', 'https://openalex.org/W2952729433', 'https://openalex.org/W3037752994', 'https://openalex.org/W4287591426', 'https://openalex.org/W2973957133', 'https://openalex.org/W2563574619', 'https://openalex.org/W4243527522', 'https://openalex.org/W3198757395', 'https://openalex.org/W1551770093', 'https://openalex.org/W1487691575', 'https://openalex.org/W3090449556', 'https://openalex.org/W2140324965', 'https://openalex.org/W4252588748', 'https://openalex.org/W4287865629', 'https://openalex.org/W3118485687', 'https://openalex.org/W4236383353', 'https://openalex.org/W3098613713', 'https://openalex.org/W2964151654', 'https://openalex.org/W2054125330', 'https://openalex.org/W3099434687', 'https://openalex.org/W4295371519', 'https://openalex.org/W2978670439']",2022-11-19
https://openalex.org/W4394150413,https://doi.org/10.6084/m9.figshare.7492052,Carnegie Mellon Pronouncing Dictionary,"This was originally a pronouncing dictionary, and can be found on the net with phonetic information included in the file. That file also includes an informative text header explaining the list's origin and purpose. This list was originally upper case; I have converted it to lower case. It contained many duplicates, showing multiple pronunciations: these have been removed. It does not contain compound forms. 111,308 entries<br>url_information: ""http://www.puzzlers.org/wordlists/cmudict_info.txt",[],2018-01-01
https://openalex.org/W3213014097,https://doi.org/10.18653/v1/2021.conll-1.49,BabyBERTa: Learning More Grammar With Small-Scale Child-Directed Language,"Transformer-based language models have taken the NLP world by storm. However, their potential for addressing important questions in language acquisition research has been largely ignored. In this work, we examined the grammatical knowledge of RoBERTa (Liu et al., 2019) when trained on a 5M word corpus of language acquisition data to simulate the input available to children between the ages 1 and 6. Using the behavioral probing paradigm, we found that a smaller version of RoBERTa-base that never predicts unmasked tokens, which we term BabyBERTa, acquires grammatical knowledge comparable to that of pre-trained RoBERTa-base - and does so with approximately 15X fewer parameters and 6,000X fewer words. We discuss implications for building more efficient models and the learnability of grammar from input available to children. Lastly, to support research on this front, we release our novel grammar test suite that is compatible with the small vocabulary of child-directed input.","['https://openalex.org/W3134522972', 'https://openalex.org/W2166735162', 'https://openalex.org/W2962911926', 'https://openalex.org/W1992119553', 'https://openalex.org/W1599016936', 'https://openalex.org/W2980282514', 'https://openalex.org/W2048631778', 'https://openalex.org/W4298742451', 'https://openalex.org/W2996728628', 'https://openalex.org/W2882319491', 'https://openalex.org/W4211121027', 'https://openalex.org/W1980096805', 'https://openalex.org/W2100175650', 'https://openalex.org/W3014415613', 'https://openalex.org/W4205537036', 'https://openalex.org/W2965373594', 'https://openalex.org/W4255026538', 'https://openalex.org/W2127438782', 'https://openalex.org/W2943552823', 'https://openalex.org/W2738473203', 'https://openalex.org/W2787076719', 'https://openalex.org/W2962801832', 'https://openalex.org/W3035267217', 'https://openalex.org/W3034510440', 'https://openalex.org/W2963751529', 'https://openalex.org/W3211156350', 'https://openalex.org/W2549835527', 'https://openalex.org/W2143992713', 'https://openalex.org/W3168987555', 'https://openalex.org/W2963341956', 'https://openalex.org/W2167543949', 'https://openalex.org/W4385245566', 'https://openalex.org/W3041594829', 'https://openalex.org/W2011364639', 'https://openalex.org/W4236083629', 'https://openalex.org/W3004346089', 'https://openalex.org/W2101252293', 'https://openalex.org/W2001223827', 'https://openalex.org/W4288255289', 'https://openalex.org/W3042795397', 'https://openalex.org/W3034775979', 'https://openalex.org/W3103536442', 'https://openalex.org/W4288631803', 'https://openalex.org/W2135891083', 'https://openalex.org/W3098613713', 'https://openalex.org/W2798665661', 'https://openalex.org/W2132730112', 'https://openalex.org/W2592920763']",2021-01-01
https://openalex.org/W3031133340,https://doi.org/10.21437/interspeech.2020-1690,An Open-Source Voice Type Classifier for Child-Centered Daylong Recordings,International audience,"['https://openalex.org/W1269382222', 'https://openalex.org/W2167543949', 'https://openalex.org/W2044321477', 'https://openalex.org/W2888800758', 'https://openalex.org/W2115857751', 'https://openalex.org/W2561127898', 'https://openalex.org/W2058878924', 'https://openalex.org/W2885156775', 'https://openalex.org/W3004481867', 'https://openalex.org/W2964054038', 'https://openalex.org/W3015783745', 'https://openalex.org/W2989863749', 'https://openalex.org/W2919849250', 'https://openalex.org/W1533561824', 'https://openalex.org/W2406262283', 'https://openalex.org/W2070218750', 'https://openalex.org/W4285719527', 'https://openalex.org/W2964052309', 'https://openalex.org/W2219249508', 'https://openalex.org/W2048632248', 'https://openalex.org/W2343593471', 'https://openalex.org/W2972449503', 'https://openalex.org/W3045733287', 'https://openalex.org/W2750259098', 'https://openalex.org/W2010604004', 'https://openalex.org/W2131168675', 'https://openalex.org/W1516907663']",2020-10-25
https://openalex.org/W4390854704,,Statistical learning bootstraps early language acquisition,,[],2023-02-16
https://openalex.org/W2765364385,https://doi.org/10.1111/cdev.12974,Child‐Directed Speech Is Infrequent in a Forager‐Farmer Population: A Time Allocation Study,"This article provides an estimation of how frequently, and from whom, children aged 0–11 years ( N s between 9 and 24) receive one‐on‐one verbal input among Tsimane forager‐horticulturalists of lowland Bolivia. Analyses of systematic daytime behavioral observations reveal &lt; 1 min per daylight hour is spent talking to children younger than 4 years of age, which is 4 times less than estimates for others present at the same time and place. Adults provide a majority of the input at 0–3 years of age but not afterward. When integrated with previous work, these results reveal large cross‐cultural variation in the linguistic experiences provided to young children. Consideration of more diverse human populations is necessary to build generalizable theories of language acquisition.","['https://openalex.org/W1773852799', 'https://openalex.org/W1966135462', 'https://openalex.org/W2485934324', 'https://openalex.org/W2088377333', 'https://openalex.org/W2038594453', 'https://openalex.org/W2064304610', 'https://openalex.org/W2022947275', 'https://openalex.org/W2153397505', 'https://openalex.org/W2104779658', 'https://openalex.org/W1981849723', 'https://openalex.org/W2070157293', 'https://openalex.org/W2174111886', 'https://openalex.org/W2118294818', 'https://openalex.org/W1993227273', 'https://openalex.org/W2089358714', 'https://openalex.org/W2106640230', 'https://openalex.org/W2008621799', 'https://openalex.org/W2104261441', 'https://openalex.org/W2148264472', 'https://openalex.org/W1988577457', 'https://openalex.org/W2797989611', 'https://openalex.org/W2486607307', 'https://openalex.org/W2020944885', 'https://openalex.org/W2103462724', 'https://openalex.org/W1690765785', 'https://openalex.org/W2260412635', 'https://openalex.org/W1983349220', 'https://openalex.org/W2278948841', 'https://openalex.org/W2291118760', 'https://openalex.org/W2896342372', 'https://openalex.org/W1977979148', 'https://openalex.org/W1968736064', 'https://openalex.org/W2156639694', 'https://openalex.org/W2125766564', 'https://openalex.org/W2171849228', 'https://openalex.org/W2109994782', 'https://openalex.org/W2395225233', 'https://openalex.org/W2113799705', 'https://openalex.org/W41489184', 'https://openalex.org/W2131273696', 'https://openalex.org/W2097515925', 'https://openalex.org/W2059168261', 'https://openalex.org/W2129430770', 'https://openalex.org/W2096333121', 'https://openalex.org/W2028721072', 'https://openalex.org/W4232614171', 'https://openalex.org/W2419654175', 'https://openalex.org/W2162994165', 'https://openalex.org/W2634961244', 'https://openalex.org/W2102040782', 'https://openalex.org/W2244079055', 'https://openalex.org/W2115646488', 'https://openalex.org/W2123148042', 'https://openalex.org/W2009503271', 'https://openalex.org/W2051002832', 'https://openalex.org/W2121512847', 'https://openalex.org/W6760520499', 'https://openalex.org/W2570655866', 'https://openalex.org/W2970889810', 'https://openalex.org/W634105429', 'https://openalex.org/W2924537978', 'https://openalex.org/W4285719527', 'https://openalex.org/W2582743722', 'https://openalex.org/W2167543949', 'https://openalex.org/W2599276130', 'https://openalex.org/W4399545439', 'https://openalex.org/W4298742451']",2017-11-02
https://openalex.org/W4298742451,https://doi.org/10.5860/choice.33-3435,Meaningful differences in the everyday experience of young American children,,[],1996-02-01
https://openalex.org/W4292779060,https://doi.org/10.4230/lipics.giscience.2023.43,Evaluating the Effectiveness of Large Language Models in Representing Textual Descriptions of Geometry and Spatial Relations (Short Paper),"This research focuses on assessing the ability of large language models (LLMs) in representing geometries and their spatial relations. We utilize LLMs including GPT-2 and BERT to encode the well-known text (WKT) format of geometries and then feed their embeddings into classifiers and regressors to evaluate the effectiveness of the LLMs-generated embeddings for geometric attributes. The experiments demonstrate that while the LLMs-generated embeddings can preserve geometry types and capture some spatial relations (up to 73% accuracy), challenges remain in estimating numeric values and retrieving spatially related objects. This research highlights the need for improvement in terms of capturing the nuances and complexities of the underlying geospatial data and integrating domain knowledge to support various GeoAI applications using foundation models.",[],2023-01-01
https://openalex.org/W4247178956,https://doi.org/10.31234/osf.io/pt9xq,Reverse engineering language acquisition with child-centered long-form recordings,"Language use in everyday life can be studied using lightweight, wearable recorders that collect long-form recordings - that is, audio (including speech) over whole days. The hardware and software underlying this technique is increasingly accessible and inexpensive, and these data are revolutionizing the language acquisition field. We first place this technique into the broader context of the current ways of studying both the input being received by children and children’s own language production, laying out the main advantages and drawbacks of long-form recordings. We then go on to argue that a unique advantage of long-form recordings is that they can fuel realistic models of early language acquisition that use speech to represent children's input and/or to establish production benchmarks. To enable the field to make the most of this unique empirical and conceptual contribution, we outline what this reverse engineering approach from long-form recordings entails, why it is useful, and how to evaluate success.","['https://openalex.org/W2759573091', 'https://openalex.org/W3177829661', 'https://openalex.org/W1592295210', 'https://openalex.org/W1532494781', 'https://openalex.org/W6789725041', 'https://openalex.org/W2885156775', 'https://openalex.org/W2063303346', 'https://openalex.org/W2772732614', 'https://openalex.org/W3112495382', 'https://openalex.org/W6665016202', 'https://openalex.org/W1984586950', 'https://openalex.org/W3046659789', 'https://openalex.org/W6790730029', 'https://openalex.org/W6781919819', 'https://openalex.org/W2997253105', 'https://openalex.org/W2944539396', 'https://openalex.org/W2586148577', 'https://openalex.org/W4213306813', 'https://openalex.org/W3123651923', 'https://openalex.org/W3005165546', 'https://openalex.org/W2015075592', 'https://openalex.org/W3135377987', 'https://openalex.org/W2483390977', 'https://openalex.org/W2160997109', 'https://openalex.org/W2774051897', 'https://openalex.org/W6685399832', 'https://openalex.org/W2991557631', 'https://openalex.org/W2112883467', 'https://openalex.org/W6633336849', 'https://openalex.org/W2071591642', 'https://openalex.org/W2889102505', 'https://openalex.org/W6781576031', 'https://openalex.org/W6629325461', 'https://openalex.org/W6641916425', 'https://openalex.org/W2085478996', 'https://openalex.org/W3110458199', 'https://openalex.org/W2618478924', 'https://openalex.org/W2132566726', 'https://openalex.org/W2972476505', 'https://openalex.org/W3025683731', 'https://openalex.org/W3125043549', 'https://openalex.org/W6729411815', 'https://openalex.org/W3129957462', 'https://openalex.org/W3125087428', 'https://openalex.org/W2801193150', 'https://openalex.org/W2141994663', 'https://openalex.org/W6658483803', 'https://openalex.org/W2799770360', 'https://openalex.org/W2805234167', 'https://openalex.org/W6681346506', 'https://openalex.org/W4407276585', 'https://openalex.org/W2065159495', 'https://openalex.org/W2621934507', 'https://openalex.org/W2252657604', 'https://openalex.org/W2101509422', 'https://openalex.org/W2803055582', 'https://openalex.org/W2058616551', 'https://openalex.org/W2135563147', 'https://openalex.org/W2060238187', 'https://openalex.org/W4253971549', 'https://openalex.org/W4246103655', 'https://openalex.org/W2058354688', 'https://openalex.org/W2343593471', 'https://openalex.org/W4255020641', 'https://openalex.org/W4251221781', 'https://openalex.org/W1559022555', 'https://openalex.org/W4232589384', 'https://openalex.org/W1558150890', 'https://openalex.org/W4297612016', 'https://openalex.org/W4245117732', 'https://openalex.org/W2546861836', 'https://openalex.org/W4253947715', 'https://openalex.org/W2032543155', 'https://openalex.org/W4287591426', 'https://openalex.org/W3080620940', 'https://openalex.org/W1967834254', 'https://openalex.org/W1485633403', 'https://openalex.org/W4242334097', 'https://openalex.org/W4236000557', 'https://openalex.org/W3047246203', 'https://openalex.org/W4251435902', 'https://openalex.org/W2995680346', 'https://openalex.org/W3126722376', 'https://openalex.org/W4252366034']",2021-03-31
https://openalex.org/W4286984129,https://doi.org/10.48550/arxiv.2109.03264,Text-Free Prosody-Aware Generative Spoken Language Modeling,"Speech pre-training has primarily demonstrated efficacy on classification tasks, while its capability of generating novel speech, similar to how GPT-2 can generate coherent paragraphs, has barely been explored. Generative Spoken Language Modeling (GSLM) \cite{Lakhotia2021} is the only prior work addressing the generative aspects of speech pre-training, which replaces text with discovered phone-like units for language modeling and shows the ability to generate meaningful novel sentences. Unfortunately, despite eliminating the need of text, the units used in GSLM discard most of the prosodic information. Hence, GSLM fails to leverage prosody for better comprehension, and does not generate expressive speech. In this work, we present a prosody-aware generative spoken language model (pGSLM). It is composed of a multi-stream transformer language model (MS-TLM) of speech, represented as discovered unit and prosodic feature streams, and an adapted HiFi-GAN model converting MS-TLM outputs to waveforms. We devise a series of metrics for prosody modeling and generation, and re-use metrics from GSLM for content modeling. Experimental results show that the pGSLM can utilize prosody to improve both prosody and content modeling, and also generate natural, meaningful, and coherent speech given a spoken prompt. Audio samples can be found at https://speechbot.github.io/pgslm. Codes and models are available at https://github.com/pytorch/fairseq/tree/main/examples/textless_nlp/pgslm.","['https://openalex.org/W4297808394', 'https://openalex.org/W2160473997', 'https://openalex.org/W3160799772', 'https://openalex.org/W1522301498', 'https://openalex.org/W2527729766', 'https://openalex.org/W2810914326', 'https://openalex.org/W2519091744', 'https://openalex.org/W1597422500', 'https://openalex.org/W2913151434', 'https://openalex.org/W2143827132', 'https://openalex.org/W4394671563', 'https://openalex.org/W2973049979', 'https://openalex.org/W2107740512', 'https://openalex.org/W3198771897', 'https://openalex.org/W2151083697', 'https://openalex.org/W2963609956', 'https://openalex.org/W2093585241', 'https://openalex.org/W1494198834', 'https://openalex.org/W2426479676', 'https://openalex.org/W2972943112', 'https://openalex.org/W2112078429', 'https://openalex.org/W2796738181', 'https://openalex.org/W3112034174', 'https://openalex.org/W2123409957', 'https://openalex.org/W3095948607', 'https://openalex.org/W2995181338', 'https://openalex.org/W3197103763', 'https://openalex.org/W3144810982', 'https://openalex.org/W3169320628', 'https://openalex.org/W2141885148', 'https://openalex.org/W2963799213', 'https://openalex.org/W1524333225', 'https://openalex.org/W359161088', 'https://openalex.org/W4292779060', 'https://openalex.org/W3033411150', 'https://openalex.org/W3036601975', 'https://openalex.org/W3197580070', 'https://openalex.org/W2118748593', 'https://openalex.org/W2130086727', 'https://openalex.org/W3140429000', 'https://openalex.org/W3148101939', 'https://openalex.org/W2982223350']",2021-09-07
https://openalex.org/W4200300291,https://doi.org/10.21105/joss.03958,Phonemizer: Text to Phones Transcription for Multiple Languages in Python,"Phones are elementary sounds the speech is made of, on which syllables and words are built.The transcription of texts from their orthographic form into a phonetic alphabet is an important requirement in various applications related to speech and language processing, for instance for text to speech systems.Phonemizer is a Python package addressing precisely this issue: it transcribes a text from its orthographic representation into a phonetic one.The package is user-friendly and exposes a single high-level phonemize function, a lower lovel API, and is also available as a command-line interface.It supports about a hundred different languages and provides end-user functionalities such as punctuation preservation, phones accentuation, tokenization at phone/syllable/word levels, as well as parallel processing of large input texts.","['https://openalex.org/W2935067899', 'https://openalex.org/W6893487223', 'https://openalex.org/W2911157912', 'https://openalex.org/W2963620343', 'https://openalex.org/W2741325934', 'https://openalex.org/W2962780374', 'https://openalex.org/W1548813916', 'https://openalex.org/W2747874407', 'https://openalex.org/W3085007956']",2021-12-18
https://openalex.org/W4240474221,https://doi.org/10.31219/osf.io/jvdme,Language input to infants of different socioeconomic statuses: A quantitative meta-analysis,This Registered Report has been published at Developmental Science.,"['https://openalex.org/W2169759015', 'https://openalex.org/W2085985404', 'https://openalex.org/W1950016431', 'https://openalex.org/W2885156775', 'https://openalex.org/W2895356663', 'https://openalex.org/W1699419358', 'https://openalex.org/W2052194417', 'https://openalex.org/W1999173569', 'https://openalex.org/W2000615646', 'https://openalex.org/W3012222659', 'https://openalex.org/W1974062950', 'https://openalex.org/W2997253105', 'https://openalex.org/W3080620940', 'https://openalex.org/W2080665939', 'https://openalex.org/W2046757311', 'https://openalex.org/W2914888987', 'https://openalex.org/W2765364385', 'https://openalex.org/W3123651923', 'https://openalex.org/W156406360', 'https://openalex.org/W3031875957', 'https://openalex.org/W2018592135', 'https://openalex.org/W3004567105', 'https://openalex.org/W2023651217', 'https://openalex.org/W2153897911', 'https://openalex.org/W3109843697', 'https://openalex.org/W1974990679', 'https://openalex.org/W2129870134', 'https://openalex.org/W2605959375', 'https://openalex.org/W2108946139', 'https://openalex.org/W2911553802', 'https://openalex.org/W6983383401', 'https://openalex.org/W7075616624', 'https://openalex.org/W2113941258', 'https://openalex.org/W2107492371', 'https://openalex.org/W2891606517', 'https://openalex.org/W2021548302', 'https://openalex.org/W2108449190', 'https://openalex.org/W2045495963', 'https://openalex.org/W2165708294', 'https://openalex.org/W2187417910', 'https://openalex.org/W84667726', 'https://openalex.org/W1690765785', 'https://openalex.org/W2059200279', 'https://openalex.org/W2168184718', 'https://openalex.org/W1984982865', 'https://openalex.org/W2606433734', 'https://openalex.org/W2081848479', 'https://openalex.org/W4294215472', 'https://openalex.org/W1871959546', 'https://openalex.org/W4252163017', 'https://openalex.org/W2012197026', 'https://openalex.org/W4243852216', 'https://openalex.org/W2159320937', 'https://openalex.org/W4232493471', 'https://openalex.org/W2981093683', 'https://openalex.org/W2582743722', 'https://openalex.org/W2156639694', 'https://openalex.org/W2125766564', 'https://openalex.org/W2395225233', 'https://openalex.org/W2029123611', 'https://openalex.org/W2097515925', 'https://openalex.org/W2343157330', 'https://openalex.org/W2802302202', 'https://openalex.org/W2105027765', 'https://openalex.org/W2121109532', 'https://openalex.org/W2167290899', 'https://openalex.org/W1990391852', 'https://openalex.org/W2139168999', 'https://openalex.org/W2419654175', 'https://openalex.org/W4242712582', 'https://openalex.org/W2102040782', 'https://openalex.org/W1532019657', 'https://openalex.org/W2097612954', 'https://openalex.org/W4234766338', 'https://openalex.org/W2064303689', 'https://openalex.org/W1497181033', 'https://openalex.org/W4254710272', 'https://openalex.org/W4251942283', 'https://openalex.org/W1901083222', 'https://openalex.org/W2791591082', 'https://openalex.org/W3001333523', 'https://openalex.org/W4298742451']",2021-02-11
https://openalex.org/W2741692265,https://doi.org/10.18653/v1/e17-2020,Comparing Character-level Neural Language Models Using a Lexical Decision Task,International audience,"['https://openalex.org/W2014307400', 'https://openalex.org/W2168979204', 'https://openalex.org/W2037387434', 'https://openalex.org/W2963251942', 'https://openalex.org/W2141599568', 'https://openalex.org/W2740606810', 'https://openalex.org/W2531882892', 'https://openalex.org/W4254816979', 'https://openalex.org/W1548013675', 'https://openalex.org/W4362220304', 'https://openalex.org/W2549835527', 'https://openalex.org/W303185113', 'https://openalex.org/W1989462718', 'https://openalex.org/W2138723686', 'https://openalex.org/W2110485445', 'https://openalex.org/W1836465849', 'https://openalex.org/W1566289585', 'https://openalex.org/W2098192529', 'https://openalex.org/W1522301498', 'https://openalex.org/W2064675550', 'https://openalex.org/W2185277953', 'https://openalex.org/W1938755728', 'https://openalex.org/W2951559648', 'https://openalex.org/W2964121744', 'https://openalex.org/W2885588803', 'https://openalex.org/W2020220682', 'https://openalex.org/W1917177419', 'https://openalex.org/W2962776659', 'https://openalex.org/W2515741950', 'https://openalex.org/W1990948551']",2017-01-01
https://openalex.org/W4318621130,https://doi.org/10.48550/arxiv.2301.11796,Call for Papers -- The BabyLM Challenge: Sample-efficient pretraining on a developmentally plausible corpus,"We present the call for papers for the BabyLM Challenge: Sample-efficient pretraining on a developmentally plausible corpus. This shared task is intended for participants with an interest in small scale language modeling, human language acquisition, low-resource NLP, and cognitive modeling. In partnership with CoNLL and CMCL, we provide a platform for approaches to pretraining with a limited-size corpus sourced from data inspired by the input to children. The task has three tracks, two of which restrict the training data to pre-released datasets of 10M and 100M words and are dedicated to explorations of approaches such as architectural variations, self-supervised objectives, or curriculum learning. The final track only restricts the amount of text used, allowing innovation in the choice of the data, its domain, and even its modality (i.e., data from sources other than text is welcome). We will release a shared evaluation pipeline which scores models on a variety of benchmarks and tasks, including targeted syntactic evaluations and natural language understanding.",[],2023-01-27
https://openalex.org/W2155042697,,A joint model of word segmentation and phonological variation for English word-final /t/-deletion,"Word-final /t/-deletion refers to a common phenomenon in spoken English where words such as /wEst / “west ” are pronounced as [wEs] “wes ” in certain contexts. Phonological variation like this is common in naturally occurring speech. Current computational models of unsupervised word segmentation usually assume idealized input that is devoid of these kinds of variation. We extend a non-parametric model of word segmentation by adding phonological rules that map from underlying forms to surface forms to produce a mathematically well-defined joint model as a first step towards handling variation and segmentation in a single model. We analyse how our model handles /t/-deletion on a large corpus of transcribed speech, and show that the joint model can perform word segmentation and recover underlying /t/s. We find that Bigram dependencies are important for performing well on real data and for learning appropriate deletion probabilities for different contexts. 1 1","['https://openalex.org/W3037265734', 'https://openalex.org/W2115901636', 'https://openalex.org/W2168925951', 'https://openalex.org/W2337127743', 'https://openalex.org/W2107959623', 'https://openalex.org/W147653292', 'https://openalex.org/W2126449874', 'https://openalex.org/W2119389517', 'https://openalex.org/W2103152638', 'https://openalex.org/W1598851216', 'https://openalex.org/W2158266063', 'https://openalex.org/W2117126688', 'https://openalex.org/W1562911371', 'https://openalex.org/W2126953647', 'https://openalex.org/W2126377586']",2013-08-01
https://openalex.org/W4281492411,https://doi.org/10.1109/jstsp.2022.3207050,Self-Supervised Speech Representation Learning: A Review,"Although supervised deep learning has revolutionized speech and audio\nprocessing, it has necessitated the building of specialist models for\nindividual tasks and application scenarios. It is likewise difficult to apply\nthis to dialects and languages for which only limited labeled data is\navailable. Self-supervised representation learning methods promise a single\nuniversal model that would benefit a wide variety of tasks and domains. Such\nmethods have shown success in natural language processing and computer vision\ndomains, achieving new levels of performance while reducing the number of\nlabels required for many downstream scenarios. Speech representation learning\nis experiencing similar progress in three main categories: generative,\ncontrastive, and predictive methods. Other approaches rely on multi-modal data\nfor pre-training, mixing text or visual data streams with speech. Although\nself-supervised speech representation is still a nascent research area, it is\nclosely related to acoustic word embedding and learning with zero lexical\nresources, both of which have seen active research for many years. This review\npresents approaches for self-supervised speech representation learning and\ntheir connection to other research areas. Since many current methods focus\nsolely on automatic speech recognition as a downstream task, we review recent\nefforts on benchmarking learned representations to extend the application\nbeyond speech recognition.\n","['https://openalex.org/W2919115771', 'https://openalex.org/W2160815625', 'https://openalex.org/W811578723', 'https://openalex.org/W1555037511', 'https://openalex.org/W1975113979', 'https://openalex.org/W2110073835', 'https://openalex.org/W2124537004', 'https://openalex.org/W6683825394', 'https://openalex.org/W2163922914', 'https://openalex.org/W1901616594', 'https://openalex.org/W4244017338', 'https://openalex.org/W4239390603', 'https://openalex.org/W6675401909', 'https://openalex.org/W1902027874', 'https://openalex.org/W2100495367', 'https://openalex.org/W6800751262', 'https://openalex.org/W3207924272', 'https://openalex.org/W3035725276', 'https://openalex.org/W6773996589', 'https://openalex.org/W3185341429', 'https://openalex.org/W6784023748', 'https://openalex.org/W3011574394', 'https://openalex.org/W3023371261', 'https://openalex.org/W6811170316', 'https://openalex.org/W6772230580', 'https://openalex.org/W1703050006', 'https://openalex.org/W2048648518', 'https://openalex.org/W2100969003', 'https://openalex.org/W1979447841', 'https://openalex.org/W1877570817', 'https://openalex.org/W6680522077', 'https://openalex.org/W1487784522', 'https://openalex.org/W2155230809', 'https://openalex.org/W2150769028', 'https://openalex.org/W2408021097', 'https://openalex.org/W6681096077', 'https://openalex.org/W6680106237', 'https://openalex.org/W2145889472', 'https://openalex.org/W2113606819', 'https://openalex.org/W2067474491', 'https://openalex.org/W6736430770', 'https://openalex.org/W2116064496', 'https://openalex.org/W2923014074', 'https://openalex.org/W3197580070', 'https://openalex.org/W2326925005', 'https://openalex.org/W2883725317', 'https://openalex.org/W343636949', 'https://openalex.org/W6640963894', 'https://openalex.org/W6639732818', 'https://openalex.org/W3217536461', 'https://openalex.org/W2962739339', 'https://openalex.org/W6767997687', 'https://openalex.org/W2896457183', 'https://openalex.org/W6766673545', 'https://openalex.org/W6844194202', 'https://openalex.org/W3035524453', 'https://openalex.org/W6774670964', 'https://openalex.org/W6779997284', 'https://openalex.org/W2962907457', 'https://openalex.org/W3026041220', 'https://openalex.org/W3096338464', 'https://openalex.org/W6811088048', 'https://openalex.org/W2913340405', 'https://openalex.org/W2291975472', 'https://openalex.org/W3112702554', 'https://openalex.org/W4226380987', 'https://openalex.org/W2973157397', 'https://openalex.org/W6617744952', 'https://openalex.org/W6712395597', 'https://openalex.org/W2962850167', 'https://openalex.org/W6745117592', 'https://openalex.org/W6757193177', 'https://openalex.org/W2752796333', 'https://openalex.org/W3140429000', 'https://openalex.org/W3198217962', 'https://openalex.org/W6790356757', 'https://openalex.org/W6690026940', 'https://openalex.org/W2097012520', 'https://openalex.org/W1945356021', 'https://openalex.org/W3100270690', 'https://openalex.org/W6729448088', 'https://openalex.org/W2972867623', 'https://openalex.org/W2035424729', 'https://openalex.org/W2020607164', 'https://openalex.org/W2396043527', 'https://openalex.org/W1545920196', 'https://openalex.org/W1796128977', 'https://openalex.org/W2932675979', 'https://openalex.org/W2972943112', 'https://openalex.org/W3016011332', 'https://openalex.org/W2020883660', 'https://openalex.org/W2146444479', 'https://openalex.org/W3035202887', 'https://openalex.org/W3097286738', 'https://openalex.org/W3015265920', 'https://openalex.org/W2982223350', 'https://openalex.org/W6769238691', 'https://openalex.org/W6778265221', 'https://openalex.org/W3003875258', 'https://openalex.org/W3160345865', 'https://openalex.org/W3196919915', 'https://openalex.org/W3041561163', 'https://openalex.org/W3198858531', 'https://openalex.org/W3096485810', 'https://openalex.org/W3196798358', 'https://openalex.org/W6674330103', 'https://openalex.org/W3015213852', 'https://openalex.org/W2963425185', 'https://openalex.org/W6840487619', 'https://openalex.org/W3015949486', 'https://openalex.org/W2982039329', 'https://openalex.org/W2963571336', 'https://openalex.org/W3148040514', 'https://openalex.org/W2963317665', 'https://openalex.org/W2973049979', 'https://openalex.org/W3016181583', 'https://openalex.org/W3102342027', 'https://openalex.org/W6769196770', 'https://openalex.org/W6780218876', 'https://openalex.org/W3197411683', 'https://openalex.org/W4226033575', 'https://openalex.org/W3198608154', 'https://openalex.org/W3015356564', 'https://openalex.org/W3209059054', 'https://openalex.org/W3209984917', 'https://openalex.org/W6810007534', 'https://openalex.org/W6810673746', 'https://openalex.org/W6677884823', 'https://openalex.org/W6682948231', 'https://openalex.org/W2124509324', 'https://openalex.org/W6762931180', 'https://openalex.org/W3159481202', 'https://openalex.org/W1536680647', 'https://openalex.org/W6766978945', 'https://openalex.org/W6600971220', 'https://openalex.org/W2096391593', 'https://openalex.org/W1974783905', 'https://openalex.org/W2091863306', 'https://openalex.org/W4237938692', 'https://openalex.org/W142945732', 'https://openalex.org/W2594690981', 'https://openalex.org/W6810168380', 'https://openalex.org/W2016538560', 'https://openalex.org/W4396724964', 'https://openalex.org/W2296654356', 'https://openalex.org/W6686207219', 'https://openalex.org/W900447646', 'https://openalex.org/W6606244218', 'https://openalex.org/W4237723258', 'https://openalex.org/W6631216910', 'https://openalex.org/W6639103823', 'https://openalex.org/W6728094556', 'https://openalex.org/W6693697572', 'https://openalex.org/W1484147505', 'https://openalex.org/W2130055251', 'https://openalex.org/W2049252044', 'https://openalex.org/W6678885645', 'https://openalex.org/W1531883353', 'https://openalex.org/W6633682082', 'https://openalex.org/W2136189984', 'https://openalex.org/W4297841641', 'https://openalex.org/W3157861865', 'https://openalex.org/W6864391120', 'https://openalex.org/W6729977899', 'https://openalex.org/W2962862718', 'https://openalex.org/W2971709506', 'https://openalex.org/W3197828817', 'https://openalex.org/W3200287550', 'https://openalex.org/W2988907666', 'https://openalex.org/W3196698946', 'https://openalex.org/W3205715971', 'https://openalex.org/W6809593508', 'https://openalex.org/W6770596778', 'https://openalex.org/W2586148577', 'https://openalex.org/W2964115348', 'https://openalex.org/W2963902314', 'https://openalex.org/W4224875474', 'https://openalex.org/W3095293218', 'https://openalex.org/W2963330681', 'https://openalex.org/W2920166246', 'https://openalex.org/W2895651543', 'https://openalex.org/W2973135958', 'https://openalex.org/W6803092890', 'https://openalex.org/W1577418252', 'https://openalex.org/W1496120315', 'https://openalex.org/W2962980711', 'https://openalex.org/W2964169922', 'https://openalex.org/W6720204814', 'https://openalex.org/W2296681920', 'https://openalex.org/W2059652594', 'https://openalex.org/W2889313720', 'https://openalex.org/W2963720603', 'https://openalex.org/W6786885278', 'https://openalex.org/W2407151108', 'https://openalex.org/W2190506272', 'https://openalex.org/W3037530970', 'https://openalex.org/W3201254286', 'https://openalex.org/W3150635893', 'https://openalex.org/W2995181338', 'https://openalex.org/W2593116425', 'https://openalex.org/W4289665794', 'https://openalex.org/W6603931906', 'https://openalex.org/W1494198834', 'https://openalex.org/W2024490156', 'https://openalex.org/W6771467084', 'https://openalex.org/W3095410713', 'https://openalex.org/W3119308075', 'https://openalex.org/W6696449567', 'https://openalex.org/W3213029956', 'https://openalex.org/W3206252155', 'https://openalex.org/W3198694222', 'https://openalex.org/W2799473636', 'https://openalex.org/W6691509046', 'https://openalex.org/W2166637769', 'https://openalex.org/W3139878283', 'https://openalex.org/W1526236009', 'https://openalex.org/W2963242190', 'https://openalex.org/W2963127222', 'https://openalex.org/W2884797218', 'https://openalex.org/W6712941328', 'https://openalex.org/W2883409523', 'https://openalex.org/W6936113694', 'https://openalex.org/W2726515241', 'https://openalex.org/W2972584841', 'https://openalex.org/W1567520911', 'https://openalex.org/W6748215858', 'https://openalex.org/W3196509775', 'https://openalex.org/W2094544353', 'https://openalex.org/W6727418883', 'https://openalex.org/W6712757354', 'https://openalex.org/W6731521493', 'https://openalex.org/W6688816777', 'https://openalex.org/W2883595988', 'https://openalex.org/W6750665317', 'https://openalex.org/W2775794021', 'https://openalex.org/W6736723571', 'https://openalex.org/W2972894903', 'https://openalex.org/W3033038061', 'https://openalex.org/W942963634', 'https://openalex.org/W3197223534', 'https://openalex.org/W6784614252', 'https://openalex.org/W6753575415', 'https://openalex.org/W3160554450', 'https://openalex.org/W6803378298', 'https://openalex.org/W3189296823', 'https://openalex.org/W3093096176', 'https://openalex.org/W6809947431', 'https://openalex.org/W3006926732', 'https://openalex.org/W4225713393', 'https://openalex.org/W3096216486', 'https://openalex.org/W3095361818', 'https://openalex.org/W2251253014', 'https://openalex.org/W6795952400', 'https://openalex.org/W2970820321', 'https://openalex.org/W6801828775', 'https://openalex.org/W3198815374', 'https://openalex.org/W3024182269', 'https://openalex.org/W4224934179', 'https://openalex.org/W3096017728', 'https://openalex.org/W3162133897', 'https://openalex.org/W6784614126', 'https://openalex.org/W2786608204', 'https://openalex.org/W3207558756', 'https://openalex.org/W3198771897', 'https://openalex.org/W3198429080', 'https://openalex.org/W2962799225', 'https://openalex.org/W2802557066', 'https://openalex.org/W6735913928', 'https://openalex.org/W6751433836', 'https://openalex.org/W6744957266', 'https://openalex.org/W2899134946', 'https://openalex.org/W6750365303', 'https://openalex.org/W6757699909', 'https://openalex.org/W2962799131', 'https://openalex.org/W6738077056', 'https://openalex.org/W6760519848', 'https://openalex.org/W3214697273', 'https://openalex.org/W6678282225', 'https://openalex.org/W4319862670', 'https://openalex.org/W6745740328', 'https://openalex.org/W6745388339', 'https://openalex.org/W3204917342', 'https://openalex.org/W2962699523', 'https://openalex.org/W2963739817', 'https://openalex.org/W3015280134', 'https://openalex.org/W2963796886', 'https://openalex.org/W2963581463', 'https://openalex.org/W2972889948', 'https://openalex.org/W2119717200', 'https://openalex.org/W2046932483', 'https://openalex.org/W6640059789', 'https://openalex.org/W2577366047', 'https://openalex.org/W2964243274', 'https://openalex.org/W6756385397', 'https://openalex.org/W2940200615', 'https://openalex.org/W3008480565', 'https://openalex.org/W3024464021', 'https://openalex.org/W3016008406', 'https://openalex.org/W2883586237', 'https://openalex.org/W2964012862', 'https://openalex.org/W3097632072', 'https://openalex.org/W2963216553', 'https://openalex.org/W2025482506', 'https://openalex.org/W2963620343', 'https://openalex.org/W2940544976', 'https://openalex.org/W6786696081', 'https://openalex.org/W2347098582', 'https://openalex.org/W2787447541', 'https://openalex.org/W2972374322', 'https://openalex.org/W3197381195', 'https://openalex.org/W6803066952', 'https://openalex.org/W4307680525', 'https://openalex.org/W4221146627', 'https://openalex.org/W6805530253', 'https://openalex.org/W6777028661', 'https://openalex.org/W4287854499', 'https://openalex.org/W6759579507', 'https://openalex.org/W3176828726', 'https://openalex.org/W6787411158', 'https://openalex.org/W4225274946', 'https://openalex.org/W4226162428', 'https://openalex.org/W6796551075', 'https://openalex.org/W3203140070', 'https://openalex.org/W6685943813', 'https://openalex.org/W3137147200', 'https://openalex.org/W3085139254', 'https://openalex.org/W3198039885', 'https://openalex.org/W6839738141', 'https://openalex.org/W6803547063', 'https://openalex.org/W4297841871', 'https://openalex.org/W3214576767', 'https://openalex.org/W4296068785', 'https://openalex.org/W3209376089', 'https://openalex.org/W4221140371', 'https://openalex.org/W4292825791', 'https://openalex.org/W3101648800', 'https://openalex.org/W4200635400', 'https://openalex.org/W3088409176', 'https://openalex.org/W4286918540', 'https://openalex.org/W2102409316', 'https://openalex.org/W3211224152', 'https://openalex.org/W4288348042', 'https://openalex.org/W2981991061', 'https://openalex.org/W2998249245', 'https://openalex.org/W3009561768', 'https://openalex.org/W2242818861', 'https://openalex.org/W2997574889', 'https://openalex.org/W1515020792', 'https://openalex.org/W2965373594', 'https://openalex.org/W2530846021', 'https://openalex.org/W4297808394', 'https://openalex.org/W1915251500', 'https://openalex.org/W4295116917', 'https://openalex.org/W2964303773', 'https://openalex.org/W3026842484', 'https://openalex.org/W2125290066', 'https://openalex.org/W2219249508', 'https://openalex.org/W2095705004', 'https://openalex.org/W22517275', 'https://openalex.org/W4221145109', 'https://openalex.org/W4287591426', 'https://openalex.org/W2898727538', 'https://openalex.org/W2797583228', 'https://openalex.org/W3195577433', 'https://openalex.org/W3099142230', 'https://openalex.org/W3107298252', 'https://openalex.org/W3213873715', 'https://openalex.org/W2973026522', 'https://openalex.org/W4289750118', 'https://openalex.org/W4394671563', 'https://openalex.org/W3207222250', 'https://openalex.org/W3024605872', 'https://openalex.org/W3161411634', 'https://openalex.org/W2973727699', 'https://openalex.org/W4320013820', 'https://openalex.org/W1508165687', 'https://openalex.org/W2138204974']",2022-09-15
https://openalex.org/W1861492603,https://doi.org/10.1007/978-3-319-10602-1_48,Microsoft COCO: Common Objects in Context,,"['https://openalex.org/W2108598243', 'https://openalex.org/W2031489346', 'https://openalex.org/W2017814585', 'https://openalex.org/W2031454541', 'https://openalex.org/W2102605133', 'https://openalex.org/W2098411764', 'https://openalex.org/W2070148066', 'https://openalex.org/W2535410496', 'https://openalex.org/W125693051', 'https://openalex.org/W1832500336', 'https://openalex.org/W2171943915', 'https://openalex.org/W2110764733', 'https://openalex.org/W2055302526', 'https://openalex.org/W2143890915', 'https://openalex.org/W1861492603', 'https://openalex.org/W2147253850', 'https://openalex.org/W2145607950', 'https://openalex.org/W2135166986', 'https://openalex.org/W4235505822', 'https://openalex.org/W2163965432', 'https://openalex.org/W1972515067', 'https://openalex.org/W2054279472', 'https://openalex.org/W2110158442', 'https://openalex.org/W2134270519', 'https://openalex.org/W1516887802', 'https://openalex.org/W4244390938', 'https://openalex.org/W2031342017', 'https://openalex.org/W2020308406', 'https://openalex.org/W2168356304', 'https://openalex.org/W2046875449', 'https://openalex.org/W2055349880', 'https://openalex.org/W2083542343', 'https://openalex.org/W2161446043', 'https://openalex.org/W191001584', 'https://openalex.org/W2148675068', 'https://openalex.org/W2161969291', 'https://openalex.org/W3092654410', 'https://openalex.org/W2963542991', 'https://openalex.org/W2056933870', 'https://openalex.org/W4285719527', 'https://openalex.org/W2038721957', 'https://openalex.org/W2119775030', 'https://openalex.org/W1576445103', 'https://openalex.org/W2104974755', 'https://openalex.org/W2109586012', 'https://openalex.org/W3118608800', 'https://openalex.org/W2163605009', 'https://openalex.org/W2160014001', 'https://openalex.org/W2155904486']",2014-01-01
https://openalex.org/W2799124508,https://doi.org/10.48550/arxiv.1805.01070,What you can cram into a single vector: Probing sentence embeddings for\n linguistic properties,"Although much effort has recently been devoted to training high-quality\nsentence embeddings, we still have a poor understanding of what they are\ncapturing. ""Downstream"" tasks, often based on sentence classification, are\ncommonly used to evaluate the quality of sentence representations. The\ncomplexity of the tasks makes it however difficult to infer what kind of\ninformation is present in the representations. We introduce here 10 probing\ntasks designed to capture simple linguistic features of sentences, and we use\nthem to study embeddings generated by three different encoders trained in eight\ndistinct ways, uncovering intriguing properties of both encoders and training\nmethods.\n","['https://openalex.org/W2606837722', 'https://openalex.org/W2963846996', 'https://openalex.org/W2473344385', 'https://openalex.org/W2117130368', 'https://openalex.org/W2962777840', 'https://openalex.org/W2625398819', 'https://openalex.org/W2251919380', 'https://openalex.org/W2962776659', 'https://openalex.org/W2605717780', 'https://openalex.org/W2964159778', 'https://openalex.org/W2953084091', 'https://openalex.org/W2563574619', 'https://openalex.org/W2786685006', 'https://openalex.org/W2141599568', 'https://openalex.org/W2124807415', 'https://openalex.org/W2790235966', 'https://openalex.org/W2613904329', 'https://openalex.org/W2251047310', 'https://openalex.org/W2949888546', 'https://openalex.org/W2963069010', 'https://openalex.org/W2549835527', 'https://openalex.org/W22168010', 'https://openalex.org/W2097606805', 'https://openalex.org/W2250539671', 'https://openalex.org/W2950726992', 'https://openalex.org/W2949433733', 'https://openalex.org/W2949831469', 'https://openalex.org/W2250790822', 'https://openalex.org/W2103305545', 'https://openalex.org/W2950577311', 'https://openalex.org/W2114524997', 'https://openalex.org/W2295676751', 'https://openalex.org/W2780932362', 'https://openalex.org/W2951008357', 'https://openalex.org/W2752172973', 'https://openalex.org/W2773621464', 'https://openalex.org/W2771305881', 'https://openalex.org/W2963991316', 'https://openalex.org/W2292919134', 'https://openalex.org/W2963918774', 'https://openalex.org/W2963970792']",2018-05-02
https://openalex.org/W3157861865,https://doi.org/10.1613/jair.1.12967,"Visually Grounded Models of Spoken Language: A Survey of Datasets, Architectures and Evaluation Techniques","This survey provides an overview of the evolution of visually grounded models of spoken language over the last 20 years. Such models are inspired by the observation that when children pick up a language, they rely on a wide range of indirect and noisy clues, crucially including signals from the visual modality co-occurring with spoken utterances. Several fields have made important contributions to this approach to modeling or mimicking the process of learning language: Machine Learning, Natural Language and Speech Processing, Computer Vision and Cognitive Science. The current paper brings together these contributions in order to provide a useful introduction and overview for practitioners in all these areas. We discuss the central research questions addressed, the timeline of developments, and the datasets which enabled much of this work. We then summarize the main modeling architectures and offer an exhaustive overview of the evaluation metrics and analysis techniques.","['https://openalex.org/W2524365899', 'https://openalex.org/W3105148948', 'https://openalex.org/W3177829661', 'https://openalex.org/W6747045456', 'https://openalex.org/W2230076941', 'https://openalex.org/W2957089051', 'https://openalex.org/W2752168051', 'https://openalex.org/W2282219577', 'https://openalex.org/W6766153511', 'https://openalex.org/W2006969979', 'https://openalex.org/W2906407728', 'https://openalex.org/W2586148577', 'https://openalex.org/W4393717817', 'https://openalex.org/W3017025049', 'https://openalex.org/W1924770834', 'https://openalex.org/W2553608650', 'https://openalex.org/W6676297131', 'https://openalex.org/W2531381952', 'https://openalex.org/W2102605133', 'https://openalex.org/W2796156786', 'https://openalex.org/W2137010615', 'https://openalex.org/W2580178245', 'https://openalex.org/W2927673779', 'https://openalex.org/W2991557631', 'https://openalex.org/W2796315435', 'https://openalex.org/W2556930864', 'https://openalex.org/W2736876693', 'https://openalex.org/W4288076474', 'https://openalex.org/W4393840460', 'https://openalex.org/W2920166246', 'https://openalex.org/W2974048280', 'https://openalex.org/W6687483927', 'https://openalex.org/W3092512595', 'https://openalex.org/W3161348170', 'https://openalex.org/W2960271609', 'https://openalex.org/W3114436296', 'https://openalex.org/W2974393448', 'https://openalex.org/W2938991416', 'https://openalex.org/W2808286951', 'https://openalex.org/W2601713192', 'https://openalex.org/W2903320905', 'https://openalex.org/W1905882502', 'https://openalex.org/W2112912048', 'https://openalex.org/W3164946614', 'https://openalex.org/W2160654481', 'https://openalex.org/W3093241733', 'https://openalex.org/W6756021500', 'https://openalex.org/W6639102338', 'https://openalex.org/W2250790822', 'https://openalex.org/W6767668184', 'https://openalex.org/W2948859046', 'https://openalex.org/W1614298861', 'https://openalex.org/W3160014322', 'https://openalex.org/W1574972348', 'https://openalex.org/W2533598788', 'https://openalex.org/W3095881291', 'https://openalex.org/W3015300171', 'https://openalex.org/W3111013239', 'https://openalex.org/W2941492599', 'https://openalex.org/W6656414902', 'https://openalex.org/W6801926475', 'https://openalex.org/W2992526251', 'https://openalex.org/W3034875620', 'https://openalex.org/W2132921748', 'https://openalex.org/W2080320702', 'https://openalex.org/W2107917162', 'https://openalex.org/W3143035657', 'https://openalex.org/W6773790731', 'https://openalex.org/W2593779438', 'https://openalex.org/W3029315861', 'https://openalex.org/W1686810756', 'https://openalex.org/W6864391120', 'https://openalex.org/W2752796333', 'https://openalex.org/W3027324582', 'https://openalex.org/W6739901393', 'https://openalex.org/W3158565912', 'https://openalex.org/W2611064105', 'https://openalex.org/W2029096624', 'https://openalex.org/W6678493852', 'https://openalex.org/W2766091292', 'https://openalex.org/W2134670479', 'https://openalex.org/W2507296351', 'https://openalex.org/W2784025607', 'https://openalex.org/W6720905350', 'https://openalex.org/W2989358187', 'https://openalex.org/W2952132648', 'https://openalex.org/W2971709506', 'https://openalex.org/W385555557', 'https://openalex.org/W4288595436', 'https://openalex.org/W2965147078', 'https://openalex.org/W2984008963', 'https://openalex.org/W4287240590', 'https://openalex.org/W4393617183', 'https://openalex.org/W2973135958', 'https://openalex.org/W1861492603', 'https://openalex.org/W3159476814', 'https://openalex.org/W3200287550', 'https://openalex.org/W2972892814', 'https://openalex.org/W3121480429', 'https://openalex.org/W3174311593', 'https://openalex.org/W2995680346', 'https://openalex.org/W2988907666', 'https://openalex.org/W2963983719', 'https://openalex.org/W2962862718', 'https://openalex.org/W1797268635', 'https://openalex.org/W2964001192', 'https://openalex.org/W2963799213', 'https://openalex.org/W2108598243', 'https://openalex.org/W3196698946', 'https://openalex.org/W2963778889', 'https://openalex.org/W2972808286', 'https://openalex.org/W2123815913', 'https://openalex.org/W2963403868', 'https://openalex.org/W3100813302', 'https://openalex.org/W2119775030', 'https://openalex.org/W2964099072', 'https://openalex.org/W3213502289', 'https://openalex.org/W2194775991', 'https://openalex.org/W2095897464', 'https://openalex.org/W2125566341', 'https://openalex.org/W4297606427', 'https://openalex.org/W4385245566', 'https://openalex.org/W2963902314', 'https://openalex.org/W2963525826', 'https://openalex.org/W4237938692', 'https://openalex.org/W2963163163', 'https://openalex.org/W2963330681', 'https://openalex.org/W2950133079', 'https://openalex.org/W3100923070', 'https://openalex.org/W2024490156', 'https://openalex.org/W2963115079', 'https://openalex.org/W3095670406', 'https://openalex.org/W2962753610', 'https://openalex.org/W4394453761', 'https://openalex.org/W4294555862', 'https://openalex.org/W4230640548', 'https://openalex.org/W3095361818', 'https://openalex.org/W2962813140', 'https://openalex.org/W3217290931', 'https://openalex.org/W4286973758', 'https://openalex.org/W4297826211', 'https://openalex.org/W3197828817', 'https://openalex.org/W3005578234', 'https://openalex.org/W3035750922', 'https://openalex.org/W4300047444', 'https://openalex.org/W3170972077', 'https://openalex.org/W2940544976']",2022-02-18
https://openalex.org/W2896457183,https://doi.org/10.5281/zenodo.12561108,EMBI,"Requirements are an integral part of industry operation and projects. Not only do requirements dictate industrial operations, but they are used in legally binding contracts between supplier and purchaser. Some companies even have requirements as their core business. Most requirements are found in textual documents, this brings a couple of challenges such as ambiguity, scalability, maintenance, and finding relevant and related requirements. Having the requirements in a machine-readable format would be a solution to these challenges, however, existing requirements need to be transformed into machine-readable requirements using NLP technology. Using state-of-the-art NLP methods based on end-to-end neural modelling on such documents is not trivial because the language is technical and domain-specific and training data is not available. In this paper, we focus on one step in that direction, namely scope detection of textual requirements using weak supervision and a simple classifier based on BERT general domain word embeddings and show that using openly available data, it is possible to get promising results on domain-specific requirements documents.","['https://openalex.org/W2131462252', 'https://openalex.org/W2963310665', 'https://openalex.org/W3104033643', 'https://openalex.org/W2158108973', 'https://openalex.org/W2949433733', 'https://openalex.org/W2025768430', 'https://openalex.org/W2963748441', 'https://openalex.org/W2149933564', 'https://openalex.org/W1840435438', 'https://openalex.org/W2153579005', 'https://openalex.org/W2251939518', 'https://openalex.org/W2270070752', 'https://openalex.org/W2413794162', 'https://openalex.org/W2880875857', 'https://openalex.org/W2130903752', 'https://openalex.org/W2963026768', 'https://openalex.org/W1599016936', 'https://openalex.org/W2963339397', 'https://openalex.org/W2963804993', 'https://openalex.org/W2886490473', 'https://openalex.org/W2130158090', 'https://openalex.org/W1486649854', 'https://openalex.org/W2951714314', 'https://openalex.org/W2963756346', 'https://openalex.org/W2963563735', 'https://openalex.org/W2897076808', 'https://openalex.org/W2158139315', 'https://openalex.org/W2507974895', 'https://openalex.org/W2462831000', 'https://openalex.org/W2963564796', 'https://openalex.org/W2117130368', 'https://openalex.org/W2806120502', 'https://openalex.org/W2962808855', 'https://openalex.org/W2108598243', 'https://openalex.org/W2962718483', 'https://openalex.org/W2963846996', 'https://openalex.org/W2551396370', 'https://openalex.org/W2963918774', 'https://openalex.org/W2888329843', 'https://openalex.org/W2962739339', 'https://openalex.org/W2121227244', 'https://openalex.org/W2144578941', 'https://openalex.org/W2963644595', 'https://openalex.org/W2610858497', 'https://openalex.org/W2784823820', 'https://openalex.org/W2525778437', 'https://openalex.org/W3098057198', 'https://openalex.org/W2250539671', 'https://openalex.org/W2963403868', 'https://openalex.org/W2396767181', 'https://openalex.org/W131533222', 'https://openalex.org/W2891602716', 'https://openalex.org/W2963159690', 'https://openalex.org/W2170973209', 'https://openalex.org/W2131744502']",2024-06-27
https://openalex.org/W3037109418,https://doi.org/10.18653/v1/2020.acl-demos.14,Stanza: A Python Natural Language Processing Toolkit for Many Human Languages,"We introduce Stanza, an open-source Python natural language processing toolkit supporting 66 human languages. Compared to existing widely used toolkits, Stanza features a language-agnostic fully neural pipeline for text analysis, including tokenization, multi-word token expansion, lemmatization, part-of-speech and morphological feature tagging, dependency parsing, and named entity recognition. We have trained Stanza on a total of 112 datasets, including the Universal Dependencies treebanks and other multilingual corpora, and show that the same neural architecture generalizes well and achieves competitive performance on all languages tested. Additionally, Stanza includes a native Python interface to the widely used Java Stanford CoreNLP software, which further extends its functionality to cover other tasks such as coreference resolution and relation extraction. Source code, documentation, and pretrained models for 66 languages are available at https://stanfordnlp.github.io/stanza/.","['https://openalex.org/W3139377003', 'https://openalex.org/W1539309091', 'https://openalex.org/W2144578941', 'https://openalex.org/W2740840489', 'https://openalex.org/W2493916176', 'https://openalex.org/W2880875857', 'https://openalex.org/W2903193068', 'https://openalex.org/W2963571341', 'https://openalex.org/W2898879711', 'https://openalex.org/W2899024931', 'https://openalex.org/W2251160521', 'https://openalex.org/W2915429162', 'https://openalex.org/W38462120', 'https://openalex.org/W2120844411', 'https://openalex.org/W1697700638', 'https://openalex.org/W3031245789', 'https://openalex.org/W2988304195', 'https://openalex.org/W2552110825', 'https://openalex.org/W2123442489', 'https://openalex.org/W3018647120', 'https://openalex.org/W2611669587', 'https://openalex.org/W2952087486']",2020-01-01
https://openalex.org/W2906152891,https://doi.org/10.1162/tacl_a_00254,Analysis Methods in Neural Language Processing: A Survey,"Abstract The field of natural language processing has seen impressive progress in recent years, with neural network models replacing many of the traditional systems. A plethora of new models have been proposed, many of which are thought to be opaque compared to their feature-rich counterparts. This has led researchers to analyze, interpret, and evaluate neural networks in novel and more fine-grained ways. In this survey paper, we review analysis methods in neural language processing, categorize them according to prominent research trends, highlight existing limitations, and point to potential directions for future work.","['https://openalex.org/W2752177116', 'https://openalex.org/W2625720409', 'https://openalex.org/W2625455707', 'https://openalex.org/W2962807820', 'https://openalex.org/W2962718684', 'https://openalex.org/W2561412020', 'https://openalex.org/W2964045325', 'https://openalex.org/W2963558636', 'https://openalex.org/W2963240572', 'https://openalex.org/W2767019613', 'https://openalex.org/W2605717780', 'https://openalex.org/W2884991722', 'https://openalex.org/W2892205701', 'https://openalex.org/W2963651521', 'https://openalex.org/W2161658801', 'https://openalex.org/W1840435438', 'https://openalex.org/W2622101571', 'https://openalex.org/W2756888147', 'https://openalex.org/W2082345008', 'https://openalex.org/W2963583362', 'https://openalex.org/W2048374649', 'https://openalex.org/W2962995403', 'https://openalex.org/W2250877157', 'https://openalex.org/W2963706817', 'https://openalex.org/W2586148577', 'https://openalex.org/W2799005354', 'https://openalex.org/W2964204621', 'https://openalex.org/W2963400886', 'https://openalex.org/W2966280323', 'https://openalex.org/W2803461564', 'https://openalex.org/W2741040846', 'https://openalex.org/W3104119469', 'https://openalex.org/W2758849341', 'https://openalex.org/W2799194071', 'https://openalex.org/W2890774895', 'https://openalex.org/W2888760383', 'https://openalex.org/W1554027614', 'https://openalex.org/W2110485445', 'https://openalex.org/W2087946919', 'https://openalex.org/W2516090925', 'https://openalex.org/W2963419157', 'https://openalex.org/W2140610559', 'https://openalex.org/W2962816513', 'https://openalex.org/W3216404684', 'https://openalex.org/W1988126949', 'https://openalex.org/W2296540674', 'https://openalex.org/W2963330800', 'https://openalex.org/W2605069615', 'https://openalex.org/W2962818281', 'https://openalex.org/W2121029939', 'https://openalex.org/W2963366649', 'https://openalex.org/W2885396331', 'https://openalex.org/W2964222268', 'https://openalex.org/W2798665661', 'https://openalex.org/W2964108524', 'https://openalex.org/W4210984920', 'https://openalex.org/W2963751529', 'https://openalex.org/W2250382531', 'https://openalex.org/W2887906913', 'https://openalex.org/W2962736243', 'https://openalex.org/W4235493488', 'https://openalex.org/W2962753610', 'https://openalex.org/W1854884267', 'https://openalex.org/W2963430224', 'https://openalex.org/W2964130895', 'https://openalex.org/W2963126845', 'https://openalex.org/W2891488835', 'https://openalex.org/W2962990231', 'https://openalex.org/W2963969878', 'https://openalex.org/W2292919134', 'https://openalex.org/W2963951265', 'https://openalex.org/W2060377713', 'https://openalex.org/W2301095666', 'https://openalex.org/W2264869955', 'https://openalex.org/W2963233086', 'https://openalex.org/W2609368435', 'https://openalex.org/W2549835527', 'https://openalex.org/W2805281898', 'https://openalex.org/W2251869843', 'https://openalex.org/W4238619744', 'https://openalex.org/W2171928131', 'https://openalex.org/W2964200170', 'https://openalex.org/W2657631929', 'https://openalex.org/W2963615251', 'https://openalex.org/W2964142373', 'https://openalex.org/W2295676751', 'https://openalex.org/W2511774920', 'https://openalex.org/W2745565856', 'https://openalex.org/W2029248633', 'https://openalex.org/W2890719433', 'https://openalex.org/W2603766943', 'https://openalex.org/W2963834268', 'https://openalex.org/W2963609017', 'https://openalex.org/W2757667583', 'https://openalex.org/W2888329843', 'https://openalex.org/W2889468083', 'https://openalex.org/W2962843521', 'https://openalex.org/W1971844566', 'https://openalex.org/W2560864221', 'https://openalex.org/W2511550932', 'https://openalex.org/W2799007037', 'https://openalex.org/W2759173152', 'https://openalex.org/W2963098487', 'https://openalex.org/W2963457723', 'https://openalex.org/W2964132420', 'https://openalex.org/W2963957386', 'https://openalex.org/W2963083752', 'https://openalex.org/W2885588803', 'https://openalex.org/W2561386235', 'https://openalex.org/W2563574619', 'https://openalex.org/W2901791692', 'https://openalex.org/W2752194699', 'https://openalex.org/W2897507397', 'https://openalex.org/W2806414572', 'https://openalex.org/W2962911926', 'https://openalex.org/W2799051177', 'https://openalex.org/W2962935543', 'https://openalex.org/W2923014074', 'https://openalex.org/W2748318213', 'https://openalex.org/W2889404673', 'https://openalex.org/W2962799131', 'https://openalex.org/W2963059228', 'https://openalex.org/W2791751435', 'https://openalex.org/W2211192759', 'https://openalex.org/W2963374347', 'https://openalex.org/W2963082289', 'https://openalex.org/W2963526187', 'https://openalex.org/W2099471712', 'https://openalex.org/W2408141691', 'https://openalex.org/W3104033643', 'https://openalex.org/W2896667998', 'https://openalex.org/W3101025374', 'https://openalex.org/W2219598741', 'https://openalex.org/W2133086981', 'https://openalex.org/W2791941932', 'https://openalex.org/W2251012068', 'https://openalex.org/W2808315098', 'https://openalex.org/W2964060510', 'https://openalex.org/W2562979205', 'https://openalex.org/W2606089314', 'https://openalex.org/W2570685808', 'https://openalex.org/W2962965405', 'https://openalex.org/W2963029978', 'https://openalex.org/W2963267799', 'https://openalex.org/W2788924045', 'https://openalex.org/W2951174316', 'https://openalex.org/W2515741950', 'https://openalex.org/W2963661177', 'https://openalex.org/W2735135478', 'https://openalex.org/W2153332911', 'https://openalex.org/W2091818076', 'https://openalex.org/W2963207607', 'https://openalex.org/W2887076749', 'https://openalex.org/W3104570147', 'https://openalex.org/W2594475271', 'https://openalex.org/W2298037295', 'https://openalex.org/W3207342693', 'https://openalex.org/W2962713901', 'https://openalex.org/W2962958286', 'https://openalex.org/W2964153729', 'https://openalex.org/W810147176', 'https://openalex.org/W3099668342', 'https://openalex.org/W3105148948', 'https://openalex.org/W2887665106', 'https://openalex.org/W2964159778', 'https://openalex.org/W2805757971', 'https://openalex.org/W179875071', 'https://openalex.org/W2962813140', 'https://openalex.org/W2899032424', 'https://openalex.org/W2805083708', 'https://openalex.org/W2964174820', 'https://openalex.org/W2053921957', 'https://openalex.org/W2097009961', 'https://openalex.org/W2133564696', 'https://openalex.org/W2531381952', 'https://openalex.org/W2898200493', 'https://openalex.org/W2799118206', 'https://openalex.org/W2773621464', 'https://openalex.org/W2963723151', 'https://openalex.org/W2963846239', 'https://openalex.org/W3099142230', 'https://openalex.org/W2765811634', 'https://openalex.org/W2886197491', 'https://openalex.org/W2963916869', 'https://openalex.org/W2962777840', 'https://openalex.org/W2159426623', 'https://openalex.org/W2785699986', 'https://openalex.org/W2962790223', 'https://openalex.org/W2606308499', 'https://openalex.org/W2259472270', 'https://openalex.org/W2805337546', 'https://openalex.org/W2137735870', 'https://openalex.org/W2594633041', 'https://openalex.org/W3101950626', 'https://openalex.org/W2130942839', 'https://openalex.org/W2964291396', 'https://openalex.org/W2811010710', 'https://openalex.org/W2963174078', 'https://openalex.org/W2574741565', 'https://openalex.org/W2118463056', 'https://openalex.org/W1571111764', 'https://openalex.org/W2777449390', 'https://openalex.org/W4214784700', 'https://openalex.org/W2788527488', 'https://openalex.org/W1951216520', 'https://openalex.org/W2775543300', 'https://openalex.org/W2933374552', 'https://openalex.org/W2786028390', 'https://openalex.org/W2963758829']",2019-04-01
https://openalex.org/W2752168051,https://doi.org/10.48550/arxiv.1709.04482,Analyzing Hidden Representations in End-to-End Automatic Speech Recognition Systems,"Neural models have become ubiquitous in automatic speech recognition systems. While neural networks are typically used as acoustic models in more complex systems, recent studies have explored end-to-end speech recognition systems based on neural networks, which can be trained to directly predict text from input acoustic features. Although such systems are conceptually elegant and simpler than traditional systems, it is less obvious how to interpret the trained models. In this work, we analyze the speech representations learned by a deep end-to-end model that is based on convolutional and recurrent layers, and trained with a connectionist temporal classification (CTC) loss. We use a pre-trained model to generate frame-level features which are given to a classifier that is trained on frame classification into phones. We evaluate representations from different layers of the deep model and compare their quality for predicting phone labels. Our experiments shed light on important aspects of the end-to-end model such as layer depth, model complexity, and other design choices.","['https://openalex.org/W2172097686', 'https://openalex.org/W2607361225', 'https://openalex.org/W2158373110', 'https://openalex.org/W2605717780', 'https://openalex.org/W2580178245', 'https://openalex.org/W2964060510', 'https://openalex.org/W2102113734', 'https://openalex.org/W2077804127', 'https://openalex.org/W3105148948', 'https://openalex.org/W2962826786', 'https://openalex.org/W2949117887', 'https://openalex.org/W1522301498', 'https://openalex.org/W2563574619', 'https://openalex.org/W2545177271', 'https://openalex.org/W1586532344', 'https://openalex.org/W1600744878', 'https://openalex.org/W2963583362', 'https://openalex.org/W1736701665', 'https://openalex.org/W2327501763', 'https://openalex.org/W2064675550', 'https://openalex.org/W2187089797', 'https://openalex.org/W2962949994', 'https://openalex.org/W1494198834', 'https://openalex.org/W2127141656', 'https://openalex.org/W2531381952', 'https://openalex.org/W2586148577', 'https://openalex.org/W2295676751']",2017-09-13
https://openalex.org/W3035750922,https://doi.org/10.18653/v1/2020.acl-main.381,Analyzing analytical methods: The case of phonology in neural models of\n spoken language,"Given the fast development of analysis techniques for NLP and speech\nprocessing systems, few systematic studies have been conducted to compare the\nstrengths and weaknesses of each method. As a step in this direction we study\nthe case of representations of phonology in neural network models of spoken\nlanguage. We use two commonly applied analytical techniques, diagnostic\nclassifiers and representational similarity analysis, to quantify to what\nextent neural activation patterns encode phonemes and phoneme sequences. We\nmanipulate two factors that can affect the outcome of analysis. First, we\ninvestigate the role of learning by comparing neural activations extracted from\ntrained versus randomly-initialized models. Second, we examine the temporal\nscope of the activations by probing both local activations corresponding to a\nfew milliseconds of the speech signal, and global activations pooled over the\nwhole utterance. We conclude that reporting analysis results with randomly\ninitialized models is crucial, and that global-scope methods tend to yield more\nconsistent results and we recommend their use as a complement to local-scope\ndiagnostic methods.\n","['https://openalex.org/W2946296745', 'https://openalex.org/W2137010615', 'https://openalex.org/W2295676751', 'https://openalex.org/W2963525826', 'https://openalex.org/W3105148948', 'https://openalex.org/W1522301498', 'https://openalex.org/W2766219058', 'https://openalex.org/W2963250244', 'https://openalex.org/W2964308564', 'https://openalex.org/W2971709506', 'https://openalex.org/W4289490673', 'https://openalex.org/W2984673553', 'https://openalex.org/W2970971581', 'https://openalex.org/W2964204621', 'https://openalex.org/W4385245566', 'https://openalex.org/W2888912391', 'https://openalex.org/W2963403868', 'https://openalex.org/W2962776659', 'https://openalex.org/W6908809', 'https://openalex.org/W2973047874', 'https://openalex.org/W2556930864', 'https://openalex.org/W1494198834', 'https://openalex.org/W2586148577', 'https://openalex.org/W2103179919', 'https://openalex.org/W2929581986', 'https://openalex.org/W2752168051', 'https://openalex.org/W2972808286', 'https://openalex.org/W2936774411', 'https://openalex.org/W2964121744', 'https://openalex.org/W2515741950', 'https://openalex.org/W2160654481', 'https://openalex.org/W2906152891', 'https://openalex.org/W2964054038', 'https://openalex.org/W4295312788', 'https://openalex.org/W2893141505', 'https://openalex.org/W2962813140', 'https://openalex.org/W2962862718', 'https://openalex.org/W3099142230', 'https://openalex.org/W2194775991', 'https://openalex.org/W2133564696', 'https://openalex.org/W2962780374', 'https://openalex.org/W2963430224']",2020-04-15
https://openalex.org/W2295676751,https://doi.org/10.21437/interspeech.2015-422,Exploring how deep neural networks form phonemic categories,"Deep neural networks (DNNs) have become the dominant technique for acoustic-phonetic modeling due to their markedly improved performance over other models. Despite this, little is understood about the computation they implement in creating phonemic categories from highly variable acoustic signals. In this paper, we analyzed a DNN trained for phoneme recognition and characterized its representational properties, both at the single node and population level in each layer. At the single node level, we found strong selectivity to distinct phonetic features in all layers. Node selectivity to specific manners and places of articulation appeared from the first hidden layer and became more explicit in deeper layers. Furthermore, we found that nodes with similar phonetic feature selectivity were differentially activated to different exemplars of these features. Thus, each node becomes tuned to a particular acoustic manifestation of the same feature, providing an effective representational basis for the formation of invariant phonemic categories. This study reveals that phonetic features organize the activations in different layers of a DNN, a result that mirrors the recent findings of feature encoding in the human auditory system. These insights may provide better understanding of the limitations of current models, leading to new strategies to improve their performance. Index Terms: Deep neural networks, deep learning, automatic speech recognition.","['https://openalex.org/W2091432990', 'https://openalex.org/W2032759346', 'https://openalex.org/W2028119394', 'https://openalex.org/W2483020829', 'https://openalex.org/W1992153276', 'https://openalex.org/W1598851216', 'https://openalex.org/W2136922672', 'https://openalex.org/W2079207700', 'https://openalex.org/W2140372979', 'https://openalex.org/W2147768505', 'https://openalex.org/W2964153729', 'https://openalex.org/W2172097686', 'https://openalex.org/W2296748324', 'https://openalex.org/W1849277567', 'https://openalex.org/W1970533835', 'https://openalex.org/W1993882792', 'https://openalex.org/W1558874939', 'https://openalex.org/W2213952365', 'https://openalex.org/W2160815625', 'https://openalex.org/W1595178389']",2015-09-06
https://openalex.org/W2160654481,https://doi.org/10.3389/neuro.06.004.2008,Representational similarity analysis – connecting the branches of systems neuroscience,"A FUNDAMENTAL CHALLENGE FOR SYSTEMS NEUROSCIENCE IS TO QUANTITATIVELY RELATE ITS THREE MAJOR BRANCHES OF RESEARCH: brain-activity measurement, behavioral measurement, and computational modeling. Using measured brain-activity patterns to evaluate computational network models is complicated by the need to define the correspondency between the units of the model and the channels of the brain-activity data, e.g., single-cell recordings or voxels from functional magnetic resonance imaging (fMRI). Similar correspondency problems complicate relating activity patterns between different modalities of brain-activity measurement (e.g., fMRI and invasive or scalp electrophysiology), and between subjects and species. In order to bridge these divides, we suggest abstracting from the activity patterns themselves and computing representational dissimilarity matrices (RDMs), which characterize the information carried by a given representation in a brain or model. Building on a rich psychological and mathematical literature on similarity analysis, we propose a new experimental and data-analytical framework called representational similarity analysis (RSA), in which multi-channel measures of neural activity are quantitatively related to each other and to computational theory and behavior by comparing RDMs. We demonstrate RSA by relating representations of visual objects as measured with fMRI in early visual cortex and the fusiform face area to computational models spanning a wide range of complexities. The RDMs are simultaneously related via second-level application of multidimensional scaling and tested using randomization and bootstrap techniques. We discuss the broad potential of RSA, including novel approaches to experimental design, and argue that these ideas, which have deep roots in psychology and neuroscience, will allow the integrated quantitative analysis of data from all three branches, thus contributing to a more unified systems neuroscience.","['https://openalex.org/W2138727818', 'https://openalex.org/W6655065987', 'https://openalex.org/W2131996077', 'https://openalex.org/W2093443629', 'https://openalex.org/W2108997568', 'https://openalex.org/W6650404239', 'https://openalex.org/W2075770396', 'https://openalex.org/W2110437310', 'https://openalex.org/W6647199041', 'https://openalex.org/W2116649573', 'https://openalex.org/W6656961601', 'https://openalex.org/W6652227577', 'https://openalex.org/W2000908757', 'https://openalex.org/W7055040554', 'https://openalex.org/W6673765422', 'https://openalex.org/W2171178117', 'https://openalex.org/W2099571672', 'https://openalex.org/W2048631316', 'https://openalex.org/W2123544472', 'https://openalex.org/W6828693573', 'https://openalex.org/W2002660165', 'https://openalex.org/W2009284521', 'https://openalex.org/W2139906140', 'https://openalex.org/W2161126623', 'https://openalex.org/W2172168442', 'https://openalex.org/W2089632738', 'https://openalex.org/W2041716195', 'https://openalex.org/W2077477064', 'https://openalex.org/W6664538703', 'https://openalex.org/W2166130385', 'https://openalex.org/W6649948367', 'https://openalex.org/W2036084760', 'https://openalex.org/W2159383776', 'https://openalex.org/W6682932459', 'https://openalex.org/W6648925459', 'https://openalex.org/W2170117095', 'https://openalex.org/W2049075375', 'https://openalex.org/W2011804471', 'https://openalex.org/W2111609296', 'https://openalex.org/W6666352833', 'https://openalex.org/W2041045861', 'https://openalex.org/W2002476095', 'https://openalex.org/W2141287989', 'https://openalex.org/W2112532472', 'https://openalex.org/W2007804187', 'https://openalex.org/W2123923307', 'https://openalex.org/W2071714163', 'https://openalex.org/W2050717100', 'https://openalex.org/W1544637914', 'https://openalex.org/W2132447257', 'https://openalex.org/W1968635050', 'https://openalex.org/W6674609164', 'https://openalex.org/W6663771851', 'https://openalex.org/W2053186076', 'https://openalex.org/W1980914952', 'https://openalex.org/W2132172482', 'https://openalex.org/W1624854622', 'https://openalex.org/W2086220442', 'https://openalex.org/W2063910430', 'https://openalex.org/W6667273186', 'https://openalex.org/W765247945', 'https://openalex.org/W2152832320', 'https://openalex.org/W2025472057', 'https://openalex.org/W2001141328', 'https://openalex.org/W6664635345', 'https://openalex.org/W2005815123', 'https://openalex.org/W131918210', 'https://openalex.org/W2052404970', 'https://openalex.org/W2080514369', 'https://openalex.org/W2051691068', 'https://openalex.org/W6665420608', 'https://openalex.org/W2096289837', 'https://openalex.org/W1998475172', 'https://openalex.org/W2007226897', 'https://openalex.org/W3046579346', 'https://openalex.org/W2129158941', 'https://openalex.org/W2066851670', 'https://openalex.org/W2319824271', 'https://openalex.org/W2000133833', 'https://openalex.org/W4380030747', 'https://openalex.org/W2025283285', 'https://openalex.org/W2097560155', 'https://openalex.org/W2092939357', 'https://openalex.org/W2118332749', 'https://openalex.org/W2116495562', 'https://openalex.org/W1994310769', 'https://openalex.org/W2056957254', 'https://openalex.org/W2058713030', 'https://openalex.org/W2073683361', 'https://openalex.org/W2106664807', 'https://openalex.org/W2125299581', 'https://openalex.org/W4249632413', 'https://openalex.org/W2062240844', 'https://openalex.org/W2051650830', 'https://openalex.org/W3127623214', 'https://openalex.org/W3203780707', 'https://openalex.org/W2056930330', 'https://openalex.org/W2188850810', 'https://openalex.org/W2132914434', 'https://openalex.org/W2007483873', 'https://openalex.org/W769359332', 'https://openalex.org/W1486735428', 'https://openalex.org/W2123341385', 'https://openalex.org/W2041853331', 'https://openalex.org/W2154141654', 'https://openalex.org/W2018528947', 'https://openalex.org/W1998871699', 'https://openalex.org/W3099839986', 'https://openalex.org/W4231923904', 'https://openalex.org/W1987733777', 'https://openalex.org/W2160448907', 'https://openalex.org/W4246354968', 'https://openalex.org/W2114104729', 'https://openalex.org/W2059982399', 'https://openalex.org/W2124264256', 'https://openalex.org/W4249293656', 'https://openalex.org/W4248055992']",2008-01-01
https://openalex.org/W2946296745,https://doi.org/10.18653/v1/p19-1283,Correlating Neural and Symbolic Representations of Language,"Analysis methods which enable us to better understand the representations and\nfunctioning of neural models of language are increasingly needed as deep\nlearning becomes the dominant approach in NLP. Here we present two methods\nbased on Representational Similarity Analysis (RSA) and Tree Kernels (TK) which\nallow us to directly quantify how strongly the information encoded in neural\nactivation patterns corresponds to information represented by symbolic\nstructures such as syntax trees. We first validate our methods on the case of a\nsimple synthetic language for arithmetic expressions with clearly defined\nsyntax and semantics, and show that they exhibit the expected pattern of\nresults. We then apply our methods to correlate neural representations of\nEnglish sentences with their constituency parse trees.\n","['https://openalex.org/W1787224781', 'https://openalex.org/W2963644595', 'https://openalex.org/W4385245566', 'https://openalex.org/W2761988601', 'https://openalex.org/W2950976310', 'https://openalex.org/W2963525826', 'https://openalex.org/W2896457183', 'https://openalex.org/W2963403868', 'https://openalex.org/W2250263931', 'https://openalex.org/W2962776659', 'https://openalex.org/W2963341956', 'https://openalex.org/W3102226577', 'https://openalex.org/W4288351520', 'https://openalex.org/W2893141505', 'https://openalex.org/W2274405424', 'https://openalex.org/W4254816979', 'https://openalex.org/W2963753324', 'https://openalex.org/W2962739339', 'https://openalex.org/W2913124272', 'https://openalex.org/W224064951', 'https://openalex.org/W2110485445', 'https://openalex.org/W4289490673', 'https://openalex.org/W2786464815', 'https://openalex.org/W2889636732', 'https://openalex.org/W2888912391', 'https://openalex.org/W2963918774', 'https://openalex.org/W1486649854', 'https://openalex.org/W2740290232', 'https://openalex.org/W2493916176', 'https://openalex.org/W2906152891', 'https://openalex.org/W2610858497', 'https://openalex.org/W3105148948', 'https://openalex.org/W2160654481', 'https://openalex.org/W2914557243', 'https://openalex.org/W2127713198', 'https://openalex.org/W2799124508', 'https://openalex.org/W2064675550', 'https://openalex.org/W2130632639', 'https://openalex.org/W2963430224']",2019-01-01
https://openalex.org/W4230640548,https://doi.org/10.31234/osf.io/37zna,"Can phones, syllables, and words emerge as side-products of cross-situational audiovisual learning? - A computational investigation","Database hosting this document is corrupted and OSF is unable to fix it. Please refer to https://doi.org/10.34842/w3vw-s845 for openly available manuscript. ------- Previous abstract ------ Decades of research has studied how language learning infants learn to discriminate speech sounds, segment words, and associate words with their meanings. While gradual development of such capabilities is unquestionable, the exact nature of these skills and the underlying mental representations yet remains unclear. In parallel, computational studies have shown that basic comprehension of speech can be achieved by statistical learning between speech and concurrent referentially ambiguous visual input. These models can operate without prior linguistic knowledge such as representations of linguistic units, and without learning mechanisms specifically targeted at such units. This has raised the question of to what extent knowledge of linguistic units, such as phone(me)s, syllables, and words, could actually emerge as latent representations supporting the translation between speech and representations in other modalities, and without the units being proximal learning targets for the learner. In this study, we formulate this idea as the so-called latent language hypothesis (LLH), connecting linguistic representation learning to general predictive processing within and across sensory modalities. We review the extent that the audiovisual aspect of LLH is supported by the existing computational studies. We then explore LLH further in extensive learning simulations with different neural network models for audiovisual cross-situational learning, and comparing learning from both synthetic and real speech data. We investigate whether the latent representations learned by the networks reflect phonetic, syllabic, or lexical structure of input speech by utilizing an array of complementary evaluation metrics related to linguistic selectivity and temporal characteristics of the representations. As a result, we find that representations associated with phonetic, syllabic, and lexical units of speech indeed emerge from the audiovisual learning process. The finding is also robust against variations in model architecture or characteristics of model training and testing data. The results suggest that cross-modal and cross-situational learning may, in principle, assist in early language development much beyond just enabling association of acoustic word forms to their referential meanings.",[],2021-02-17
https://openalex.org/W2127713198,https://doi.org/10.7551/mitpress/1120.003.0085,Convolution Kernels for Natural Language,"We describe the application of kernel methods to Natural Language Processing (NLP) problems. In many NLP tasks the objects being modeled are strings, trees, graphs or other discrete structures which require some mechanism to convert them into feature vectors. We describe kernels for various natural language structures, allowing rich, high dimensional representations of these structures. We show how a kernel over trees can be applied to parsing using the voted perceptron algorithm, and we give experimental results on the ATIS corpus of parse trees.","['https://openalex.org/W2554813760', 'https://openalex.org/W1844099549', 'https://openalex.org/W2107425660', 'https://openalex.org/W3021452258', 'https://openalex.org/W2098379588', 'https://openalex.org/W1526146785', 'https://openalex.org/W1539587067', 'https://openalex.org/W1580051296', 'https://openalex.org/W2119821739', 'https://openalex.org/W3002694247', 'https://openalex.org/W1992254746', 'https://openalex.org/W2726537443', 'https://openalex.org/W1576213419', 'https://openalex.org/W1632114991', 'https://openalex.org/W1979711143', 'https://openalex.org/W4285719527']",2002-11-08
https://openalex.org/W3196986263,https://doi.org/10.1162/tacl_a_00519,Neuron-level Interpretation of Deep NLP Models: A Survey,"Abstract The proliferation of Deep Neural Networks in various domains has seen an increased need for interpretability of these models. Preliminary work done along this line, and papers that surveyed such, are focused on high-level representation analysis. However, a recent branch of work has concentrated on interpretability at a more granular level of analyzing neurons within these models. In this paper, we survey the work done on neuron analysis including: i) methods to discover and understand neurons in a network; ii) evaluation methods; iii) major findings including cross architectural comparisons that neuron analysis has unraveled; iv) applications of neuron probing such as: controlling the model, domain adaptation, and so forth; and v) a discussion on open issues and future research directions.","['https://openalex.org/W6726295259', 'https://openalex.org/W3176390156', 'https://openalex.org/W6795792319', 'https://openalex.org/W6802754217', 'https://openalex.org/W4287887120', 'https://openalex.org/W6679434410', 'https://openalex.org/W6755641643', 'https://openalex.org/W2605717780', 'https://openalex.org/W2997244573', 'https://openalex.org/W6747233023', 'https://openalex.org/W6602483677', 'https://openalex.org/W6628754748', 'https://openalex.org/W2964204621', 'https://openalex.org/W6794025307', 'https://openalex.org/W2963400886', 'https://openalex.org/W6838978922', 'https://openalex.org/W3104136798', 'https://openalex.org/W3106325613', 'https://openalex.org/W6755207826', 'https://openalex.org/W6773354836', 'https://openalex.org/W6751739117', 'https://openalex.org/W3174088532', 'https://openalex.org/W3104350794', 'https://openalex.org/W3159900299', 'https://openalex.org/W2140610559', 'https://openalex.org/W3031652686', 'https://openalex.org/W2962816513', 'https://openalex.org/W6751979845', 'https://openalex.org/W2296540674', 'https://openalex.org/W2964108524', 'https://openalex.org/W3137415782', 'https://openalex.org/W3102812725', 'https://openalex.org/W2970862333', 'https://openalex.org/W2826721128', 'https://openalex.org/W6638529280', 'https://openalex.org/W2292919134', 'https://openalex.org/W6640820311', 'https://openalex.org/W2922523190', 'https://openalex.org/W6636133922', 'https://openalex.org/W6730559633', 'https://openalex.org/W6718991148', 'https://openalex.org/W6760434389', 'https://openalex.org/W6737947904', 'https://openalex.org/W2786672974', 'https://openalex.org/W6775623058', 'https://openalex.org/W3101717721', 'https://openalex.org/W6636510571', 'https://openalex.org/W3037626499', 'https://openalex.org/W6759471849', 'https://openalex.org/W2792641098', 'https://openalex.org/W3035305735', 'https://openalex.org/W2892156241', 'https://openalex.org/W6745682157', 'https://openalex.org/W6793772038', 'https://openalex.org/W4283691240', 'https://openalex.org/W6810864673', 'https://openalex.org/W4246122894', 'https://openalex.org/W6777454573', 'https://openalex.org/W6734194636', 'https://openalex.org/W6679436768', 'https://openalex.org/W2946417913', 'https://openalex.org/W2962911926', 'https://openalex.org/W6771587362', 'https://openalex.org/W6607433388', 'https://openalex.org/W3104235057', 'https://openalex.org/W3022561973', 'https://openalex.org/W2971237698', 'https://openalex.org/W2914924671', 'https://openalex.org/W6733905848', 'https://openalex.org/W2963813662', 'https://openalex.org/W4298324854', 'https://openalex.org/W2964159778', 'https://openalex.org/W2799124508', 'https://openalex.org/W2963751529', 'https://openalex.org/W3099668342', 'https://openalex.org/W1951216520', 'https://openalex.org/W2562979205', 'https://openalex.org/W2950577311', 'https://openalex.org/W3117696238', 'https://openalex.org/W1847618513', 'https://openalex.org/W2549835527', 'https://openalex.org/W2963150021', 'https://openalex.org/W2964308564', 'https://openalex.org/W2515741950', 'https://openalex.org/W4299527668', 'https://openalex.org/W2590082389', 'https://openalex.org/W2767204723', 'https://openalex.org/W2964303116', 'https://openalex.org/W2888922637', 'https://openalex.org/W60493759', 'https://openalex.org/W2805390961', 'https://openalex.org/W2594633041', 'https://openalex.org/W2923014074', 'https://openalex.org/W3024936740', 'https://openalex.org/W2133564696', 'https://openalex.org/W2130942839', 'https://openalex.org/W2995648150', 'https://openalex.org/W3098680936', 'https://openalex.org/W4382202746', 'https://openalex.org/W2963483561', 'https://openalex.org/W182298072', 'https://openalex.org/W3169168151', 'https://openalex.org/W3014794741', 'https://openalex.org/W4296157158', 'https://openalex.org/W2612690371', 'https://openalex.org/W3144194608', 'https://openalex.org/W3167660944', 'https://openalex.org/W3034487470', 'https://openalex.org/W2963503967', 'https://openalex.org/W3170463198', 'https://openalex.org/W2896457183', 'https://openalex.org/W2962790223', 'https://openalex.org/W3152884768']",2022-01-01
https://openalex.org/W224064951,,Making Tree Kernels Practical for Natural Language Learning.,"In recent years tree kernels have been proposed for the automatic learning of natural language applications. Unfortunately, they show (a) an inherent super linear complexity and (b) a lower accuracy than traditional attribute/value methods.","['https://openalex.org/W2131297983', 'https://openalex.org/W2086004682', 'https://openalex.org/W2116786260', 'https://openalex.org/W12836875', 'https://openalex.org/W1632114991', 'https://openalex.org/W2050751769', 'https://openalex.org/W2151170651', 'https://openalex.org/W2138043057', 'https://openalex.org/W2154626406', 'https://openalex.org/W1480643256', 'https://openalex.org/W2107425660', 'https://openalex.org/W1981082061', 'https://openalex.org/W2009082462', 'https://openalex.org/W2120814856', 'https://openalex.org/W147273232', 'https://openalex.org/W1576520375']",2006-04-01
https://openalex.org/W2982223350,https://doi.org/10.1109/icassp40776.2020.9054458,Mockingjay: Unsupervised Speech Representation Learning with Deep Bidirectional Transformer Encoders,"We present Mockingjay as a new speech representation learning approach, where\nbidirectional Transformer encoders are pre-trained on a large amount of\nunlabeled speech. Previous speech representation methods learn through\nconditioning on past frames and predicting information about future frames.\nWhereas Mockingjay is designed to predict the current frame through jointly\nconditioning on both past and future contexts. The Mockingjay representation\nimproves performance for a wide range of downstream tasks, including phoneme\nclassification, speaker recognition, and sentiment classification on spoken\ncontent, while outperforming other approaches. Mockingjay is empirically\npowerful and can be fine-tuned with downstream models, with only 2 epochs we\nfurther improve performance dramatically. In a low resource setting with only\n0.1% of labeled data, we outperform the result of Mel-features that uses all\n100% labeled data.\n","['https://openalex.org/W2947445680', 'https://openalex.org/W6607333740', 'https://openalex.org/W6755207826', 'https://openalex.org/W6780226713', 'https://openalex.org/W2964089206', 'https://openalex.org/W2972451902', 'https://openalex.org/W6737778391', 'https://openalex.org/W2270070752', 'https://openalex.org/W6766673545', 'https://openalex.org/W6768021236', 'https://openalex.org/W2963571336', 'https://openalex.org/W2963425185', 'https://openalex.org/W2972943112', 'https://openalex.org/W2842511635', 'https://openalex.org/W2979476256', 'https://openalex.org/W2973049979', 'https://openalex.org/W3100270690', 'https://openalex.org/W2998649947', 'https://openalex.org/W6739901393', 'https://openalex.org/W2962739339', 'https://openalex.org/W6631190155', 'https://openalex.org/W1494198834', 'https://openalex.org/W2747874407', 'https://openalex.org/W6674330103', 'https://openalex.org/W2883409523', 'https://openalex.org/W2996428491', 'https://openalex.org/W2943493972', 'https://openalex.org/W4297808394', 'https://openalex.org/W3125709657', 'https://openalex.org/W2613904329', 'https://openalex.org/W2336585117', 'https://openalex.org/W2975059944', 'https://openalex.org/W2787560479', 'https://openalex.org/W2965373594', 'https://openalex.org/W1522301498', 'https://openalex.org/W4385245566', 'https://openalex.org/W2996383576', 'https://openalex.org/W179875071', 'https://openalex.org/W2896457183', 'https://openalex.org/W2626778328', 'https://openalex.org/W3037932933', 'https://openalex.org/W2095705004']",2020-04-09
https://openalex.org/W2151083697,https://doi.org/10.1016/j.specom.2011.07.009,Prosodic and temporal features for language modeling for dialog,,"['https://openalex.org/W1977021391', 'https://openalex.org/W2167797279', 'https://openalex.org/W2018128570', 'https://openalex.org/W6636685859', 'https://openalex.org/W1974098752', 'https://openalex.org/W2118938353', 'https://openalex.org/W2020073413', 'https://openalex.org/W6680532216', 'https://openalex.org/W2016597489', 'https://openalex.org/W2140624706', 'https://openalex.org/W2162520983', 'https://openalex.org/W6638882188', 'https://openalex.org/W1568653222', 'https://openalex.org/W6629637077', 'https://openalex.org/W2012798429', 'https://openalex.org/W2140615673', 'https://openalex.org/W2143331706', 'https://openalex.org/W2166637769', 'https://openalex.org/W6757851854', 'https://openalex.org/W7030227021', 'https://openalex.org/W6657657388', 'https://openalex.org/W2078179100', 'https://openalex.org/W2046811668', 'https://openalex.org/W6879422177', 'https://openalex.org/W2010505910', 'https://openalex.org/W2071172502', 'https://openalex.org/W2115501357', 'https://openalex.org/W1964384448', 'https://openalex.org/W2067097374', 'https://openalex.org/W2153190547', 'https://openalex.org/W2086207208', 'https://openalex.org/W2133054063', 'https://openalex.org/W6678672963', 'https://openalex.org/W1631260214', 'https://openalex.org/W1582730572', 'https://openalex.org/W1981249277', 'https://openalex.org/W2134473538', 'https://openalex.org/W1972873790', 'https://openalex.org/W2071473964', 'https://openalex.org/W50922381', 'https://openalex.org/W2118748593', 'https://openalex.org/W113213642', 'https://openalex.org/W2123025256', 'https://openalex.org/W4390926600', 'https://openalex.org/W2148367388', 'https://openalex.org/W2071315630', 'https://openalex.org/W1508165687', 'https://openalex.org/W1903951673', 'https://openalex.org/W1996419606', 'https://openalex.org/W1984218255', 'https://openalex.org/W634071039', 'https://openalex.org/W1491238342', 'https://openalex.org/W2551521043', 'https://openalex.org/W2501398076', 'https://openalex.org/W2028109239', 'https://openalex.org/W2123409957', 'https://openalex.org/W157494344', 'https://openalex.org/W2159398820', 'https://openalex.org/W2998704965', 'https://openalex.org/W2004729255', 'https://openalex.org/W2151293530', 'https://openalex.org/W1632402631', 'https://openalex.org/W2141885148', 'https://openalex.org/W2395318165', 'https://openalex.org/W4285719527', 'https://openalex.org/W1838628832', 'https://openalex.org/W2911776943', 'https://openalex.org/W335758531', 'https://openalex.org/W1963080254', 'https://openalex.org/W1494910745']",2011-08-13
https://openalex.org/W4392931281,https://doi.org/10.1109/icassp48485.2024.10446933,Paralinguistics-Enhanced Large Language Modeling of Spoken Dialogue,"Large Language Models (LLMs) have demonstrated superior abilities in tasks such as chatting, reasoning, and question-answering. However, standard LLMs may ignore crucial paralinguistic information, such as sentiment, emotion, and speaking style, which are essential for achieving natural, human-like spoken conversation, especially when such information is conveyed by acoustic cues. We therefore propose Paralinguistics-enhanced Generative Pretrained Transformer (ParalinGPT), an LLM that utilizes text and speech modalities to better model the linguistic content and paralinguistic attributes of spoken dialogue. The model takes the conversational context of text, speech embeddings, and paralinguistic attributes as input prompts within a serialized multitasking multimodal framework. Specifically, our framework serializes tasks in the order of current paralinguistic attribute prediction, response paralinguistic attribute prediction, and response text generation with autoregressive conditioning. We utilize the Switchboard-1 corpus, including its sentiment labels as the paralinguistic attribute, as our spoken dialogue dataset. Experimental results indicate the proposed serialized multitasking method outperforms typical sequence classification techniques on current and response sentiment classification. Furthermore, leveraging conversational context and speech embeddings significantly improves both response text generation and sentiment prediction. Our proposed framework achieves relative improvements of 6.7%, 12.0%, and 3.5% in current sentiment accuracy, response sentiment accuracy, and response text BLEU score, respectively.","['https://openalex.org/W6851678396', 'https://openalex.org/W6763494226', 'https://openalex.org/W2766833041', 'https://openalex.org/W4293714393', 'https://openalex.org/W2952088495', 'https://openalex.org/W3048664667', 'https://openalex.org/W3153025627', 'https://openalex.org/W3174716116', 'https://openalex.org/W2128970689', 'https://openalex.org/W2151083697', 'https://openalex.org/W2897636448', 'https://openalex.org/W6804073865', 'https://openalex.org/W4285273040', 'https://openalex.org/W2936162287', 'https://openalex.org/W6791303579', 'https://openalex.org/W2548264631', 'https://openalex.org/W2586286573', 'https://openalex.org/W4319862652', 'https://openalex.org/W2968228919', 'https://openalex.org/W3095607145', 'https://openalex.org/W4385823311', 'https://openalex.org/W6790356757', 'https://openalex.org/W3198217962', 'https://openalex.org/W4307680525', 'https://openalex.org/W4381786045', 'https://openalex.org/W6853998256', 'https://openalex.org/W4389524500', 'https://openalex.org/W3015489952', 'https://openalex.org/W3197236059', 'https://openalex.org/W6780218876', 'https://openalex.org/W3198771897', 'https://openalex.org/W4319862479', 'https://openalex.org/W2166637769', 'https://openalex.org/W6778490555', 'https://openalex.org/W4381827575', 'https://openalex.org/W3036601975', 'https://openalex.org/W4394671563', 'https://openalex.org/W3133903425', 'https://openalex.org/W4366559955', 'https://openalex.org/W3193377986', 'https://openalex.org/W4226422436']",2024-03-18
https://openalex.org/W4307323391,https://doi.org/10.48550/arxiv.2210.13438,High Fidelity Neural Audio Compression,"We introduce a state-of-the-art real-time, high-fidelity, audio codec leveraging neural networks. It consists in a streaming encoder-decoder architecture with quantized latent space trained in an end-to-end fashion. We simplify and speed-up the training by using a single multiscale spectrogram adversary that efficiently reduces artifacts and produce high-quality samples. We introduce a novel loss balancer mechanism to stabilize training: the weight of a loss now defines the fraction of the overall gradient it should represent, thus decoupling the choice of this hyper-parameter from the typical scale of the loss. Finally, we study how lightweight Transformer models can be used to further compress the obtained representation by up to 40%, while staying faster than real time. We provide a detailed description of the key design choices of the proposed model including: training objective, architectural changes and a study of various perceptual loss functions. We present an extensive subjective evaluation (MUSHRA tests) together with an ablation study for a range of bandwidths and audio domains, including speech, noisy-reverberant speech, and music. Our approach is superior to the baselines methods across all evaluated settings, considering both 24 kHz monophonic and 48 kHz stereophonic audio. Code and models are available at github.com/facebookresearch/encodec.",[],2022-10-24
https://openalex.org/W4390075359,https://doi.org/10.1162/tacl_a_00618,"Speak, Read and Prompt: High-Fidelity Text-to-Speech with Minimal Supervision","Abstract We introduce SPEAR-TTS, a multi-speaker text-to-speech (TTS) system that can be trained with minimal supervision. By combining two types of discrete speech representations, we cast TTS as a composition of two sequence-to-sequence tasks: from text to high-level semantic tokens (akin to “reading”) and from semantic tokens to low-level acoustic tokens (“speaking”). Decoupling these two tasks enables training of the “speaking” module using abundant audio-only data, and unlocks the highly efficient combination of pretraining and backtranslation to reduce the need for parallel data when training the “reading” component. To control the speaker identity, we adopt example prompting, which allows SPEAR-TTS to generalize to unseen speakers using only a short sample of 3 seconds, without any explicit speaker representation or speaker labels. Our experiments demonstrate that SPEAR-TTS achieves a character error rate that is competitive with state-of-the-art methods using only 15 minutes of parallel data, while matching ground-truth speech in naturalness and acoustic quality.","['https://openalex.org/W6849105126', 'https://openalex.org/W3205644108', 'https://openalex.org/W4381786045', 'https://openalex.org/W6778883912', 'https://openalex.org/W6805710207', 'https://openalex.org/W3209984917', 'https://openalex.org/W4226033575', 'https://openalex.org/W6800767084', 'https://openalex.org/W2889326796', 'https://openalex.org/W6638667902', 'https://openalex.org/W6917585676', 'https://openalex.org/W4380874786', 'https://openalex.org/W2995181338', 'https://openalex.org/W3198217962', 'https://openalex.org/W6804184754', 'https://openalex.org/W6849956205', 'https://openalex.org/W6783867762', 'https://openalex.org/W4385574033', 'https://openalex.org/W6790356757', 'https://openalex.org/W4296068981', 'https://openalex.org/W3034999214', 'https://openalex.org/W6810406373', 'https://openalex.org/W3015419784', 'https://openalex.org/W4307680525', 'https://openalex.org/W1494198834', 'https://openalex.org/W4285182272', 'https://openalex.org/W3140429000', 'https://openalex.org/W6769627184', 'https://openalex.org/W3161480375', 'https://openalex.org/W3033411150', 'https://openalex.org/W3016181583', 'https://openalex.org/W6853998256', 'https://openalex.org/W2963216553', 'https://openalex.org/W6751104502', 'https://openalex.org/W2964243274', 'https://openalex.org/W6677920722', 'https://openalex.org/W6739901393', 'https://openalex.org/W6848735303', 'https://openalex.org/W3215615641', 'https://openalex.org/W2972359262', 'https://openalex.org/W4394671563', 'https://openalex.org/W4288089799', 'https://openalex.org/W4381827575', 'https://openalex.org/W4296070453', 'https://openalex.org/W4320459320', 'https://openalex.org/W4318351475', 'https://openalex.org/W4385245566', 'https://openalex.org/W3198123200', 'https://openalex.org/W3215895588', 'https://openalex.org/W3092028330', 'https://openalex.org/W4313679638', 'https://openalex.org/W4292779060']",2023-01-01
https://openalex.org/W4386132131,https://doi.org/10.1109/lsp.2023.3308474,LM-VC: Zero-Shot Voice Conversion via Speech Generation Based on Language Models,"Language model (LM) based audio generation frameworks, e.g., AudioLM, have recently achieved new state-of-the-art performance in zero-shot audio generation. In this paper, we explore the feasibility of LMs for <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">zero-shot voice conversion</i> . An intuitive approach is to follow AudioLM – Tokenizing speech into semantic and acoustic tokens respectively by HuBERT and SoundStream, and converting source semantic tokens to target acoustic tokens conditioned on acoustic tokens of the target speaker. However, such an approach encounters several issues: 1) the linguistic content contained in semantic tokens may get dispersed during multi-layer modeling while the lengthy speech input in the voice conversion task makes contextual learning even harder; 2) the semantic tokens still contain speaker-related information, which may be leaked to the target speech, lowering the target speaker similarity; 3) the generation diversity in the sampling of the LM can lead to unexpected outcomes during inference, leading to unnatural pronunciation and speech quality degradation. To mitigate these problems, we propose <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">LM-VC</i> , a two-stage language modeling approach that generates coarse acoustic tokens for recovering the source linguistic content and target speaker's timbre, and then reconstructs the fine for acoustic details as converted speech. Specifically, to enhance content preservation and facilitates better disentanglement, a masked prefix LM with a mask prediction strategy is used for coarse acoustic modeling. This model is encouraged to recover the masked content from the surrounding context and generate target speech based on the target speaker's utterance and corrupted semantic tokens. Besides, to further alleviate the sampling error in the generation, an external LM, which employs window attention to capture the local acoustic relations, is introduced to participate in the coarse acoustic modeling through shallow fusion. Finally, a prefix LM reconstructs fine acoustic tokens from the coarse and results in the converted speech. Experiments demonstrate that LM-VC outperforms competitive systems in speech naturalness and speaker similarity.","['https://openalex.org/W6762533536', 'https://openalex.org/W6776390925', 'https://openalex.org/W6802029025', 'https://openalex.org/W2518172956', 'https://openalex.org/W6803547063', 'https://openalex.org/W3161627112', 'https://openalex.org/W6810447587', 'https://openalex.org/W2972659941', 'https://openalex.org/W6852638271', 'https://openalex.org/W3197659778', 'https://openalex.org/W3198082505', 'https://openalex.org/W4221141917', 'https://openalex.org/W3162390194', 'https://openalex.org/W4381786045', 'https://openalex.org/W6849105126', 'https://openalex.org/W6848735303', 'https://openalex.org/W4390075359', 'https://openalex.org/W3209059054', 'https://openalex.org/W3138516171', 'https://openalex.org/W6640059789', 'https://openalex.org/W6805710207', 'https://openalex.org/W3215615641', 'https://openalex.org/W4385245566', 'https://openalex.org/W4285294723', 'https://openalex.org/W6762122294', 'https://openalex.org/W6844194202', 'https://openalex.org/W6780218876', 'https://openalex.org/W6794185780', 'https://openalex.org/W2972359262', 'https://openalex.org/W1494198834', 'https://openalex.org/W6936113694', 'https://openalex.org/W6603838645', 'https://openalex.org/W6634186343', 'https://openalex.org/W4296069138', 'https://openalex.org/W3024869864', 'https://openalex.org/W2091318760', 'https://openalex.org/W6854308872', 'https://openalex.org/W6852503157', 'https://openalex.org/W3152740956', 'https://openalex.org/W3197358873', 'https://openalex.org/W4318351475', 'https://openalex.org/W4376632433', 'https://openalex.org/W4297808394', 'https://openalex.org/W4313679638', 'https://openalex.org/W4376632463', 'https://openalex.org/W1572989473', 'https://openalex.org/W4384648639', 'https://openalex.org/W1915251500', 'https://openalex.org/W3202267900', 'https://openalex.org/W3154308281']",2023-01-01
https://openalex.org/W4392902611,https://doi.org/10.1109/icassp48485.2024.10447774,Low-Latency Speech Enhancement via Speech Token Generation,"Existing deep learning based speech enhancement mainly employ a data-driven approach, which leverage large amounts of data with a variety of noise types to achieve noise removal from noisy signal. However, the high dependence on the data limits its generalization on the unseen complex noises in real-life environment. In this paper, we focus on the low-latency scenario and regard speech enhancement as a speech generation problem conditioned on the noisy signal, where we generate clean speech instead of identifying and removing noises. Specifically, we propose a conditional generative framework for speech enhancement, which models clean speech by acoustic codes of a neural speech codec and generates the speech codes conditioned on past noisy frames in an auto-regressive way. Moreover, we propose an explicitalignment approach to align noisy frames with the generated speech tokens to improve the robustness and scalability to different input lengths. Different from other methods that leverage multiple stages to generate speech codes, we leverage a single-stage speech generation approach based on the TF-Codec neural codec to achieve high speech quality with low latency. Extensive results on both synthetic and real-recorded test set show its superiority over data-driven approaches in terms of noise robustness and temporal speech coherence.","['https://openalex.org/W2952218014', 'https://openalex.org/W3015199127', 'https://openalex.org/W2996969697', 'https://openalex.org/W2404892923', 'https://openalex.org/W2998161426', 'https://openalex.org/W2940275453', 'https://openalex.org/W2069681747', 'https://openalex.org/W1482149378', 'https://openalex.org/W2291877678', 'https://openalex.org/W1897240248', 'https://openalex.org/W3096159803', 'https://openalex.org/W3163296124', 'https://openalex.org/W4200483526', 'https://openalex.org/W4372266927', 'https://openalex.org/W4381786045', 'https://openalex.org/W6848735303', 'https://openalex.org/W4225287045', 'https://openalex.org/W4377231659', 'https://openalex.org/W4225905067', 'https://openalex.org/W4225302959', 'https://openalex.org/W4221167707', 'https://openalex.org/W3099330747', 'https://openalex.org/W4313679638']",2024-03-18
https://openalex.org/W2752796333,,Neural Discrete Representation Learning.,"Learning useful representations without supervision remains a key challenge in machine learning. In this paper, we propose a simple yet powerful generative model that learns such discrete representations. Our model, the Vector Quantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways: the encoder network outputs discrete, rather than continuous, codes; and the prior is learnt rather than static. In order to learn a discrete latent representation, we incorporate ideas from vector quantisation (VQ). Using the VQ method allows the model to circumvent issues of posterior collapse -- where the latents are ignored when they are paired with a powerful autoregressive decoder -- typically observed in the VAE framework. Pairing these representations with an autoregressive prior, the model can generate high quality images, videos, and speech as well as doing high quality speaker conversion and unsupervised learning of phonemes, providing further evidence of the utility of the learnt representations.",[],2017-11-02
https://openalex.org/W4372259964,https://doi.org/10.1109/icassp49357.2023.10094723,Disentangled Feature Learning for Real-Time Neural Speech Coding,"Recently end-to-end neural audio/speech coding has shown its great potential to outperform traditional signal analysis based audio codecs. This is mostly achieved by following the VQ-VAE paradigm where blind features are learned, vector-quantized and coded. In this paper, instead of blind end-to-end learning, we propose to learn disentangled features for real-time neural speech coding. Specifically, more global-like speaker identity and local content features are learned with disentanglement to represent speech. Such a compact feature decomposition not only achieves better coding efficiency by exploiting bit allocation among different features but also provides the flexibility to do audio editing in embedding space, such as voice conversion in real-time communications. Both subjective and objective results demonstrate its coding efficiency and we find that the learned disentangled features show comparable performance on any-to-any voice conversion with modern self-supervised speech representation learning models with far less parameters and low latency, showing the potential of our neural coding framework.","['https://openalex.org/W2775336875', 'https://openalex.org/W2963208781', 'https://openalex.org/W3163662330', 'https://openalex.org/W2935711438', 'https://openalex.org/W3215615641', 'https://openalex.org/W4225287045', 'https://openalex.org/W3214758449', 'https://openalex.org/W2752796333', 'https://openalex.org/W3160584619', 'https://openalex.org/W3015434413', 'https://openalex.org/W3197659778', 'https://openalex.org/W2972659941', 'https://openalex.org/W3140429000', 'https://openalex.org/W3207018606', 'https://openalex.org/W6769196770', 'https://openalex.org/W1494198834', 'https://openalex.org/W3207300132', 'https://openalex.org/W3197580070', 'https://openalex.org/W4205788663', 'https://openalex.org/W2187089797', 'https://openalex.org/W2963799213']",2023-05-05
https://openalex.org/W4377231659,https://doi.org/10.1109/taslp.2023.3277693,Latent-Domain Predictive Neural Speech Coding,"Neural audio/speech coding has recently demonstrated its capability to deliver high quality at much lower bitrates than traditional methods. However, existing neural audio/speech codecs employ either acoustic features or learned blind features with a convolutional neural network for encoding, by which there are still temporal redundancies within encoded features. This article introduces latent-domain predictive coding into the VQ-VAE framework to fully remove such redundancies and proposes the TF-Codec for low-latency neural speech coding in an end-to-end manner. Specifically, the extracted features are encoded conditioned on a prediction from past quantized latent frames so that temporal correlations are further removed. Moreover, we introduce a learnable compression on the time-frequency input to adaptively adjust the attention paid to main frequencies and details at different bitrates. A differentiable vector quantization scheme based on distance-to-soft mapping and Gumbel-Softmax is proposed to better model the latent distributions with rate constraint. Subjective results on multilingual speech datasets show that, with low latency, the proposed TF-Codec at 1 kbps achieves significantly better quality than Opus at 9 kbps, and TF-Codec at 3 kbps outperforms both EVS at 9.6 kbps and Opus at 12 kbps. Numerous studies are conducted to demonstrate the effectiveness of these techniques.","['https://openalex.org/W2752796333', 'https://openalex.org/W4296069296', 'https://openalex.org/W4225287045', 'https://openalex.org/W4283830195', 'https://openalex.org/W2140199336', 'https://openalex.org/W2140196014', 'https://openalex.org/W2747874407', 'https://openalex.org/W1494198834', 'https://openalex.org/W4225311785', 'https://openalex.org/W2632564668', 'https://openalex.org/W3214758449', 'https://openalex.org/W6917585676', 'https://openalex.org/W3135530072', 'https://openalex.org/W2146395539', 'https://openalex.org/W2055815603', 'https://openalex.org/W1970272279', 'https://openalex.org/W6636170946', 'https://openalex.org/W6631190155', 'https://openalex.org/W6782481672', 'https://openalex.org/W2963189033', 'https://openalex.org/W4289665794', 'https://openalex.org/W1481955708', 'https://openalex.org/W6781251213', 'https://openalex.org/W2067295501', 'https://openalex.org/W3215615641', 'https://openalex.org/W3160584619', 'https://openalex.org/W2972354707', 'https://openalex.org/W3016003977', 'https://openalex.org/W2963208781', 'https://openalex.org/W2935711438', 'https://openalex.org/W3096468295', 'https://openalex.org/W2593414223', 'https://openalex.org/W6739901393', 'https://openalex.org/W1677182931', 'https://openalex.org/W6783867762', 'https://openalex.org/W4307323391', 'https://openalex.org/W6769196770', 'https://openalex.org/W3161411634', 'https://openalex.org/W2937484199', 'https://openalex.org/W6741057705', 'https://openalex.org/W3163662330', 'https://openalex.org/W2775336875', 'https://openalex.org/W6640185926', 'https://openalex.org/W6767111847', 'https://openalex.org/W2148371116', 'https://openalex.org/W2963091184', 'https://openalex.org/W3207018606', 'https://openalex.org/W4372348514', 'https://openalex.org/W2969260367', 'https://openalex.org/W6802036239', 'https://openalex.org/W6639363673', 'https://openalex.org/W6732429163', 'https://openalex.org/W2151626637', 'https://openalex.org/W3092028330', 'https://openalex.org/W3203234039', 'https://openalex.org/W2584032004', 'https://openalex.org/W2519091744', 'https://openalex.org/W2979476256', 'https://openalex.org/W4287694050', 'https://openalex.org/W2963799213', 'https://openalex.org/W1607435270', 'https://openalex.org/W2970006822', 'https://openalex.org/W4385245566', 'https://openalex.org/W4225905067', 'https://openalex.org/W2187089797', 'https://openalex.org/W1921523184', 'https://openalex.org/W1522301498', 'https://openalex.org/W2732044853', 'https://openalex.org/W4205788663']",2023-01-01
https://openalex.org/W4385245566,https://doi.org/10.4230/lipics.itp.2023.19,MizAR 60 for Mizar 50,"As a present to Mizar on its 50th anniversary, we develop an AI/TP system that automatically proves about 60% of the Mizar theorems in the hammer setting. We also automatically prove 75% of the Mizar theorems when the automated provers are helped by using only the premises used in the human-written Mizar proofs. We describe the methods and large-scale experiments leading to these results. This includes in particular the E and Vampire provers, their ENIGMA and Deepire learning modifications, a number of learning-based premise selection methods, and the incremental loop that interleaves growing a corpus of millions of ATP proofs with training increasingly strong AI/TP systems on them. We also present a selection of Mizar problems that were proved automatically.",[],2023-01-01
https://openalex.org/W4385570550,https://doi.org/10.18653/v1/2023.acl-long.872,UnitY: Two-pass Direct Speech-to-speech Translation with Discrete Units,"Hirofumi Inaguma, Sravya Popuri, Ilia Kulikov, Peng-Jen Chen, Changhan Wang, Yu-An Chung, Yun Tang, Ann Lee, Shinji Watanabe, Juan Pino. Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2023.","['https://openalex.org/W3193521535', 'https://openalex.org/W2972495969', 'https://openalex.org/W4223622550', 'https://openalex.org/W2963799213', 'https://openalex.org/W2752047430', 'https://openalex.org/W3186200218', 'https://openalex.org/W3006381853', 'https://openalex.org/W2949328740', 'https://openalex.org/W4307770080', 'https://openalex.org/W2292087804', 'https://openalex.org/W2250357346', 'https://openalex.org/W2161192091', 'https://openalex.org/W3142316150', 'https://openalex.org/W3035390927', 'https://openalex.org/W4226033575', 'https://openalex.org/W2133564696', 'https://openalex.org/W3140429000', 'https://openalex.org/W2972625221', 'https://openalex.org/W2933138175', 'https://openalex.org/W4372349107', 'https://openalex.org/W2963779652', 'https://openalex.org/W2972802841', 'https://openalex.org/W3168212167', 'https://openalex.org/W3107826490', 'https://openalex.org/W3095410713', 'https://openalex.org/W2763421725', 'https://openalex.org/W4280617721', 'https://openalex.org/W3036601975', 'https://openalex.org/W4287333042', 'https://openalex.org/W4285188582', 'https://openalex.org/W2958953787', 'https://openalex.org/W2605131327', 'https://openalex.org/W3175301726', 'https://openalex.org/W3175871055', 'https://openalex.org/W2972448360', 'https://openalex.org/W4287072252', 'https://openalex.org/W2136545725', 'https://openalex.org/W3011339933', 'https://openalex.org/W2938973646', 'https://openalex.org/W4285158119', 'https://openalex.org/W2572474373', 'https://openalex.org/W4221155340', 'https://openalex.org/W4226444650', 'https://openalex.org/W3103182178', 'https://openalex.org/W3172862365', 'https://openalex.org/W3097777922', 'https://openalex.org/W1494198834', 'https://openalex.org/W4385893869', 'https://openalex.org/W3135335819', 'https://openalex.org/W3169320628', 'https://openalex.org/W3091928890', 'https://openalex.org/W3176711365', 'https://openalex.org/W3196509775', 'https://openalex.org/W3007068036', 'https://openalex.org/W2995181338', 'https://openalex.org/W3015698636', 'https://openalex.org/W4385245566', 'https://openalex.org/W3173767661', 'https://openalex.org/W2130942839', 'https://openalex.org/W3119308075', 'https://openalex.org/W2964161387', 'https://openalex.org/W2183341477', 'https://openalex.org/W2046932483', 'https://openalex.org/W4300558631', 'https://openalex.org/W22168010', 'https://openalex.org/W2963250244', 'https://openalex.org/W1538023239', 'https://openalex.org/W4287213456', 'https://openalex.org/W3139878283', 'https://openalex.org/W2936969148', 'https://openalex.org/W3030437843', 'https://openalex.org/W2963979492', 'https://openalex.org/W2806412155', 'https://openalex.org/W3092028330', 'https://openalex.org/W2157331557', 'https://openalex.org/W3012492057', 'https://openalex.org/W2973122799', 'https://openalex.org/W4287694131', 'https://openalex.org/W2963887123', 'https://openalex.org/W3139918052', 'https://openalex.org/W2903739847', 'https://openalex.org/W2095705004', 'https://openalex.org/W4226054021', 'https://openalex.org/W3100806282', 'https://openalex.org/W4281789500', 'https://openalex.org/W3174864715', 'https://openalex.org/W4287854499', 'https://openalex.org/W4221153524', 'https://openalex.org/W4296070387', 'https://openalex.org/W2963532001', 'https://openalex.org/W338621447', 'https://openalex.org/W3118578889']",2023-01-01
https://openalex.org/W4289665794,https://doi.org/10.1145/3197517.3201357,Looking to listen at the cocktail party,"We present a joint audio-visual model for isolating a single speech signal from a mixture of sounds such as other speakers and background noise. Solving this task using only audio as input is extremely challenging and does not provide an association of the separated speech signals with speakers in the video. In this paper, we present a deep network-based model that incorporates both visual and auditory signals to solve this task. The visual features are used to ""focus"" the audio on desired speakers in a scene and to improve the speech separation quality. To train our joint audio-visual model, we introduce AVS peech , a new dataset comprised of thousands of hours of video segments from the Web. We demonstrate the applicability of our method to classic speech separation tasks, as well as real-world scenarios involving heated interviews, noisy bars, and screaming children, only requiring the user to specify the face of the person in the video whose speech they want to isolate. Our method shows clear advantage over state-of-the-art audio-only speech separation in cases of mixed speech. In addition, our model, which is speaker-independent (trained once, applicable to any speaker), produces better results than recent audio-visual speech separation methods that are speaker-dependent (require training a separate model for each speaker of interest).","['https://openalex.org/W2168010845', 'https://openalex.org/W1991139021', 'https://openalex.org/W2598036111', 'https://openalex.org/W2963019222', 'https://openalex.org/W1482149378', 'https://openalex.org/W2735090526', 'https://openalex.org/W2963218389', 'https://openalex.org/W2593116425', 'https://openalex.org/W2081144555', 'https://openalex.org/W2029199293', 'https://openalex.org/W2128653983', 'https://openalex.org/W2221409856', 'https://openalex.org/W1976188834', 'https://openalex.org/W2788241093', 'https://openalex.org/W1964448421', 'https://openalex.org/W2088079940', 'https://openalex.org/W1971168548', 'https://openalex.org/W1503933356', 'https://openalex.org/W2962960500', 'https://openalex.org/W2148659689', 'https://openalex.org/W2660943524', 'https://openalex.org/W2167734090', 'https://openalex.org/W1552314771', 'https://openalex.org/W2311038409', 'https://openalex.org/W2605589342', 'https://openalex.org/W2067295501', 'https://openalex.org/W2101045344', 'https://openalex.org/W2127851351', 'https://openalex.org/W2069681747', 'https://openalex.org/W2532854561', 'https://openalex.org/W1897240248', 'https://openalex.org/W2460742184', 'https://openalex.org/W1849277567', 'https://openalex.org/W2962865004', 'https://openalex.org/W1899185266', 'https://openalex.org/W2525694994', 'https://openalex.org/W2952746495', 'https://openalex.org/W2101036994', 'https://openalex.org/W2796992393', 'https://openalex.org/W2962866211', 'https://openalex.org/W2495705551', 'https://openalex.org/W1836465849', 'https://openalex.org/W2099128937', 'https://openalex.org/W3127686677', 'https://openalex.org/W2963812294', 'https://openalex.org/W2750143381', 'https://openalex.org/W2771039075', 'https://openalex.org/W3105024549', 'https://openalex.org/W3105099157', 'https://openalex.org/W2621109248', 'https://openalex.org/W1496883935', 'https://openalex.org/W2730845691', 'https://openalex.org/W2184188583', 'https://openalex.org/W4302114989', 'https://openalex.org/W2962715207', 'https://openalex.org/W2556930864', 'https://openalex.org/W2964171275', 'https://openalex.org/W4307196995', 'https://openalex.org/W1755563775']",2018-07-30
https://openalex.org/W3095410713,https://doi.org/10.21437/interspeech.2020-2826,MLS: A Large-Scale Multilingual Dataset for Speech Research,"This paper introduces Multilingual LibriSpeech (MLS) dataset, a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of 8 languages, including about 44.5K hours of English and a total of about 6K hours for other languages. Additionally, we provide Language Models (LM) and baseline Automatic Speech Recognition (ASR) models and for all the languages in our dataset. We believe such a large transcribed dataset will open new avenues in ASR and Text-To-Speech (TTS) research. The dataset will be made freely available for anyone at http://www.openslr.org.","['https://openalex.org/W2953190524', 'https://openalex.org/W4297818305', 'https://openalex.org/W2087347434', 'https://openalex.org/W2127141656', 'https://openalex.org/W4385245566', 'https://openalex.org/W2134800885', 'https://openalex.org/W2786234940', 'https://openalex.org/W2996159613', 'https://openalex.org/W3030437843', 'https://openalex.org/W3198270883', 'https://openalex.org/W2972630480', 'https://openalex.org/W2936774411', 'https://openalex.org/W3093502935', 'https://openalex.org/W1494198834', 'https://openalex.org/W3096104971', 'https://openalex.org/W2937197076', 'https://openalex.org/W2520160253', 'https://openalex.org/W2991213871', 'https://openalex.org/W2995181338', 'https://openalex.org/W2975381464', 'https://openalex.org/W3001899777', 'https://openalex.org/W2781384251', 'https://openalex.org/W2963979492', 'https://openalex.org/W2626778328', 'https://openalex.org/W2146502635', 'https://openalex.org/W2972359262', 'https://openalex.org/W2087064593']",2020-10-25
https://openalex.org/W3081192838,https://doi.org/10.5281/zenodo.1188976,The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS),"Description The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) contains 7356 files (total size: 24.8 GB). The dataset contains 24 professional actors (12 female, 12 male), vocalizing two lexically-matched statements in a neutral North American accent. Speech includes calm, happy, sad, angry, fearful, surprise, and disgust expressions, and song contains calm, happy, sad, angry, and fearful emotions. Each expression is produced at two levels of emotional intensity (normal, strong), with an additional neutral expression. All conditions are available in three modality formats: Audio-only (16bit, 48kHz .wav), Audio-Video (720p H.264, AAC 48kHz, .mp4), and Video-only (no sound). Note, there are no song files for Actor_18. The RAVDESS was developed by Dr Steven R. Livingstone, who now leads the Affective Data Science Lab, and Dr Frank A. Russo who leads the SMART Lab. Citing the RAVDESS The RAVDESS is released under a Creative Commons Attribution license, so please cite the RAVDESS if it is used in your work in any form. Published academic papers should use the academic paper citation for our PLoS1 paper. Personal works, such as machine learning projects/blog posts, should provide a URL to this Zenodo page, though a reference to our PLoS1 paper would also be appreciated. Academic paper citation Livingstone SR, Russo FA (2018) The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English. PLoS ONE 13(5): e0196391. https://doi.org/10.1371/journal.pone.0196391. Personal use citation Include a link to this Zenodo page - https://zenodo.org/record/1188976 Commercial Licenses Commercial licenses for the RAVDESS can be purchased. For more information, please visit our license page of fees, or contact us at ravdess@gmail.com. Contact Information If you would like further information about the RAVDESS, to purchase a commercial license, or if you experience any issues downloading files, please contact us at ravdess@gmail.com. Example Videos Watch a sample of the RAVDESS speech and song videos. Emotion Classification Users If you're interested in using machine learning to classify emotional expressions with the RAVDESS, please see our new RAVDESS Facial Landmark Tracking data set [Zenodo project page]. Construction and Validation Full details on the construction and perceptual validation of the RAVDESS are described in our PLoS ONE paper - https://doi.org/10.1371/journal.pone.0196391. The RAVDESS contains 7356 files. Each file was rated 10 times on emotional validity, intensity, and genuineness. Ratings were provided by 247 individuals who were characteristic of untrained adult research participants from North America. A further set of 72 participants provided test-retest data. High levels of emotional validity, interrater reliability, and test-retest intrarater reliability were reported. Validation data is open-access, and can be downloaded along with our paper from PLoS ONE. Contents Audio-only files Audio-only files of all actors (01-24) are available as two separate zip files (~200 MB each): Speech file (Audio_Speech_Actors_01-24.zip, 215 MB) contains 1440 files: 60 trials per actor x 24 actors = 1440. Song file (Audio_Song_Actors_01-24.zip, 198 MB) contains 1012 files: 44 trials per actor x 23 actors = 1012. Audio-Visual and Video-only files Video files are provided as separate zip downloads for each actor (01-24, ~500 MB each), and are split into separate speech and song downloads: Speech files (Video_Speech_Actor_01.zip to Video_Speech_Actor_24.zip) collectively contains 2880 files: 60 trials per actor x 2 modalities (AV, VO) x 24 actors = 2880. Song files (Video_Song_Actor_01.zip to Video_Song_Actor_24.zip) collectively contains 2024 files: 44 trials per actor x 2 modalities (AV, VO) x 23 actors = 2024. File Summary In total, the RAVDESS collection includes 7356 files (2880+2024+1440+1012 files). File naming convention Each of the 7356 RAVDESS files has a unique filename. The filename consists of a 7-part numerical identifier (e.g., 02-01-06-01-02-01-12.mp4). These identifiers define the stimulus characteristics: Filename identifiers Modality (01 = full-AV, 02 = video-only, 03 = audio-only). Vocal channel (01 = speech, 02 = song). Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised). Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion. Statement (01 = ""Kids are talking by the door"", 02 = ""Dogs are sitting by the door""). Repetition (01 = 1st repetition, 02 = 2nd repetition). Actor (01 to 24. Odd numbered actors are male, even numbered actors are female). Filename example: 02-01-06-01-02-01-12.mp4 Video-only (02) Speech (01) Fearful (06) Normal intensity (01) Statement ""dogs"" (02) 1st Repetition (01) 12th Actor (12) Female, as the actor ID number is even. License information The RAVDESS is released under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License, CC BY-NC-SA 4.0 Commercial licenses for the RAVDESS can also be purchased. For more information, please visit our license fee page, or contact us at ravdess@gmail.com. Related Data sets RAVDESS Facial Landmark Tracking data set [Zenodo project page].",[],2018-04-05
https://openalex.org/W2935711438,https://doi.org/10.1109/icassp.2019.8683277,Low Bit-rate Speech Coding with VQ-VAE and a WaveNet Decoder,"In order to efficiently transmit and store speech signals, speech codecs create a minimally redundant representation of the input signal which is then decoded at the receiver with the best possible perceptual quality. In this work we demonstrate that a neural network architecture based on VQ-VAE with a WaveNet decoder can be used to perform very low bit-rate speech coding with high reconstruction quality. A prosody-transparent and speaker-independent model trained on the LibriSpeech corpus coding audio at 1.6 kbps exhibits perceptual quality which is around halfway between the MELP codec at 2.4 kbps and AMR-WB codec at 23.05 kbps. In addition, when training on high-quality recorded speech with the test speaker included in the training set, a model coding speech at 1.6 kbps produces output of similar perceptual quality to that generated by AMR-WB at 23.05 kbps.","['https://openalex.org/W2165291881', 'https://openalex.org/W2752796333', 'https://openalex.org/W6640963894', 'https://openalex.org/W1494198834', 'https://openalex.org/W6696768431', 'https://openalex.org/W2108532241', 'https://openalex.org/W6752888775', 'https://openalex.org/W6738494155', 'https://openalex.org/W6735849998', 'https://openalex.org/W2963182577', 'https://openalex.org/W2309400744', 'https://openalex.org/W2632564668', 'https://openalex.org/W2552465432', 'https://openalex.org/W6734035190', 'https://openalex.org/W2775336875', 'https://openalex.org/W6755135894', 'https://openalex.org/W2808706139', 'https://openalex.org/W2950237263', 'https://openalex.org/W2963799213', 'https://openalex.org/W1959608418', 'https://openalex.org/W2616159609', 'https://openalex.org/W4294567867', 'https://openalex.org/W2604231067', 'https://openalex.org/W2892620417', 'https://openalex.org/W2951004968', 'https://openalex.org/W2519091744', 'https://openalex.org/W2963449488', 'https://openalex.org/W2962676454', 'https://openalex.org/W3124456579', 'https://openalex.org/W2292235217']",2019-04-16
https://openalex.org/W2130086727,https://doi.org/10.1016/j.specom.2007.09.003,A method for fundamental frequency estimation and voicing decision: Application to infant utterances recorded in real acoustical environments,,"['https://openalex.org/W6718334172', 'https://openalex.org/W6683576537', 'https://openalex.org/W2012060056', 'https://openalex.org/W104734300', 'https://openalex.org/W2107831318', 'https://openalex.org/W6769316794', 'https://openalex.org/W1926680708', 'https://openalex.org/W6636700880', 'https://openalex.org/W2091425152', 'https://openalex.org/W4235716345', 'https://openalex.org/W289873009', 'https://openalex.org/W1978244610', 'https://openalex.org/W2049686551', 'https://openalex.org/W2092655206', 'https://openalex.org/W6685452626', 'https://openalex.org/W1791774586', 'https://openalex.org/W2063619969', 'https://openalex.org/W2084044763', 'https://openalex.org/W2088632109', 'https://openalex.org/W2004163116', 'https://openalex.org/W2100384625', 'https://openalex.org/W2129120544', 'https://openalex.org/W2143039550', 'https://openalex.org/W2163067280', 'https://openalex.org/W3216401400', 'https://openalex.org/W2556247670', 'https://openalex.org/W2441833056', 'https://openalex.org/W2171840027', 'https://openalex.org/W86348706', 'https://openalex.org/W2294819182', 'https://openalex.org/W2160566140']",2007-09-26
https://openalex.org/W2107740512,https://doi.org/10.1109/icassp.2009.4960497,Reducing F0 Frame Error of F0 tracking algorithms under noisy conditions with an unvoiced/voiced classification frontend,"In this paper, we propose an F0 Frame Error (FFE) metric which combines Gross Pitch Error (GPE) and Voicing Decision Error (VDE) to objectively evaluate the performance of fundamental frequency (F0) tracking methods. A GPE-VDE curve is then developed to show the trade-off between GPE and VDE. In addition, we introduce a model-based Unvoiced/Voiced (U/V) classification frontend which can be used by any F0 tracking algorithm. In the U/V classification, we train speaker independent U/V models, and then adapt them to speaker dependent models in an unsupervised fashion. The U/V classification result is taken as a mask for F0 tracking. Experiments using the KEELE corpus with additive noise show that our statistically-based U/V classifier can reduce VDE and FFE for the pitch tracker TEMPO in both white and babble noise conditions, and that minimizing FFE instead of VDE results in a reduction in error rates for a number of F0 tracking algorithms, especially in babble noise.","['https://openalex.org/W1974387177', 'https://openalex.org/W2151484683', 'https://openalex.org/W2146871184', 'https://openalex.org/W23669922', 'https://openalex.org/W2130086727', 'https://openalex.org/W2088632109', 'https://openalex.org/W4402490932', 'https://openalex.org/W2108819501', 'https://openalex.org/W147159200', 'https://openalex.org/W2091425152', 'https://openalex.org/W6639350448', 'https://openalex.org/W2171748469', 'https://openalex.org/W2129120544', 'https://openalex.org/W1875231349', 'https://openalex.org/W2141684970', 'https://openalex.org/W2084562624']",2009-04-01
https://openalex.org/W4225956675,https://doi.org/10.21437/interspeech.2022-439,UTMOS: UTokyo-SaruLab System for VoiceMOS Challenge 2022,"We present the UTokyo-SaruLab mean opinion score (MOS) prediction system submitted to VoiceMOS Challenge 2022.The challenge is to predict the MOS values of speech samples collected from previous Blizzard Challenges and Voice Conversion Challenges for two tracks: a main track for in-domain prediction and an out-of-domain (OOD) track for which there is less labeled data from different listening tests.Our system is based on ensemble learning of strong and weak learners.Strong learners incorporate several improvements to the previous finetuning models of self-supervised learning (SSL) models, while weak learners use basic machine-learning methods to predict scores from SSL features.In the Challenge, our system had the highest score on several metrics for both the main and OOD tracks.In addition, we conducted ablation studies to investigate the effectiveness of our proposed methods.","['https://openalex.org/W3196225973', 'https://openalex.org/W3209984917', 'https://openalex.org/W4300816538', 'https://openalex.org/W3090098535', 'https://openalex.org/W1673310716', 'https://openalex.org/W70888257', 'https://openalex.org/W3030437843', 'https://openalex.org/W3169320628', 'https://openalex.org/W3036601975', 'https://openalex.org/W2557915412', 'https://openalex.org/W3198429080', 'https://openalex.org/W3144810982', 'https://openalex.org/W4322714819', 'https://openalex.org/W2962897394', 'https://openalex.org/W2768348081', 'https://openalex.org/W2972394484', 'https://openalex.org/W3200245256', 'https://openalex.org/W1494198834', 'https://openalex.org/W3202278141', 'https://openalex.org/W4311829866', 'https://openalex.org/W3160506022', 'https://openalex.org/W1522301498', 'https://openalex.org/W28412257', 'https://openalex.org/W3161558238', 'https://openalex.org/W605727707']",2022-09-16
https://openalex.org/W3037038648,https://doi.org/10.1109/qomex48832.2020.9123150,ViSQOL v3: An Open Source Production Ready Objective Speech and Audio Metric,"The 12th International Conference on Quality of Multimedia Experience (QoMEX), Athlone, Ireland (held online due to coronavirus outbreak), 26-28 May 2020","['https://openalex.org/W2775336875', 'https://openalex.org/W2963208781', 'https://openalex.org/W2963300588', 'https://openalex.org/W1976188834', 'https://openalex.org/W2922332774', 'https://openalex.org/W2111964411', 'https://openalex.org/W6638872167', 'https://openalex.org/W2469918093', 'https://openalex.org/W2623662528', 'https://openalex.org/W2972359262', 'https://openalex.org/W2153635508', 'https://openalex.org/W2108708552', 'https://openalex.org/W6636045042', 'https://openalex.org/W1496883935', 'https://openalex.org/W6636170946', 'https://openalex.org/W6754761153', 'https://openalex.org/W1552314771', 'https://openalex.org/W2040151471', 'https://openalex.org/W2990738305', 'https://openalex.org/W1606487971', 'https://openalex.org/W1849775568', 'https://openalex.org/W1607435270', 'https://openalex.org/W2892330131', 'https://openalex.org/W2103934944', 'https://openalex.org/W2987307811']",2020-05-01
https://openalex.org/W2030931454,https://doi.org/10.1109/taffc.2014.2336244,CREMA-D: Crowd-Sourced Emotional Multimodal Actors Dataset,"People convey their emotional state in their face and voice. We present an audio-visual data set uniquely suited for the study of multi-modal emotion expression and perception. The data set consists of facial and vocal emotional expressions in sentences spoken in a range of basic emotional states (happy, sad, anger, fear, disgust, and neutral). 7,442 clips of 91 actors with diverse ethnic backgrounds were rated by multiple raters in three modalities: audio, visual, and audio-visual. Categorical emotion labels and real-value intensity values for the perceived emotion were collected using crowd-sourcing from 2,443 raters. The human recognition of intended emotion for the audio-only, visual-only, and audio-visual data are 40.9%, 58.2% and 63.6% respectively. Recognition rates are highest for neutral, followed by happy, anger, disgust, fear, and sad. Average intensity levels of emotion are rated highest for visual-only perception. The accurate recognition of disgust and fear requires simultaneous audio-visual cues, while anger and happiness can be well recognized based on evidence from a single modality. The large dataset we introduce can be used to probe other questions concerning the audio-visual perception of emotion.","['https://openalex.org/W2104084893', 'https://openalex.org/W60557504', 'https://openalex.org/W2115839658', 'https://openalex.org/W2154739180', 'https://openalex.org/W414188911', 'https://openalex.org/W6678622670', 'https://openalex.org/W2146334809', 'https://openalex.org/W2097732741', 'https://openalex.org/W1496540195', 'https://openalex.org/W2110911841', 'https://openalex.org/W2088456207', 'https://openalex.org/W2077030430', 'https://openalex.org/W2136380346', 'https://openalex.org/W1966797434', 'https://openalex.org/W1986101067', 'https://openalex.org/W4245744384', 'https://openalex.org/W6608271823', 'https://openalex.org/W2151008812', 'https://openalex.org/W175750906', 'https://openalex.org/W2120227312', 'https://openalex.org/W2127531292', 'https://openalex.org/W2121222025', 'https://openalex.org/W6686245862', 'https://openalex.org/W2019029324', 'https://openalex.org/W2143350951', 'https://openalex.org/W2043152858', 'https://openalex.org/W1844030040', 'https://openalex.org/W2045528981', 'https://openalex.org/W6729439171', 'https://openalex.org/W2075274068', 'https://openalex.org/W1997537978', 'https://openalex.org/W2125127226', 'https://openalex.org/W2161634108', 'https://openalex.org/W2107497073', 'https://openalex.org/W1965696296', 'https://openalex.org/W2122348661', 'https://openalex.org/W2169294293', 'https://openalex.org/W2062207950', 'https://openalex.org/W2048765566', 'https://openalex.org/W2011604423', 'https://openalex.org/W1973378890', 'https://openalex.org/W6741840311', 'https://openalex.org/W1972280480', 'https://openalex.org/W2292984643', 'https://openalex.org/W2024166834', 'https://openalex.org/W6697452742', 'https://openalex.org/W2122098299', 'https://openalex.org/W1581332777', 'https://openalex.org/W2058647607', 'https://openalex.org/W2020944977', 'https://openalex.org/W125412883', 'https://openalex.org/W2294447324', 'https://openalex.org/W2739071228', 'https://openalex.org/W202968570', 'https://openalex.org/W4230579509', 'https://openalex.org/W2012378416', 'https://openalex.org/W2548474255', 'https://openalex.org/W2774090594', 'https://openalex.org/W2980097029', 'https://openalex.org/W2182392283', 'https://openalex.org/W2125744402', 'https://openalex.org/W2118789253', 'https://openalex.org/W4285719527']",2014-09-25
https://openalex.org/W2972359262,https://doi.org/10.21437/interspeech.2019-2441,LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech,"This paper introduces a new speech corpus called ""LibriTTS"" designed for text-to-speech use.It is derived from the original audio and text materials of the LibriSpeech corpus, which has been used for training and evaluating automatic speech recognition systems.The new corpus inherits desired properties of the LibriSpeech corpus while addressing a number of issues which make LibriSpeech less than ideal for text-to-speech work.The released corpus consists of 585 hours of speech data at 24kHz sampling rate from 2,456 speakers and the corresponding texts.Experimental results show that neural end-to-end TTS models trained from the LibriTTS corpus achieved above 4.0 in mean opinion scores in naturalness in five out of six evaluation speakers.","['https://openalex.org/W2892620417', 'https://openalex.org/W4232345992', 'https://openalex.org/W2794490148', 'https://openalex.org/W2182214061', 'https://openalex.org/W2808706139', 'https://openalex.org/W2129142580', 'https://openalex.org/W4298174729', 'https://openalex.org/W2105961775', 'https://openalex.org/W2103085228', 'https://openalex.org/W4294619240', 'https://openalex.org/W2963827314', 'https://openalex.org/W2604184139', 'https://openalex.org/W1597121597', 'https://openalex.org/W1522301498', 'https://openalex.org/W2964243274', 'https://openalex.org/W2788357188', 'https://openalex.org/W2736900972', 'https://openalex.org/W2901997113', 'https://openalex.org/W2885800352', 'https://openalex.org/W2033256038', 'https://openalex.org/W4289383906', 'https://openalex.org/W3177989406', 'https://openalex.org/W2747681982', 'https://openalex.org/W4298580827', 'https://openalex.org/W1574170747', 'https://openalex.org/W2892140764', 'https://openalex.org/W2293634267', 'https://openalex.org/W4298240696', 'https://openalex.org/W4295731579', 'https://openalex.org/W1494198834', 'https://openalex.org/W2889028433']",2019-09-13
https://openalex.org/W4389519587,https://doi.org/10.18653/v1/2023.emnlp-demo.49,Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding,"We present Video-LLaMA, a multi-modal framework that empowers Large Language Models (LLMs) with the capability of understanding both visual and auditory content in the video. Video-LLaMA bootstraps cross-modal training from the frozen pre-trained visual & audio encoders and the frozen LLMs. Unlike previous works that complement LLMs to process the visual or audio signals only, Video-LLaMA enables video comprehension by tackling two challenges: (1) capturing the temporal changes in visual scenes, (2) integrating audio-visual signals. To counter the first challenge, we propose a Video Q-former to assemble a pre-trained image encoder into our video encoder and introduce a video-to-text generation task to learn video-language correspondence. For the second challenge, we leverage ImageBind, a universal embedding model aligning multiple modalities, as the pre-trained audio encoder and introduce an Audio Q-former on top of ImageBind to learn reasonable auditory query embeddings for the LLM module. To align the output of both visual & audio encoders with LLM’s embedding space, we first train Video-LLaMA on massive video/image-caption pairs and then tune our model with visual-instruction datasets of moderate amount but higher quality. We found Video-LLaMA shows the ability to perceive and comprehend video content and generate meaningful responses grounded in the visual and auditory information presented in the videos.","['https://openalex.org/W4361866031', 'https://openalex.org/W4323717348', 'https://openalex.org/W4375869762', 'https://openalex.org/W4366330503', 'https://openalex.org/W4389524372', 'https://openalex.org/W4378711593', 'https://openalex.org/W4383987498', 'https://openalex.org/W4224308101', 'https://openalex.org/W4319049530', 'https://openalex.org/W4311642023', 'https://openalex.org/W4311991106', 'https://openalex.org/W4287113019', 'https://openalex.org/W4285225959', 'https://openalex.org/W4327810158', 'https://openalex.org/W4380559123', 'https://openalex.org/W4386071707', 'https://openalex.org/W4376167553', 'https://openalex.org/W4367367040', 'https://openalex.org/W4229005866', 'https://openalex.org/W4322718246', 'https://openalex.org/W4366850747', 'https://openalex.org/W4402671548', 'https://openalex.org/W4225323055', 'https://openalex.org/W4367061106', 'https://openalex.org/W4367628410', 'https://openalex.org/W4389524500', 'https://openalex.org/W4386076522', 'https://openalex.org/W4384112212', 'https://openalex.org/W4322718191', 'https://openalex.org/W2886641317', 'https://openalex.org/W4382132560', 'https://openalex.org/W3204588463', 'https://openalex.org/W4318718936']",2023-01-01
https://openalex.org/W4372266552,https://doi.org/10.1109/icassp49357.2023.10095889,CLAP Learning Audio Concepts from Natural Language Supervision,"Mainstream machine listening models are trained to learn audio concepts under the paradigm of one class label to many recordings focusing on one task. Learning under such restricted supervision limits the flexibility of models because they require labeled audio for training and can only predict the predefined categories. Instead, we propose to learn audio concepts from natural language supervision. We call our approach Contrastive Language-Audio Pretraining (CLAP), which connects language and audio by using two encoders and a contrastive learning objective, bringing audio and text descriptions into a joint multimodal space. We trained CLAP with 128k audio and text pairs and evaluated it on 16 downstream tasks across 7 domains, such as classification of sound events, scenes, music, and speech. CLAP establishes state-of-the-art (SoTA) in Zero-Shot performance. Also, we evaluated CLAP's audio encoder in a supervised learning setup and achieved SoTA in 5 tasks. The Zero-Shot capability removes the need of training with class labeled audio, enables flexible class prediction at inference time, and generalizes well in multiple downstream tasks. Code is available at: https://github.com/microsoft/CLAP.","['https://openalex.org/W6802510933', 'https://openalex.org/W3196496149', 'https://openalex.org/W4205633160', 'https://openalex.org/W3049446265', 'https://openalex.org/W6809947431', 'https://openalex.org/W2938440247', 'https://openalex.org/W2046972719', 'https://openalex.org/W4205689591', 'https://openalex.org/W4225299287', 'https://openalex.org/W3015591594', 'https://openalex.org/W3138521398', 'https://openalex.org/W2979826702', 'https://openalex.org/W3213454282', 'https://openalex.org/W3162331882', 'https://openalex.org/W3094550259', 'https://openalex.org/W2038484192', 'https://openalex.org/W4284898017', 'https://openalex.org/W6803872405', 'https://openalex.org/W3176445421', 'https://openalex.org/W3209984917', 'https://openalex.org/W3204696009', 'https://openalex.org/W6791353385', 'https://openalex.org/W6780218876', 'https://openalex.org/W4221150524', 'https://openalex.org/W3215626407', 'https://openalex.org/W3205475937', 'https://openalex.org/W3166396011', 'https://openalex.org/W3036601975']",2023-05-05
https://openalex.org/W4372260310,https://doi.org/10.1109/icassp49357.2023.10095969,Large-Scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation,International audience,"['https://openalex.org/W6766673545', 'https://openalex.org/W4226442948', 'https://openalex.org/W3015591594', 'https://openalex.org/W2593116425', 'https://openalex.org/W4205689591', 'https://openalex.org/W6755207826', 'https://openalex.org/W3094550259', 'https://openalex.org/W2108598243', 'https://openalex.org/W6791353385', 'https://openalex.org/W6807957504', 'https://openalex.org/W2112796928', 'https://openalex.org/W6749029207', 'https://openalex.org/W6739622702', 'https://openalex.org/W6631190155', 'https://openalex.org/W3205475937', 'https://openalex.org/W6797613833', 'https://openalex.org/W3138516171', 'https://openalex.org/W6769627184', 'https://openalex.org/W3094897602', 'https://openalex.org/W3015371781', 'https://openalex.org/W2052666245', 'https://openalex.org/W2038484192', 'https://openalex.org/W4221157007', 'https://openalex.org/W3198452188', 'https://openalex.org/W4284898017', 'https://openalex.org/W6838439425', 'https://openalex.org/W3176445421', 'https://openalex.org/W6849549116', 'https://openalex.org/W2622263826', 'https://openalex.org/W3166396011', 'https://openalex.org/W2965373594', 'https://openalex.org/W2896457183', 'https://openalex.org/W4288089799', 'https://openalex.org/W3174906557', 'https://openalex.org/W4210913346', 'https://openalex.org/W4372266552', 'https://openalex.org/W4385822467', 'https://openalex.org/W1522301498', 'https://openalex.org/W2792643794']",2023-05-05
https://openalex.org/W3206996142,https://doi.org/10.1609/aaai.v36i10.21315,SSAST: Self-Supervised Audio Spectrogram Transformer,"Recently, neural networks based purely on self-attention, such as the Vision Transformer (ViT), have been shown to outperform deep learning models constructed with convolutional neural networks (CNNs) on various vision tasks, thus extending the success of Transformers, which were originally developed for language processing, to the vision domain. A recent study showed that a similar methodology can also be applied to the audio domain. Specifically, the Audio Spectrogram Transformer (AST) achieves state-of-the-art results on various audio classification benchmarks. However, pure Transformer models tend to require more training data compared to CNNs, and the success of the AST relies on supervised pretraining that requires a large amount of labeled data and a complex training pipeline, thus limiting the practical usage of AST. This paper focuses on audio and speech classification, and aims to reduce the need for large amounts of labeled data for the AST by leveraging self-supervised learning using unlabeled data. Specifically, we propose to pretrain the AST model with joint discriminative and generative masked spectrogram patch modeling (MSPM) using unlabeled audio from AudioSet and Librispeech. We evaluate our pretrained models on both audio and speech classification tasks including audio event classification, keyword spotting, emotion recognition, and speaker identification. The proposed self-supervised framework significantly boosts AST performance on all tasks, with an average improvement of 60.9%, leading to similar or even better results than a supervised pretrained AST. To the best of our knowledge, it is the first patch-based self-supervised learning framework in the audio and speech domain, and also the first self-supervised learning framework for AST.","['https://openalex.org/W3141838378', 'https://openalex.org/W2146334809', 'https://openalex.org/W2926827382', 'https://openalex.org/W6676297131', 'https://openalex.org/W3094502228', 'https://openalex.org/W2593116425', 'https://openalex.org/W6792861227', 'https://openalex.org/W2902332991', 'https://openalex.org/W6631190155', 'https://openalex.org/W1538131130', 'https://openalex.org/W2981087920', 'https://openalex.org/W2321533354', 'https://openalex.org/W1494198834', 'https://openalex.org/W2936774411', 'https://openalex.org/W4398958419', 'https://openalex.org/W3002741552', 'https://openalex.org/W3093563057', 'https://openalex.org/W6600721412', 'https://openalex.org/W2768188490', 'https://openalex.org/W6739901393', 'https://openalex.org/W2982223350', 'https://openalex.org/W3143083666', 'https://openalex.org/W3119786062', 'https://openalex.org/W2963403868', 'https://openalex.org/W2972943112', 'https://openalex.org/W1522301498', 'https://openalex.org/W2963855133', 'https://openalex.org/W3145450063', 'https://openalex.org/W3160799772', 'https://openalex.org/W3162391496', 'https://openalex.org/W2842511635', 'https://openalex.org/W3170874841', 'https://openalex.org/W4297808394', 'https://openalex.org/W3036601975', 'https://openalex.org/W2797583228', 'https://openalex.org/W3096587983', 'https://openalex.org/W2108598243', 'https://openalex.org/W2964328535', 'https://openalex.org/W2964121744', 'https://openalex.org/W4287631799', 'https://openalex.org/W4287236261', 'https://openalex.org/W4385245566', 'https://openalex.org/W3159481202', 'https://openalex.org/W3201143670', 'https://openalex.org/W2973157397', 'https://openalex.org/W2973049979', 'https://openalex.org/W3170863103', 'https://openalex.org/W3135828102', 'https://openalex.org/W3196974791', 'https://openalex.org/W3121523901', 'https://openalex.org/W3198035615', 'https://openalex.org/W2948433173', 'https://openalex.org/W2052666245', 'https://openalex.org/W3157923770']",2022-06-28
https://openalex.org/W3205550549,https://doi.org/10.1109/icassp43922.2022.9746490,Conformer-Based Self-Supervised Learning For Non-Speech Audio Tasks,"Representation learning from unlabeled data has been of major interest in artificial intelligence research. While self-supervised speech representation learning has been popular in the speech research community, very few works have comprehensively analyzed audio representation learning for non-speech audio tasks. In this paper, we propose a self-supervised audio representation learning method and apply it to a variety of downstream non-speech audio tasks. We combine the well-known wav2vec 2.0 framework, which has shown success in self-supervised learning for speech tasks, with parameter-efficient conformer architectures. Our self-supervised pre-training can reduce the need for labeled data by two-thirds. On the AudioSet benchmark, we achieve a mean average precision (mAP) score of 0.415, which is a new state-of-the-art on this dataset through audio-only self-supervised learning. Our fine-tuned conformers also surpass or match the performance of previous systems pre-trained in a supervised way on several downstream tasks. We further discuss the important design considerations for both pre-training and fine-tuning.","['https://openalex.org/W3196974791', 'https://openalex.org/W6790117948', 'https://openalex.org/W6793728465', 'https://openalex.org/W6780294235', 'https://openalex.org/W6791537541', 'https://openalex.org/W6840046036', 'https://openalex.org/W3094550259', 'https://openalex.org/W6779503413', 'https://openalex.org/W3198882010', 'https://openalex.org/W6734260513', 'https://openalex.org/W2963610932', 'https://openalex.org/W3160766462', 'https://openalex.org/W6631190155', 'https://openalex.org/W2052666245', 'https://openalex.org/W2982343573', 'https://openalex.org/W6752516136', 'https://openalex.org/W6678969435', 'https://openalex.org/W6791429434', 'https://openalex.org/W6793736971', 'https://openalex.org/W3095727342', 'https://openalex.org/W6780218876', 'https://openalex.org/W6798422254', 'https://openalex.org/W3158504903', 'https://openalex.org/W6799303324', 'https://openalex.org/W3097777922', 'https://openalex.org/W6787335539', 'https://openalex.org/W6774314701', 'https://openalex.org/W6784614252', 'https://openalex.org/W6755207826', 'https://openalex.org/W6955071965', 'https://openalex.org/W6791353385', 'https://openalex.org/W3170837227', 'https://openalex.org/W6745136726', 'https://openalex.org/W2936774411', 'https://openalex.org/W2767754137', 'https://openalex.org/W3015817524', 'https://openalex.org/W3157916917', 'https://openalex.org/W3025165719', 'https://openalex.org/W2948982921', 'https://openalex.org/W3034978746', 'https://openalex.org/W3139211892', 'https://openalex.org/W3166396011', 'https://openalex.org/W2883935097', 'https://openalex.org/W4295723153', 'https://openalex.org/W3146639881', 'https://openalex.org/W3126565544', 'https://openalex.org/W1522301498', 'https://openalex.org/W3005680577', 'https://openalex.org/W3100177202', 'https://openalex.org/W3093579165', 'https://openalex.org/W3112616666', 'https://openalex.org/W3198275944', 'https://openalex.org/W2127870748', 'https://openalex.org/W2963341956', 'https://openalex.org/W3099782249', 'https://openalex.org/W2593116425', 'https://openalex.org/W3164279099', 'https://openalex.org/W3037309139', 'https://openalex.org/W3180180466', 'https://openalex.org/W2896457183', 'https://openalex.org/W2765407302', 'https://openalex.org/W3034886385', 'https://openalex.org/W2964121744', 'https://openalex.org/W3036601975', 'https://openalex.org/W4286582832', 'https://openalex.org/W3040498734', 'https://openalex.org/W3186781156', 'https://openalex.org/W2619947201', 'https://openalex.org/W3134486096', 'https://openalex.org/W3154596443']",2022-04-27
https://openalex.org/W4226442948,https://doi.org/10.1109/icassp43922.2022.9746312,HTS-AT: A Hierarchical Token-Semantic Audio Transformer for Sound Classification and Detection,International audience,"['https://openalex.org/W2963610932', 'https://openalex.org/W3094550259', 'https://openalex.org/W3205743929', 'https://openalex.org/W6739901393', 'https://openalex.org/W3196974791', 'https://openalex.org/W2108598243', 'https://openalex.org/W3142837074', 'https://openalex.org/W3138516171', 'https://openalex.org/W3006275583', 'https://openalex.org/W6745136726', 'https://openalex.org/W4226151502', 'https://openalex.org/W6750665317', 'https://openalex.org/W3162999565', 'https://openalex.org/W3163379884', 'https://openalex.org/W6781423933', 'https://openalex.org/W3005441616', 'https://openalex.org/W6781553146', 'https://openalex.org/W2052666245', 'https://openalex.org/W2593116425', 'https://openalex.org/W1975817689', 'https://openalex.org/W2973109987', 'https://openalex.org/W3178592608', 'https://openalex.org/W2936774411', 'https://openalex.org/W6840046036', 'https://openalex.org/W3119913666', 'https://openalex.org/W3198035615', 'https://openalex.org/W6788135285', 'https://openalex.org/W6762718338', 'https://openalex.org/W4385245566', 'https://openalex.org/W3047453285', 'https://openalex.org/W2797583228', 'https://openalex.org/W2955425717', 'https://openalex.org/W3170874841', 'https://openalex.org/W3197827948', 'https://openalex.org/W4286582832', 'https://openalex.org/W2016215128', 'https://openalex.org/W2765407302', 'https://openalex.org/W3047386385', 'https://openalex.org/W3101039626']",2022-04-27
https://openalex.org/W4396877837,https://doi.org/10.1109/taslp.2024.3399607,AudioLDM 2: Learning Holistic Audio Generation With Self-Supervised Pretraining,"Although audio generation shares commonalities across different types of audio, such as speech, music, and sound effects, designing models for each type requires careful consideration of specific objectives and biases that can significantly differ from those of other types. To bring us closer to a unified perspective of audio generation, this paper proposes a holistic framework that utilizes the same learning method for speech, music, and sound effect generation. Our framework utilizes a general representation of audio, called ""language of audio"" (LOA). Any audio can be translated into LOA based on AudioMAE, a self-supervised pre-trained representation learning model. In the generation process, we translate other modalities into LOA by using a GPT-2 model, and we perform self-supervised audio generation learning with a latent diffusion model conditioned on the LOA of audio in our training set. The proposed framework naturally brings advantages such as reusable self-supervised pretrained latent diffusion models. Experiments on the major benchmarks of text-to-audio, text-to-music, and text-to-speech with three AudioLDM 2 variants demonstrate competitive performance of the AudioLDM 2 variants framework against previous approaches. Our code, pretrained model, and demo are available at <uri xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://audioldm.github.io/audioldm2</uri> .","['https://openalex.org/W4391020683', 'https://openalex.org/W6845479124', 'https://openalex.org/W6849109464', 'https://openalex.org/W4389524500', 'https://openalex.org/W6855691466', 'https://openalex.org/W6849105126', 'https://openalex.org/W6610228593', 'https://openalex.org/W6771763809', 'https://openalex.org/W6778823374', 'https://openalex.org/W2559726422', 'https://openalex.org/W6852824296', 'https://openalex.org/W4367359628', 'https://openalex.org/W6849416043', 'https://openalex.org/W6802017037', 'https://openalex.org/W6810007534', 'https://openalex.org/W4386071707', 'https://openalex.org/W6852871851', 'https://openalex.org/W3127705815', 'https://openalex.org/W4312933868', 'https://openalex.org/W6851775633', 'https://openalex.org/W3215615641', 'https://openalex.org/W4381786045', 'https://openalex.org/W6917585676', 'https://openalex.org/W4372348103', 'https://openalex.org/W6802805937', 'https://openalex.org/W6795261426', 'https://openalex.org/W6777694618', 'https://openalex.org/W6849635556', 'https://openalex.org/W6853096648', 'https://openalex.org/W4226033575', 'https://openalex.org/W6779823529', 'https://openalex.org/W6786375611', 'https://openalex.org/W6795288823', 'https://openalex.org/W6809885388', 'https://openalex.org/W6838639034', 'https://openalex.org/W3155072588', 'https://openalex.org/W6782760101', 'https://openalex.org/W6783182287', 'https://openalex.org/W6838844135', 'https://openalex.org/W6844305113', 'https://openalex.org/W6845281891', 'https://openalex.org/W6848482659', 'https://openalex.org/W6799642162', 'https://openalex.org/W6797095309', 'https://openalex.org/W4224931676', 'https://openalex.org/W4387969125', 'https://openalex.org/W4372266890', 'https://openalex.org/W4393157029', 'https://openalex.org/W4393161149', 'https://openalex.org/W6780218876', 'https://openalex.org/W6640963894', 'https://openalex.org/W3094502228', 'https://openalex.org/W2593116425', 'https://openalex.org/W6853393314', 'https://openalex.org/W3209059054', 'https://openalex.org/W2973049979', 'https://openalex.org/W3201143670', 'https://openalex.org/W6783867762', 'https://openalex.org/W2052666245', 'https://openalex.org/W3046747294', 'https://openalex.org/W6769915798', 'https://openalex.org/W6728610325', 'https://openalex.org/W2066334462', 'https://openalex.org/W4372260310', 'https://openalex.org/W4372260340', 'https://openalex.org/W6847076894', 'https://openalex.org/W6769627184', 'https://openalex.org/W4378602476', 'https://openalex.org/W6739901393', 'https://openalex.org/W6840815571', 'https://openalex.org/W6810940779', 'https://openalex.org/W6850843143', 'https://openalex.org/W3015371781', 'https://openalex.org/W6732646663', 'https://openalex.org/W6633499030', 'https://openalex.org/W3198694222', 'https://openalex.org/W4372259760', 'https://openalex.org/W2526050071', 'https://openalex.org/W3205475937', 'https://openalex.org/W6633724138', 'https://openalex.org/W4375869413', 'https://openalex.org/W6783713337', 'https://openalex.org/W6757817989', 'https://openalex.org/W6852971826', 'https://openalex.org/W6849517043', 'https://openalex.org/W4313447020', 'https://openalex.org/W4224035735', 'https://openalex.org/W4376632781', 'https://openalex.org/W4318351475', 'https://openalex.org/W2984284833', 'https://openalex.org/W4318718630', 'https://openalex.org/W4288089799', 'https://openalex.org/W1959608418', 'https://openalex.org/W1560729591', 'https://openalex.org/W3203491020', 'https://openalex.org/W4379251869', 'https://openalex.org/W4400033239', 'https://openalex.org/W4362515116', 'https://openalex.org/W2187089797', 'https://openalex.org/W4378942405', 'https://openalex.org/W4385328213', 'https://openalex.org/W4319989813', 'https://openalex.org/W4303440777']",2024-01-01
https://openalex.org/W4391021627,https://doi.org/10.1109/asru57964.2023.10389742,Joint Audio and Speech Understanding,"Humans are surrounded by audio signals that include both speech and non-speech sounds. The recognition and understanding of speech and non-speech audio events, along with a profound comprehension of the relationship between them, constitute fundamental cognitive capabilities. For the first time, we build a machine learning model, called LTU-AS, that has a conceptually similar universal audio perception and advanced reasoning ability. Specifically, by integrating Whisper [1] as a perception module and LLaMA [2] as a reasoning module, LTU-AS can simultaneously recognize and jointly understand spoken text, speech paralinguistics, and non-speech audio events - almost everything perceivable from audio signals.","['https://openalex.org/W6847363464', 'https://openalex.org/W6850625674', 'https://openalex.org/W4385807453', 'https://openalex.org/W6778883912', 'https://openalex.org/W6853249747', 'https://openalex.org/W3196974791', 'https://openalex.org/W4375869243', 'https://openalex.org/W3095738461', 'https://openalex.org/W4224932123', 'https://openalex.org/W6809947431', 'https://openalex.org/W4297841687', 'https://openalex.org/W6851847159', 'https://openalex.org/W6850477478', 'https://openalex.org/W4389524500', 'https://openalex.org/W4390874621', 'https://openalex.org/W4385823034', 'https://openalex.org/W6739901393', 'https://openalex.org/W6677258307', 'https://openalex.org/W6796581206', 'https://openalex.org/W2963096510', 'https://openalex.org/W6768028577', 'https://openalex.org/W2146334809', 'https://openalex.org/W2883409523', 'https://openalex.org/W2808631503', 'https://openalex.org/W4210267911', 'https://openalex.org/W2191779130', 'https://openalex.org/W6732646663', 'https://openalex.org/W3162999565', 'https://openalex.org/W2593116425', 'https://openalex.org/W3015371781', 'https://openalex.org/W4205689591', 'https://openalex.org/W2982554818', 'https://openalex.org/W3205743929', 'https://openalex.org/W2052666245', 'https://openalex.org/W1494198834', 'https://openalex.org/W6785932716', 'https://openalex.org/W4226442948', 'https://openalex.org/W3204696009', 'https://openalex.org/W3209984917', 'https://openalex.org/W3097525302', 'https://openalex.org/W3176445421', 'https://openalex.org/W4372266552', 'https://openalex.org/W2964067969', 'https://openalex.org/W4311000453', 'https://openalex.org/W4292779060', 'https://openalex.org/W4377130946', 'https://openalex.org/W4300957348', 'https://openalex.org/W4385245566', 'https://openalex.org/W4221150524', 'https://openalex.org/W3168867926', 'https://openalex.org/W4322718191', 'https://openalex.org/W2973049837', 'https://openalex.org/W4322825254', 'https://openalex.org/W4393178509']",2023-12-16
https://openalex.org/W4390872297,https://doi.org/10.1109/iccv51070.2023.00387,Scalable Diffusion Models with Transformers,"We explore a new class of diffusion models based on the transformer architecture. We train latent diffusion models of images, replacing the commonly-used U-Net backbone with a transformer that operates on latent patches. We analyze the scalability of our Diffusion Transformers (DiTs) through the lens of forward pass complexity as measured by Gflops. We find that DiTs with higher Gflops—through increased transformer depth/width or increased number of input tokens—consistently have lower FID. In addition to possessing good scalability properties, our largest DiT-XL/2 models outperform all prior diffusion models on the class-conditional ImageNet 512×512 and 256×256 benchmarks, achieving a state-of-the-art FID of 2.27 on the latter.","['https://openalex.org/W6755312952', 'https://openalex.org/W6778883912', 'https://openalex.org/W4313021454', 'https://openalex.org/W6796289742', 'https://openalex.org/W6779879114', 'https://openalex.org/W6761628794', 'https://openalex.org/W6755207826', 'https://openalex.org/W6795288823', 'https://openalex.org/W6784333009', 'https://openalex.org/W3180355996', 'https://openalex.org/W6739622702', 'https://openalex.org/W4312388283', 'https://openalex.org/W2194775991', 'https://openalex.org/W6755977528', 'https://openalex.org/W6784913597', 'https://openalex.org/W6765779288', 'https://openalex.org/W6779823529', 'https://openalex.org/W6797359156', 'https://openalex.org/W6840815571', 'https://openalex.org/W6630178513', 'https://openalex.org/W2963073614', 'https://openalex.org/W6847386351', 'https://openalex.org/W6804244202', 'https://openalex.org/W6772383348', 'https://openalex.org/W6838452192', 'https://openalex.org/W2962770929', 'https://openalex.org/W6631190155', 'https://openalex.org/W6640963894', 'https://openalex.org/W2618530766', 'https://openalex.org/W6761519460', 'https://openalex.org/W6757817989', 'https://openalex.org/W6791436925', 'https://openalex.org/W6810940779', 'https://openalex.org/W6788990321', 'https://openalex.org/W4312694728', 'https://openalex.org/W6763509872', 'https://openalex.org/W6843572181', 'https://openalex.org/W2760103357', 'https://openalex.org/W6791353385', 'https://openalex.org/W2981563141', 'https://openalex.org/W3034429256', 'https://openalex.org/W6809885388', 'https://openalex.org/W6790978476', 'https://openalex.org/W4312933868', 'https://openalex.org/W1901129140', 'https://openalex.org/W6838639034', 'https://openalex.org/W6718379498', 'https://openalex.org/W6732492507', 'https://openalex.org/W6810483347', 'https://openalex.org/W6679045638', 'https://openalex.org/W6783713337', 'https://openalex.org/W6765775151', 'https://openalex.org/W6798160016', 'https://openalex.org/W2423557781', 'https://openalex.org/W2752796333', 'https://openalex.org/W6739901393', 'https://openalex.org/W6797790494', 'https://openalex.org/W6839643428', 'https://openalex.org/W3172942063']",2023-10-01
https://openalex.org/W4392931276,https://doi.org/10.1109/icassp48485.2024.10448291,Matcha-TTS: A Fast TTS Architecture with Conditional Flow Matching,"We introduce Matcha-TTS, a new encoder-decoder architecture for speedy TTS acoustic modelling, trained using optimal-transport conditional flow matching (OT-CFM). This yields an ODE-based decoder capable of high output quality in fewer synthesis steps than models trained using score matching. Careful design choices additionally ensure each synthesis step is fast to run. The method is probabilistic, non-autoregressive, and learns to speak from scratch without external alignments. Compared to strong pre-trained baseline models, the Matcha-TTS system has the smallest memory footprint, rivals the speed of the fastest model on long utterances, and attains the highest mean opinion score in a listening test.","['https://openalex.org/W6765775151', 'https://openalex.org/W6795288823', 'https://openalex.org/W4312933868', 'https://openalex.org/W4377010269', 'https://openalex.org/W4385993915', 'https://openalex.org/W6782760101', 'https://openalex.org/W3198769980', 'https://openalex.org/W6795261426', 'https://openalex.org/W3198213150', 'https://openalex.org/W6783182287', 'https://openalex.org/W6786375611', 'https://openalex.org/W6844938924', 'https://openalex.org/W6752307458', 'https://openalex.org/W6846539466', 'https://openalex.org/W4296069326', 'https://openalex.org/W6852421699', 'https://openalex.org/W6763832098', 'https://openalex.org/W6778823374', 'https://openalex.org/W6800569930', 'https://openalex.org/W6777694618', 'https://openalex.org/W2963925437', 'https://openalex.org/W3196718914', 'https://openalex.org/W4388979610', 'https://openalex.org/W3175475869', 'https://openalex.org/W4385822499', 'https://openalex.org/W4304099317', 'https://openalex.org/W2972569067', 'https://openalex.org/W3198332267', 'https://openalex.org/W6838843145', 'https://openalex.org/W6843731886', 'https://openalex.org/W4387968164', 'https://openalex.org/W6853888607', 'https://openalex.org/W4200300291', 'https://openalex.org/W6783867762', 'https://openalex.org/W2963300588', 'https://openalex.org/W6847363464', 'https://openalex.org/W3196568361', 'https://openalex.org/W4395961422', 'https://openalex.org/W4385822565', 'https://openalex.org/W4385993869', 'https://openalex.org/W2973177710', 'https://openalex.org/W4376632512', 'https://openalex.org/W4382603054']",2024-03-18
https://openalex.org/W4393178509,https://doi.org/10.1609/aaai.v38i21.30570,"AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head","Large language models (LLMs) have exhibited remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. Despite the recent success, current LLMs are not capable of processing complex audio information or conducting spoken conversations (like Siri or Alexa). In this work, we propose a multi-modal AI system named AudioGPT, which complements LLMs (i.e., ChatGPT) with 1) foundation models to process complex audio information and solve numerous understanding and generation tasks; and 2) the input/output interface (ASR, TTS) to support spoken dialogue. With an increasing demand to evaluate multi-modal LLMs of human intention understanding and cooperation with foundation models, we outline the principles and processes and test AudioGPT in terms of consistency, capability, and robustness. Experimental results demonstrate the capabilities of AudioGPT in solving 16 AI tasks with speech, music, sound, and talking head understanding and generation in multi-round dialogues, which empower humans to create rich and diverse audio content with unprecedented ease. Code can be found in https://github.com/AIGC-Audio/AudioGPT","['https://openalex.org/W3158405307', 'https://openalex.org/W3169320628', 'https://openalex.org/W3205398360', 'https://openalex.org/W3158762648', 'https://openalex.org/W2952218014', 'https://openalex.org/W6792340124', 'https://openalex.org/W3208601549', 'https://openalex.org/W4297841486', 'https://openalex.org/W3207340675', 'https://openalex.org/W3206857696', 'https://openalex.org/W4226419874', 'https://openalex.org/W4287184558', 'https://openalex.org/W4318718996', 'https://openalex.org/W4224871700', 'https://openalex.org/W4323717348', 'https://openalex.org/W4372271367', 'https://openalex.org/W4285345683', 'https://openalex.org/W4318906029', 'https://openalex.org/W4292779060', 'https://openalex.org/W3033411150', 'https://openalex.org/W4303519914', 'https://openalex.org/W4311000453', 'https://openalex.org/W4280542470', 'https://openalex.org/W4361866031', 'https://openalex.org/W3172862365', 'https://openalex.org/W4226278401', 'https://openalex.org/W4367359628', 'https://openalex.org/W3138953166', 'https://openalex.org/W4298017177', 'https://openalex.org/W4288089799', 'https://openalex.org/W2896457183']",2024-03-24
https://openalex.org/W4408353629,https://doi.org/10.1109/icassp49660.2025.10890588,Boosting Large Language Model for Speech Synthesis: An Empirical Study,,"['https://openalex.org/W6854866820', 'https://openalex.org/W6810738896', 'https://openalex.org/W6846002521', 'https://openalex.org/W6852800892', 'https://openalex.org/W6850015000', 'https://openalex.org/W4389519587', 'https://openalex.org/W6857054612', 'https://openalex.org/W6853116092', 'https://openalex.org/W4402671548', 'https://openalex.org/W4404783556', 'https://openalex.org/W6859099255', 'https://openalex.org/W4404781855', 'https://openalex.org/W4391021666', 'https://openalex.org/W4392903956', 'https://openalex.org/W6855801281', 'https://openalex.org/W2127141656', 'https://openalex.org/W4389524500', 'https://openalex.org/W6853998256', 'https://openalex.org/W6848735303', 'https://openalex.org/W6739901393', 'https://openalex.org/W4307323391', 'https://openalex.org/W6796581206', 'https://openalex.org/W6811340617', 'https://openalex.org/W6850334629', 'https://openalex.org/W4406417959', 'https://openalex.org/W1494198834', 'https://openalex.org/W3095410713', 'https://openalex.org/W6631190155', 'https://openalex.org/W6761164592', 'https://openalex.org/W3209984917', 'https://openalex.org/W3097206152', 'https://openalex.org/W6761551260', 'https://openalex.org/W6853611000', 'https://openalex.org/W6771812881']",2025-03-12
https://openalex.org/W4408345930,https://doi.org/10.1109/icassp49660.2025.10888461,Stable Audio Open,,"['https://openalex.org/W6845479124', 'https://openalex.org/W6849109464', 'https://openalex.org/W4396877837', 'https://openalex.org/W6861353174', 'https://openalex.org/W6864798992', 'https://openalex.org/W6849105126', 'https://openalex.org/W6858340110', 'https://openalex.org/W6734260513', 'https://openalex.org/W6853096648', 'https://openalex.org/W6769627184', 'https://openalex.org/W4372260310', 'https://openalex.org/W6779577414', 'https://openalex.org/W4390872297', 'https://openalex.org/W4388979610', 'https://openalex.org/W6838322825', 'https://openalex.org/W6703652217', 'https://openalex.org/W6776218486', 'https://openalex.org/W6779823529', 'https://openalex.org/W3094550259', 'https://openalex.org/W6853515095', 'https://openalex.org/W4307323391', 'https://openalex.org/W6809884996', 'https://openalex.org/W4411528087', 'https://openalex.org/W2939574508', 'https://openalex.org/W3205475937', 'https://openalex.org/W2972478942', 'https://openalex.org/W6849416043', 'https://openalex.org/W6858779713', 'https://openalex.org/W6849141701', 'https://openalex.org/W6862995742']",2025-03-12
https://openalex.org/W2593116425,https://doi.org/10.1109/icassp.2017.7952261,Audio Set: An ontology and human-labeled dataset for audio events,"Audio event recognition, the human-like ability to identify and relate sounds from audio, is a nascent problem in machine perception. Comparable problems such as object detection in images have reaped enormous benefits from comprehensive datasets - principally ImageNet. This paper describes the creation of Audio Set, a large-scale dataset of manually-annotated audio events that endeavors to bridge the gap in data availability between image and audio research. Using a carefully structured hierarchical ontology of 632 audio classes guided by the literature and manual curation, we collect data from human labelers to probe the presence of specific audio classes in 10 second segments of YouTube videos. Segments are proposed for labeling using searches based on metadata, context (e.g., links), and content analysis. The result is a dataset of unprecedented breadth and size that will, we hope, substantially stimulate the development of high-performance audio event recognizers.","['https://openalex.org/W6632100227', 'https://openalex.org/W2038484192', 'https://openalex.org/W2074188409', 'https://openalex.org/W6675872639', 'https://openalex.org/W2086384421', 'https://openalex.org/W2566935005', 'https://openalex.org/W2068737686', 'https://openalex.org/W2117539524', 'https://openalex.org/W4236923591', 'https://openalex.org/W4319290960', 'https://openalex.org/W2081913879', 'https://openalex.org/W2008142581', 'https://openalex.org/W6674914833', 'https://openalex.org/W6684191040', 'https://openalex.org/W2032337854', 'https://openalex.org/W2081580037', 'https://openalex.org/W2526050071', 'https://openalex.org/W2210407171', 'https://openalex.org/W2194775991', 'https://openalex.org/W2508979362', 'https://openalex.org/W2097117768', 'https://openalex.org/W2126422864', 'https://openalex.org/W2163605009', 'https://openalex.org/W1535031652', 'https://openalex.org/W2105068979']",2017-03-01
https://openalex.org/W3015371781,https://doi.org/10.1109/icassp40776.2020.9053174,Vggsound: A Large-Scale Audio-Visual Dataset,"Our goal is to collect a large-scale audio-visual dataset with low label noise from videos `in the wild' using computer vision techniques. The resulting dataset can be used for training and evaluating audio recognition models. We make three contributions. First, we propose a scalable pipeline based on computer vision techniques to create an audio dataset from open-source media. Our pipeline involves obtaining videos from YouTube; using image classification algorithms to localize audio-visual correspondence; and filtering out ambient noise using audio verification. Second, we use this pipeline to curate the VGGSound dataset consisting of more than 200k videos for 300 audio classes. Third, we investigate various Convolutional Neural Network (CNN) architectures and aggregation approaches to establish audio recognition baselines for our new dataset. Compared to existing audio datasets, VGGSound ensures audio-visual correspondence and is collected under unconstrained conditions. Code and the dataset are available at http://www.robots.ox.ac.uk/~vgg/data/vggsound/.","['https://openalex.org/W6682691769', 'https://openalex.org/W6754337694', 'https://openalex.org/W2963723765', 'https://openalex.org/W2593116425', 'https://openalex.org/W2726515241', 'https://openalex.org/W2981087920', 'https://openalex.org/W2808631503', 'https://openalex.org/W2179042386', 'https://openalex.org/W2916104401', 'https://openalex.org/W2105582566', 'https://openalex.org/W2964345931', 'https://openalex.org/W6750599028', 'https://openalex.org/W2341412280', 'https://openalex.org/W2194775991', 'https://openalex.org/W2342547278', 'https://openalex.org/W6637373629', 'https://openalex.org/W2038484192', 'https://openalex.org/W2963451564', 'https://openalex.org/W2526050071', 'https://openalex.org/W2770119437', 'https://openalex.org/W821549425', 'https://openalex.org/W2108598243', 'https://openalex.org/W2566935005', 'https://openalex.org/W2031489346', 'https://openalex.org/W2938440247', 'https://openalex.org/W2115447976', 'https://openalex.org/W2964109005', 'https://openalex.org/W6696804643', 'https://openalex.org/W2153220212', 'https://openalex.org/W6682320352', 'https://openalex.org/W6600006618', 'https://openalex.org/W2152305730', 'https://openalex.org/W2294701319', 'https://openalex.org/W2962865004', 'https://openalex.org/W1686810756', 'https://openalex.org/W2962835968', 'https://openalex.org/W4294170691', 'https://openalex.org/W2963543871', 'https://openalex.org/W2620629206', 'https://openalex.org/W2153579005', 'https://openalex.org/W2887051120', 'https://openalex.org/W183860', 'https://openalex.org/W2619697695']",2020-04-09
https://openalex.org/W2052666245,https://doi.org/10.1145/2733373.2806390,ESC,"One of the obstacles in research activities concentrating on environmental sound classification is the scarcity of suitable and publicly available datasets. This paper tries to address that issue by presenting a new annotated collection of 2000 short clips comprising 50 classes of various common sound events, and an abundant unified compilation of 250000 unlabeled auditory excerpts extracted from recordings available through the Freesound project. The paper also provides an evaluation of human accuracy in classifying environmental sounds and compares it to the performance of selected baseline classifiers using features derived from mel-frequency cepstral coefficients and zero-crossing rate.","['https://openalex.org/W2113278353', 'https://openalex.org/W2103235956', 'https://openalex.org/W2313745396', 'https://openalex.org/W2033875152', 'https://openalex.org/W2008415856', 'https://openalex.org/W47831154', 'https://openalex.org/W2963922351', 'https://openalex.org/W2122663001', 'https://openalex.org/W1972567154', 'https://openalex.org/W2092216166', 'https://openalex.org/W2038484192', 'https://openalex.org/W2901908104', 'https://openalex.org/W3103385400', 'https://openalex.org/W1757247158', 'https://openalex.org/W2154252319', 'https://openalex.org/W2982303213', 'https://openalex.org/W2622886161']",2015-10-13
https://openalex.org/W4392902957,https://doi.org/10.1109/icassp48485.2024.10446663,Adapting Frechet Audio Distance for Generative Music Evaluation,"The growing popularity of generative music models underlines the need for perceptually relevant, objective music quality metrics. The Frechet Audio Distance (FAD) is commonly used for this purpose even though its correlation with perceptual quality is understudied. We show that FAD performance may be hampered by sample size bias, poor choice of audio embeddings, or the use of biased or low-quality reference sets. We propose reducing sample size bias by extrapolating scores towards an infinite sample size. Through comparisons with MusicCaps labels and a listening test we identify audio embeddings and music reference sets that yield FAD scores well-correlated with acoustic and musical quality. Our results suggest that per-song FAD can be useful to identify outlier samples and predict perceptual quality for a range of music sets and generative models. Finally, we release a toolkit that allows adapting FAD for generative music evaluation.","['https://openalex.org/W4367359628', 'https://openalex.org/W2526050071', 'https://openalex.org/W3034664137', 'https://openalex.org/W6766320909', 'https://openalex.org/W6855434424', 'https://openalex.org/W4221165315', 'https://openalex.org/W2939574508', 'https://openalex.org/W3006926732', 'https://openalex.org/W4392903801', 'https://openalex.org/W6846849257', 'https://openalex.org/W6853393314', 'https://openalex.org/W6790489232', 'https://openalex.org/W4307323391', 'https://openalex.org/W6853515095', 'https://openalex.org/W3094550259', 'https://openalex.org/W4372266552', 'https://openalex.org/W4226343611', 'https://openalex.org/W4294534174', 'https://openalex.org/W4379251869', 'https://openalex.org/W4221152471', 'https://openalex.org/W4283382678', 'https://openalex.org/W3160506022', 'https://openalex.org/W4318752004', 'https://openalex.org/W4380136719', 'https://openalex.org/W4289106098', 'https://openalex.org/W2615063356', 'https://openalex.org/W4380551955', 'https://openalex.org/W4293575120', 'https://openalex.org/W4385473570', 'https://openalex.org/W4318351475', 'https://openalex.org/W2580221632', 'https://openalex.org/W4319452539', 'https://openalex.org/W4319989813', 'https://openalex.org/W4298310324']",2024-03-18
https://openalex.org/W2506483933,https://doi.org/10.1007/978-3-319-46454-1_24,SPICE: Semantic Propositional Image Caption Evaluation,,"['https://openalex.org/W2951183276', 'https://openalex.org/W6601955380', 'https://openalex.org/W68733909', 'https://openalex.org/W2185175083', 'https://openalex.org/W1861492603', 'https://openalex.org/W6600018615', 'https://openalex.org/W1969616664', 'https://openalex.org/W2128856065', 'https://openalex.org/W2282219577', 'https://openalex.org/W2101105183', 'https://openalex.org/W1956340063', 'https://openalex.org/W2133459682', 'https://openalex.org/W2077069816', 'https://openalex.org/W2250378130', 'https://openalex.org/W2296308987', 'https://openalex.org/W2086842362', 'https://openalex.org/W2097606805', 'https://openalex.org/W2343888024', 'https://openalex.org/W2149837184', 'https://openalex.org/W2963720566', 'https://openalex.org/W1773149199', 'https://openalex.org/W2031342017', 'https://openalex.org/W2054125330', 'https://openalex.org/W2164418233', 'https://openalex.org/W2916548775', 'https://openalex.org/W2251610689', 'https://openalex.org/W6835303316', 'https://openalex.org/W1905882502', 'https://openalex.org/W1931639407', 'https://openalex.org/W1895577753', 'https://openalex.org/W6702248584', 'https://openalex.org/W2139380585', 'https://openalex.org/W6605520847', 'https://openalex.org/W2028176545', 'https://openalex.org/W2154652894', 'https://openalex.org/W2163986298', 'https://openalex.org/W1962622193', 'https://openalex.org/W2953158660', 'https://openalex.org/W2252081299', 'https://openalex.org/W2171361956', 'https://openalex.org/W2119775030', 'https://openalex.org/W2952782394', 'https://openalex.org/W2962706528', 'https://openalex.org/W2885050925', 'https://openalex.org/W2250375035', 'https://openalex.org/W1947481528', 'https://openalex.org/W2277195237']",2016-01-01
https://openalex.org/W3205860970,https://doi.org/10.1109/icassp43922.2022.9746427,Can Audio Captions Be Evaluated With Image Caption Metrics?,"Automated audio captioning aims at generating textual descriptions for an audio clip. To evaluate the quality of generated audio captions, previous works directly adopt image captioning metrics like SPICE and CIDEr, without justifying their suitability in this new domain, which may mislead the development of advanced models. This problem is still unstudied due to the lack of human judgment datasets on caption quality. Therefore, we first construct two evaluation benchmarks, AudioCaps-Eval and Clotho-Eval. They are established with pairwise comparison instead of absolute rating to achieve better inter-annotator agreement. Current metrics are found in poor correlation with human annotations on these datasets. To overcome their limitations, we propose a metric named FENSE, where we combine the strength of Sentence-BERT in capturing similarity, and a novel Error Detector to penalize erroneous sentences for robustness. On the newly established benchmarks, FENSE outperforms current metrics by 14-25% accuracy. <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">1</sup>","['https://openalex.org/W6678262379', 'https://openalex.org/W1956340063', 'https://openalex.org/W6725318829', 'https://openalex.org/W2963672599', 'https://openalex.org/W2896780650', 'https://openalex.org/W6761205521', 'https://openalex.org/W3035252911', 'https://openalex.org/W2970641574', 'https://openalex.org/W3094550259', 'https://openalex.org/W3160577380', 'https://openalex.org/W2916103538', 'https://openalex.org/W6898505805', 'https://openalex.org/W3015591594', 'https://openalex.org/W6682631176', 'https://openalex.org/W2964213897', 'https://openalex.org/W2788277448', 'https://openalex.org/W6755207826', 'https://openalex.org/W1975879668', 'https://openalex.org/W2970858040', 'https://openalex.org/W3204363391', 'https://openalex.org/W2123301721', 'https://openalex.org/W2963341956', 'https://openalex.org/W2936695845', 'https://openalex.org/W2101105183', 'https://openalex.org/W2950446064', 'https://openalex.org/W2996403597', 'https://openalex.org/W2506483933', 'https://openalex.org/W2154652894', 'https://openalex.org/W2945761034', 'https://openalex.org/W2896457183']",2022-04-27
https://openalex.org/W2133824856,https://doi.org/10.1109/tsa.2002.800560,Musical genre classification of audio signals,"Musical genres are categorical labels created by humans to characterize pieces of music. A musical genre is characterized by the common characteristics shared by its members. These characteristics typically are related to the instrumentation, rhythmic structure, and harmonic content of the music. Genre hierarchies are commonly used to structure the large collections of music available on the Web. Currently musical genre annotation is performed manually. Automatic musical genre classification can assist or replace the human user in this process and would be a valuable addition to music information retrieval systems. In addition, automatic musical genre classification provides a framework for developing and evaluating features for any type of content-based analysis of musical signals. In this paper, the automatic classification of audio signals into an hierarchy of musical genres is explored. More specifically, three feature sets for representing timbral texture, rhythmic content and pitch content are proposed. The performance and relative importance of the proposed features is investigated by training statistical pattern recognition classifiers using real-world audio collections. Both whole file and real-time frame-based classification schemes are described. Using the proposed feature sets, classification of 61% for ten musical genres is achieved. This result is comparable to results reported for human musical genre classification.","['https://openalex.org/W2148154194', 'https://openalex.org/W2106055371', 'https://openalex.org/W2128838222', 'https://openalex.org/W6605678257', 'https://openalex.org/W2144345993', 'https://openalex.org/W2124867748', 'https://openalex.org/W2074188409', 'https://openalex.org/W2111331420', 'https://openalex.org/W6640934164', 'https://openalex.org/W2110458017', 'https://openalex.org/W2067063915', 'https://openalex.org/W2160531276', 'https://openalex.org/W2112630930', 'https://openalex.org/W2129338995', 'https://openalex.org/W6638699884', 'https://openalex.org/W6600593648', 'https://openalex.org/W2098914003', 'https://openalex.org/W2149095746', 'https://openalex.org/W6604454234', 'https://openalex.org/W2130976598', 'https://openalex.org/W2059020775', 'https://openalex.org/W97140021', 'https://openalex.org/W1497564599', 'https://openalex.org/W2154642142', 'https://openalex.org/W6779561511', 'https://openalex.org/W1861596447', 'https://openalex.org/W2166248431', 'https://openalex.org/W2062170755', 'https://openalex.org/W1954587310', 'https://openalex.org/W4285719527', 'https://openalex.org/W3034415380', 'https://openalex.org/W139898027', 'https://openalex.org/W1774234760', 'https://openalex.org/W15066456', 'https://openalex.org/W2039275978', 'https://openalex.org/W2799061466', 'https://openalex.org/W1835965142', 'https://openalex.org/W2115755118', 'https://openalex.org/W110296819', 'https://openalex.org/W4244494905', 'https://openalex.org/W1560013842']",2002-07-01
