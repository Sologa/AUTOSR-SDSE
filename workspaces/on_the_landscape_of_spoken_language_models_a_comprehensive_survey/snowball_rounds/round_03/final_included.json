[
  {
    "status": "include",
    "title": "Duplex Conversation: Towards Human-like Interaction in Spoken Dialogue Systems",
    "normalized_title": "duplexconversation:towardshuman-likeinteractioninspokendialoguesystems",
    "doi": "10.1145/3534678.3539209",
    "openalex_id": "",
    "arxiv_id": "2205.15060",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Augmentation Invariant Discrete Representation for Generative Spoken Language Modeling",
    "normalized_title": "augmentationinvariantdiscreterepresentationforgenerativespokenlanguagemodeling",
    "doi": "10.48550/arxiv.2209.15483",
    "openalex_id": "",
    "arxiv_id": "2209.15483",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Self-supervised language learning from raw audio: Lessons from the Zero Resource Speech Challenge",
    "normalized_title": "self-supervisedlanguagelearningfromrawaudio:lessonsfromthezeroresourcespeechchallenge",
    "doi": "10.1109/jstsp.2022.3206084",
    "openalex_id": "",
    "arxiv_id": "2210.15759",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Analysing Discrete Self Supervised Speech Representation for Spoken Language Modeling",
    "normalized_title": "analysingdiscreteselfsupervisedspeechrepresentationforspokenlanguagemodeling",
    "doi": "10.1109/icassp49357.2023.10097097",
    "openalex_id": "",
    "arxiv_id": "2301.00591",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec Language Modeling",
    "normalized_title": "speakforeignlanguageswithyourownvoice:cross-lingualneuralcodeclanguagemodeling",
    "doi": "10.48550/arxiv.2303.03926",
    "openalex_id": "",
    "arxiv_id": "2303.03926",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM",
    "normalized_title": "spokenquestionansweringandspeechcontinuationusingspectrogram-poweredllm",
    "doi": "10.48550/arxiv.2305.15255",
    "openalex_id": "",
    "arxiv_id": "2305.15255",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "VioLA: Unified Codec Language Models for Speech Recognition, Synthesis, and Translation",
    "normalized_title": "viola:unifiedcodeclanguagemodelsforspeechrecognition,synthesis,andtranslation",
    "doi": "10.48550/arxiv.2305.16107",
    "openalex_id": "",
    "arxiv_id": "2305.16107",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Wave to Syntax: Probing spoken language models for syntax",
    "normalized_title": "wavetosyntax:probingspokenlanguagemodelsforsyntax",
    "doi": "10.21437/interspeech.2023-679",
    "openalex_id": "",
    "arxiv_id": "2305.18957",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "How Generative Spoken Language Modeling Encodes Noisy Speech: Investigation from Phonetics to Syntactics",
    "normalized_title": "howgenerativespokenlanguagemodelingencodesnoisyspeech:investigationfromphoneticstosyntactics",
    "doi": "10.48550/arxiv.2306.00697",
    "openalex_id": "",
    "arxiv_id": "2306.00697",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "BabySLM: language-acquisition-friendly benchmark of self-supervised spoken language models",
    "normalized_title": "babyslm:language-acquisition-friendlybenchmarkofself-supervisedspokenlanguagemodels",
    "doi": "10.21437/interspeech.2023-978",
    "openalex_id": "",
    "arxiv_id": "2306.01506",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SpeechX: Neural Codec Language Model as a Versatile Speech Transformer",
    "normalized_title": "speechx:neuralcodeclanguagemodelasaversatilespeechtransformer",
    "doi": "10.48550/arxiv.2308.06873",
    "openalex_id": "",
    "arxiv_id": "2308.06873",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Towards Practical and Efficient Image-to-Speech Captioning with Vision-Language Pre-training and Multi-modal Tokens",
    "normalized_title": "towardspracticalandefficientimage-to-speechcaptioningwithvision-languagepre-trainingandmulti-modaltokens",
    "doi": "10.48550/arxiv.2309.08531",
    "openalex_id": "",
    "arxiv_id": "2309.08531",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "LauraGPT: Listen, Attend, Understand, and Regenerate Audio with GPT",
    "normalized_title": "lauragpt:listen,attend,understand,andregenerateaudiowithgpt",
    "doi": "10.48550/arxiv.2310.04673",
    "openalex_id": "",
    "arxiv_id": "2310.04673",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Generative Spoken Language Model based on continuous word-sized audio tokens",
    "normalized_title": "generativespokenlanguagemodelbasedoncontinuousword-sizedaudiotokens",
    "doi": "10.48550/arxiv.2310.05224",
    "openalex_id": "",
    "arxiv_id": "2310.05224",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SD-HuBERT: Sentence-Level Self-Distillation Induces Syllabic Organization in HuBERT",
    "normalized_title": "sd-hubert:sentence-levelself-distillationinducessyllabicorganizationinhubert",
    "doi": "10.48550/arxiv.2310.10803",
    "openalex_id": "",
    "arxiv_id": "2310.10803",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion",
    "normalized_title": "turn-takingandbackchannelpredictionwithacousticandlargelanguagemodelfusion",
    "doi": "10.48550/arxiv.2401.14717",
    "openalex_id": "",
    "arxiv_id": "2401.14717",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Encoding of lexical tone in self-supervised models of spoken language",
    "normalized_title": "encodingoflexicaltoneinself-supervisedmodelsofspokenlanguage",
    "doi": "10.48550/arxiv.2403.16865",
    "openalex_id": "",
    "arxiv_id": "2403.16865",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild",
    "normalized_title": "voicecraft:zero-shotspeecheditingandtext-to-speechinthewild",
    "doi": "10.48550/arxiv.2403.16973",
    "openalex_id": "",
    "arxiv_id": "2403.16973",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SpeechAlign: Aligning Speech Generation to Human Preferences",
    "normalized_title": "speechalign:aligningspeechgenerationtohumanpreferences",
    "doi": "10.48550/arxiv.2404.05600",
    "openalex_id": "",
    "arxiv_id": "2404.05600",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "MAD Speech: Measures of Acoustic Diversity of Speech",
    "normalized_title": "madspeech:measuresofacousticdiversityofspeech",
    "doi": "10.48550/arxiv.2404.10419",
    "openalex_id": "",
    "arxiv_id": "2404.10419",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "CoLM-DSR: Leveraging Neural Codec Language Modeling for Multi-Modal Dysarthric Speech Reconstruction",
    "normalized_title": "colm-dsr:leveragingneuralcodeclanguagemodelingformulti-modaldysarthricspeechreconstruction",
    "doi": "10.48550/arxiv.2406.08336",
    "openalex_id": "",
    "arxiv_id": "2406.08336",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "NAST: Noise Aware Speech Tokenization for Speech Language Models",
    "normalized_title": "nast:noiseawarespeechtokenizationforspeechlanguagemodels",
    "doi": "10.48550/arxiv.2406.11037",
    "openalex_id": "",
    "arxiv_id": "2406.11037",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Investigating the Effects of Large-Scale Pseudo-Stereo Data and Different Speech Foundation Model on Dialogue Generative Spoken Language Model",
    "normalized_title": "investigatingtheeffectsoflarge-scalepseudo-stereodataanddifferentspeechfoundationmodelondialoguegenerativespokenlanguagemodel",
    "doi": "10.48550/arxiv.2407.01911",
    "openalex_id": "",
    "arxiv_id": "2407.01911",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "J-CHAT: Japanese Large-scale Spoken Dialogue Corpus for Spoken Dialogue Language Modeling",
    "normalized_title": "j-chat:japaneselarge-scalespokendialoguecorpusforspokendialoguelanguagemodeling",
    "doi": "10.48550/arxiv.2407.15828",
    "openalex_id": "",
    "arxiv_id": "2407.15828",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Language Model Can Listen While Speaking",
    "normalized_title": "languagemodelcanlistenwhilespeaking",
    "doi": "10.48550/arxiv.2408.02622",
    "openalex_id": "",
    "arxiv_id": "2408.02622",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Mini-Omni: Language Models Can Hear, Talk While Thinking in Streaming",
    "normalized_title": "mini-omni:languagemodelscanhear,talkwhilethinkinginstreaming",
    "doi": "10.48550/arxiv.2408.16725",
    "openalex_id": "",
    "arxiv_id": "2408.16725",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "LAST: Language Model Aware Speech Tokenization",
    "normalized_title": "last:languagemodelawarespeechtokenization",
    "doi": "10.48550/arxiv.2409.03701",
    "openalex_id": "",
    "arxiv_id": "2409.03701",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "TSELM: Target Speaker Extraction using Discrete Tokens and Language Models",
    "normalized_title": "tselm:targetspeakerextractionusingdiscretetokensandlanguagemodels",
    "doi": "10.48550/arxiv.2409.07841",
    "openalex_id": "",
    "arxiv_id": "2409.07841",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents",
    "normalized_title": "beyondturn-basedinterfaces:synchronousllmsasfull-duplexdialogueagents",
    "doi": "10.48550/arxiv.2409.15594",
    "openalex_id": "",
    "arxiv_id": "2409.15594",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Analyzing and Mitigating Inconsistency in Discrete Audio Tokens for Neural Codec Language Models",
    "normalized_title": "analyzingandmitigatinginconsistencyindiscreteaudiotokensforneuralcodeclanguagemodels",
    "doi": "10.48550/arxiv.2409.19283",
    "openalex_id": "",
    "arxiv_id": "2409.19283",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Improving Spoken Language Modeling with Phoneme Classification: A Simple Fine-tuning Approach",
    "normalized_title": "improvingspokenlanguagemodelingwithphonemeclassification:asimplefine-tuningapproach",
    "doi": "10.48550/arxiv.2410.00025",
    "openalex_id": "",
    "arxiv_id": "2410.00025",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Moshi: a speech-text foundation model for real-time dialogue",
    "normalized_title": "moshi:aspeech-textfoundationmodelforreal-timedialogue",
    "doi": "10.48550/arxiv.2410.00037",
    "openalex_id": "",
    "arxiv_id": "2410.00037",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SyllableLM: Learning Coarse Semantic Units for Speech Language Models",
    "normalized_title": "syllablelm:learningcoarsesemanticunitsforspeechlanguagemodels",
    "doi": "10.48550/arxiv.2410.04029",
    "openalex_id": "",
    "arxiv_id": "2410.04029",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "HALL-E: Hierarchical Neural Codec Language Model for Minute-Long Zero-Shot Text-to-Speech Synthesis",
    "normalized_title": "hall-e:hierarchicalneuralcodeclanguagemodelforminute-longzero-shottext-to-speechsynthesis",
    "doi": "10.48550/arxiv.2410.04380",
    "openalex_id": "",
    "arxiv_id": "2410.04380",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Sylber: Syllabic Embedding Representation of Speech from Raw Audio",
    "normalized_title": "sylber:syllabicembeddingrepresentationofspeechfromrawaudio",
    "doi": "10.48550/arxiv.2410.07168",
    "openalex_id": "",
    "arxiv_id": "2410.07168",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "DC-Spin: A Speaker-invariant Speech Tokenizer for Spoken Language Models",
    "normalized_title": "dc-spin:aspeaker-invariantspeechtokenizerforspokenlanguagemodels",
    "doi": "10.48550/arxiv.2410.24177",
    "openalex_id": "",
    "arxiv_id": "2410.24177",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Align-SLM: Textless Spoken Language Models with Reinforcement Learning from AI Feedback",
    "normalized_title": "align-slm:textlessspokenlanguagemodelswithreinforcementlearningfromaifeedback",
    "doi": "10.48550/arxiv.2411.01834",
    "openalex_id": "",
    "arxiv_id": "2411.01834",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Dynamic-SUPERB Phase-2: A Collaboratively Expanding Benchmark for Measuring the Capabilities of Spoken Language Models with 180 Tasks",
    "normalized_title": "dynamic-superbphase-2:acollaborativelyexpandingbenchmarkformeasuringthecapabilitiesofspokenlanguagemodelswith180tasks",
    "doi": "10.48550/arxiv.2411.05361",
    "openalex_id": "",
    "arxiv_id": "2411.05361",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Building a Taiwanese Mandarin Spoken Language Model: A First Attempt",
    "normalized_title": "buildingataiwanesemandarinspokenlanguagemodel:afirstattempt",
    "doi": "10.48550/arxiv.2411.07111",
    "openalex_id": "",
    "arxiv_id": "2411.07111",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "A Comparative Study of Discrete Speech Tokens for Semantic-Related Tasks with Large Language Models",
    "normalized_title": "acomparativestudyofdiscretespeechtokensforsemantic-relatedtaskswithlargelanguagemodels",
    "doi": "10.48550/arxiv.2411.08742",
    "openalex_id": "",
    "arxiv_id": "2411.08742",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SALMONN-omni: A Codec-free LLM for Full-duplex Speech Understanding and Generation",
    "normalized_title": "salmonn-omni:acodec-freellmforfull-duplexspeechunderstandingandgeneration",
    "doi": "10.48550/arxiv.2411.18138",
    "openalex_id": "",
    "arxiv_id": "2411.18138",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Advancing Speech Language Models by Scaling Supervised Fine-Tuning with Over 60,000 Hours of Synthetic Speech Dialogue Data",
    "normalized_title": "advancingspeechlanguagemodelsbyscalingsupervisedfine-tuningwithover60,000hoursofsyntheticspeechdialoguedata",
    "doi": "10.48550/arxiv.2412.01078",
    "openalex_id": "",
    "arxiv_id": "2412.01078",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Whisper-GPT: A Hybrid Representation Audio Large Language Model",
    "normalized_title": "whisper-gpt:ahybridrepresentationaudiolargelanguagemodel",
    "doi": "10.48550/arxiv.2412.11449",
    "openalex_id": "",
    "arxiv_id": "2412.11449",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SLAM-Omni: Timbre-Controllable Voice Interaction System with Single-Stage Training",
    "normalized_title": "slam-omni:timbre-controllablevoiceinteractionsystemwithsingle-stagetraining",
    "doi": "10.48550/arxiv.2412.15649",
    "openalex_id": "",
    "arxiv_id": "2412.15649",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Why Do Speech Language Models Fail to Generate Semantically Coherent Outputs? A Modality Evolving Perspective",
    "normalized_title": "whydospeechlanguagemodelsfailtogeneratesemanticallycoherentoutputs?amodalityevolvingperspective",
    "doi": "10.48550/arxiv.2412.17048",
    "openalex_id": "",
    "arxiv_id": "2412.17048",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Long-Form Speech Generation with Spoken Language Models",
    "normalized_title": "long-formspeechgenerationwithspokenlanguagemodels",
    "doi": "10.48550/arxiv.2412.18603",
    "openalex_id": "",
    "arxiv_id": "2412.18603",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SLIDE: Integrating Speech Language Model with LLM for Spontaneous Spoken Dialogue Generation",
    "normalized_title": "slide:integratingspeechlanguagemodelwithllmforspontaneousspokendialoguegeneration",
    "doi": "10.48550/arxiv.2501.00805",
    "openalex_id": "",
    "arxiv_id": "2501.00805",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Real-Time Textless Dialogue Generation",
    "normalized_title": "real-timetextlessdialoguegeneration",
    "doi": "10.48550/arxiv.2501.04877",
    "openalex_id": "",
    "arxiv_id": "2501.04877",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "GenSE: Generative Speech Enhancement via Language Models using Hierarchical Modeling",
    "normalized_title": "gense:generativespeechenhancementvialanguagemodelsusinghierarchicalmodeling",
    "doi": "10.48550/arxiv.2502.02942",
    "openalex_id": "",
    "arxiv_id": "2502.02942",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "High-Fidelity Simultaneous Speech-To-Speech Translation",
    "normalized_title": "high-fidelitysimultaneousspeech-to-speechtranslation",
    "doi": "10.48550/arxiv.2502.03382",
    "openalex_id": "",
    "arxiv_id": "2502.03382",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "LLM-Enhanced Dialogue Management for Full-Duplex Spoken Dialogue Systems",
    "normalized_title": "llm-enhanceddialoguemanagementforfull-duplexspokendialoguesystems",
    "doi": "10.48550/arxiv.2502.14145",
    "openalex_id": "",
    "arxiv_id": "2502.14145",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Baichuan-Audio: A Unified Framework for End-to-End Speech Interaction",
    "normalized_title": "baichuan-audio:aunifiedframeworkforend-to-endspeechinteraction",
    "doi": "10.48550/arxiv.2502.17239",
    "openalex_id": "",
    "arxiv_id": "2502.17239",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Talking Turns: Benchmarking Audio Foundation Models on Turn-Taking Dynamics",
    "normalized_title": "talkingturns:benchmarkingaudiofoundationmodelsonturn-takingdynamics",
    "doi": "10.48550/arxiv.2503.01174",
    "openalex_id": "",
    "arxiv_id": "2503.01174",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Full-Duplex-Bench: A Benchmark to Evaluate Full-duplex Spoken Dialogue Models on Turn-taking Capabilities",
    "normalized_title": "full-duplex-bench:abenchmarktoevaluatefull-duplexspokendialoguemodelsonturn-takingcapabilities",
    "doi": "10.48550/arxiv.2503.04721",
    "openalex_id": "",
    "arxiv_id": "2503.04721",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Universal Speech Token Learning via Low-Bitrate Neural Codec and Pretrained Representations",
    "normalized_title": "universalspeechtokenlearningvialow-bitrateneuralcodecandpretrainedrepresentations",
    "doi": "10.1109/jstsp.2024.3488557",
    "openalex_id": "",
    "arxiv_id": "2503.12115",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Qwen2.5-Omni Technical Report",
    "normalized_title": "qwen2.5-omnitechnicalreport",
    "doi": "10.48550/arxiv.2503.20215",
    "openalex_id": "",
    "arxiv_id": "2503.20215",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Make Some Noise: Towards LLM audio reasoning and generation using sound tokens",
    "normalized_title": "makesomenoise:towardsllmaudioreasoningandgenerationusingsoundtokens",
    "doi": "10.1109/icassp49660.2025.10888809",
    "openalex_id": "",
    "arxiv_id": "2503.22275",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "TASTE: Text-Aligned Speech Tokenization and Embedding for Spoken Language Modeling",
    "normalized_title": "taste:text-alignedspeechtokenizationandembeddingforspokenlanguagemodeling",
    "doi": "10.48550/arxiv.2504.07053",
    "openalex_id": "",
    "arxiv_id": "2504.07053",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "base_review",
    "updated_at": "2025-12-29T17:54:14.499702+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SpeechPrompt: Prompting Speech Language Models for Speech Processing Tasks",
    "normalized_title": "speechprompt:promptingspeechlanguagemodelsforspeechprocessingtasks",
    "doi": "10.1109/taslp.2024.3436618",
    "openalex_id": "https://openalex.org/w4401246677",
    "arxiv_id": "",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "snowball_review",
    "updated_at": "2025-12-29T17:57:25.858631+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "XLS-R fine-tuning on noisy word boundaries for unsupervised speech segmentation into words",
    "normalized_title": "xls-rfine-tuningonnoisywordboundariesforunsupervisedspeechsegmentationintowords",
    "doi": "10.18653/v1/2023.findings-emnlp.810",
    "openalex_id": "https://openalex.org/w4389524126",
    "arxiv_id": "",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "snowball_review",
    "updated_at": "2025-12-29T17:57:25.858631+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities",
    "normalized_title": "speechgpt:empoweringlargelanguagemodelswithintrinsiccross-modalconversationalabilities",
    "doi": "10.18653/v1/2023.findings-emnlp.1055",
    "openalex_id": "https://openalex.org/w4389524500",
    "arxiv_id": "",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "snowball_review",
    "updated_at": "2025-12-29T17:57:25.858631+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Homophone Disambiguation Reveals Patterns of Context Mixing in Speech Transformers",
    "normalized_title": "homophonedisambiguationrevealspatternsofcontextmixinginspeechtransformers",
    "doi": "10.18653/v1/2023.emnlp-main.513",
    "openalex_id": "https://openalex.org/w4389520784",
    "arxiv_id": "",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "snowball_review",
    "updated_at": "2025-12-29T17:57:25.858631+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Benchmarking Open-ended Audio Dialogue Understanding for Large Audio-Language Models",
    "normalized_title": "benchmarkingopen-endedaudiodialogueunderstandingforlargeaudio-languagemodels",
    "doi": "10.32388/758n37",
    "openalex_id": "https://openalex.org/w4405547956",
    "arxiv_id": "",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "snowball_review",
    "updated_at": "2025-12-29T17:57:25.858631+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "LM-VC: Zero-Shot Voice Conversion via Speech Generation Based on Language Models",
    "normalized_title": "lm-vc:zero-shotvoiceconversionviaspeechgenerationbasedonlanguagemodels",
    "doi": "10.1109/lsp.2023.3308474",
    "openalex_id": "https://openalex.org/w4386132131",
    "arxiv_id": "",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "snowball_review",
    "updated_at": "2025-12-29T17:57:25.858631+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "SLM: Bridge the Thin Gap Between Speech and Text Foundation Models",
    "normalized_title": "slm:bridgethethingapbetweenspeechandtextfoundationmodels",
    "doi": "10.1109/asru57964.2023.10389703",
    "openalex_id": "https://openalex.org/w4391021623",
    "arxiv_id": "",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "snowball_review",
    "updated_at": "2025-12-29T18:00:54.134649+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "SpeechTokenizer: Unified Speech Tokenizer for Speech Large Language Models",
    "normalized_title": "speechtokenizer:unifiedspeechtokenizerforspeechlargelanguagemodels",
    "doi": "10.48550/arxiv.2308.16692",
    "openalex_id": "https://openalex.org/w4386384714",
    "arxiv_id": "",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "snowball_review",
    "updated_at": "2025-12-29T18:00:54.134649+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Dynamic-Superb: Towards a Dynamic, Collaborative, and Comprehensive Instruction-Tuning Benchmark For Speech",
    "normalized_title": "dynamic-superb:towardsadynamic,collaborative,andcomprehensiveinstruction-tuningbenchmarkforspeech",
    "doi": "10.1109/icassp48485.2024.10448257",
    "openalex_id": "https://openalex.org/w4392902623",
    "arxiv_id": "",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "snowball_review",
    "updated_at": "2025-12-29T18:00:54.134649+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Audio Flamingo: A Novel Audio Language Model with Few-Shot Learning and Dialogue Abilities",
    "normalized_title": "audioflamingo:anovelaudiolanguagemodelwithfew-shotlearninganddialogueabilities",
    "doi": "10.48550/arxiv.2402.01831",
    "openalex_id": "https://openalex.org/w4391591726",
    "arxiv_id": "",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "snowball_review",
    "updated_at": "2025-12-29T18:00:54.134649+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "AudioPaLM: A Large Language Model That Can Speak and Listen",
    "normalized_title": "audiopalm:alargelanguagemodelthatcanspeakandlisten",
    "doi": "10.48550/arxiv.2306.12925",
    "openalex_id": "https://openalex.org/w4381827575",
    "arxiv_id": "",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "snowball_review",
    "updated_at": "2025-12-29T18:01:51.821805+00:00",
    "round": 3
  },
  {
    "status": "include",
    "title": "SpeechGen: Unlocking the Generative Power of Speech Language Models with Prompts",
    "normalized_title": "speechgen:unlockingthegenerativepowerofspeechlanguagemodelswithprompts",
    "doi": "10.48550/arxiv.2306.02207",
    "openalex_id": "https://openalex.org/w4379539302",
    "arxiv_id": "",
    "criteria_hash": "badd3f251a2232a292429d0e02fbb7a36292ea17539b3e7e160d4b704e6c1f56",
    "source": "snowball_review",
    "updated_at": "2025-12-29T18:01:51.821805+00:00",
    "round": 3
  }
]