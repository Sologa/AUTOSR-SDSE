{
  "topic": "On The Landscape of Spoken Language Models: A Comprehensive Survey",
  "recency_hint": "過去3年",
  "mode": "pdf+web",
  "generated_at": "2026-01-31T14:19:51.188196+00:00",
  "cutoff_before_date": null,
  "exclude_title": null,
  "source_validation": null,
  "search_prompt": "你是系統性回顧助理。\n我們正準備撰寫與該主題相關的 survey/systematic review，需產出可直接用於收錄/排除的篩選 paper 規則。\n請使用內建 web search，且至少引用 3 個 https 來源。\n輸出語言：全部以中文撰寫。\n主題：On The Landscape of Spoken Language Models: A Comprehensive Survey。\n來源頁面需提供明確年月日（YYYY-MM-DD）；僅有年份或年月者視為不合格來源。\n請先以純文字整理資訊，不要輸出 JSON、Markdown 表格或程式碼區塊。\n依序撰寫下列段落：\n### Topic Definition\n- 以 1–2 段中文精準定義主題，可包含背景脈絡與核心能力描述。\n### Summary\n- 以 2–3 句中文概述趨勢與亮點。\n### Summary Topics\n- 列 3–4 個主題節點，格式為 `S1: 描述`。\n### Inclusion Criteria (Required)\n- 僅保留必須同時滿足的條件：① 主題定義條款（以『主題定義：』+定義原文開頭）、② 提供英文可評估性的條件。\n- 每條附上來源 (source) 與對應 topic id；一般條件需為 https。\n### Inclusion Criteria (Any-of Groups)\n- 針對技術覆蓋或差異化條件建立至少一個群組，格式為 `- Group 名稱` 搭配 `* Option:`，各自附上 source 與 topic ids。\n- 群組語意為 OR：只需滿足任一群組中的任一 option 即可。\n- 若筆記中原本在 Required 段落出現多個技術細節條件，請搬移到任選群組，不要重複留在 Required。\n- 若確實沒有任選條件，再寫 `(none)`。\n### Exclusion Criteria\n- 條列需要排除的情境，同樣附來源與 topic ids；若屬於系統設定（如 exclude_title），可標示 source: internal 或留空。\n- source 必須能直接支持該排除條件；若找不到合適來源，請用 internal。\n### Sources\n- 逐行呈現所有引用來源 (https)，不包含 internal/空白來源。\n- 優先引用一手論文頁（arXiv/期刊/會議/出版社），避免動態排行榜、搜尋結果頁或彙整站作為核心依據。",
  "structured_prompt_template": "你是系統性回顧助理。\n主題：On The Landscape of Spoken Language Models: A Comprehensive Survey。\n我們正準備撰寫與該主題相關的 survey/systematic review，需產出可直接用於收錄/排除的篩選 paper 規則。\n請使用內建 web search，且至少引用 3 個 https 來源。\n輸出語言：全部以中文撰寫。\n來源頁面需提供明確年月日（YYYY-MM-DD）；僅有年份或年月者視為不合格來源。\n僅輸出單一 JSON 物件，鍵為：topic_definition、summary、summary_topics、inclusion_criteria、exclusion_criteria；JSON 外勿輸出其他文字。\ntopic_definition：以中文撰寫，1–2 段清楚定義主題，可補充背景脈絡與核心能力描述。\ntopic_definition 的來源應優先引用一手論文頁（如 arXiv/期刊/會議頁），避免彙整站、排行榜或動態搜尋結果頁。\nsummary：中文、簡潔扼要。\nsummary_topics：列出 3–4 項主題，每項含 id（如 S1、S2）與 description；用詞與 summary 一致。\ninclusion_criteria：每條含 criterion、source、topic_ids（至少 1 個）；僅能使用正向條件（不得寫否定句）。\ninclusion_criteria 的第一條必須以『主題定義：』+ topic_definition 原文開頭，之後接上『—』或『:』與具體條件（需逐字包含 topic_definition）。\ninclusion_criteria 中至少一條需明確要求英文（例如提供英文全文或英文評估語料）。\n若條件之間為 OR 關係，請放入 inclusion_criteria.any_of 的 options。\nany_of 群組語意：只需滿足「任一群組中的任一 option」即可；群組彼此為 OR，而非全部都必須滿足。\ninclusion_criteria 的範圍僅量廣泛，不可限縮在特定的小範圍內。\nexclusion_criteria：列『具體剔除情境』，不可是 inclusion 的鏡像否定（例如僅單一語言或單一應用、與主題無關）；每條同樣含 source、topic_ids。\nsource 規則：一般條件必須是 https；若條件屬於系統設定（例如 exclude_title），可用 source=internal 或留空，且這類來源不要放入 sources 清單。\n來源一致性：source 必須能直接支持該條件，不可使用會與條件相矛盾的來源；若找不到合適來源，請用 source=internal。\n來源選擇：避免動態排行榜、搜尋結果頁或彙整站，優先使用一手論文頁或正式出版頁。\n一致性：每條 criterion 必須對應至少一個 summary topic（以 topic_ids 連結）。",
  "web_search_notes": "以下內容依照你的指示撰寫，並以可直接用於系統性回顧（systematic review / survey）之收錄與排除規則為目標。\n\n---\n\n### Topic Definition\n本主題聚焦於「Spoken Language Models（SLMs）」的整體研究版圖，涵蓋能直接以語音為核心建模單位、並支援語音理解、生成或推理的通用模型。相較於傳統以語音辨識（ASR）或語音合成（TTS）為主的模組化管線，SLMs 嘗試將語音視為一級語言表示，類似文字領域中大型語言模型（LLMs）的發展脈絡。\n\n在技術內涵上，Spoken Language Models 包含純語音語言模型（直接對離散或連續語音 token 建模），以及語音與文字深度整合的模型（例如以語音編碼器結合文字 LLM，或以音訊 token 作為跨模態表示）。研究重點涵蓋模型架構、訓練策略、資料與評估設定，以及其在通用語音理解與互動上的潛力。([arxiv.org](https://arxiv.org/abs/2504.08528?utm_source=openai))\n\n---\n\n### Summary\n近年研究顯示，語音處理正從任務導向、級聯式系統，轉向可重用、可泛化的 Spoken Language Models。此趨勢與文字 LLM 的發展相呼應，並促進語音與語言之間更緊密的表示共享。整體亮點在於跨模態整合方法的多樣化，以及對通用評估與基準仍未成熟的共識。([arxiv.org](https://arxiv.org/abs/2504.08528?utm_source=openai))\n\n---\n\n### Summary Topics\nS1: Spoken Language Models 的定義與發展脈絡  \nS2: 模型架構與語音表示方式（連續、離散、音訊 token）  \nS3: 語音與大型語言模型（LLMs）的整合策略  \nS4: 訓練資料、評估任務與未來挑戰  \n\n---\n\n### Inclusion Criteria (Required)\n- 必須同時滿足以下所有條件：\n\n1. 主題定義：研究內容必須符合「Spoken Language Models 為以語音作為核心建模對象，並具備通用語音理解、生成或跨模態語言能力之模型」的定義，且明確討論模型層級（非僅單一應用系統）。  \n   source: https://arxiv.org/abs/2504.08528  \n   topic ids: S1, S2\n\n2. 論文需以英文撰寫，並提供可評估的技術描述（如模型架構、訓練方式或實驗設計），以利一致性審查。  \n   source: https://arxiv.org/abs/2504.08528  \n   topic ids: S1\n\n---\n\n### Inclusion Criteria (Any-of Groups)\n- Group 技術取向與模型差異\n  * Option: 探討「純語音語言模型」或以離散／連續語音 token 為核心表示的研究。  \n    source: https://arxiv.org/abs/2504.08528  \n    topic ids: S2\n\n  * Option: 探討語音與大型語言模型（LLMs）之整合方法（如文字介面式、潛在表示式或音訊 token 式整合）。  \n    source: https://arxiv.org/abs/2502.19548  \n    topic ids: S3\n\n  * Option: 提出或系統性分析具跨模態（語音–文字–其他模態）能力的語言模型架構。  \n    source: https://arxiv.org/abs/2305.11000  \n    topic ids: S3, S4\n\n---\n\n### Exclusion Criteria\n- 僅聚焦於單一傳統任務（如 ASR、TTS），且未討論通用語音語言建模或語言層級能力者，予以排除。  \n  source: https://arxiv.org/abs/2504.08528  \n  topic ids: S1\n\n- 僅為資料集介紹、評測基準或應用系統展示，未提出或分析 Spoken Language Model 架構與訓練原則者，予以排除。  \n  source: https://arxiv.org/abs/2104.13225  \n  topic ids: S4\n\n- 非研究論文（如教學投影片、部落格文章、未經審查之簡報），或缺乏完整技術細節者，予以排除。  \n  source: internal  \n  topic ids: S1\n\n---\n\n### Sources\nhttps://arxiv.org/abs/2504.08528  \nhttps://arxiv.org/abs/2502.19548  \nhttps://arxiv.org/abs/2104.13225  \nhttps://arxiv.org/abs/2305.11000",
  "structured_payload": {
    "topic": {
      "title": "On The Landscape of Spoken Language Models: A Comprehensive Survey",
      "topic_definition": "本主題聚焦於口語語言模型（Spoken Language Models, SLMs）的研究版圖：以語音作為核心建模對象，涵蓋純語音語言模型（對離散/連續語音 token 建模）、語音+文字模型、語音感知文字模型，以及其架構設計、訓練策略、資料來源、評估方法與作為通用、可指令化語音處理系統（可做語音理解/生成/推理、跨任務泛化、語音-文字對齊、即時/全雙工對話、信任性評估等）的潛力與限制。",
      "scope_notes": [
        "涵蓋：SLM 架構（語音編碼器/解碼器、tokenization、跨模態融合、序列建模）、訓練（自監督預訓練、多階段對齊、instruction tuning）、資料（未標註語音、語音-文字配對、合成語音對話等）、評估（生成品質、泛化、對齊、對話能力、信任性如幻覺/偏見/deepfake）。",
        "強調：從單一任務導向（ASR/TTS 等）走向可重用、通用、可指令化的語音模型與系統。"
      ],
      "concept_clusters": [
        {
          "id": "S1",
          "name": "SLM 定義與發展脈絡",
          "description": "SLM 作為以語音為一級語言表示、朝通用與可指令化能力發展的模型範式。"
        },
        {
          "id": "S2",
          "name": "語音表示與模型架構",
          "description": "連續/離散語音表示、音訊 token、純語音 LM、speech+text LM、speech-aware text LM 與其組件與整體設計。"
        },
        {
          "id": "S3",
          "name": "語音與文字 LLM 的整合策略",
          "description": "語音編碼器接文字 LLM、共享/對齊表示、音訊 token 介面、跨模態融合與指令化交互。"
        },
        {
          "id": "S4",
          "name": "訓練資料、評估與挑戰",
          "description": "資料規模與來源、基準與評測方法、LLM-as-judge、信任性與安全議題、全雙工與即時對話等。"
        }
      ]
    },
    "inclusion_criteria": {
      "required": [
        {
          "criterion": "研究內容必須符合「Spoken Language Models 為以語音作為核心建模對象，並具備通用語音理解、生成或跨模態語言能力之模型」的定義，且明確討論模型層級（非僅單一應用系統）。",
          "topic_ids": [
            "S1",
            "S2"
          ],
          "sources": [
            "https://arxiv.org/abs/2504.08528"
          ]
        },
        {
          "criterion": "論文需以英文撰寫，並提供可評估的技術描述（如模型架構、訓練方式或實驗設計），以利一致性審查。",
          "topic_ids": [
            "S1"
          ],
          "sources": [
            "https://arxiv.org/abs/2504.08528"
          ]
        }
      ],
      "any_of_groups": [
        {
          "group_name": "技術取向與模型差異（至少符合其一）",
          "options": [
            {
              "option": "探討「純語音語言模型」或以離散／連續語音 token 為核心表示的研究。",
              "topic_ids": [
                "S2"
              ],
              "sources": [
                "https://arxiv.org/abs/2504.08528"
              ]
            },
            {
              "option": "探討語音與大型語言模型（LLMs）之整合方法（如文字介面式、潛在表示式或音訊 token 式整合）。",
              "topic_ids": [
                "S3"
              ],
              "sources": [
                "https://arxiv.org/abs/2502.19548"
              ]
            },
            {
              "option": "提出或系統性分析具跨模態（語音–文字–其他模態）能力的語言模型架構。",
              "topic_ids": [
                "S3",
                "S4"
              ],
              "sources": [
                "https://arxiv.org/abs/2305.11000"
              ]
            }
          ]
        },
        {
          "group_name": "通用化能力與評估面向（至少符合其一）",
          "options": [
            {
              "option": "討論多任務/跨任務泛化、自然語言指令化（instruction tuning 或等價的指令追隨訓練設定）以支援多種語音任務。",
              "topic_ids": [
                "S1",
                "S4"
              ],
              "sources": [
                "https://arxiv.org/abs/2504.08528"
              ]
            },
            {
              "option": "涵蓋語音-文字對齊/融合（cross-modal alignment、speech-text alignment）或語音感知文字建模等跨模態對齊議題。",
              "topic_ids": [
                "S2",
                "S3"
              ],
              "sources": [
                "https://arxiv.org/abs/2504.08528"
              ]
            },
            {
              "option": "涵蓋互動式語音能力（如即時對話或全雙工/低延遲語音對話）之模型設計、訓練或評估討論。",
              "topic_ids": [
                "S4"
              ],
              "sources": [
                "https://arxiv.org/abs/2504.08528"
              ]
            },
            {
              "option": "討論 SLM 的評估方法或基準設計，且評估超出單一傳統 ASR/TTS 指標（例如多維度能力、生成品質、泛化、信任性/安全）。",
              "topic_ids": [
                "S4"
              ],
              "sources": [
                "https://arxiv.org/abs/2504.08528"
              ]
            }
          ]
        }
      ]
    },
    "exclusion_criteria": [
      {
        "criterion": "僅聚焦於單一傳統語音任務（如 ASR、TTS、SID 等），且未討論通用語音語言建模、跨任務泛化或可指令化語言層級能力者。",
        "topic_ids": [
          "S1",
          "S2"
        ],
        "sources": [
          "https://arxiv.org/abs/2504.08528"
        ]
      },
      {
        "criterion": "研究主體為非語音的音訊（如音樂、環境聲）建模，且未與語音語言理解/生成之模型能力與設定緊密結合者。",
        "topic_ids": [
          "S1"
        ],
        "sources": [
          "https://arxiv.org/abs/2504.08528"
        ]
      },
      {
        "criterion": "僅介紹資料集、評測基準或應用系統展示，未提出或分析 Spoken Language Model 的模型架構、訓練策略或可泛化能力者。",
        "topic_ids": [
          "S4"
        ],
        "sources": [
          "https://arxiv.org/abs/2104.13225"
        ]
      },
      {
        "criterion": "僅討論單一組件技術（如僅 tokenizer、僅語音編碼器或僅語音解碼器）而未置於完整 SLM 架構/端到端設定或未連結到通用 SLM 能力分析者。",
        "topic_ids": [
          "S2"
        ],
        "sources": [
          "https://arxiv.org/abs/2504.08528"
        ]
      },
      {
        "criterion": "非學術研究論文或缺乏可評估的技術細節（例如無足夠的模型/訓練/實驗描述，導致無法進行一致性資料萃取與偏差評估）者。",
        "topic_ids": [
          "S1"
        ],
        "sources": [
          "https://arxiv.org/abs/2504.08528"
        ]
      }
    ],
    "screening_hints": {
      "include_signals": [
        "研究主張或實作以語音 token（離散或連續）進行語言建模，或將語音作為主要序列建模單位。",
        "明確把語音與文字 LLM 深度整合，用於語音理解/生成/對話/推理等多能力設定。",
        "描述多階段訓練（自監督語音表徵 + 跨模態對齊 + 指令化微調）或等價流程。",
        "提供超越單一任務的能力評估（多基準、多維度、人評/LLM-as-judge、信任性測試等）。"
      ],
      "exclude_signals": [
        "僅是 ASR 或 TTS 的單點改良（例如只提升 WER 或 MOS）且沒有通用化/跨任務/指令化討論。",
        "僅為傳統規則式/模組化對話系統而無現代 SLM/LLM 架構整合。",
        "只做非語音音訊生成/分類且與語音語言能力無關。"
      ]
    },
    "sources": [
      {
        "url": "https://arxiv.org/abs/2504.08528",
        "relation": "primary_topic_anchor"
      },
      {
        "url": "https://arxiv.org/abs/2502.19548",
        "relation": "integration_with_llms_any_of_support"
      },
      {
        "url": "https://arxiv.org/abs/2305.11000",
        "relation": "multimodal_architecture_any_of_support"
      },
      {
        "url": "https://arxiv.org/abs/2104.13225",
        "relation": "benchmark_or_dataset_exclusion_support"
      }
    ],
    "json_schema_version": "1.0"
  },
  "pdf_background": "### PDF Topic Definition\n本篇為「On The Landscape of Spoken Language Models: A Comprehensive Survey」的系統性綜述，聚焦於口語語言模型（Spoken Language Models, SLMs）的發展現況。主題涵蓋SLM的架構設計、訓練策略、資料來源、評估方法，以及其作為「通用語音處理系統」的潛力。核心概念包括純語音模型（pure speech LM）、語音+文字模型（speech+text LM）、語音感知文字模型（speech-aware text LM），以及這些模型如何從單一任務導向逐步邁向能以自然語言指令處理多種語音任務的通用系統。評估面向則涵蓋生成品質、任務泛化能力、語音與文字對齊、即時對話能力、信任性（如幻覺、偏見、deepfake）等。\n\n### PDF Key Trends\n- 語音處理領域正從任務專屬模型轉向通用、可指令化的SLM，類比於文字LLM的發展路徑。\n- 模型架構趨向多模態融合，結合語音編碼器、文字編碼器、序列建模與模態轉換器。\n- 訓練策略從自監督預訓練（如wav2vec 2.0, HuBERT）延伸至多階段、跨模態對齊與指令微調（instruction tuning）。\n- 資料來源多元，包括大規模未標註語音、語音-文字配對資料、合成語音對話數據等。\n- 研究重點逐漸從單一任務（如ASR、TTS）擴展至複雜推理、開放式問答、全雙工對話與語音生成。\n- 評估方法快速演進，從傳統ASR/TTS指標到多維度基準（如Dynamic-SUPERB、AIR-Bench）、LLM-as-a-judge、信任性測試等。\n\n### PDF Capability Highlights\n- 能處理語音輸入/輸出，並可選擇性支援文字輸入/輸出。\n- 具備以自然語言指令處理多種語音任務的能力。\n- 支援語音與文字的對齊與融合，實現跨模態理解與生成。\n- 具備端到端語音生成、語音理解、對話管理等複合任務能力。\n- 可進行即時或全雙工語音對話，並處理語者特徵、情緒、韻律等非語義資訊。\n\n### PDF Inclusion Signals\n- 關鍵字：「spoken language model」、「speech+text LM」、「universal speech processing」、「instruction tuning」、「duplex dialogue」、「speech-aware text LM」、「full-duplex」、「speech-text alignment」。\n- 章節參考：Section 2（Overall architecture）、Section 3（SLM components）、Section 4（Training Strategies）、Section 6（Duplex speech dialogue）、Section 7（Benchmarking and Evaluating SLMs）。\n- 涉及多模態語音-文字融合、自然語言指令、跨任務泛化能力、語音生成與理解等主題。\n- 涉及SLM模型設計、訓練流程、評估基準（如Dynamic-SUPERB, AIR-Bench, VoiceBench）。\n- 以通用語音處理為目標，非僅針對單一ASR/TTS任務。\n\n### PDF Exclusion Signals\n- 僅聚焦於單一傳統語音任務（如ASR、TTS、SID）且無泛化或指令化能力。\n- 只討論音樂、環境聲音等非語音音訊模型，未與語音處理深度結合。\n- 僅為語音編碼器、語音解碼器、tokenizer等單一組件技術，未涉及完整SLM架構。\n- 缺乏自然語言指令、無多任務/多模態能力，或僅以任務標籤（task token）操作。\n- 僅為傳統對話系統、規則式語音處理，未結合現代LLM/SLM技術。\n\n### PDF Notes\n- On_The_Landscape_of_Spoken_Language_Models_A_Comprehensive_Survey.pdf: \n  - 系統性梳理SLM發展，明確分類純語音、語音+文字、語音感知文字模型，並比較其架構、訓練、評估方法與挑戰。\n  - 強調通用語音處理系統的目標與現階段限制，提出標準化評測、開源資源、跨語言/跨領域應用等未來方向。\n  - 詳細整理各類SLM的設計選擇、代表性模型、訓練與評估基準，並提供發展時間線與模型對照表。\n  - 深入探討全雙工對話、信任性評估（幻覺、偏見、deepfake）、語音-文字對齊等議題。\n  - 提供豐富的模型與基準資料，便於後續篩選與比較。",
  "combined_notes": "### PDF Background (Survey Summaries)\n### PDF Topic Definition\n本篇為「On The Landscape of Spoken Language Models: A Comprehensive Survey」的系統性綜述，聚焦於口語語言模型（Spoken Language Models, SLMs）的發展現況。主題涵蓋SLM的架構設計、訓練策略、資料來源、評估方法，以及其作為「通用語音處理系統」的潛力。核心概念包括純語音模型（pure speech LM）、語音+文字模型（speech+text LM）、語音感知文字模型（speech-aware text LM），以及這些模型如何從單一任務導向逐步邁向能以自然語言指令處理多種語音任務的通用系統。評估面向則涵蓋生成品質、任務泛化能力、語音與文字對齊、即時對話能力、信任性（如幻覺、偏見、deepfake）等。\n\n### PDF Key Trends\n- 語音處理領域正從任務專屬模型轉向通用、可指令化的SLM，類比於文字LLM的發展路徑。\n- 模型架構趨向多模態融合，結合語音編碼器、文字編碼器、序列建模與模態轉換器。\n- 訓練策略從自監督預訓練（如wav2vec 2.0, HuBERT）延伸至多階段、跨模態對齊與指令微調（instruction tuning）。\n- 資料來源多元，包括大規模未標註語音、語音-文字配對資料、合成語音對話數據等。\n- 研究重點逐漸從單一任務（如ASR、TTS）擴展至複雜推理、開放式問答、全雙工對話與語音生成。\n- 評估方法快速演進，從傳統ASR/TTS指標到多維度基準（如Dynamic-SUPERB、AIR-Bench）、LLM-as-a-judge、信任性測試等。\n\n### PDF Capability Highlights\n- 能處理語音輸入/輸出，並可選擇性支援文字輸入/輸出。\n- 具備以自然語言指令處理多種語音任務的能力。\n- 支援語音與文字的對齊與融合，實現跨模態理解與生成。\n- 具備端到端語音生成、語音理解、對話管理等複合任務能力。\n- 可進行即時或全雙工語音對話，並處理語者特徵、情緒、韻律等非語義資訊。\n\n### PDF Inclusion Signals\n- 關鍵字：「spoken language model」、「speech+text LM」、「universal speech processing」、「instruction tuning」、「duplex dialogue」、「speech-aware text LM」、「full-duplex」、「speech-text alignment」。\n- 章節參考：Section 2（Overall architecture）、Section 3（SLM components）、Section 4（Training Strategies）、Section 6（Duplex speech dialogue）、Section 7（Benchmarking and Evaluating SLMs）。\n- 涉及多模態語音-文字融合、自然語言指令、跨任務泛化能力、語音生成與理解等主題。\n- 涉及SLM模型設計、訓練流程、評估基準（如Dynamic-SUPERB, AIR-Bench, VoiceBench）。\n- 以通用語音處理為目標，非僅針對單一ASR/TTS任務。\n\n### PDF Exclusion Signals\n- 僅聚焦於單一傳統語音任務（如ASR、TTS、SID）且無泛化或指令化能力。\n- 只討論音樂、環境聲音等非語音音訊模型，未與語音處理深度結合。\n- 僅為語音編碼器、語音解碼器、tokenizer等單一組件技術，未涉及完整SLM架構。\n- 缺乏自然語言指令、無多任務/多模態能力，或僅以任務標籤（task token）操作。\n- 僅為傳統對話系統、規則式語音處理，未結合現代LLM/SLM技術。\n\n### PDF Notes\n- On_The_Landscape_of_Spoken_Language_Models_A_Comprehensive_Survey.pdf: \n  - 系統性梳理SLM發展，明確分類純語音、語音+文字、語音感知文字模型，並比較其架構、訓練、評估方法與挑戰。\n  - 強調通用語音處理系統的目標與現階段限制，提出標準化評測、開源資源、跨語言/跨領域應用等未來方向。\n  - 詳細整理各類SLM的設計選擇、代表性模型、訓練與評估基準，並提供發展時間線與模型對照表。\n  - 深入探討全雙工對話、信任性評估（幻覺、偏見、deepfake）、語音-文字對齊等議題。\n  - 提供豐富的模型與基準資料，便於後續篩選與比較。\n### Web Search Notes\n以下內容依照你的指示撰寫，並以可直接用於系統性回顧（systematic review / survey）之收錄與排除規則為目標。\n\n---\n\n### Topic Definition\n本主題聚焦於「Spoken Language Models（SLMs）」的整體研究版圖，涵蓋能直接以語音為核心建模單位、並支援語音理解、生成或推理的通用模型。相較於傳統以語音辨識（ASR）或語音合成（TTS）為主的模組化管線，SLMs 嘗試將語音視為一級語言表示，類似文字領域中大型語言模型（LLMs）的發展脈絡。\n\n在技術內涵上，Spoken Language Models 包含純語音語言模型（直接對離散或連續語音 token 建模），以及語音與文字深度整合的模型（例如以語音編碼器結合文字 LLM，或以音訊 token 作為跨模態表示）。研究重點涵蓋模型架構、訓練策略、資料與評估設定，以及其在通用語音理解與互動上的潛力。([arxiv.org](https://arxiv.org/abs/2504.08528?utm_source=openai))\n\n---\n\n### Summary\n近年研究顯示，語音處理正從任務導向、級聯式系統，轉向可重用、可泛化的 Spoken Language Models。此趨勢與文字 LLM 的發展相呼應，並促進語音與語言之間更緊密的表示共享。整體亮點在於跨模態整合方法的多樣化，以及對通用評估與基準仍未成熟的共識。([arxiv.org](https://arxiv.org/abs/2504.08528?utm_source=openai))\n\n---\n\n### Summary Topics\nS1: Spoken Language Models 的定義與發展脈絡  \nS2: 模型架構與語音表示方式（連續、離散、音訊 token）  \nS3: 語音與大型語言模型（LLMs）的整合策略  \nS4: 訓練資料、評估任務與未來挑戰  \n\n---\n\n### Inclusion Criteria (Required)\n- 必須同時滿足以下所有條件：\n\n1. 主題定義：研究內容必須符合「Spoken Language Models 為以語音作為核心建模對象，並具備通用語音理解、生成或跨模態語言能力之模型」的定義，且明確討論模型層級（非僅單一應用系統）。  \n   source: https://arxiv.org/abs/2504.08528  \n   topic ids: S1, S2\n\n2. 論文需以英文撰寫，並提供可評估的技術描述（如模型架構、訓練方式或實驗設計），以利一致性審查。  \n   source: https://arxiv.org/abs/2504.08528  \n   topic ids: S1\n\n---\n\n### Inclusion Criteria (Any-of Groups)\n- Group 技術取向與模型差異\n  * Option: 探討「純語音語言模型」或以離散／連續語音 token 為核心表示的研究。  \n    source: https://arxiv.org/abs/2504.08528  \n    topic ids: S2\n\n  * Option: 探討語音與大型語言模型（LLMs）之整合方法（如文字介面式、潛在表示式或音訊 token 式整合）。  \n    source: https://arxiv.org/abs/2502.19548  \n    topic ids: S3\n\n  * Option: 提出或系統性分析具跨模態（語音–文字–其他模態）能力的語言模型架構。  \n    source: https://arxiv.org/abs/2305.11000  \n    topic ids: S3, S4\n\n---\n\n### Exclusion Criteria\n- 僅聚焦於單一傳統任務（如 ASR、TTS），且未討論通用語音語言建模或語言層級能力者，予以排除。  \n  source: https://arxiv.org/abs/2504.08528  \n  topic ids: S1\n\n- 僅為資料集介紹、評測基準或應用系統展示，未提出或分析 Spoken Language Model 架構與訓練原則者，予以排除。  \n  source: https://arxiv.org/abs/2104.13225  \n  topic ids: S4\n\n- 非研究論文（如教學投影片、部落格文章、未經審查之簡報），或缺乏完整技術細節者，予以排除。  \n  source: internal  \n  topic ids: S1\n\n---\n\n### Sources\nhttps://arxiv.org/abs/2504.08528  \nhttps://arxiv.org/abs/2502.19548  \nhttps://arxiv.org/abs/2104.13225  \nhttps://arxiv.org/abs/2305.11000",
  "augmented_formatter_messages": [
    {
      "role": "system",
      "content": "你是系統性回顧的資料整理助理，需將研究助理的筆記轉為結構化 JSON。\n僅能輸出單一 JSON 物件，勿加入額外敘述或 Markdown。"
    },
    {
      "role": "user",
      "content": "以下內容結合了兩種來源：\n1) PDF Background (Survey Summaries)：模型閱讀本地 PDF 後的背景整理，僅供提供更準確的主題定義與條件靈感，來源欄請勿引用非 https 連結。\n2) Web Search Notes：OpenAI Web Search 所產出的即時筆記與來源。\n請輸出最終 JSON，並確保所有 source 欄位皆為 https URL。\n主題：On The Landscape of Spoken Language Models: A Comprehensive Survey。\ninclusion_criteria.required 段落僅能包含主題定義逐字條款與英文可評估性條款；其餘條件請歸入 any_of 群組。\n不得要求標題/摘要必須包含特定字串或關鍵字；避免任何硬字串匹配條款。\n將以下筆記整合後再輸出：\n---\n### PDF Background (Survey Summaries)\n### PDF Topic Definition\n本篇為「On The Landscape of Spoken Language Models: A Comprehensive Survey」的系統性綜述，聚焦於口語語言模型（Spoken Language Models, SLMs）的發展現況。主題涵蓋SLM的架構設計、訓練策略、資料來源、評估方法，以及其作為「通用語音處理系統」的潛力。核心概念包括純語音模型（pure speech LM）、語音+文字模型（speech+text LM）、語音感知文字模型（speech-aware text LM），以及這些模型如何從單一任務導向逐步邁向能以自然語言指令處理多種語音任務的通用系統。評估面向則涵蓋生成品質、任務泛化能力、語音與文字對齊、即時對話能力、信任性（如幻覺、偏見、deepfake）等。\n\n### PDF Key Trends\n- 語音處理領域正從任務專屬模型轉向通用、可指令化的SLM，類比於文字LLM的發展路徑。\n- 模型架構趨向多模態融合，結合語音編碼器、文字編碼器、序列建模與模態轉換器。\n- 訓練策略從自監督預訓練（如wav2vec 2.0, HuBERT）延伸至多階段、跨模態對齊與指令微調（instruction tuning）。\n- 資料來源多元，包括大規模未標註語音、語音-文字配對資料、合成語音對話數據等。\n- 研究重點逐漸從單一任務（如ASR、TTS）擴展至複雜推理、開放式問答、全雙工對話與語音生成。\n- 評估方法快速演進，從傳統ASR/TTS指標到多維度基準（如Dynamic-SUPERB、AIR-Bench）、LLM-as-a-judge、信任性測試等。\n\n### PDF Capability Highlights\n- 能處理語音輸入/輸出，並可選擇性支援文字輸入/輸出。\n- 具備以自然語言指令處理多種語音任務的能力。\n- 支援語音與文字的對齊與融合，實現跨模態理解與生成。\n- 具備端到端語音生成、語音理解、對話管理等複合任務能力。\n- 可進行即時或全雙工語音對話，並處理語者特徵、情緒、韻律等非語義資訊。\n\n### PDF Inclusion Signals\n- 關鍵字：「spoken language model」、「speech+text LM」、「universal speech processing」、「instruction tuning」、「duplex dialogue」、「speech-aware text LM」、「full-duplex」、「speech-text alignment」。\n- 章節參考：Section 2（Overall architecture）、Section 3（SLM components）、Section 4（Training Strategies）、Section 6（Duplex speech dialogue）、Section 7（Benchmarking and Evaluating SLMs）。\n- 涉及多模態語音-文字融合、自然語言指令、跨任務泛化能力、語音生成與理解等主題。\n- 涉及SLM模型設計、訓練流程、評估基準（如Dynamic-SUPERB, AIR-Bench, VoiceBench）。\n- 以通用語音處理為目標，非僅針對單一ASR/TTS任務。\n\n### PDF Exclusion Signals\n- 僅聚焦於單一傳統語音任務（如ASR、TTS、SID）且無泛化或指令化能力。\n- 只討論音樂、環境聲音等非語音音訊模型，未與語音處理深度結合。\n- 僅為語音編碼器、語音解碼器、tokenizer等單一組件技術，未涉及完整SLM架構。\n- 缺乏自然語言指令、無多任務/多模態能力，或僅以任務標籤（task token）操作。\n- 僅為傳統對話系統、規則式語音處理，未結合現代LLM/SLM技術。\n\n### PDF Notes\n- On_The_Landscape_of_Spoken_Language_Models_A_Comprehensive_Survey.pdf: \n  - 系統性梳理SLM發展，明確分類純語音、語音+文字、語音感知文字模型，並比較其架構、訓練、評估方法與挑戰。\n  - 強調通用語音處理系統的目標與現階段限制，提出標準化評測、開源資源、跨語言/跨領域應用等未來方向。\n  - 詳細整理各類SLM的設計選擇、代表性模型、訓練與評估基準，並提供發展時間線與模型對照表。\n  - 深入探討全雙工對話、信任性評估（幻覺、偏見、deepfake）、語音-文字對齊等議題。\n  - 提供豐富的模型與基準資料，便於後續篩選與比較。\n### Web Search Notes\n以下內容依照你的指示撰寫，並以可直接用於系統性回顧（systematic review / survey）之收錄與排除規則為目標。\n\n---\n\n### Topic Definition\n本主題聚焦於「Spoken Language Models（SLMs）」的整體研究版圖，涵蓋能直接以語音為核心建模單位、並支援語音理解、生成或推理的通用模型。相較於傳統以語音辨識（ASR）或語音合成（TTS）為主的模組化管線，SLMs 嘗試將語音視為一級語言表示，類似文字領域中大型語言模型（LLMs）的發展脈絡。\n\n在技術內涵上，Spoken Language Models 包含純語音語言模型（直接對離散或連續語音 token 建模），以及語音與文字深度整合的模型（例如以語音編碼器結合文字 LLM，或以音訊 token 作為跨模態表示）。研究重點涵蓋模型架構、訓練策略、資料與評估設定，以及其在通用語音理解與互動上的潛力。([arxiv.org](https://arxiv.org/abs/2504.08528?utm_source=openai))\n\n---\n\n### Summary\n近年研究顯示，語音處理正從任務導向、級聯式系統，轉向可重用、可泛化的 Spoken Language Models。此趨勢與文字 LLM 的發展相呼應，並促進語音與語言之間更緊密的表示共享。整體亮點在於跨模態整合方法的多樣化，以及對通用評估與基準仍未成熟的共識。([arxiv.org](https://arxiv.org/abs/2504.08528?utm_source=openai))\n\n---\n\n### Summary Topics\nS1: Spoken Language Models 的定義與發展脈絡  \nS2: 模型架構與語音表示方式（連續、離散、音訊 token）  \nS3: 語音與大型語言模型（LLMs）的整合策略  \nS4: 訓練資料、評估任務與未來挑戰  \n\n---\n\n### Inclusion Criteria (Required)\n- 必須同時滿足以下所有條件：\n\n1. 主題定義：研究內容必須符合「Spoken Language Models 為以語音作為核心建模對象，並具備通用語音理解、生成或跨模態語言能力之模型」的定義，且明確討論模型層級（非僅單一應用系統）。  \n   source: https://arxiv.org/abs/2504.08528  \n   topic ids: S1, S2\n\n2. 論文需以英文撰寫，並提供可評估的技術描述（如模型架構、訓練方式或實驗設計），以利一致性審查。  \n   source: https://arxiv.org/abs/2504.08528  \n   topic ids: S1\n\n---\n\n### Inclusion Criteria (Any-of Groups)\n- Group 技術取向與模型差異\n  * Option: 探討「純語音語言模型」或以離散／連續語音 token 為核心表示的研究。  \n    source: https://arxiv.org/abs/2504.08528  \n    topic ids: S2\n\n  * Option: 探討語音與大型語言模型（LLMs）之整合方法（如文字介面式、潛在表示式或音訊 token 式整合）。  \n    source: https://arxiv.org/abs/2502.19548  \n    topic ids: S3\n\n  * Option: 提出或系統性分析具跨模態（語音–文字–其他模態）能力的語言模型架構。  \n    source: https://arxiv.org/abs/2305.11000  \n    topic ids: S3, S4\n\n---\n\n### Exclusion Criteria\n- 僅聚焦於單一傳統任務（如 ASR、TTS），且未討論通用語音語言建模或語言層級能力者，予以排除。  \n  source: https://arxiv.org/abs/2504.08528  \n  topic ids: S1\n\n- 僅為資料集介紹、評測基準或應用系統展示，未提出或分析 Spoken Language Model 架構與訓練原則者，予以排除。  \n  source: https://arxiv.org/abs/2104.13225  \n  topic ids: S4\n\n- 非研究論文（如教學投影片、部落格文章、未經審查之簡報），或缺乏完整技術細節者，予以排除。  \n  source: internal  \n  topic ids: S1\n\n---\n\n### Sources\nhttps://arxiv.org/abs/2504.08528  \nhttps://arxiv.org/abs/2502.19548  \nhttps://arxiv.org/abs/2104.13225  \nhttps://arxiv.org/abs/2305.11000\n---"
    }
  ],
  "formatter_raw": "{\n  \"topic\": {\n    \"title\": \"On The Landscape of Spoken Language Models: A Comprehensive Survey\",\n    \"topic_definition\": \"本主題聚焦於口語語言模型（Spoken Language Models, SLMs）的研究版圖：以語音作為核心建模對象，涵蓋純語音語言模型（對離散/連續語音 token 建模）、語音+文字模型、語音感知文字模型，以及其架構設計、訓練策略、資料來源、評估方法與作為通用、可指令化語音處理系統（可做語音理解/生成/推理、跨任務泛化、語音-文字對齊、即時/全雙工對話、信任性評估等）的潛力與限制。\",\n    \"scope_notes\": [\n      \"涵蓋：SLM 架構（語音編碼器/解碼器、tokenization、跨模態融合、序列建模）、訓練（自監督預訓練、多階段對齊、instruction tuning）、資料（未標註語音、語音-文字配對、合成語音對話等）、評估（生成品質、泛化、對齊、對話能力、信任性如幻覺/偏見/deepfake）。\",\n      \"強調：從單一任務導向（ASR/TTS 等）走向可重用、通用、可指令化的語音模型與系統。\"\n    ],\n    \"concept_clusters\": [\n      {\n        \"id\": \"S1\",\n        \"name\": \"SLM 定義與發展脈絡\",\n        \"description\": \"SLM 作為以語音為一級語言表示、朝通用與可指令化能力發展的模型範式。\"\n      },\n      {\n        \"id\": \"S2\",\n        \"name\": \"語音表示與模型架構\",\n        \"description\": \"連續/離散語音表示、音訊 token、純語音 LM、speech+text LM、speech-aware text LM 與其組件與整體設計。\"\n      },\n      {\n        \"id\": \"S3\",\n        \"name\": \"語音與文字 LLM 的整合策略\",\n        \"description\": \"語音編碼器接文字 LLM、共享/對齊表示、音訊 token 介面、跨模態融合與指令化交互。\"\n      },\n      {\n        \"id\": \"S4\",\n        \"name\": \"訓練資料、評估與挑戰\",\n        \"description\": \"資料規模與來源、基準與評測方法、LLM-as-judge、信任性與安全議題、全雙工與即時對話等。\"\n      }\n    ]\n  },\n  \"inclusion_criteria\": {\n    \"required\": [\n      {\n        \"criterion\": \"研究內容必須符合「Spoken Language Models 為以語音作為核心建模對象，並具備通用語音理解、生成或跨模態語言能力之模型」的定義，且明確討論模型層級（非僅單一應用系統）。\",\n        \"topic_ids\": [\"S1\", \"S2\"],\n        \"sources\": [\"https://arxiv.org/abs/2504.08528\"]\n      },\n      {\n        \"criterion\": \"論文需以英文撰寫，並提供可評估的技術描述（如模型架構、訓練方式或實驗設計），以利一致性審查。\",\n        \"topic_ids\": [\"S1\"],\n        \"sources\": [\"https://arxiv.org/abs/2504.08528\"]\n      }\n    ],\n    \"any_of_groups\": [\n      {\n        \"group_name\": \"技術取向與模型差異（至少符合其一）\",\n        \"options\": [\n          {\n            \"option\": \"探討「純語音語言模型」或以離散／連續語音 token 為核心表示的研究。\",\n            \"topic_ids\": [\"S2\"],\n            \"sources\": [\"https://arxiv.org/abs/2504.08528\"]\n          },\n          {\n            \"option\": \"探討語音與大型語言模型（LLMs）之整合方法（如文字介面式、潛在表示式或音訊 token 式整合）。\",\n            \"topic_ids\": [\"S3\"],\n            \"sources\": [\"https://arxiv.org/abs/2502.19548\"]\n          },\n          {\n            \"option\": \"提出或系統性分析具跨模態（語音–文字–其他模態）能力的語言模型架構。\",\n            \"topic_ids\": [\"S3\", \"S4\"],\n            \"sources\": [\"https://arxiv.org/abs/2305.11000\"]\n          }\n        ]\n      },\n      {\n        \"group_name\": \"通用化能力與評估面向（至少符合其一）\",\n        \"options\": [\n          {\n            \"option\": \"討論多任務/跨任務泛化、自然語言指令化（instruction tuning 或等價的指令追隨訓練設定）以支援多種語音任務。\",\n            \"topic_ids\": [\"S1\", \"S4\"],\n            \"sources\": [\"https://arxiv.org/abs/2504.08528\"]\n          },\n          {\n            \"option\": \"涵蓋語音-文字對齊/融合（cross-modal alignment、speech-text alignment）或語音感知文字建模等跨模態對齊議題。\",\n            \"topic_ids\": [\"S2\", \"S3\"],\n            \"sources\": [\"https://arxiv.org/abs/2504.08528\"]\n          },\n          {\n            \"option\": \"涵蓋互動式語音能力（如即時對話或全雙工/低延遲語音對話）之模型設計、訓練或評估討論。\",\n            \"topic_ids\": [\"S4\"],\n            \"sources\": [\"https://arxiv.org/abs/2504.08528\"]\n          },\n          {\n            \"option\": \"討論 SLM 的評估方法或基準設計，且評估超出單一傳統 ASR/TTS 指標（例如多維度能力、生成品質、泛化、信任性/安全）。\",\n            \"topic_ids\": [\"S4\"],\n            \"sources\": [\"https://arxiv.org/abs/2504.08528\"]\n          }\n        ]\n      }\n    ]\n  },\n  \"exclusion_criteria\": [\n    {\n      \"criterion\": \"僅聚焦於單一傳統語音任務（如 ASR、TTS、SID 等），且未討論通用語音語言建模、跨任務泛化或可指令化語言層級能力者。\",\n      \"topic_ids\": [\"S1\", \"S2\"],\n      \"sources\": [\"https://arxiv.org/abs/2504.08528\"]\n    },\n    {\n      \"criterion\": \"研究主體為非語音的音訊（如音樂、環境聲）建模，且未與語音語言理解/生成之模型能力與設定緊密結合者。\",\n      \"topic_ids\": [\"S1\"],\n      \"sources\": [\"https://arxiv.org/abs/2504.08528\"]\n    },\n    {\n      \"criterion\": \"僅介紹資料集、評測基準或應用系統展示，未提出或分析 Spoken Language Model 的模型架構、訓練策略或可泛化能力者。\",\n      \"topic_ids\": [\"S4\"],\n      \"sources\": [\"https://arxiv.org/abs/2104.13225\"]\n    },\n    {\n      \"criterion\": \"僅討論單一組件技術（如僅 tokenizer、僅語音編碼器或僅語音解碼器）而未置於完整 SLM 架構/端到端設定或未連結到通用 SLM 能力分析者。\",\n      \"topic_ids\": [\"S2\"],\n      \"sources\": [\"https://arxiv.org/abs/2504.08528\"]\n    },\n    {\n      \"criterion\": \"非學術研究論文或缺乏可評估的技術細節（例如無足夠的模型/訓練/實驗描述，導致無法進行一致性資料萃取與偏差評估）者。\",\n      \"topic_ids\": [\"S1\"],\n      \"sources\": [\"https://arxiv.org/abs/2504.08528\"]\n    }\n  ],\n  \"screening_hints\": {\n    \"include_signals\": [\n      \"研究主張或實作以語音 token（離散或連續）進行語言建模，或將語音作為主要序列建模單位。\",\n      \"明確把語音與文字 LLM 深度整合，用於語音理解/生成/對話/推理等多能力設定。\",\n      \"描述多階段訓練（自監督語音表徵 + 跨模態對齊 + 指令化微調）或等價流程。\",\n      \"提供超越單一任務的能力評估（多基準、多維度、人評/LLM-as-judge、信任性測試等）。\"\n    ],\n    \"exclude_signals\": [\n      \"僅是 ASR 或 TTS 的單點改良（例如只提升 WER 或 MOS）且沒有通用化/跨任務/指令化討論。\",\n      \"僅為傳統規則式/模組化對話系統而無現代 SLM/LLM 架構整合。\",\n      \"只做非語音音訊生成/分類且與語音語言能力無關。\"\n    ]\n  },\n  \"sources\": [\n    {\n      \"url\": \"https://arxiv.org/abs/2504.08528\",\n      \"relation\": \"primary_topic_anchor\"\n    },\n    {\n      \"url\": \"https://arxiv.org/abs/2502.19548\",\n      \"relation\": \"integration_with_llms_any_of_support\"\n    },\n    {\n      \"url\": \"https://arxiv.org/abs/2305.11000\",\n      \"relation\": \"multimodal_architecture_any_of_support\"\n    },\n    {\n      \"url\": \"https://arxiv.org/abs/2104.13225\",\n      \"relation\": \"benchmark_or_dataset_exclusion_support\"\n    }\n  ],\n  \"json_schema_version\": \"1.0\"\n}"
}