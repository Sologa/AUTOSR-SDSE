### PDF Background (Survey Summaries)
### PDF Topic Definition
本系統性回顧聚焦於「離散音訊標記（Discrete Audio Tokens）」的技術與應用。離散音訊標記是一種將連續音訊訊號壓縮為可分類、低維度的離散單元（token），目標在於同時保留知覺品質、語音內容與說話者特徵，並提升儲存、傳輸與推論效率。該主題涵蓋語音、音樂與一般音訊三大領域，並從編碼-解碼架構、量化技術、訓練範式、串流能力與應用場域等面向，進行分類與評估。評估重點包括重建品質、下游任務表現（如語音辨識、語者驗證、情感辨識、音樂生成等），以及作為音訊語言模型（Acoustic LLM）基礎的能力。

### PDF Key Trends
- 神經編碼器（Neural Codec）逐漸取代傳統編碼器，並以離散標記作為核心中介。
- 量化技術多元化（如RVQ、SVQ、FSQ、K-means等），並出現多層次、多尺度設計。
- 訓練範式從後訓練（post-training）逐步轉向端到端聯合訓練（joint training），並大量引入自監督學習（SSL）與語意蒸餾（semantic distillation）。
- 評估標準趨向多元，包括信號重建（Codec-SUPERB, VERSA）、下游任務（DASB）、語音語言模型（SALMon, Zero-resource）等綜合指標。
- 音訊標記已成為多模態大型語言模型（LLM）整合語音/音樂/音訊的關鍵橋樑，並廣泛應用於語音合成、語音轉換、音樂生成等新興任務。
- 研究資料來源橫跨公開語音語料庫（LibriSpeech, VoxCeleb, CommonVoice）、音樂資料集（MUSDB, FMA）及音訊事件集（AudioSet, ESC-50）等。

### PDF Capability Highlights
- 能夠將連續音訊訊號有效轉換為緊湊、可分類的離散標記。
- 支援多種量化策略（RVQ, SVQ, FSQ, K-means等）並可靈活調整位元率與碼本結構。
- 提供端到端訓練流程，並可結合語音、音樂及一般音訊多域資料。
- 具備串流（streaming）處理能力，適用於低延遲應用。
- 能與大型語言模型（LLM）無縫整合，支援多模態生成與理解任務。

### PDF Inclusion Signals
- 關鍵詞：「discrete audio token」、「neural codec」、「vector quantization」、「semantic distillation」、「audio language model」
- 涉及多域應用（speech, music, audio）之離散標記技術（見 Table 1, Table 2）
- 具體量化方法討論（RVQ, SVQ, FSQ, K-means等，見 Section 2.2）
- 涉及下游任務或語音/音樂/音訊生成、辨識、分離等應用（見 Section 3.2, 3.3）
- 評估指標涵蓋重建品質、語音/音樂/音訊下游任務、語音語言模型（見 Section 3）

### PDF Exclusion Signals
- 僅討論傳統連續特徵（continuous features）或未涉及離散標記化的音訊處理技術。
- 只聚焦於單一領域（如僅語音壓縮，無跨域比較或多任務應用）。
- 未涉及量化技術、離散標記產生流程或相關架構設計。
- 僅為語音合成/辨識/分離等應用介紹，未與離散標記技術結合。
- 缺乏對下游任務、生成任務或語音語言模型的實證評估。

### PDF Notes
- Discrete_Audio_Tokens_More_Than_a_Survey.pdf: 
  - 提供離散音訊標記領域最全面的分類、技術回顧與多維度基準評測，涵蓋語音、音樂及一般音訊，並深入探討量化技術、訓練範式、串流能力與跨域應用；同時提出統一的分類法與開放基準，對未來研究趨勢、挑戰與設計原則給出具體建議。
### Web Search Notes
以下內容依照你的指示整理，可直接用於系統性回顧（systematic review）之前期的 paper 篩選規則設計，並以「Discrete Audio Tokens: More Than a Survey!」為核心主題進行擴展與操作化定義。

---

### Topic Definition

離散音訊標記（Discrete Audio Tokens）是指將連續音訊訊號（如波形或頻譜特徵）透過量化與編碼模型，轉換為有限字彙表中的離散符號序列之方法。此類方法通常建立於編碼器–解碼器架構之上，並結合向量量化（如 VQ、RVQ、FSQ 等）或聚類技術，使音訊得以像文字一樣被語言模型處理。其核心目標是在可控的位元率與標記長度下，盡可能保留語音內容、語義資訊、說話者特徵與感知品質。

在近年大型語言模型與多模態模型快速發展的背景下，離散音訊標記被視為連結音訊與文字世界的關鍵中介表示。相較於連續特徵，離散標記更適合自回歸建模、跨模態對齊與大規模訓練，因此被廣泛應用於語音生成、音樂生成、語音辨識、語音理解與音訊語言模型等任務，並逐漸形成一個跨語音、音樂與一般聲音的研究體系。([arxiv.org](https://arxiv.org/abs/2506.10274?utm_source=openai))

---

### Summary

整體趨勢顯示，離散音訊標記已從早期的壓縮導向設計，演進為服務於生成式與語言導向任務的通用表徵。近期研究特別關注不同量化策略、語義與聲學標記的取捨，以及在統一基準下的可比較性。系統化的分類與基準評測逐漸成為該領域的重要研究基礎。([arxiv.org](https://arxiv.org/abs/2506.10274?utm_source=openai))

---

### Summary Topics

S1: 離散音訊標記的編碼器–解碼器與量化設計  
S2: 語義標記（semantic tokens）與聲學標記（acoustic tokens）的區分  
S3: 離散音訊標記在生成式與判別式任務中的效能評估  
S4: 跨語音、音樂與一般音訊的統一基準與比較方法  

---

### Inclusion Criteria (Required)

1. 主題定義：離散音訊標記（Discrete Audio Tokens）是指將連續音訊表示轉換為可索引、有限集合的離散符號序列，並可用於下游音訊或語言相關任務之方法。  
   英文可評估性條件：論文需明確使用 “discrete audio tokens”, “audio tokenization”, “acoustic tokens” 或等價英文術語描述其方法或研究問題。  
   source: https://arxiv.org/abs/2506.10274 ，topic ids: S1, S2  

2. 研究內容需以音訊（語音、音樂或一般聲音）為主要處理對象，而非僅為影像或純文字離散化方法的延伸應用。  
   英文可評估性條件：摘要或方法段落中需明確出現 “speech”, “audio”, “music” 等作為主要資料模態。  
   source: https://arxiv.org/abs/2406.14294 ，topic ids: S3, S4  

3. 論文需為可公開取得之英文學術文獻（如 arXiv、期刊或會議論文），並包含明確的方法描述與實驗或分析。  
   英文可評估性條件：全文以英文撰寫，且包含 “method”, “experiment”, 或 “evaluation” 等結構化章節。  
   source: https://arxiv.org/abs/2506.10274 ，topic ids: S4  

---

### Inclusion Criteria (Any-of Groups)

- Group A：量化與標記生成技術  
  * Option: 使用向量量化（如 VQ-VAE、RVQ、FSQ、或其變體）來生成離散音訊標記。  
    source: https://arxiv.org/abs/2506.10274 ，topic ids: S1  

- Group B：任務導向或評測導向研究  
  * Option: 將離散音訊標記系統性地評估於一個或多個下游任務（如語音辨識、語音生成、音訊字幕、TTS 等）。  
    source: https://arxiv.org/abs/2505.14989 ，topic ids: S3  

- Group C：基準或比較性研究  
  * Option: 提供多種離散音訊標記方法的統一比較、排行榜或基準資料集。  
    source: https://arxiv.org/abs/2406.14294 ，topic ids: S4  

---

### Exclusion Criteria

- 僅討論連續音訊表示（continuous representations）且明確排除離散化設計之研究。  
  source: https://blog.yueqianlin.com/daily-publication/250910/ ，topic ids: S1  

- 僅將離散化作為輔助步驟，且研究重心不在音訊標記設計、分析或評估（例如僅聚焦文字或影像 token）。  
  source: internal ，topic ids: S1  

- 非學術性文章（如僅為部落格、論壇貼文，且無完整方法與實驗）。  
  source: internal ，topic ids: S4  

---

### Sources

https://arxiv.org/abs/2506.10274  
https://arxiv.org/abs/2406.14294  
https://arxiv.org/abs/2505.14989  
https://blog.yueqianlin.com/daily-publication/250910/