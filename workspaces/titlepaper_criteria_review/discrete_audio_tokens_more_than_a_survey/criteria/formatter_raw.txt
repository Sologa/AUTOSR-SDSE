{
  "topic": {
    "title": "Discrete Audio Tokens: More Than a Survey!",
    "topic_definition": "離散音訊標記（Discrete Audio Tokens）是指將連續音訊訊號（如波形或頻譜特徵）透過編碼器–解碼器與量化/聚類等機制，轉換為有限字彙表中的離散符號序列（tokens），以在可控位元率與序列長度下，盡可能保留知覺品質、語音內容/語義資訊與說話者特徵，並提升儲存、傳輸與推論效率；此表示可作為音訊語言模型或多模態模型的中介表徵，並用於語音、音樂與一般音訊的生成式與判別式下游任務之方法與評估。",
    "scope_notes": [
      "涵蓋語音、音樂、一般音訊（audio events/sounds）之離散化表示。",
      "關注：編碼-解碼架構、量化策略（RVQ/SVQ/FSQ/K-means 等）、訓練範式（端到端/聯合訓練、SSL、semantic distillation）、串流/低延遲能力、以及基準與評測（重建品質、下游任務、作為音訊語言模型基礎）。"
    ],
    "summary_topics": [
      {
        "id": "S1",
        "name": "編碼器–解碼器與量化/標記生成設計"
      },
      {
        "id": "S2",
        "name": "語義標記（semantic tokens）與聲學標記（acoustic tokens）的區分與取捨"
      },
      {
        "id": "S3",
        "name": "生成式與判別式下游任務的效能評估"
      },
      {
        "id": "S4",
        "name": "跨語音/音樂/一般音訊的統一基準與可比較性"
      }
    ]
  },
  "inclusion_criteria": {
    "required": [
      {
        "id": "R1",
        "clause": "主題定義：離散音訊標記（Discrete Audio Tokens）是指將連續音訊表示轉換為可索引、有限集合的離散符號序列，並可用於下游音訊或語言相關任務之方法。",
        "english_screening_clause": "論文需明確使用 “discrete audio tokens”, “audio tokenization”, “acoustic tokens” 或等價英文術語描述其方法或研究問題。",
        "source": "https://arxiv.org/abs/2506.10274",
        "topic_ids": [
          "S1",
          "S2"
        ]
      },
      {
        "id": "R2",
        "clause": "研究內容需以音訊（語音、音樂或一般聲音）為主要處理對象，而非僅為影像或純文字離散化方法的延伸應用。",
        "english_screening_clause": "摘要或方法段落中需明確出現 “speech”, “audio”, “music” 等作為主要資料模態。",
        "source": "https://arxiv.org/abs/2406.14294",
        "topic_ids": [
          "S3",
          "S4"
        ]
      },
      {
        "id": "R3",
        "clause": "論文需為可公開取得之英文學術文獻（如 arXiv、期刊或會議論文），並包含明確的方法描述與實驗或分析。",
        "english_screening_clause": "全文以英文撰寫，且包含 “method”, “experiment”, 或 “evaluation” 等結構化章節。",
        "source": "https://arxiv.org/abs/2506.10274",
        "topic_ids": [
          "S4"
        ]
      }
    ],
    "any_of_groups": [
      {
        "group_id": "A",
        "group_name": "量化與標記生成技術",
        "options": [
          {
            "id": "A1",
            "criterion": "使用向量量化或聚類式離散化（例如 VQ-VAE、RVQ、SVQ、FSQ、K-means 或其變體）來生成離散音訊標記，並描述碼本/位元率/層級或多尺度設計等關鍵設定。",
            "source": "https://arxiv.org/abs/2506.10274",
            "topic_ids": [
              "S1"
            ]
          }
        ]
      },
      {
        "group_id": "B",
        "group_name": "任務導向或評測導向研究",
        "options": [
          {
            "id": "B1",
            "criterion": "將離散音訊標記方法以實證方式評估於一個或多個下游任務（例如 ASR、語音/音樂生成、TTS/VC、音訊字幕、語者/情感/事件辨識、分離等），或作為音訊語言模型/多模態模型之中介表示進行評估。",
            "source": "https://arxiv.org/abs/2505.14989",
            "topic_ids": [
              "S3"
            ]
          }
        ]
      },
      {
        "group_id": "C",
        "group_name": "基準或比較性研究",
        "options": [
          {
            "id": "C1",
            "criterion": "提供多種離散音訊標記方法的統一比較（同一資料/指標/協定下）、排行榜或基準資源（例如跨語音/音樂/一般音訊或跨任務的評測套件），並報告重建與/或下游任務表現。",
            "source": "https://arxiv.org/abs/2406.14294",
            "topic_ids": [
              "S4"
            ]
          }
        ]
      }
    ],
    "logic_note": "納入需同時滿足所有 required 條款，並且至少符合任一 any_of_groups 之 option（A/B/C 任一）。"
  },
  "exclusion_criteria": [
    {
      "id": "E1",
      "criterion": "僅討論連續音訊表示（continuous representations），且研究貢獻不包含將音訊離散化為可索引 tokens 的設計、分析或評估。",
      "source": "https://blog.yueqianlin.com/daily-publication/250910/",
      "topic_ids": [
        "S1"
      ]
    },
    {
      "id": "E2",
      "criterion": "離散化僅作為次要輔助步驟，研究重心不在音訊標記（token）設計、訓練、分析或系統性評估；主要貢獻在文字或影像 token，音訊僅為附帶應用或示例。",
      "source": "https://arxiv.org/abs/2506.10274",
      "topic_ids": [
        "S1"
      ]
    },
    {
      "id": "E3",
      "criterion": "非英文或不可公開取得之學術文獻，或缺乏可檢核的方法描述與實驗/評估（例如僅意見性文章、未提供實驗或分析）。",
      "source": "https://arxiv.org/abs/2506.10274",
      "topic_ids": [
        "S4"
      ]
    }
  ],
  "data_extraction_fields": {
    "bibliography": [
      "title",
      "authors",
      "year",
      "venue_or_platform",
      "url",
      "version"
    ],
    "study_characteristics": [
      "audio_domain (speech/music/general audio)",
      "primary_task_type (tokenization/codec/benchmark/ALM integration/downstream evaluation)",
      "model_architecture (encoder/decoder, autoregressive/non-AR, streaming-capable)",
      "token_type (acoustic/semantic/hybrid)",
      "training_paradigm (post-training/joint training/SSL/semantic distillation)",
      "quantization_or_discretization_method (VQ/RVQ/SVQ/FSQ/K-means/other)",
      "codebook_structure (size, levels, multi-codebook, hierarchical/multi-scale)",
      "bitrate_or_token_rate",
      "latency_or_streaming_constraints"
    ],
    "datasets": [
      "dataset_names",
      "dataset_domain",
      "dataset_size_or_hours (if reported)",
      "licenses_or_availability (if reported)"
    ],
    "evaluation": [
      "reconstruction_metrics (e.g., MOS, PESQ, SI-SDR, etc., as reported)",
      "benchmark_suites (e.g., Codec-SUPERB/VERSA/DASB/etc., as reported)",
      "downstream_tasks_and_metrics",
      "comparators_or_ablation",
      "compute_reporting (params/FLOPs/training time, if reported)"
    ],
    "outcomes_for_synthesis": [
      "key_findings",
      "tradeoffs (quality vs bitrate; semantic vs acoustic; latency vs quality)",
      "generalization (cross-domain/cross-speaker/cross-dataset)",
      "limitations"
    ]
  },
  "sources_used": [
    {
      "type": "web",
      "url": "https://arxiv.org/abs/2506.10274"
    },
    {
      "type": "web",
      "url": "https://arxiv.org/abs/2406.14294"
    },
    {
      "type": "web",
      "url": "https://arxiv.org/abs/2505.14989"
    },
    {
      "type": "web",
      "url": "https://blog.yueqianlin.com/daily-publication/250910/"
    }
  ]
}