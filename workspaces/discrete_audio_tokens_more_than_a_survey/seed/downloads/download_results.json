{
  "topic": "Discrete Audio Tokens: More Than a Survey!",
  "anchors": [
    "discrete audio tokens",
    "audio tokens",
    "discrete tokens"
  ],
  "survey_terms": [
    "survey",
    "review",
    "overview",
    "systematic review",
    "systematic literature review",
    "scoping review",
    "mapping study",
    "tutorial"
  ],
  "anchor_mode": "phrase",
  "search_query": "(all:\"discrete audio tokens\" OR all:\"audio tokens\" OR all:\"discrete tokens\") AND (all:\"survey\" OR all:\"review\" OR all:\"overview\" OR all:\"systematic review\" OR all:\"systematic literature review\" OR all:\"scoping review\" OR all:\"mapping study\" OR all:\"tutorial\")",
  "raw_query": null,
  "max_results": 25,
  "download_top_k": 5,
  "downloaded_at": "2026-01-07T05:01:11.805682+00:00",
  "downloads": {
    "arxiv": [
      {
        "source": "arxiv",
        "identifier": "2502.12448",
        "metadata": {
          "arxiv_id": "2502.12448",
          "title": "From Principles to Applications: A Comprehensive Survey of Discrete Tokenizers in Generation, Comprehension, Recommendation, and Information Retrieval",
          "summary": "Discrete tokenizers have emerged as indispensable components in modern machine learning systems, particularly within the context of autoregressive modeling and large language models (LLMs). These tokenizers serve as the critical interface that transforms raw, unstructured data from diverse modalities into discrete tokens, enabling LLMs to operate effectively across a wide range of tasks. Despite their central role in generation, comprehension, and recommendation systems, a comprehensive survey dedicated to discrete tokenizers remains conspicuously absent in the literature. This paper addresses this gap by providing a systematic review of the design principles, applications, and challenges of discrete tokenizers. We begin by dissecting the sub-modules of tokenizers and systematically demonstrate their internal mechanisms to provide a comprehensive understanding of their functionality and design. Building on this foundation, we synthesize state-of-the-art methods, categorizing them into multimodal generation and comprehension tasks, and semantic tokens for personalized recommendations. Furthermore, we critically analyze the limitations of existing tokenizers and outline promising directions for future research. By presenting a unified framework for understanding discrete tokenizers, this survey aims to guide researchers and practitioners in addressing open challenges and advancing the field, ultimately contributing to the development of more robust and versatile AI systems.",
          "authors": [
            "Jian Jia",
            "Jingtong Gao",
            "Ben Xue",
            "Junhao Wang",
            "Qingpeng Cai",
            "Quan Chen",
            "Xiangyu Zhao",
            "Peng Jiang",
            "Kun Gai"
          ],
          "published": "2025-02-18T02:29:51Z",
          "updated": "2025-02-18T02:29:51Z",
          "categories": [
            "cs.IR"
          ],
          "pdf_url": "https://arxiv.org/pdf/2502.12448v1",
          "landing_url": "https://arxiv.org/abs/2502.12448v1",
          "doi": "https://doi.org/10.48550/arXiv.2502.12448"
        },
        "pdf_path": "workspaces/discrete_audio_tokens_more_than_a_survey/seed/downloads/arxiv/2502.12448.pdf",
        "bibtex_path": null,
        "issues": [
          {
            "asset": "bibtex",
            "reason": "missing",
            "url": "https://arxiv.org/bibtex/2502.12448"
          }
        ]
      },
      {
        "source": "arxiv",
        "identifier": "2502.19548",
        "metadata": {
          "arxiv_id": "2502.19548",
          "title": "When Large Language Models Meet Speech: A Survey on Integration Approaches",
          "summary": "Recent advancements in large language models (LLMs) have spurred interest in expanding their application beyond text-based tasks. A large number of studies have explored integrating other modalities with LLMs, notably speech modality, which is naturally related to text. This paper surveys the integration of speech with LLMs, categorizing the methodologies into three primary approaches: text-based, latent-representation-based, and audio-token-based integration. We also demonstrate how these methods are applied across various speech-related applications and highlight the challenges in this field to offer inspiration for",
          "authors": [
            "Zhengdong Yang",
            "Shuichiro Shimizu",
            "Yahan Yu",
            "Chenhui Chu"
          ],
          "published": "2025-02-26T20:40:49Z",
          "updated": "2025-09-09T09:27:16Z",
          "categories": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
          ],
          "pdf_url": "https://arxiv.org/pdf/2502.19548v2",
          "landing_url": "https://arxiv.org/abs/2502.19548v2",
          "doi": "https://doi.org/10.48550/arXiv.2502.19548"
        },
        "pdf_path": "workspaces/discrete_audio_tokens_more_than_a_survey/seed/downloads/arxiv/2502.19548.pdf",
        "bibtex_path": null,
        "issues": [
          {
            "asset": "bibtex",
            "reason": "missing",
            "url": "https://arxiv.org/bibtex/2502.19548"
          }
        ]
      },
      {
        "source": "arxiv",
        "identifier": "2502.08869",
        "metadata": {
          "arxiv_id": "2502.08869",
          "title": "Harnessing Vision Models for Time Series Analysis: A Survey",
          "summary": "Time series analysis has witnessed the inspiring development from traditional autoregressive models, deep learning models, to recent Transformers and Large Language Models (LLMs). Efforts in leveraging vision models for time series analysis have also been made along the way but are less visible to the community due to the predominant research on sequence modeling in this domain. However, the discrepancy between continuous time series and the discrete token space of LLMs, and the challenges in explicitly modeling the correlations of variates in multivariate time series have shifted some research attentions to the equally successful Large Vision Models (LVMs) and Vision Language Models (VLMs). To fill the blank in the existing literature, this survey discusses the advantages of vision models over LLMs in time series analysis. It provides a comprehensive and in-depth overview of the existing methods, with dual views of detailed taxonomy that answer the key research questions including how to encode time series as images and how to model the imaged time series for various tasks. Additionally, we address the challenges in the pre- and post-processing steps involved in this framework and outline future directions to further advance time series analysis with vision models.",
          "authors": [
            "Jingchao Ni",
            "Ziming Zhao",
            "ChengAo Shen",
            "Hanghang Tong",
            "Dongjin Song",
            "Wei Cheng",
            "Dongsheng Luo",
            "Haifeng Chen"
          ],
          "published": "2025-02-13T00:42:11Z",
          "updated": "2025-08-30T06:05:18Z",
          "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
          ],
          "pdf_url": "https://arxiv.org/pdf/2502.08869v2",
          "landing_url": "https://arxiv.org/abs/2502.08869v2",
          "doi": "https://doi.org/10.48550/arXiv.2502.08869"
        },
        "pdf_path": "workspaces/discrete_audio_tokens_more_than_a_survey/seed/downloads/arxiv/2502.08869.pdf",
        "bibtex_path": null,
        "issues": [
          {
            "asset": "bibtex",
            "reason": "missing",
            "url": "https://arxiv.org/bibtex/2502.08869"
          }
        ]
      }
    ],
    "semantic_scholar": [],
    "dblp": []
  },
  "rewrite_attempts": 1,
  "rewrite_query": "discrete audio tokens",
  "rewrite_queries": [
    "discrete audio tokens",
    "audio tokens",
    "discrete tokens"
  ]
}