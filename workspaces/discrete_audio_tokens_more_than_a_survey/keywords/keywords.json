{
  "topic": "Discrete Audio Tokens: More Than a Survey!",
  "anchor_terms": [
    "discrete speech tokens",
    "speech representation",
    "acoustic tokens",
    "semantic tokens"
  ],
  "search_terms": {
    "tokenization_methods": [
      "vector quantization",
      "offline clustering",
      "k-means clustering",
      "gumbel vq",
      "finite scalar quantization",
      "residual vq",
      "grouped vq",
      "codebook",
      "speech tokenization"
    ],
    "neural_codec_models": [
      "neural audio codec",
      "vq-gan",
      "vq-vae",
      "diffusion",
      "flow matching",
      "encoder decoder",
      "discriminator",
      "speech token vocoder",
      "acoustic tokens"
    ],
    "semantic_token_models": [
      "self-supervised learning",
      "hubert",
      "wav2vec 2 0",
      "wavlm",
      "vq-wav2vec",
      "supervised tokens",
      "internal quantization",
      "external quantization",
      "discrete speech tokens",
      "semantic tokens"
    ],
    "sequence_compression": [
      "frame rate",
      "bitrate",
      "vocabulary size",
      "length reduction",
      "deduplication",
      "acoustic bpe",
      "variable frame rate",
      "unit discovery"
    ],
    "evaluation_benchmarks": [
      "reconstruction",
      "voice conversion",
      "word error rate",
      "pesq",
      "stoi",
      "speaker similarity",
      "codec-superb",
      "dasb"
    ]
  },
  "papers": [
    {
      "id": "guo_discrete_speech_tokens_2025",
      "source_id": "arXiv:2502.06490",
      "title": "Recent Advances in Discrete Speech Tokens: A Review",
      "abstract": "The rapid advancement of speech generation technologies in the era of large language models (LLMs) has established discrete speech tokens as a foundational paradigm for speech representation. These tokens, characterized by their discrete, compact, and concise nature, are not only advantageous for efficient transmission and storage, but also inherently compatible with the language modeling framework, enabling seamless integration of speech into text-dominated LLM architectures. Current research categorizes discrete speech tokens into two principal classes: acoustic tokens and semantic tokens, each of which has evolved into a rich research domain characterized by unique design philosophies and methodological approaches. This survey systematically synthesizes the existing taxonomy and recent innovations in discrete speech tokenization, conducts a critical examination of the strengths and limitations of each paradigm, and presents systematic experimental comparisons across token types. Furthermore, we identify persistent challenges in the field and propose potential research directions, aiming to offer actionable insights to inspire future advancements in the development and application of discrete speech tokens.",
      "year": "2025",
      "source_url": "https://arxiv.org/abs/2502.06490v4",
      "detected_keywords": [
        {
          "term": "discrete speech tokens",
          "category": "semantic_token_models",
          "evidence": {
            "quote": "Index Termsâ€”Discrete speech tokens, neural audio codec, speech tokenizer, speech LLMs, spoken language modeling, speech generation, acoustic tokens, semantic tokens",
            "page": "1"
          },
          "confidence": 0.6
        },
        {
          "term": "speech tokenization",
          "category": "tokenization_methods",
          "evidence": {
            "quote": "Therefore, a necessary step before applying speech data to LLM is the tokenization of speech",
            "page": "1"
          },
          "confidence": 0.55
        },
        {
          "term": "acoustic tokens",
          "category": "neural_codec_models",
          "evidence": {
            "quote": "two types of speech tokens: acoustic tokens and semantic tokens.",
            "page": "1"
          },
          "confidence": 0.55
        },
        {
          "term": "semantic tokens",
          "category": "semantic_token_models",
          "evidence": {
            "quote": "two types of speech tokens: acoustic tokens and semantic tokens.",
            "page": "1"
          },
          "confidence": 0.55
        },
        {
          "term": "offline clustering",
          "category": "tokenization_methods",
          "evidence": {
            "quote": "A. Offline Clustering",
            "page": "2"
          },
          "confidence": 0.45
        },
        {
          "term": "k-means clustering",
          "category": "tokenization_methods",
          "evidence": {
            "quote": "The most frequently used clustering method for discrete speech tokens is k-means clustering",
            "page": "2"
          },
          "confidence": 0.45
        },
        {
          "term": "vector quantization",
          "category": "tokenization_methods",
          "evidence": {
            "quote": "B. Vector Quantization",
            "page": "2"
          },
          "confidence": 0.45
        },
        {
          "term": "finite scalar quantization",
          "category": "tokenization_methods",
          "evidence": {
            "quote": "3) Finite Scalar Quantization (FSQ):",
            "page": "3"
          },
          "confidence": 0.4
        },
        {
          "term": "VQ-GAN",
          "category": "neural_codec_models",
          "evidence": {
            "quote": "1) VQ-GAN: VQ-GAN [66] is a very commonly adopted framework of codec models",
            "page": "5"
          },
          "confidence": 0.45
        },
        {
          "term": "diffusion",
          "category": "neural_codec_models",
          "evidence": {
            "quote": "2) Diffusion: Different from VQ-GAN which uses GAN to generate waveforms or frequency features, some codecs also use denoising diffusion",
            "page": "5"
          },
          "confidence": 0.45
        },
        {
          "term": "deduplication",
          "category": "sequence_compression",
          "evidence": {
            "quote": "A common approach to reduce token sequence lengths is deduplication",
            "page": "11"
          },
          "confidence": 0.45
        },
        {
          "term": "acoustic BPE",
          "category": "sequence_compression",
          "evidence": {
            "quote": "Another popular approach is acoustic byte-pair encoding (BPE)",
            "page": "11"
          },
          "confidence": 0.45
        },
        {
          "term": "variable frame rate",
          "category": "sequence_compression",
          "evidence": {
            "quote": "This kind of discrete speech tokens is referred to as variable frame rate (VFR) tokens in this review.",
            "page": "12"
          },
          "confidence": 0.45
        },
        {
          "term": "Codec-SUPERB",
          "category": "evaluation_benchmarks",
          "evidence": {
            "quote": "Codec-SUPERB [179] evaluates both signal-level reconstruction metrics and downstream performances of acoustic tokens.",
            "page": "13"
          },
          "confidence": 0.4
        },
        {
          "term": "DASB",
          "category": "evaluation_benchmarks",
          "evidence": {
            "quote": "DASB [147] performs more downstream probing tasks, and includes generative tasks as well as semantic tokens.",
            "page": "13"
          },
          "confidence": 0.4
        }
      ]
    }
  ]
}