[
  {
    "status": "include",
    "title": "Recent Advances in Discrete Speech Tokens: A Review",
    "normalized_title": "recentadvancesindiscretespeechtokens:areview",
    "doi": "10.48550/arxiv.2502.06490",
    "openalex_id": "",
    "arxiv_id": "2502.06490",
    "published_date": "2025-02-10",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Self-supervised speech unit discovery from articulatory and acoustic features using VQ-VAE",
    "normalized_title": "self-supervisedspeechunitdiscoveryfromarticulatoryandacousticfeaturesusingvq-vae",
    "doi": "10.48550/arxiv.2206.08790",
    "openalex_id": "",
    "arxiv_id": "2206.08790",
    "published_date": "2022-06-17",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "A Comparative Study of Self-supervised Speech Representation Based Voice Conversion",
    "normalized_title": "acomparativestudyofself-supervisedspeechrepresentationbasedvoiceconversion",
    "doi": "10.1109/jstsp.2022.3193761",
    "openalex_id": "",
    "arxiv_id": "2207.04356",
    "published_date": "2022-07-10",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "DelightfulTTS 2: End-to-End Speech Synthesis with Adversarial Vector-Quantized Auto-Encoders",
    "normalized_title": "delightfultts2:end-to-endspeechsynthesiswithadversarialvector-quantizedauto-encoders",
    "doi": "10.48550/arxiv.2207.04646",
    "openalex_id": "",
    "arxiv_id": "2207.04646",
    "published_date": "2022-07-11",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "A Multi-Stage Multi-Codebook VQ-VAE Approach to High-Performance Neural TTS",
    "normalized_title": "amulti-stagemulti-codebookvq-vaeapproachtohigh-performanceneuraltts",
    "doi": "10.48550/arxiv.2209.10887",
    "openalex_id": "",
    "arxiv_id": "2209.10887",
    "published_date": "2022-09-22",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "CoBERT: Self-Supervised Speech Representation Learning Through Code Representation Learning",
    "normalized_title": "cobert:self-supervisedspeechrepresentationlearningthroughcoderepresentationlearning",
    "doi": "10.48550/arxiv.2210.04062",
    "openalex_id": "",
    "arxiv_id": "2210.04062",
    "published_date": "2022-10-08",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "JukeDrummer: Conditional Beat-aware Audio-domain Drum Accompaniment Generation via Transformer VQ-VAE",
    "normalized_title": "jukedrummer:conditionalbeat-awareaudio-domaindrumaccompanimentgenerationviatransformervq-vae",
    "doi": "10.48550/arxiv.2210.06007",
    "openalex_id": "",
    "arxiv_id": "2210.06007",
    "published_date": "2022-10-12",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Towards High-Quality Neural TTS for Low-Resource Languages by Learning Compact Speech Representations",
    "normalized_title": "towardshigh-qualityneuralttsforlow-resourcelanguagesbylearningcompactspeechrepresentations",
    "doi": "10.48550/arxiv.2210.15131",
    "openalex_id": "",
    "arxiv_id": "2210.15131",
    "published_date": "2022-10-27",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "token2vec: A Joint Self-Supervised Pre-training Framework Using Unpaired Speech and Text",
    "normalized_title": "token2vec:ajointself-supervisedpre-trainingframeworkusingunpairedspeechandtext",
    "doi": "10.48550/arxiv.2210.16755",
    "openalex_id": "",
    "arxiv_id": "2210.16755",
    "published_date": "2022-10-30",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SpeechLMScore: Evaluating speech generation using speech language model",
    "normalized_title": "speechlmscore:evaluatingspeechgenerationusingspeechlanguagemodel",
    "doi": "10.48550/arxiv.2212.04559",
    "openalex_id": "",
    "arxiv_id": "2212.04559",
    "published_date": "2022-12-08",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "BEATs: Audio Pre-Training with Acoustic Tokenizers",
    "normalized_title": "beats:audiopre-trainingwithacoustictokenizers",
    "doi": "10.48550/arxiv.2212.09058",
    "openalex_id": "",
    "arxiv_id": "2212.09058",
    "published_date": "2022-12-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Analysing Discrete Self Supervised Speech Representation for Spoken Language Modeling",
    "normalized_title": "analysingdiscreteselfsupervisedspeechrepresentationforspokenlanguagemodeling",
    "doi": "10.1109/icassp49357.2023.10097097",
    "openalex_id": "",
    "arxiv_id": "2301.00591",
    "published_date": "2023-01-02",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers",
    "normalized_title": "neuralcodeclanguagemodelsarezero-shottexttospeechsynthesizers",
    "doi": "10.48550/arxiv.2301.02111",
    "openalex_id": "",
    "arxiv_id": "2301.02111",
    "published_date": "2023-01-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "InstructTTS: Modelling Expressive TTS in Discrete Latent Space with Natural Language Style Prompt",
    "normalized_title": "instructtts:modellingexpressivettsindiscretelatentspacewithnaturallanguagestyleprompt",
    "doi": "10.48550/arxiv.2301.13662",
    "openalex_id": "",
    "arxiv_id": "2301.13662",
    "published_date": "2023-01-31",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Speak, Read and Prompt: High-Fidelity Text-to-Speech with Minimal Supervision",
    "normalized_title": "speak,readandprompt:high-fidelitytext-to-speechwithminimalsupervision",
    "doi": "10.48550/arxiv.2302.03540",
    "openalex_id": "",
    "arxiv_id": "2302.03540",
    "published_date": "2023-02-07",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech",
    "normalized_title": "avectorquantizedapproachfortexttospeechsynthesisonreal-worldspontaneousspeech",
    "doi": "10.48550/arxiv.2302.04215",
    "openalex_id": "",
    "arxiv_id": "2302.04215",
    "published_date": "2023-02-08",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Speech Enhancement with Multi-granularity Vector Quantization",
    "normalized_title": "speechenhancementwithmulti-granularityvectorquantization",
    "doi": "10.48550/arxiv.2302.08342",
    "openalex_id": "",
    "arxiv_id": "2302.08342",
    "published_date": "2023-02-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "FoundationTTS: Text-to-Speech for ASR Customization with Generative Language Model",
    "normalized_title": "foundationtts:text-to-speechforasrcustomizationwithgenerativelanguagemodel",
    "doi": "10.48550/arxiv.2303.02939",
    "openalex_id": "",
    "arxiv_id": "2303.02939",
    "published_date": "2023-03-06",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec Language Modeling",
    "normalized_title": "speakforeignlanguageswithyourownvoice:cross-lingualneuralcodeclanguagemodeling",
    "doi": "10.48550/arxiv.2303.03926",
    "openalex_id": "",
    "arxiv_id": "2303.03926",
    "published_date": "2023-03-07",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "A vector quantized masked autoencoder for audiovisual speech emotion recognition",
    "normalized_title": "avectorquantizedmaskedautoencoderforaudiovisualspeechemotionrecognition",
    "doi": "10.1016/j.cviu.2025.104362",
    "openalex_id": "",
    "arxiv_id": "2305.03568",
    "published_date": "2023-05-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "A multimodal dynamical variational autoencoder for audiovisual speech representation learning",
    "normalized_title": "amultimodaldynamicalvariationalautoencoderforaudiovisualspeechrepresentationlearning",
    "doi": "10.1016/j.neunet.2024.106120",
    "openalex_id": "",
    "arxiv_id": "2305.03582",
    "published_date": "2023-05-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SoundStorm: Efficient Parallel Audio Generation",
    "normalized_title": "soundstorm:efficientparallelaudiogeneration",
    "doi": "10.48550/arxiv.2305.09636",
    "openalex_id": "",
    "arxiv_id": "2305.09636",
    "published_date": "2023-05-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Make-A-Voice: Unified Voice Synthesis With Discrete Representation",
    "normalized_title": "make-a-voice:unifiedvoicesynthesiswithdiscreterepresentation",
    "doi": "10.48550/arxiv.2305.19269",
    "openalex_id": "",
    "arxiv_id": "2305.19269",
    "published_date": "2023-05-30",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "UniCATS: A Unified Context-Aware Text-to-Speech Framework with Contextual VQ-Diffusion and Vocoding",
    "normalized_title": "unicats:aunifiedcontext-awaretext-to-speechframeworkwithcontextualvq-diffusionandvocoding",
    "doi": "10.1609/aaai.v38i16.29747",
    "openalex_id": "",
    "arxiv_id": "2306.07547",
    "published_date": "2023-06-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Pushing the Limits of Unsupervised Unit Discovery for SSL Speech Representation",
    "normalized_title": "pushingthelimitsofunsupervisedunitdiscoveryforsslspeechrepresentation",
    "doi": "10.48550/arxiv.2306.08920",
    "openalex_id": "",
    "arxiv_id": "2306.08920",
    "published_date": "2023-06-15",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "LM-VC: Zero-shot Voice Conversion via Speech Generation based on Language Models",
    "normalized_title": "lm-vc:zero-shotvoiceconversionviaspeechgenerationbasedonlanguagemodels",
    "doi": "10.48550/arxiv.2306.10521",
    "openalex_id": "",
    "arxiv_id": "2306.10521",
    "published_date": "2023-06-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "VampNet: Music Generation via Masked Acoustic Token Modeling",
    "normalized_title": "vampnet:musicgenerationviamaskedacoustictokenmodeling",
    "doi": "10.48550/arxiv.2307.04686",
    "openalex_id": "",
    "arxiv_id": "2307.04686",
    "published_date": "2023-07-10",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SpeechTokenizer: Unified Speech Tokenizer for Speech Large Language Models",
    "normalized_title": "speechtokenizer:unifiedspeechtokenizerforspeechlargelanguagemodels",
    "doi": "10.48550/arxiv.2308.16692",
    "openalex_id": "",
    "arxiv_id": "2308.16692",
    "published_date": "2023-08-31",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "QS-TTS: Towards Semi-Supervised Text-to-Speech Synthesis via Vector-Quantized Self-Supervised Speech Representation Learning",
    "normalized_title": "qs-tts:towardssemi-supervisedtext-to-speechsynthesisviavector-quantizedself-supervisedspeechrepresentationlearning",
    "doi": "10.48550/arxiv.2309.00126",
    "openalex_id": "",
    "arxiv_id": "2309.00126",
    "published_date": "2023-08-31",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "RepCodec: A Speech Representation Codec for Speech Tokenization",
    "normalized_title": "repcodec:aspeechrepresentationcodecforspeechtokenization",
    "doi": "10.48550/arxiv.2309.00169",
    "openalex_id": "",
    "arxiv_id": "2309.00169",
    "published_date": "2023-08-31",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Direct Text to Speech Translation System using Acoustic Units",
    "normalized_title": "directtexttospeechtranslationsystemusingacousticunits",
    "doi": "10.1109/lsp.2023.3313513",
    "openalex_id": "",
    "arxiv_id": "2309.07478",
    "published_date": "2023-09-14",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Voxtlm: unified decoder-only models for consolidating speech recognition/synthesis and speech/text continuation tasks",
    "normalized_title": "voxtlm:unifieddecoder-onlymodelsforconsolidatingspeechrecognition/synthesisandspeech/textcontinuationtasks",
    "doi": "10.48550/arxiv.2309.07937",
    "openalex_id": "",
    "arxiv_id": "2309.07937",
    "published_date": "2023-09-14",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Improving Language Model-Based Zero-Shot Text-to-Speech Synthesis with Multi-Scale Acoustic Prompts",
    "normalized_title": "improvinglanguagemodel-basedzero-shottext-to-speechsynthesiswithmulti-scaleacousticprompts",
    "doi": "10.48550/arxiv.2309.11977",
    "openalex_id": "",
    "arxiv_id": "2309.11977",
    "published_date": "2023-09-21",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Towards General-Purpose Text-Instruction-Guided Voice Conversion",
    "normalized_title": "towardsgeneral-purposetext-instruction-guidedvoiceconversion",
    "doi": "10.48550/arxiv.2309.14324",
    "openalex_id": "",
    "arxiv_id": "2309.14324",
    "published_date": "2023-09-25",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Vec-Tok Speech: speech vectorization and tokenization for neural speech generation",
    "normalized_title": "vec-tokspeech:speechvectorizationandtokenizationforneuralspeechgeneration",
    "doi": "10.48550/arxiv.2310.07246",
    "openalex_id": "",
    "arxiv_id": "2310.07246",
    "published_date": "2023-10-11",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Low-latency Speech Enhancement via Speech Token Generation",
    "normalized_title": "low-latencyspeechenhancementviaspeechtokengeneration",
    "doi": "10.48550/arxiv.2310.08981",
    "openalex_id": "",
    "arxiv_id": "2310.08981",
    "published_date": "2023-10-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Composer Style-specific Symbolic Music Generation Using Vector Quantized Discrete Diffusion Models",
    "normalized_title": "composerstyle-specificsymbolicmusicgenerationusingvectorquantizeddiscretediffusionmodels",
    "doi": "10.48550/arxiv.2310.14044",
    "openalex_id": "",
    "arxiv_id": "2310.14044",
    "published_date": "2023-10-21",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Acoustic BPE for Speech Generation with Discrete Tokens",
    "normalized_title": "acousticbpeforspeechgenerationwithdiscretetokens",
    "doi": "10.48550/arxiv.2310.14580",
    "openalex_id": "",
    "arxiv_id": "2310.14580",
    "published_date": "2023-10-23",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Transduce and Speak: Neural Transducer for Text-to-Speech with Semantic Token Prediction",
    "normalized_title": "transduceandspeak:neuraltransducerfortext-to-speechwithsemantictokenprediction",
    "doi": "10.48550/arxiv.2311.02898",
    "openalex_id": "",
    "arxiv_id": "2311.02898",
    "published_date": "2023-11-06",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Loss Masking Is Not Needed in Decoder-only Transformer for Discrete-token-based ASR",
    "normalized_title": "lossmaskingisnotneededindecoder-onlytransformerfordiscrete-token-basedasr",
    "doi": "10.48550/arxiv.2311.04534",
    "openalex_id": "",
    "arxiv_id": "2311.04534",
    "published_date": "2023-11-08",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SEF-VC: Speaker Embedding Free Zero-Shot Voice Conversion with Cross Attention",
    "normalized_title": "sef-vc:speakerembeddingfreezero-shotvoiceconversionwithcrossattention",
    "doi": "10.48550/arxiv.2312.08676",
    "openalex_id": "https://openalex.org/w4392902857",
    "arxiv_id": "2312.08676",
    "published_date": "2023-12-14",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "SELM: Speech Enhancement Using Discrete Tokens and Language Models",
    "normalized_title": "selm:speechenhancementusingdiscretetokensandlanguagemodels",
    "doi": "10.48550/arxiv.2312.09747",
    "openalex_id": "",
    "arxiv_id": "2312.09747",
    "published_date": "2023-12-15",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Utilizing Neural Transducers for Two-Stage Text-to-Speech via Semantic Token Prediction",
    "normalized_title": "utilizingneuraltransducersfortwo-stagetext-to-speechviasemantictokenprediction",
    "doi": "10.48550/arxiv.2401.01498",
    "openalex_id": "",
    "arxiv_id": "2401.01498",
    "published_date": "2024-01-03",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Predicting positive transfer for improved low-resource speech recognition using acoustic pseudo-tokens",
    "normalized_title": "predictingpositivetransferforimprovedlow-resourcespeechrecognitionusingacousticpseudo-tokens",
    "doi": "10.48550/arxiv.2402.02302",
    "openalex_id": "",
    "arxiv_id": "2402.02302",
    "published_date": "2024-02-03",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "BASE TTS: Lessons from building a billion-parameter Text-to-Speech model on 100K hours of data",
    "normalized_title": "basetts:lessonsfrombuildingabillion-parametertext-to-speechmodelon100khoursofdata",
    "doi": "10.48550/arxiv.2402.08093",
    "openalex_id": "",
    "arxiv_id": "2402.08093",
    "published_date": "2024-02-12",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "MobileSpeech: A Fast and High-Fidelity Framework for Mobile Zero-Shot Text-to-Speech",
    "normalized_title": "mobilespeech:afastandhigh-fidelityframeworkformobilezero-shottext-to-speech",
    "doi": "10.48550/arxiv.2402.09378",
    "openalex_id": "",
    "arxiv_id": "2402.09378",
    "published_date": "2024-02-14",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Language-Codec: Bridging Discrete Codec Representations and Speech Language Models",
    "normalized_title": "language-codec:bridgingdiscretecodecrepresentationsandspeechlanguagemodels",
    "doi": "10.48550/arxiv.2402.12208",
    "openalex_id": "",
    "arxiv_id": "2402.12208",
    "published_date": "2024-02-19",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "The X-LANCE Technical Report for Interspeech 2024 Speech Processing Using Discrete Speech Unit Challenge",
    "normalized_title": "thex-lancetechnicalreportforinterspeech2024speechprocessingusingdiscretespeechunitchallenge",
    "doi": "10.48550/arxiv.2404.06079",
    "openalex_id": "",
    "arxiv_id": "2404.06079",
    "published_date": "2024-04-09",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "ESC: Efficient Speech Coding with Cross-Scale Residual Vector Quantized Transformers",
    "normalized_title": "esc:efficientspeechcodingwithcross-scaleresidualvectorquantizedtransformers",
    "doi": "10.48550/arxiv.2404.19441",
    "openalex_id": "",
    "arxiv_id": "2404.19441",
    "published_date": "2024-04-30",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "C3LLM: Conditional Multimodal Content Generation Using Large Language Models",
    "normalized_title": "c3llm:conditionalmultimodalcontentgenerationusinglargelanguagemodels",
    "doi": "10.48550/arxiv.2405.16136",
    "openalex_id": "",
    "arxiv_id": "2405.16136",
    "published_date": "2024-05-25",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Generative Pre-trained Speech Language Model with Efficient Hierarchical Transformer",
    "normalized_title": "generativepre-trainedspeechlanguagemodelwithefficienthierarchicaltransformer",
    "doi": "10.48550/arxiv.2406.00976",
    "openalex_id": "",
    "arxiv_id": "2406.00976",
    "published_date": "2024-06-03",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "MaskSR: Masked Language Model for Full-band Speech Restoration",
    "normalized_title": "masksr:maskedlanguagemodelforfull-bandspeechrestoration",
    "doi": "10.48550/arxiv.2406.02092",
    "openalex_id": "",
    "arxiv_id": "2406.02092",
    "published_date": "2024-06-04",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Addressing Index Collapse of Large-Codebook Speech Tokenizer with Dual-Decoding Product-Quantized Variational Auto-Encoder",
    "normalized_title": "addressingindexcollapseoflarge-codebookspeechtokenizerwithdual-decodingproduct-quantizedvariationalauto-encoder",
    "doi": "10.48550/arxiv.2406.02940",
    "openalex_id": "",
    "arxiv_id": "2406.02940",
    "published_date": "2024-06-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Improving Audio Codec-based Zero-Shot Text-to-Speech Synthesis with Multi-Modal Context and Large Language Model",
    "normalized_title": "improvingaudiocodec-basedzero-shottext-to-speechsynthesiswithmulti-modalcontextandlargelanguagemodel",
    "doi": "10.48550/arxiv.2406.03706",
    "openalex_id": "",
    "arxiv_id": "2406.03706",
    "published_date": "2024-06-06",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Discrete Multimodal Transformers with a Pretrained Large Language Model for Mixed-Supervision Speech Processing",
    "normalized_title": "discretemultimodaltransformerswithapretrainedlargelanguagemodelformixed-supervisionspeechprocessing",
    "doi": "10.48550/arxiv.2406.06582",
    "openalex_id": "",
    "arxiv_id": "2406.06582",
    "published_date": "2024-06-04",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "VALL-E R: Robust and Efficient Zero-Shot Text-to-Speech Synthesis via Monotonic Alignment",
    "normalized_title": "vall-er:robustandefficientzero-shottext-to-speechsynthesisviamonotonicalignment",
    "doi": "10.48550/arxiv.2406.07855",
    "openalex_id": "",
    "arxiv_id": "2406.07855",
    "published_date": "2024-06-12",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "How Should We Extract Discrete Audio Tokens from Self-Supervised Models?",
    "normalized_title": "howshouldweextractdiscreteaudiotokensfromself-supervisedmodels?",
    "doi": "10.48550/arxiv.2406.10735",
    "openalex_id": "",
    "arxiv_id": "2406.10735",
    "published_date": "2024-06-15",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "NAST: Noise Aware Speech Tokenization for Speech Language Models",
    "normalized_title": "nast:noiseawarespeechtokenizationforspeechlanguagemodels",
    "doi": "10.48550/arxiv.2406.11037",
    "openalex_id": "",
    "arxiv_id": "2406.11037",
    "published_date": "2024-06-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "DASB - Discrete Audio and Speech Benchmark",
    "normalized_title": "dasb-discreteaudioandspeechbenchmark",
    "doi": "10.48550/arxiv.2406.14294",
    "openalex_id": "",
    "arxiv_id": "2406.14294",
    "published_date": "2024-06-20",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "High Fidelity Text-to-Speech Via Discrete Tokens Using Token Transducer and Group Masked Language Model",
    "normalized_title": "highfidelitytext-to-speechviadiscretetokensusingtokentransducerandgroupmaskedlanguagemodel",
    "doi": "10.48550/arxiv.2406.17310",
    "openalex_id": "",
    "arxiv_id": "2406.17310",
    "published_date": "2024-06-25",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "On the Effectiveness of Acoustic BPE in Decoder-Only TTS",
    "normalized_title": "ontheeffectivenessofacousticbpeindecoder-onlytts",
    "doi": "10.48550/arxiv.2407.03892",
    "openalex_id": "",
    "arxiv_id": "2407.03892",
    "published_date": "2024-07-04",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens",
    "normalized_title": "cosyvoice:ascalablemultilingualzero-shottext-to-speechsynthesizerbasedonsupervisedsemantictokens",
    "doi": "10.48550/arxiv.2407.05407",
    "openalex_id": "",
    "arxiv_id": "2407.05407",
    "published_date": "2024-07-07",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "dMel: Speech Tokenization made Simple",
    "normalized_title": "dmel:speechtokenizationmadesimple",
    "doi": "10.48550/arxiv.2407.15835",
    "openalex_id": "",
    "arxiv_id": "2407.15835",
    "published_date": "2024-07-22",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "VoxInstruct: Expressive Human Instruction-to-Speech Generation with Unified Multilingual Codec Language Modelling",
    "normalized_title": "voxinstruct:expressivehumaninstruction-to-speechgenerationwithunifiedmultilingualcodeclanguagemodelling",
    "doi": "10.1145/3664647.3681680",
    "openalex_id": "",
    "arxiv_id": "2408.15676",
    "published_date": "2024-08-28",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Enabling Beam Search for Language Model-Based Text-to-Speech Synthesis",
    "normalized_title": "enablingbeamsearchforlanguagemodel-basedtext-to-speechsynthesis",
    "doi": "10.48550/arxiv.2408.16373",
    "openalex_id": "",
    "arxiv_id": "2408.16373",
    "published_date": "2024-08-29",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Codec Does Matter: Exploring the Semantic Shortcoming of Codec for Audio Language Model",
    "normalized_title": "codecdoesmatter:exploringthesemanticshortcomingofcodecforaudiolanguagemodel",
    "doi": "10.48550/arxiv.2408.17175",
    "openalex_id": "",
    "arxiv_id": "2408.17175",
    "published_date": "2024-08-30",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer",
    "normalized_title": "maskgct:zero-shottext-to-speechwithmaskedgenerativecodectransformer",
    "doi": "10.48550/arxiv.2409.00750",
    "openalex_id": "",
    "arxiv_id": "2409.00750",
    "published_date": "2024-09-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "STAB: Speech Tokenizer Assessment Benchmark",
    "normalized_title": "stab:speechtokenizerassessmentbenchmark",
    "doi": "10.48550/arxiv.2409.02384",
    "openalex_id": "",
    "arxiv_id": "2409.02384",
    "published_date": "2024-09-04",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "FireRedTTS: A Foundation Text-To-Speech Framework for Industry-Level Generative Speech Applications",
    "normalized_title": "fireredtts:afoundationtext-to-speechframeworkforindustry-levelgenerativespeechapplications",
    "doi": "10.48550/arxiv.2409.03283",
    "openalex_id": "",
    "arxiv_id": "2409.03283",
    "published_date": "2024-09-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "LAST: Language Model Aware Speech Tokenization",
    "normalized_title": "last:languagemodelawarespeechtokenization",
    "doi": "10.48550/arxiv.2409.03701",
    "openalex_id": "",
    "arxiv_id": "2409.03701",
    "published_date": "2024-09-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Investigating Neural Audio Codecs for Speech Language Model-Based Speech Generation",
    "normalized_title": "investigatingneuralaudiocodecsforspeechlanguagemodel-basedspeechgeneration",
    "doi": "10.48550/arxiv.2409.04016",
    "openalex_id": "",
    "arxiv_id": "2409.04016",
    "published_date": "2024-09-06",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Disentangling the Prosody and Semantic Information with Pre-trained Model for In-Context Learning based Zero-Shot Voice Conversion",
    "normalized_title": "disentanglingtheprosodyandsemanticinformationwithpre-trainedmodelforin-contextlearningbasedzero-shotvoiceconversion",
    "doi": "10.48550/arxiv.2409.05004",
    "openalex_id": "",
    "arxiv_id": "2409.05004",
    "published_date": "2024-09-08",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE",
    "normalized_title": "probtalk3d:non-deterministicemotioncontrollablespeech-driven3dfacialanimationsynthesisusingvq-vae",
    "doi": "10.1145/3677388.3696320",
    "openalex_id": "",
    "arxiv_id": "2409.07966",
    "published_date": "2024-09-12",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "NDVQ: Robust Neural Audio Codec with Normal Distribution-Based Vector Quantization",
    "normalized_title": "ndvq:robustneuralaudiocodecwithnormaldistribution-basedvectorquantization",
    "doi": "10.48550/arxiv.2409.12717",
    "openalex_id": "",
    "arxiv_id": "2409.12717",
    "published_date": "2024-09-19",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "EMOVA: Empowering Language Models to See, Hear and Speak with Vivid Emotions",
    "normalized_title": "emova:empoweringlanguagemodelstosee,hearandspeakwithvividemotions",
    "doi": "10.48550/arxiv.2409.18042",
    "openalex_id": "",
    "arxiv_id": "2409.18042",
    "published_date": "2024-09-26",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Moshi: a speech-text foundation model for real-time dialogue",
    "normalized_title": "moshi:aspeech-textfoundationmodelforreal-timedialogue",
    "doi": "10.48550/arxiv.2410.00037",
    "openalex_id": "",
    "arxiv_id": "2410.00037",
    "published_date": "2024-09-17",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Textless Streaming Speech-to-Speech Translation using Semantic Speech Tokens",
    "normalized_title": "textlessstreamingspeech-to-speechtranslationusingsemanticspeechtokens",
    "doi": "10.48550/arxiv.2410.03298",
    "openalex_id": "",
    "arxiv_id": "2410.03298",
    "published_date": "2024-10-04",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Variable Bitrate Residual Vector Quantization for Audio Coding",
    "normalized_title": "variablebitrateresidualvectorquantizationforaudiocoding",
    "doi": "10.48550/arxiv.2410.06016",
    "openalex_id": "",
    "arxiv_id": "2410.06016",
    "published_date": "2024-10-08",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Sylber: Syllabic Embedding Representation of Speech from Raw Audio",
    "normalized_title": "sylber:syllabicembeddingrepresentationofspeechfromrawaudio",
    "doi": "10.48550/arxiv.2410.07168",
    "openalex_id": "",
    "arxiv_id": "2410.07168",
    "published_date": "2024-10-09",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Low Bitrate High-Quality RVQGAN-based Discrete Speech Tokenizer",
    "normalized_title": "lowbitratehigh-qualityrvqgan-baseddiscretespeechtokenizer",
    "doi": "10.21437/interspeech.2024-2366",
    "openalex_id": "",
    "arxiv_id": "2410.08325",
    "published_date": "2024-10-10",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "ERVQ: Enhanced Residual Vector Quantization with Intra-and-Inter-Codebook Optimization for Neural Audio Codecs",
    "normalized_title": "ervq:enhancedresidualvectorquantizationwithintra-and-inter-codebookoptimizationforneuralaudiocodecs",
    "doi": "10.48550/arxiv.2410.12359",
    "openalex_id": "",
    "arxiv_id": "2410.12359",
    "published_date": "2024-10-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "DM-Codec: Distilling Multimodal Representations for Speech Tokenization",
    "normalized_title": "dm-codec:distillingmultimodalrepresentationsforspeechtokenization",
    "doi": "10.48550/arxiv.2410.15017",
    "openalex_id": "",
    "arxiv_id": "2410.15017",
    "published_date": "2024-10-19",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "LSCodec: Low-Bitrate and Speaker-Decoupled Discrete Speech Codec",
    "normalized_title": "lscodec:low-bitrateandspeaker-decoupleddiscretespeechcodec",
    "doi": "10.48550/arxiv.2410.15764",
    "openalex_id": "",
    "arxiv_id": "2410.15764",
    "published_date": "2024-10-21",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "DC-Spin: A Speaker-invariant Speech Tokenizer for Spoken Language Models",
    "normalized_title": "dc-spin:aspeaker-invariantspeechtokenizerforspokenlanguagemodels",
    "doi": "10.48550/arxiv.2410.24177",
    "openalex_id": "",
    "arxiv_id": "2410.24177",
    "published_date": "2024-10-31",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "A Comparative Study of Discrete Speech Tokens for Semantic-Related Tasks with Large Language Models",
    "normalized_title": "acomparativestudyofdiscretespeechtokensforsemantic-relatedtaskswithlargelanguagemodels",
    "doi": "10.48550/arxiv.2411.08742",
    "openalex_id": "",
    "arxiv_id": "2411.08742",
    "published_date": "2024-11-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "BEST-STD: Bidirectional Mamba-Enhanced Speech Tokenization for Spoken Term Detection",
    "normalized_title": "best-std:bidirectionalmamba-enhancedspeechtokenizationforspokentermdetection",
    "doi": "10.48550/arxiv.2411.14100",
    "openalex_id": "",
    "arxiv_id": "2411.14100",
    "published_date": "2024-11-21",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "VQalAttent: a Transparent Speech Generation Pipeline based on Transformer-learned VQ-VAE Latent Space",
    "normalized_title": "vqalattent:atransparentspeechgenerationpipelinebasedontransformer-learnedvq-vaelatentspace",
    "doi": "10.48550/arxiv.2411.14642",
    "openalex_id": "",
    "arxiv_id": "2411.14642",
    "published_date": "2024-11-22",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Scaling Speech-Text Pre-training with Synthetic Interleaved Data",
    "normalized_title": "scalingspeech-textpre-trainingwithsyntheticinterleaveddata",
    "doi": "10.48550/arxiv.2411.17607",
    "openalex_id": "",
    "arxiv_id": "2411.17607",
    "published_date": "2024-11-26",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "GLM-4-Voice: Towards Intelligent and Human-Like End-to-End Spoken Chatbot",
    "normalized_title": "glm-4-voice:towardsintelligentandhuman-likeend-to-endspokenchatbot",
    "doi": "10.48550/arxiv.2412.02612",
    "openalex_id": "",
    "arxiv_id": "2412.02612",
    "published_date": "2024-12-03",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models",
    "normalized_title": "cosyvoice2:scalablestreamingspeechsynthesiswithlargelanguagemodels",
    "doi": "10.48550/arxiv.2412.10117",
    "openalex_id": "",
    "arxiv_id": "2412.10117",
    "published_date": "2024-12-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Whisper-GPT: A Hybrid Representation Audio Large Language Model",
    "normalized_title": "whisper-gpt:ahybridrepresentationaudiolargelanguagemodel",
    "doi": "10.48550/arxiv.2412.11449",
    "openalex_id": "",
    "arxiv_id": "2412.11449",
    "published_date": "2024-12-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SLAM-Omni: Timbre-Controllable Voice Interaction System with Single-Stage Training",
    "normalized_title": "slam-omni:timbre-controllablevoiceinteractionsystemwithsingle-stagetraining",
    "doi": "10.48550/arxiv.2412.15649",
    "openalex_id": "",
    "arxiv_id": "2412.15649",
    "published_date": "2024-12-20",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Causal Speech Enhancement with Predicting Semantics based on Quantized Self-supervised Learning Features",
    "normalized_title": "causalspeechenhancementwithpredictingsemanticsbasedonquantizedself-supervisedlearningfeatures",
    "doi": "10.48550/arxiv.2412.19248",
    "openalex_id": "",
    "arxiv_id": "2412.19248",
    "published_date": "2024-12-26",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SECodec: Structural Entropy-based Compressive Speech Representation Codec for Speech Language Models",
    "normalized_title": "secodec:structuralentropy-basedcompressivespeechrepresentationcodecforspeechlanguagemodels",
    "doi": "10.48550/arxiv.2501.00018",
    "openalex_id": "",
    "arxiv_id": "2501.00018",
    "published_date": "2024-12-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "MARS6: A Small and Robust Hierarchical-Codec Text-to-Speech Model",
    "normalized_title": "mars6:asmallandrobusthierarchical-codectext-to-speechmodel",
    "doi": "10.48550/arxiv.2501.05787",
    "openalex_id": "",
    "arxiv_id": "2501.05787",
    "published_date": "2025-01-10",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Optimized Self-supervised Training with BEST-RQ for Speech Recognition",
    "normalized_title": "optimizedself-supervisedtrainingwithbest-rqforspeechrecognition",
    "doi": "10.48550/arxiv.2501.16131",
    "openalex_id": "",
    "arxiv_id": "2501.16131",
    "published_date": "2025-01-27",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "GenSE: Generative Speech Enhancement via Language Models using Hierarchical Modeling",
    "normalized_title": "gense:generativespeechenhancementvialanguagemodelsusinghierarchicalmodeling",
    "doi": "10.48550/arxiv.2502.02942",
    "openalex_id": "",
    "arxiv_id": "2502.02942",
    "published_date": "2025-02-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Metis: A Foundation Speech Generation Model with Masked Generative Pre-training",
    "normalized_title": "metis:afoundationspeechgenerationmodelwithmaskedgenerativepre-training",
    "doi": "10.48550/arxiv.2502.03128",
    "openalex_id": "",
    "arxiv_id": "2502.03128",
    "published_date": "2025-02-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "IndexTTS: An Industrial-Level Controllable and Efficient Zero-Shot Text-To-Speech System",
    "normalized_title": "indextts:anindustrial-levelcontrollableandefficientzero-shottext-to-speechsystem",
    "doi": "10.48550/arxiv.2502.05512",
    "openalex_id": "",
    "arxiv_id": "2502.05512",
    "published_date": "2025-02-08",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Balancing Speech Understanding and Generation Using Continual Pre-training for Codec-based Speech LLM",
    "normalized_title": "balancingspeechunderstandingandgenerationusingcontinualpre-trainingforcodec-basedspeechllm",
    "doi": "10.48550/arxiv.2502.16897",
    "openalex_id": "",
    "arxiv_id": "2502.16897",
    "published_date": "2025-02-24",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Baichuan-Audio: A Unified Framework for End-to-End Speech Interaction",
    "normalized_title": "baichuan-audio:aunifiedframeworkforend-to-endspeechinteraction",
    "doi": "10.48550/arxiv.2502.17239",
    "openalex_id": "",
    "arxiv_id": "2502.17239",
    "published_date": "2025-02-24",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "LLaSE-G1: Incentivizing Generalization Capability for LLaMA-based Speech Enhancement",
    "normalized_title": "llase-g1:incentivizinggeneralizationcapabilityforllama-basedspeechenhancement",
    "doi": "10.48550/arxiv.2503.00493",
    "openalex_id": "",
    "arxiv_id": "2503.00493",
    "published_date": "2025-03-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Spark-TTS: An Efficient LLM-Based Text-to-Speech Model with Single-Stream Decoupled Speech Tokens",
    "normalized_title": "spark-tts:anefficientllm-basedtext-to-speechmodelwithsingle-streamdecoupledspeechtokens",
    "doi": "10.48550/arxiv.2503.01710",
    "openalex_id": "",
    "arxiv_id": "2503.01710",
    "published_date": "2025-03-03",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Universal Speech Token Learning via Low-Bitrate Neural Codec and Pretrained Representations",
    "normalized_title": "universalspeechtokenlearningvialow-bitrateneuralcodecandpretrainedrepresentations",
    "doi": "10.1109/jstsp.2024.3488557",
    "openalex_id": "",
    "arxiv_id": "2503.12115",
    "published_date": "2025-03-15",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Shushing! Let's Imagine an Authentic Speech from the Silent Video",
    "normalized_title": "shushing!let'simagineanauthenticspeechfromthesilentvideo",
    "doi": "10.48550/arxiv.2503.14928",
    "openalex_id": "",
    "arxiv_id": "2503.14928",
    "published_date": "2025-03-19",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "FireRedTTS-1S: An Upgraded Streamable Foundation Text-to-Speech System",
    "normalized_title": "fireredtts-1s:anupgradedstreamablefoundationtext-to-speechsystem",
    "doi": "10.48550/arxiv.2503.20499",
    "openalex_id": "",
    "arxiv_id": "2503.20499",
    "published_date": "2025-03-26",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Pseudo-Autoregressive Neural Codec Language Models for Efficient Zero-Shot Text-to-Speech Synthesis",
    "normalized_title": "pseudo-autoregressiveneuralcodeclanguagemodelsforefficientzero-shottext-to-speechsynthesis",
    "doi": "10.48550/arxiv.2504.10352",
    "openalex_id": "",
    "arxiv_id": "2504.10352",
    "published_date": "2025-04-14",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SimulS2S-LLM: Unlocking Simultaneous Inference of Speech LLMs for Speech-to-Speech Translation",
    "normalized_title": "simuls2s-llm:unlockingsimultaneousinferenceofspeechllmsforspeech-to-speechtranslation",
    "doi": "10.48550/arxiv.2504.15509",
    "openalex_id": "",
    "arxiv_id": "2504.15509",
    "published_date": "2025-04-22",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "DualCodec: A Low-Frame-Rate, Semantically-Enhanced Neural Audio Codec for Speech Generation",
    "normalized_title": "dualcodec:alow-frame-rate,semantically-enhancedneuralaudiocodecforspeechgeneration",
    "doi": "10.48550/arxiv.2505.13000",
    "openalex_id": "",
    "arxiv_id": "2505.13000",
    "published_date": "2025-05-19",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Improving Noise Robustness of LLM-based Zero-shot TTS via Discrete Acoustic Token Denoising",
    "normalized_title": "improvingnoiserobustnessofllm-basedzero-shotttsviadiscreteacoustictokendenoising",
    "doi": "10.48550/arxiv.2505.13830",
    "openalex_id": "",
    "arxiv_id": "2505.13830",
    "published_date": "2025-05-20",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "PAST: Phonetic-Acoustic Speech Tokenizer",
    "normalized_title": "past:phonetic-acousticspeechtokenizer",
    "doi": "10.48550/arxiv.2505.14470",
    "openalex_id": "",
    "arxiv_id": "2505.14470",
    "published_date": "2025-05-20",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Discrete Audio Representations for Automated Audio Captioning",
    "normalized_title": "discreteaudiorepresentationsforautomatedaudiocaptioning",
    "doi": "10.48550/arxiv.2505.14989",
    "openalex_id": "",
    "arxiv_id": "2505.14989",
    "published_date": "2025-05-21",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "EZ-VC: Easy Zero-shot Any-to-Any Voice Conversion",
    "normalized_title": "ez-vc:easyzero-shotany-to-anyvoiceconversion",
    "doi": "10.48550/arxiv.2505.16691",
    "openalex_id": "",
    "arxiv_id": "2505.16691",
    "published_date": "2025-05-22",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Impact of Frame Rates on Speech Tokenizer: A Case Study on Mandarin and English",
    "normalized_title": "impactofframeratesonspeechtokenizer:acasestudyonmandarinandenglish",
    "doi": "10.48550/arxiv.2505.17076",
    "openalex_id": "",
    "arxiv_id": "2505.17076",
    "published_date": "2025-05-20",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Exploring the Effect of Segmentation and Vocabulary Size on Speech Tokenization for Speech Language Models",
    "normalized_title": "exploringtheeffectofsegmentationandvocabularysizeonspeechtokenizationforspeechlanguagemodels",
    "doi": "10.48550/arxiv.2505.17446",
    "openalex_id": "",
    "arxiv_id": "2505.17446",
    "published_date": "2025-05-23",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "VoiceStar: Robust Zero-Shot Autoregressive TTS with Duration Control and Extrapolation",
    "normalized_title": "voicestar:robustzero-shotautoregressivettswithdurationcontrolandextrapolation",
    "doi": "10.48550/arxiv.2505.19462",
    "openalex_id": "",
    "arxiv_id": "2505.19462",
    "published_date": "2025-05-26",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Speech Token Prediction via Compressed-to-fine Language Modeling for Speech Generation",
    "normalized_title": "speechtokenpredictionviacompressed-to-finelanguagemodelingforspeechgeneration",
    "doi": "10.48550/arxiv.2505.24496",
    "openalex_id": "",
    "arxiv_id": "2505.24496",
    "published_date": "2025-05-30",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "FUSE: Universal Speech Enhancement using Multi-Stage Fusion of Sparse Compression and Token Generation Models for the URGENT 2025 Challenge",
    "normalized_title": "fuse:universalspeechenhancementusingmulti-stagefusionofsparsecompressionandtokengenerationmodelsfortheurgent2025challenge",
    "doi": "10.48550/arxiv.2506.00809",
    "openalex_id": "",
    "arxiv_id": "2506.00809",
    "published_date": "2025-06-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "HASRD: Hierarchical Acoustic and Semantic Representation Disentanglement",
    "normalized_title": "hasrd:hierarchicalacousticandsemanticrepresentationdisentanglement",
    "doi": "10.48550/arxiv.2506.00843",
    "openalex_id": "",
    "arxiv_id": "2506.00843",
    "published_date": "2025-06-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Pa-HuBERT: Self-Supervised Music Source Separation Via Primitive Auditory Clustering And Hidden-Unit Bert",
    "normalized_title": "pa-hubert:self-supervisedmusicsourceseparationviaprimitiveauditoryclusteringandhidden-unitbert",
    "doi": "10.1109/icasspw59220.2023.10193575",
    "openalex_id": "https://openalex.org/w4385478423",
    "arxiv_id": "",
    "published_date": "2023-06-04",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Towards Practical and Efficient Image-to-Speech Captioning with Vision-Language Pre-Training and Multi-Modal Tokens",
    "normalized_title": "towardspracticalandefficientimage-to-speechcaptioningwithvision-languagepre-trainingandmulti-modaltokens",
    "doi": "10.1109/icassp48485.2024.10446888",
    "openalex_id": "https://openalex.org/w4392904292",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "FunCodec: A Fundamental, Reproducible and Integrable Open-Source Toolkit for Neural Speech Codec",
    "normalized_title": "funcodec:afundamental,reproducibleandintegrableopen-sourcetoolkitforneuralspeechcodec",
    "doi": "10.1109/icassp48485.2024.10447523",
    "openalex_id": "https://openalex.org/w4392903389",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "ZMM-TTS: Zero-Shot Multilingual and Multispeaker Speech Synthesis Conditioned on Self-Supervised Discrete Speech Representations",
    "normalized_title": "zmm-tts:zero-shotmultilingualandmultispeakerspeechsynthesisconditionedonself-superviseddiscretespeechrepresentations",
    "doi": "10.1109/taslp.2024.3451951",
    "openalex_id": "https://openalex.org/w4402301063",
    "arxiv_id": "",
    "published_date": "2024-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "VoxtLM: Unified Decoder-Only Models for Consolidating Speech Recognition, Synthesis and Speech, Text Continuation Tasks",
    "normalized_title": "voxtlm:unifieddecoder-onlymodelsforconsolidatingspeechrecognition,synthesisandspeech,textcontinuationtasks",
    "doi": "10.1109/icassp48485.2024.10447112",
    "openalex_id": "https://openalex.org/w4392904805",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study",
    "normalized_title": "exploringspeechrecognition,translation,andunderstandingwithdiscretespeechunits:acomparativestudy",
    "doi": "10.1109/icassp48485.2024.10447929",
    "openalex_id": "https://openalex.org/w4392909068",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Speaker Adaptive Text-to-Speech With Timbre-Normalized Vector-Quantized Feature",
    "normalized_title": "speakeradaptivetext-to-speechwithtimbre-normalizedvector-quantizedfeature",
    "doi": "10.1109/taslp.2023.3308374",
    "openalex_id": "https://openalex.org/w4386133927",
    "arxiv_id": "",
    "published_date": "2023-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Fewer-Token Neural Speech Codec with Time-Invariant Codes",
    "normalized_title": "fewer-tokenneuralspeechcodecwithtime-invariantcodes",
    "doi": "10.1109/icassp48485.2024.10448454",
    "openalex_id": "https://openalex.org/w4392903006",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "TextrolSpeech: A Text Style Control Speech Corpus with Codec Language Text-to-Speech Models",
    "normalized_title": "textrolspeech:atextstylecontrolspeechcorpuswithcodeclanguagetext-to-speechmodels",
    "doi": "10.1109/icassp48485.2024.10445879",
    "openalex_id": "https://openalex.org/w4392904245",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Discrete Audio Representation as an Alternative to Mel-Spectrograms for Speaker and Speech Recognition",
    "normalized_title": "discreteaudiorepresentationasanalternativetomel-spectrogramsforspeakerandspeechrecognition",
    "doi": "10.1109/icassp48485.2024.10446998",
    "openalex_id": "https://openalex.org/w4392904154",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Yet Another Generative Model for Room Impulse Response Estimation",
    "normalized_title": "yetanothergenerativemodelforroomimpulseresponseestimation",
    "doi": "10.1109/waspaa58266.2023.10248189",
    "openalex_id": "https://openalex.org/w4386764631",
    "arxiv_id": "",
    "published_date": "2023-09-15",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Toward Joint Language Modeling for Speech Units and Text",
    "normalized_title": "towardjointlanguagemodelingforspeechunitsandtext",
    "doi": "10.18653/v1/2023.findings-emnlp.438",
    "openalex_id": "https://openalex.org/w4389518827",
    "arxiv_id": "",
    "published_date": "2023-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Generative De-Quantization for Neural Speech Codec Via Latent Diffusion",
    "normalized_title": "generativede-quantizationforneuralspeechcodecvialatentdiffusion",
    "doi": "10.1109/icassp48485.2024.10446556",
    "openalex_id": "https://openalex.org/w4392931975",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Stack-and-Delay: A New Codebook Pattern for Music Generation",
    "normalized_title": "stack-and-delay:anewcodebookpatternformusicgeneration",
    "doi": "10.1109/icassp48485.2024.10447392",
    "openalex_id": "https://openalex.org/w4392909680",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Generation-Based Target Speech Extraction with Speech Discretization and Vocoder",
    "normalized_title": "generation-basedtargetspeechextractionwithspeechdiscretizationandvocoder",
    "doi": "10.1109/icassp48485.2024.10446418",
    "openalex_id": "https://openalex.org/w4392903977",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "VQVAE Unsupervised Unit Discovery and Multi-Scale Code2Spec Inverter for Zerospeech Challenge 2019",
    "normalized_title": "vqvaeunsupervisedunitdiscoveryandmulti-scalecode2specinverterforzerospeechchallenge2019",
    "doi": "10.21437/interspeech.2019-3232",
    "openalex_id": "https://openalex.org/w2972374322",
    "arxiv_id": "",
    "published_date": "2019-09-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Speech Resynthesis from Discrete Disentangled Self-Supervised Representations",
    "normalized_title": "speechresynthesisfromdiscretedisentangledself-supervisedrepresentations",
    "doi": "10.21437/interspeech.2021-475",
    "openalex_id": "https://openalex.org/w3140429000",
    "arxiv_id": "",
    "published_date": "2021-08-27",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Any-to-One Sequence-to-Sequence Voice Conversion Using Self-Supervised Discrete Speech Representations",
    "normalized_title": "any-to-onesequence-to-sequencevoiceconversionusingself-superviseddiscretespeechrepresentations",
    "doi": "10.1109/icassp39728.2021.9415079",
    "openalex_id": "https://openalex.org/w3161695192",
    "arxiv_id": "",
    "published_date": "2021-05-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "One-Shot Voice Conversion by Vector Quantization",
    "normalized_title": "one-shotvoiceconversionbyvectorquantization",
    "doi": "10.1109/icassp40776.2020.9053854",
    "openalex_id": "https://openalex.org/w3015434413",
    "arxiv_id": "",
    "published_date": "2020-04-09",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "The Academia Sinica Systems of Voice Conversion for VCC2020",
    "normalized_title": "theacademiasinicasystemsofvoiceconversionforvcc2020",
    "doi": "10.21437/vccbc.2020-28",
    "openalex_id": "https://openalex.org/w3091890228",
    "arxiv_id": "",
    "published_date": "2020-10-30",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Hubert: How Much Can a Bad Teacher Benefit ASR Pre-Training?",
    "normalized_title": "hubert:howmuchcanabadteacherbenefitasrpre-training?",
    "doi": "10.1109/icassp39728.2021.9414460",
    "openalex_id": "https://openalex.org/w3160799772",
    "arxiv_id": "",
    "published_date": "2021-05-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Direct Speech-to-Speech Translation With Discrete Units",
    "normalized_title": "directspeech-to-speechtranslationwithdiscreteunits",
    "doi": "10.18653/v1/2022.acl-long.235",
    "openalex_id": "https://openalex.org/w3180374548",
    "arxiv_id": "",
    "published_date": "2022-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units",
    "normalized_title": "hubert:self-supervisedspeechrepresentationlearningbymaskedpredictionofhiddenunits",
    "doi": "10.1109/taslp.2021.3122291",
    "openalex_id": "https://openalex.org/w3169320628",
    "arxiv_id": "",
    "published_date": "2021-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "HuBERT: Self-Supervised Speech Representation Learning by Masked\\n Prediction of Hidden Units",
    "normalized_title": "hubert:self-supervisedspeechrepresentationlearningbymasked\\npredictionofhiddenunits",
    "doi": "10.48550/arxiv.2106.07447",
    "openalex_id": "https://openalex.org/w4287119707",
    "arxiv_id": "",
    "published_date": "2021-06-14",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "VQTTS: High-Fidelity Text-to-Speech Synthesis with Self-Supervised VQ Acoustic Feature",
    "normalized_title": "vqtts:high-fidelitytext-to-speechsynthesiswithself-supervisedvqacousticfeature",
    "doi": "10.21437/interspeech.2022-489",
    "openalex_id": "https://openalex.org/w4226132755",
    "arxiv_id": "",
    "published_date": "2022-09-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations",
    "normalized_title": "vq-wav2vec:self-supervisedlearningofdiscretespeechrepresentations",
    "doi": "10.48550/arxiv.1910.05453",
    "openalex_id": "https://openalex.org/w2979476256",
    "arxiv_id": "",
    "published_date": "2019-10-12",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations",
    "normalized_title": "wav2vec2.0:aframeworkforself-supervisedlearningofspeechrepresentations",
    "doi": "10.48550/arxiv.2006.11477",
    "openalex_id": "https://openalex.org/w3036601975",
    "arxiv_id": "",
    "published_date": "2020-06-20",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "AudioLM: A Language Modeling Approach to Audio Generation",
    "normalized_title": "audiolm:alanguagemodelingapproachtoaudiogeneration",
    "doi": "10.1109/taslp.2023.3288409",
    "openalex_id": "https://openalex.org/w4381786045",
    "arxiv_id": "",
    "published_date": "2023-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers",
    "normalized_title": "naturalspeech2:latentdiffusionmodelsarenaturalandzero-shotspeechandsingingsynthesizers",
    "doi": "10.48550/arxiv.2304.09116",
    "openalex_id": "https://openalex.org/w4366460484",
    "arxiv_id": "",
    "published_date": "2023-04-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "w2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training",
    "normalized_title": "w2v-bert:combiningcontrastivelearningandmaskedlanguagemodelingforself-supervisedspeechpre-training",
    "doi": "10.1109/asru51503.2021.9688253",
    "openalex_id": "https://openalex.org/w4226033575",
    "arxiv_id": "",
    "published_date": "2021-12-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Phonetic Analysis of Self-supervised Representations of English Speech",
    "normalized_title": "phoneticanalysisofself-supervisedrepresentationsofenglishspeech",
    "doi": "10.21437/interspeech.2022-10884",
    "openalex_id": "https://openalex.org/w4297841405",
    "arxiv_id": "",
    "published_date": "2022-09-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "A Vector Quantized Masked Autoencoder for Speech Emotion Recognition",
    "normalized_title": "avectorquantizedmaskedautoencoderforspeechemotionrecognition",
    "doi": "10.1109/icasspw59220.2023.10193151",
    "openalex_id": "https://openalex.org/w4385484923",
    "arxiv_id": "",
    "published_date": "2023-06-04",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Disentangled Feature Learning for Real-Time Neural Speech Coding",
    "normalized_title": "disentangledfeaturelearningforreal-timeneuralspeechcoding",
    "doi": "10.1109/icassp49357.2023.10094723",
    "openalex_id": "https://openalex.org/w4372259964",
    "arxiv_id": "",
    "published_date": "2023-05-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "UnitY: Two-pass Direct Speech-to-speech Translation with Discrete Units",
    "normalized_title": "unity:two-passdirectspeech-to-speechtranslationwithdiscreteunits",
    "doi": "10.18653/v1/2023.acl-long.872",
    "openalex_id": "https://openalex.org/w4385570550",
    "arxiv_id": "",
    "published_date": "2023-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Low Bit-rate Speech Coding with VQ-VAE and a WaveNet Decoder",
    "normalized_title": "lowbit-ratespeechcodingwithvq-vaeandawavenetdecoder",
    "doi": "10.1109/icassp.2019.8683277",
    "openalex_id": "https://openalex.org/w2935711438",
    "arxiv_id": "",
    "published_date": "2019-04-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "SpeechPrompt: Prompting Speech Language Models for Speech Processing Tasks",
    "normalized_title": "speechprompt:promptingspeechlanguagemodelsforspeechprocessingtasks",
    "doi": "10.1109/taslp.2024.3436618",
    "openalex_id": "https://openalex.org/w4401246677",
    "arxiv_id": "",
    "published_date": "2024-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Direct Punjabi to English Speech Translation using Discrete Units",
    "normalized_title": "directpunjabitoenglishspeechtranslationusingdiscreteunits",
    "doi": "10.5121/ijci.2024.130201",
    "openalex_id": "https://openalex.org/w4392884616",
    "arxiv_id": "",
    "published_date": "2024-03-10",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "The Zero Resource Speech Challenge 2019: TTS Without T",
    "normalized_title": "thezeroresourcespeechchallenge2019:ttswithoutt",
    "doi": "10.21437/interspeech.2019-2904",
    "openalex_id": "https://openalex.org/w2940544976",
    "arxiv_id": "",
    "published_date": "2019-09-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Speech-to-Speech Translation Between Untranscribed Unknown Languages",
    "normalized_title": "speech-to-speechtranslationbetweenuntranscribedunknownlanguages",
    "doi": "10.1109/asru46091.2019.9003853",
    "openalex_id": "https://openalex.org/w3007068036",
    "arxiv_id": "",
    "published_date": "2019-12-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "UWSpeech: Speech to Speech Translation for Unwritten Languages",
    "normalized_title": "uwspeech:speechtospeechtranslationforunwrittenlanguages",
    "doi": "10.1609/aaai.v35i16.17684",
    "openalex_id": "https://openalex.org/w3175871055",
    "arxiv_id": "",
    "published_date": "2021-05-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Robust Training of Vector Quantized Bottleneck Models",
    "normalized_title": "robusttrainingofvectorquantizedbottleneckmodels",
    "doi": "10.1109/ijcnn48605.2020.9207145",
    "openalex_id": "https://openalex.org/w3089425003",
    "arxiv_id": "",
    "published_date": "2020-07-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Transformer VQ-VAE for Unsupervised Unit Discovery and Speech Synthesis: ZeroSpeech 2020 Challenge",
    "normalized_title": "transformervq-vaeforunsupervisedunitdiscoveryandspeechsynthesis:zerospeech2020challenge",
    "doi": "10.21437/interspeech.2020-3033",
    "openalex_id": "https://openalex.org/w3096216486",
    "arxiv_id": "",
    "published_date": "2020-10-25",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Vector-Quantized Neural Networks for Acoustic Unit Discovery in the ZeroSpeech 2020 Challenge",
    "normalized_title": "vector-quantizedneuralnetworksforacousticunitdiscoveryinthezerospeech2020challenge",
    "doi": "10.21437/interspeech.2020-1693",
    "openalex_id": "https://openalex.org/w3027324582",
    "arxiv_id": "",
    "published_date": "2020-10-25",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "End-to-End Image-to-Speech Generation for Untranscribed Unknown Languages",
    "normalized_title": "end-to-endimage-to-speechgenerationforuntranscribedunknownlanguages",
    "doi": "10.1109/access.2021.3071541",
    "openalex_id": "https://openalex.org/w3155217823",
    "arxiv_id": "",
    "published_date": "2021-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Discrete representations in neural models of spoken language",
    "normalized_title": "discreterepresentationsinneuralmodelsofspokenlanguage",
    "doi": "10.18653/v1/2021.blackboxnlp-1.11",
    "openalex_id": "https://openalex.org/w3161348170",
    "arxiv_id": "",
    "published_date": "2021-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Generative Spoken Language Modeling from Raw Audio",
    "normalized_title": "generativespokenlanguagemodelingfromrawaudio",
    "doi": "10.48550/arxiv.2102.01192",
    "openalex_id": "https://openalex.org/w3129009457",
    "arxiv_id": "",
    "published_date": "2021-02-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Exploration of End-to-end Synthesisers forZero Resource Speech Challenge 2020",
    "normalized_title": "explorationofend-to-endsynthesisersforzeroresourcespeechchallenge2020",
    "doi": "10.48550/arxiv.2009.04983",
    "openalex_id": "https://openalex.org/w3084014658",
    "arxiv_id": "",
    "published_date": "2020-09-10",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Preliminary study on using vector quantization latent spaces for TTS/VC systems with consistent performance",
    "normalized_title": "preliminarystudyonusingvectorquantizationlatentspacesfortts/vcsystemswithconsistentperformance",
    "doi": "10.21437/ssw.2021-24",
    "openalex_id": "https://openalex.org/w3194622036",
    "arxiv_id": "",
    "published_date": "2021-08-24",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "A Comparison of Discrete and Soft Speech Units for Improved Voice Conversion",
    "normalized_title": "acomparisonofdiscreteandsoftspeechunitsforimprovedvoiceconversion",
    "doi": "10.1109/icassp43922.2022.9746484",
    "openalex_id": "https://openalex.org/w3210530853",
    "arxiv_id": "",
    "published_date": "2022-04-27",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "LMCodec: A Low Bitrate Speech Codec with Causal Transformer Models",
    "normalized_title": "lmcodec:alowbitratespeechcodecwithcausaltransformermodels",
    "doi": "10.1109/icassp49357.2023.10095442",
    "openalex_id": "https://openalex.org/w4375869380",
    "arxiv_id": "",
    "published_date": "2023-05-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Srcodec: Split-Residual Vector Quantization for Neural Speech Codec",
    "normalized_title": "srcodec:split-residualvectorquantizationforneuralspeechcodec",
    "doi": "10.1109/icassp48485.2024.10445966",
    "openalex_id": "https://openalex.org/w4392903887",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Back Translation for Speech-to-text Translation Without Transcripts",
    "normalized_title": "backtranslationforspeech-to-texttranslationwithouttranscripts",
    "doi": "10.18653/v1/2023.acl-long.251",
    "openalex_id": "https://openalex.org/w4385569716",
    "arxiv_id": "",
    "published_date": "2023-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Speaking Style Conversion in the Waveform Domain Using Discrete Self-Supervised Units",
    "normalized_title": "speakingstyleconversioninthewaveformdomainusingdiscreteself-supervisedunits",
    "doi": "10.18653/v1/2023.findings-emnlp.541",
    "openalex_id": "https://openalex.org/w4389524060",
    "arxiv_id": "",
    "published_date": "2023-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "SoundStream: An End-to-End Neural Audio Codec",
    "normalized_title": "soundstream:anend-to-endneuralaudiocodec",
    "doi": "10.1109/taslp.2021.3129994",
    "openalex_id": "https://openalex.org/w3178321840",
    "arxiv_id": "",
    "published_date": "2021-11-23",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Multi-Task Self-Supervised Learning Based Tibetan-Chinese Speech-to-Speech Translation",
    "normalized_title": "multi-taskself-supervisedlearningbasedtibetan-chinesespeech-to-speechtranslation",
    "doi": "10.1109/ialp61005.2023.10337040",
    "openalex_id": "https://openalex.org/w4389611346",
    "arxiv_id": "",
    "published_date": "2023-11-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "DiffS2UT: A Semantic Preserving Diffusion Model for Textless Direct Speech-to-Speech Translation",
    "normalized_title": "diffs2ut:asemanticpreservingdiffusionmodelfortextlessdirectspeech-to-speechtranslation",
    "doi": "10.18653/v1/2023.emnlp-main.709",
    "openalex_id": "https://openalex.org/w4389519423",
    "arxiv_id": "",
    "published_date": "2023-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "KaraSinger: Score-Free Singing Voice Synthesis with VQ-VAE Using Mel-Spectrograms",
    "normalized_title": "karasinger:score-freesingingvoicesynthesiswithvq-vaeusingmel-spectrograms",
    "doi": "10.1109/icassp43922.2022.9747441",
    "openalex_id": "https://openalex.org/w3206801991",
    "arxiv_id": "",
    "published_date": "2022-04-27",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Bootstrapping meaning through listening: Unsupervised learning of spoken sentence embeddings",
    "normalized_title": "bootstrappingmeaningthroughlistening:unsupervisedlearningofspokensentenceembeddings",
    "doi": "10.18653/v1/2022.findings-emnlp.81",
    "openalex_id": "https://openalex.org/w4385573456",
    "arxiv_id": "",
    "published_date": "2022-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Textless Speech Emotion Conversion using Decomposed and Discrete Representations",
    "normalized_title": "textlessspeechemotionconversionusingdecomposedanddiscreterepresentations",
    "doi": "",
    "openalex_id": "https://openalex.org/w3213873715",
    "arxiv_id": "",
    "published_date": "2021-11-14",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Direct speech-reply generation from text-dialogue context",
    "normalized_title": "directspeech-replygenerationfromtext-dialoguecontext",
    "doi": "10.23919/apsipaasc55919.2022.9979940",
    "openalex_id": "https://openalex.org/w4312097514",
    "arxiv_id": "",
    "published_date": "2022-11-07",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Semi-supervised ASR based on Iterative Joint Training with Discrete Speech Synthesis",
    "normalized_title": "semi-supervisedasrbasedoniterativejointtrainingwithdiscretespeechsynthesis",
    "doi": "10.23919/apsipaasc55919.2022.9980335",
    "openalex_id": "https://openalex.org/w4312097445",
    "arxiv_id": "",
    "published_date": "2022-11-07",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "VQVC+: One-Shot Voice Conversion by Vector Quantization and U-Net Architecture",
    "normalized_title": "vqvc+:one-shotvoiceconversionbyvectorquantizationandu-netarchitecture",
    "doi": "10.21437/interspeech.2020-1443",
    "openalex_id": "https://openalex.org/w3096524539",
    "arxiv_id": "",
    "published_date": "2020-10-25",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "VQ-CL: Learning Disentangled Speech Representations with Contrastive Learning and Vector Quantization",
    "normalized_title": "vq-cl:learningdisentangledspeechrepresentationswithcontrastivelearningandvectorquantization",
    "doi": "10.1109/icassp49357.2023.10095654",
    "openalex_id": "https://openalex.org/w4375868810",
    "arxiv_id": "",
    "published_date": "2023-05-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Exploring Disentanglement with Multilingual and Monolingual VQ-VAE",
    "normalized_title": "exploringdisentanglementwithmultilingualandmonolingualvq-vae",
    "doi": "10.48550/arxiv.2105.01573",
    "openalex_id": "https://openalex.org/w3159257553",
    "arxiv_id": "",
    "published_date": "2021-05-04",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Wav2Seq: Pre-Training Speech-to-Text Encoder-Decoder Models Using Pseudo Languages",
    "normalized_title": "wav2seq:pre-trainingspeech-to-textencoder-decodermodelsusingpseudolanguages",
    "doi": "10.1109/icassp49357.2023.10096988",
    "openalex_id": "https://openalex.org/w4372270126",
    "arxiv_id": "",
    "published_date": "2023-05-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Supervision-Guided Codebooks for Masked Prediction in Speech Pre-training",
    "normalized_title": "supervision-guidedcodebooksformaskedpredictioninspeechpre-training",
    "doi": "10.21437/interspeech.2022-936",
    "openalex_id": "https://openalex.org/w4283324001",
    "arxiv_id": "",
    "published_date": "2022-09-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "An Exploration of Hubert with Large Number of Cluster Units and Model Assessment Using Bayesian Information Criterion",
    "normalized_title": "anexplorationofhubertwithlargenumberofclusterunitsandmodelassessmentusingbayesianinformationcriterion",
    "doi": "10.1109/icassp43922.2022.9746097",
    "openalex_id": "https://openalex.org/w4224927737",
    "arxiv_id": "",
    "published_date": "2022-04-27",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Fully Unsupervised Topic Clustering of Unlabelled Spoken Audio Using Self-Supervised Representation Learning and Topic Model",
    "normalized_title": "fullyunsupervisedtopicclusteringofunlabelledspokenaudiousingself-supervisedrepresentationlearningandtopicmodel",
    "doi": "10.1109/icassp49357.2023.10095280",
    "openalex_id": "https://openalex.org/w4375869237",
    "arxiv_id": "",
    "published_date": "2023-05-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Unsupervised Data Selection via Discrete Speech Representation for ASR",
    "normalized_title": "unsuperviseddataselectionviadiscretespeechrepresentationforasr",
    "doi": "10.21437/interspeech.2022-399",
    "openalex_id": "https://openalex.org/w4297841894",
    "arxiv_id": "",
    "published_date": "2022-09-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "On the Nature of Discrete Speech Representations in Multilingual Self-supervised Models",
    "normalized_title": "onthenatureofdiscretespeechrepresentationsinmultilingualself-supervisedmodels",
    "doi": "10.18653/v1/2023.sigtyp-1.20",
    "openalex_id": "https://openalex.org/w4386566373",
    "arxiv_id": "",
    "published_date": "2023-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Towards Universal Speech Discrete Tokens: A Case Study for ASR and TTS",
    "normalized_title": "towardsuniversalspeechdiscretetokens:acasestudyforasrandtts",
    "doi": "10.1109/icassp48485.2024.10447751",
    "openalex_id": "https://openalex.org/w4392909760",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Multi-Speaker Multi-Lingual VQTTS System for LIMMITS 2023 Challenge",
    "normalized_title": "multi-speakermulti-lingualvqttssystemforlimmits2023challenge",
    "doi": "10.1109/icassp49357.2023.10096415",
    "openalex_id": "https://openalex.org/w4372260125",
    "arxiv_id": "",
    "published_date": "2023-05-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Effectiveness of Self-Supervised Pre-Training for ASR",
    "normalized_title": "effectivenessofself-supervisedpre-trainingforasr",
    "doi": "10.1109/icassp40776.2020.9054224",
    "openalex_id": "https://openalex.org/w3015356564",
    "arxiv_id": "",
    "published_date": "2020-04-09",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Data Augmentation for ASR Using TTS Via a Discrete Representation",
    "normalized_title": "dataaugmentationforasrusingttsviaadiscreterepresentation",
    "doi": "10.1109/asru51503.2021.9688218",
    "openalex_id": "https://openalex.org/w4210327373",
    "arxiv_id": "",
    "published_date": "2021-12-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Text-Free Image-to-Speech Synthesis Using Learned Segmental Units",
    "normalized_title": "text-freeimage-to-speechsynthesisusinglearnedsegmentalunits",
    "doi": "10.18653/v1/2021.acl-long.411",
    "openalex_id": "https://openalex.org/w3114436296",
    "arxiv_id": "",
    "published_date": "2021-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "VCVTS: Multi-Speaker Video-to-Speech Synthesis Via Cross-Modal Knowledge Transfer from Voice Conversion",
    "normalized_title": "vcvts:multi-speakervideo-to-speechsynthesisviacross-modalknowledgetransferfromvoiceconversion",
    "doi": "10.1109/icassp43922.2022.9747427",
    "openalex_id": "https://openalex.org/w4224926225",
    "arxiv_id": "",
    "published_date": "2022-04-27",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Cross-Scale Vector Quantization for Scalable Neural Speech Coding",
    "normalized_title": "cross-scalevectorquantizationforscalableneuralspeechcoding",
    "doi": "10.21437/interspeech.2022-10084",
    "openalex_id": "https://openalex.org/w4284957875",
    "arxiv_id": "",
    "published_date": "2022-09-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "A Comparison of Discrete Latent Variable Models for Speech Representation Learning",
    "normalized_title": "acomparisonofdiscretelatentvariablemodelsforspeechrepresentationlearning",
    "doi": "10.1109/icassp39728.2021.9413680",
    "openalex_id": "https://openalex.org/w3161411634",
    "arxiv_id": "",
    "published_date": "2021-05-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Predicting Multi-Codebook Vector Quantization Indexes for Knowledge Distillation",
    "normalized_title": "predictingmulti-codebookvectorquantizationindexesforknowledgedistillation",
    "doi": "10.1109/icassp49357.2023.10095268",
    "openalex_id": "https://openalex.org/w4375869398",
    "arxiv_id": "",
    "published_date": "2023-05-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Applying the Information Bottleneck Principle to Prosodic Representation Learning",
    "normalized_title": "applyingtheinformationbottleneckprincipletoprosodicrepresentationlearning",
    "doi": "10.21437/interspeech.2021-1049",
    "openalex_id": "https://openalex.org/w3197304925",
    "arxiv_id": "",
    "published_date": "2021-08-27",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Self Supervised Representation Learning with Deep Clustering for Acoustic Unit Discovery from Raw Speech",
    "normalized_title": "selfsupervisedrepresentationlearningwithdeepclusteringforacousticunitdiscoveryfromrawspeech",
    "doi": "10.1109/icassp43922.2022.9747259",
    "openalex_id": "https://openalex.org/w4224918488",
    "arxiv_id": "",
    "published_date": "2022-04-27",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Self-supervised Semantic-driven Phoneme Discovery for Zero-resource Speech Recognition",
    "normalized_title": "self-supervisedsemantic-drivenphonemediscoveryforzero-resourcespeechrecognition",
    "doi": "10.18653/v1/2022.acl-long.553",
    "openalex_id": "https://openalex.org/w4285258797",
    "arxiv_id": "",
    "published_date": "2022-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Improving Unsupervised Sparsespeech Acoustic Models with Categorical Reparameterization",
    "normalized_title": "improvingunsupervisedsparsespeechacousticmodelswithcategoricalreparameterization",
    "doi": "10.21437/interspeech.2020-2629",
    "openalex_id": "https://openalex.org/w3031277321",
    "arxiv_id": "",
    "published_date": "2020-10-25",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "DiscreTalk: Text-to-Speech as a Machine Translation Problem",
    "normalized_title": "discretalk:text-to-speechasamachinetranslationproblem",
    "doi": "10.48550/arxiv.2005.05525",
    "openalex_id": "https://openalex.org/w3024605872",
    "arxiv_id": "",
    "published_date": "2020-05-12",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "The Zero Resource Speech Challenge 2020: Discovering discrete subword and word units",
    "normalized_title": "thezeroresourcespeechchallenge2020:discoveringdiscretesubwordandwordunits",
    "doi": "10.48550/arxiv.2010.05967",
    "openalex_id": "https://openalex.org/w3093427098",
    "arxiv_id": "",
    "published_date": "2020-10-12",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Vector Quantized Contrastive Predictive Coding for Template-based Music Generation",
    "normalized_title": "vectorquantizedcontrastivepredictivecodingfortemplate-basedmusicgeneration",
    "doi": "10.48550/arxiv.2004.10120",
    "openalex_id": "https://openalex.org/w3018535504",
    "arxiv_id": "",
    "published_date": "2020-04-21",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Pseudo-Label Based Supervised Contrastive Loss for Robust Speech Representations",
    "normalized_title": "pseudo-labelbasedsupervisedcontrastivelossforrobustspeechrepresentations",
    "doi": "10.1109/asru57964.2023.10389725",
    "openalex_id": "https://openalex.org/w4391021561",
    "arxiv_id": "",
    "published_date": "2023-12-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Textless Direct Speech-to-Speech Translation with Discrete Speech Representation",
    "normalized_title": "textlessdirectspeech-to-speechtranslationwithdiscretespeechrepresentation",
    "doi": "10.1109/icassp49357.2023.10096797",
    "openalex_id": "https://openalex.org/w4372349107",
    "arxiv_id": "",
    "published_date": "2023-05-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Disentangling Prosody Representations With Unsupervised Speech Reconstruction",
    "normalized_title": "disentanglingprosodyrepresentationswithunsupervisedspeechreconstruction",
    "doi": "10.1109/taslp.2023.3320864",
    "openalex_id": "https://openalex.org/w4387247604",
    "arxiv_id": "",
    "published_date": "2023-10-02",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "CCC-WAV2VEC 2.0: Clustering AIDED Cross Contrastive Self-Supervised Learning of Speech Representations",
    "normalized_title": "ccc-wav2vec2.0:clusteringaidedcrosscontrastiveself-supervisedlearningofspeechrepresentations",
    "doi": "10.1109/slt54892.2023.10022552",
    "openalex_id": "https://openalex.org/w4319862416",
    "arxiv_id": "",
    "published_date": "2023-01-09",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "A Unified One-Shot Prosody and Speaker Conversion System with Self-Supervised Discrete Speech Units",
    "normalized_title": "aunifiedone-shotprosodyandspeakerconversionsystemwithself-superviseddiscretespeechunits",
    "doi": "10.1109/icassp49357.2023.10095565",
    "openalex_id": "https://openalex.org/w4372266960",
    "arxiv_id": "",
    "published_date": "2023-05-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "An ASR-Free Fluency Scoring Approach with Self-Supervised Learning",
    "normalized_title": "anasr-freefluencyscoringapproachwithself-supervisedlearning",
    "doi": "10.1109/icassp49357.2023.10095311",
    "openalex_id": "https://openalex.org/w4372259940",
    "arxiv_id": "",
    "published_date": "2023-05-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "CTCBERT: Advancing Hidden-Unit Bert with CTC Objectives",
    "normalized_title": "ctcbert:advancinghidden-unitbertwithctcobjectives",
    "doi": "10.1109/icassp49357.2023.10094922",
    "openalex_id": "https://openalex.org/w4375869113",
    "arxiv_id": "",
    "published_date": "2023-05-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "The Zero Resource Speech Challenge 2021: Spoken Language Modelling",
    "normalized_title": "thezeroresourcespeechchallenge2021:spokenlanguagemodelling",
    "doi": "10.21437/interspeech.2021-1755",
    "openalex_id": "https://openalex.org/w3187244867",
    "arxiv_id": "",
    "published_date": "2021-08-27",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "DeCoAR 2.0: Deep Contextualized Acoustic Representations with Vector Quantization",
    "normalized_title": "decoar2.0:deepcontextualizedacousticrepresentationswithvectorquantization",
    "doi": "10.48550/arxiv.2012.06659",
    "openalex_id": "https://openalex.org/w3112034174",
    "arxiv_id": "",
    "published_date": "2020-12-11",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Codified audio language modeling learns useful representations for music information retrieval",
    "normalized_title": "codifiedaudiolanguagemodelinglearnsusefulrepresentationsformusicinformationretrieval",
    "doi": "10.48550/arxiv.2107.05677",
    "openalex_id": "https://openalex.org/w3180663620",
    "arxiv_id": "",
    "published_date": "2021-07-12",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Indonesian Voice Cloning Text-to-Speech System With Vall-E-Based Model and Speech Enhancement",
    "normalized_title": "indonesianvoicecloningtext-to-speechsystemwithvall-e-basedmodelandspeechenhancement",
    "doi": "10.1109/access.2024.3519870",
    "openalex_id": "https://openalex.org/w4405521108",
    "arxiv_id": "",
    "published_date": "2024-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "TTS-Transducer: End-to-End Speech Synthesis with Neural Transducer",
    "normalized_title": "tts-transducer:end-to-endspeechsynthesiswithneuraltransducer",
    "doi": "10.1109/icassp49660.2025.10890256",
    "openalex_id": "https://openalex.org/w4408354729",
    "arxiv_id": "",
    "published_date": "2025-03-12",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Learning Contextualized Representation on Discrete Space Via Hierarchical Product Quantization",
    "normalized_title": "learningcontextualizedrepresentationondiscretespaceviahierarchicalproductquantization",
    "doi": "10.1109/icassp48485.2024.10446474",
    "openalex_id": "https://openalex.org/w4392902837",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Generating Stereophonic Music with Single-Stage Language Models",
    "normalized_title": "generatingstereophonicmusicwithsingle-stagelanguagemodels",
    "doi": "10.1109/icassp48485.2024.10446643",
    "openalex_id": "https://openalex.org/w4392902968",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Make Some Noise: Towards LLM audio reasoning and generation using sound tokens",
    "normalized_title": "makesomenoise:towardsllmaudioreasoningandgenerationusingsoundtokens",
    "doi": "10.1109/icassp49660.2025.10888809",
    "openalex_id": "https://openalex.org/w4408354829",
    "arxiv_id": "",
    "published_date": "2025-03-12",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "SpeechLM: Enhanced Speech Pre-Training With Unpaired Textual Data",
    "normalized_title": "speechlm:enhancedspeechpre-trainingwithunpairedtextualdata",
    "doi": "10.1109/taslp.2024.3379877",
    "openalex_id": "https://openalex.org/w4392979802",
    "arxiv_id": "",
    "published_date": "2024-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Are Discrete Units Necessary for Spoken Language Modeling?",
    "normalized_title": "arediscreteunitsnecessaryforspokenlanguagemodeling?",
    "doi": "10.1109/jstsp.2022.3200909",
    "openalex_id": "https://openalex.org/w4221140961",
    "arxiv_id": "",
    "published_date": "2022-08-23",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Efficient and Scalable Neural Residual Waveform Coding with Collaborative Quantization",
    "normalized_title": "efficientandscalableneuralresidualwaveformcodingwithcollaborativequantization",
    "doi": "10.1109/icassp40776.2020.9054347",
    "openalex_id": "https://openalex.org/w3015268401",
    "arxiv_id": "",
    "published_date": "2020-04-09",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "ASQ: An Ultra-Low Bit Rate ASR-Oriented Speech Quantization Method",
    "normalized_title": "asq:anultra-lowbitrateasr-orientedspeechquantizationmethod",
    "doi": "10.1109/lsp.2023.3347148",
    "openalex_id": "https://openalex.org/w4390224291",
    "arxiv_id": "",
    "published_date": "2023-12-26",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "TeNC: Low Bit-Rate Speech Coding with VQ-VAE and GAN",
    "normalized_title": "tenc:lowbit-ratespeechcodingwithvq-vaeandgan",
    "doi": "10.1145/3461615.3491114",
    "openalex_id": "https://openalex.org/w4200219715",
    "arxiv_id": "",
    "published_date": "2021-10-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Architecture for Variable Bitrate Neural Speech Codec with Configurable Computation Complexity",
    "normalized_title": "architectureforvariablebitrateneuralspeechcodecwithconfigurablecomputationcomplexity",
    "doi": "10.1109/icassp43922.2022.9747419",
    "openalex_id": "https://openalex.org/w4225311785",
    "arxiv_id": "",
    "published_date": "2022-04-27",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Enhancing into the Codec: Noise Robust Speech Coding with Vector-Quantized Autoencoders",
    "normalized_title": "enhancingintothecodec:noiserobustspeechcodingwithvector-quantizedautoencoders",
    "doi": "10.1109/icassp39728.2021.9414605",
    "openalex_id": "https://openalex.org/w3132710062",
    "arxiv_id": "",
    "published_date": "2021-05-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Improved Prosody from Learned F0 Codebook Representations for VQ-VAE Speech Waveform Reconstruction",
    "normalized_title": "improvedprosodyfromlearnedf0codebookrepresentationsforvq-vaespeechwaveformreconstruction",
    "doi": "10.48550/arxiv.2005.07884",
    "openalex_id": "https://openalex.org/w3025878903",
    "arxiv_id": "",
    "published_date": "2020-05-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Effectiveness of self-supervised pre-training for speech recognition",
    "normalized_title": "effectivenessofself-supervisedpre-trainingforspeechrecognition",
    "doi": "10.48550/arxiv.1911.03912",
    "openalex_id": "https://openalex.org/w2988736778",
    "arxiv_id": "",
    "published_date": "2019-11-10",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Jukebox: A Generative Model for Music",
    "normalized_title": "jukebox:agenerativemodelformusic",
    "doi": "10.48550/arxiv.2005.00341",
    "openalex_id": "https://openalex.org/w3021164770",
    "arxiv_id": "",
    "published_date": "2020-04-30",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Feature optimized DPGMM clustering for unsupervised subword modeling: A contribution to zerospeech 2017",
    "normalized_title": "featureoptimizeddpgmmclusteringforunsupervisedsubwordmodeling:acontributiontozerospeech2017",
    "doi": "10.1109/asru.2017.8269011",
    "openalex_id": "https://openalex.org/w2787447541",
    "arxiv_id": "",
    "published_date": "2017-12-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Generating diverse and natural text-to-speech samples using a quantized\\n fine-grained VAE and auto-regressive prosody prior",
    "normalized_title": "generatingdiverseandnaturaltext-to-speechsamplesusingaquantized\\nfine-grainedvaeandauto-regressiveprosodyprior",
    "doi": "10.48550/arxiv.2002.03788",
    "openalex_id": "https://openalex.org/w4214968481",
    "arxiv_id": "",
    "published_date": "2020-02-06",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "A Vector Quantized Variational Autoencoder (VQ-VAE) Autoregressive Neural $F_0$ Model for Statistical Parametric Speech Synthesis",
    "normalized_title": "avectorquantizedvariationalautoencoder(vq-vae)autoregressiveneural$f_0$modelforstatisticalparametricspeechsynthesis",
    "doi": "10.1109/taslp.2019.2950099",
    "openalex_id": "https://openalex.org/w2982602185",
    "arxiv_id": "",
    "published_date": "2019-10-28",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Prosospeech: Enhancing Prosody with Quantized Vector Pre-Training in Text-To-Speech",
    "normalized_title": "prosospeech:enhancingprosodywithquantizedvectorpre-trainingintext-to-speech",
    "doi": "10.1109/icassp43922.2022.9746883",
    "openalex_id": "https://openalex.org/w4221159457",
    "arxiv_id": "",
    "published_date": "2022-04-27",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "VioLA: Unified Codec Language Models for Speech Recognition, Synthesis, and Translation",
    "normalized_title": "viola:unifiedcodeclanguagemodelsforspeechrecognition,synthesis,andtranslation",
    "doi": "10.48550/arxiv.2305.16107",
    "openalex_id": "https://openalex.org/w4378501656",
    "arxiv_id": "",
    "published_date": "2023-05-25",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "High-Fidelity Audio Compression with Improved RVQGAN",
    "normalized_title": "high-fidelityaudiocompressionwithimprovedrvqgan",
    "doi": "10.48550/arxiv.2306.06546",
    "openalex_id": "https://openalex.org/w4380551955",
    "arxiv_id": "",
    "published_date": "2023-06-11",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "A Low-Resource Pipeline for Text-to-Speech from Found Data With Application to Scottish Gaelic",
    "normalized_title": "alow-resourcepipelinefortext-to-speechfromfounddatawithapplicationtoscottishgaelic",
    "doi": "10.21437/interspeech.2023-2056",
    "openalex_id": "https://openalex.org/w4385822479",
    "arxiv_id": "",
    "published_date": "2023-08-14",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models",
    "normalized_title": "naturalspeech3:zero-shotspeechsynthesiswithfactorizedcodecanddiffusionmodels",
    "doi": "10.48550/arxiv.2403.03100",
    "openalex_id": "https://openalex.org/w4392538788",
    "arxiv_id": "",
    "published_date": "2024-03-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "PolyVoice: Language Models for Speech to Speech Translation",
    "normalized_title": "polyvoice:languagemodelsforspeechtospeechtranslation",
    "doi": "10.48550/arxiv.2306.02982",
    "openalex_id": "https://openalex.org/w4379540238",
    "arxiv_id": "",
    "published_date": "2023-06-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Unsupervised Cross-Lingual Representation Learning for Speech Recognition",
    "normalized_title": "unsupervisedcross-lingualrepresentationlearningforspeechrecognition",
    "doi": "10.21437/interspeech.2021-329",
    "openalex_id": "https://openalex.org/w3037057938",
    "arxiv_id": "",
    "published_date": "2021-08-27",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "TranSpeech: Speech-to-Speech Translation With Bilateral Perturbation",
    "normalized_title": "transpeech:speech-to-speechtranslationwithbilateralperturbation",
    "doi": "10.48550/arxiv.2205.12523",
    "openalex_id": "https://openalex.org/w4281789500",
    "arxiv_id": "",
    "published_date": "2022-05-25",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "DUB: Discrete Unit Back-translation for Speech Translation",
    "normalized_title": "dub:discreteunitback-translationforspeechtranslation",
    "doi": "10.18653/v1/2023.findings-acl.447",
    "openalex_id": "https://openalex.org/w4385570101",
    "arxiv_id": "",
    "published_date": "2023-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "HiFi-Codec: Group-residual Vector quantization for High Fidelity Audio Codec",
    "normalized_title": "hifi-codec:group-residualvectorquantizationforhighfidelityaudiocodec",
    "doi": "10.48550/arxiv.2305.02765",
    "openalex_id": "https://openalex.org/w4372279529",
    "arxiv_id": "",
    "published_date": "2023-05-04",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "u-HuBERT: Unified Mixed-Modal Speech Pretraining And Zero-Shot Transfer to Unlabeled Modality",
    "normalized_title": "u-hubert:unifiedmixed-modalspeechpretrainingandzero-shottransfertounlabeledmodality",
    "doi": "10.48550/arxiv.2207.07036",
    "openalex_id": "https://openalex.org/w4285595742",
    "arxiv_id": "",
    "published_date": "2022-07-14",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "ReVISE: Self-Supervised Speech Resynthesis with Visual Input for Universal and Generalized Speech Enhancement",
    "normalized_title": "revise:self-supervisedspeechresynthesiswithvisualinputforuniversalandgeneralizedspeechenhancement",
    "doi": "10.48550/arxiv.2212.11377",
    "openalex_id": "https://openalex.org/w4312121834",
    "arxiv_id": "",
    "published_date": "2022-12-21",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "From Discrete Tokens to High-Fidelity Audio Using Multi-Band Diffusion",
    "normalized_title": "fromdiscretetokenstohigh-fidelityaudiousingmulti-banddiffusion",
    "doi": "10.48550/arxiv.2308.02560",
    "openalex_id": "https://openalex.org/w4385680913",
    "arxiv_id": "",
    "published_date": "2023-08-02",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Learning Disentangled Phone and Speaker Representations in a Semi-Supervised VQ-VAE Paradigm",
    "normalized_title": "learningdisentangledphoneandspeakerrepresentationsinasemi-supervisedvq-vaeparadigm",
    "doi": "10.1109/icassp39728.2021.9413543",
    "openalex_id": "https://openalex.org/w3160584619",
    "arxiv_id": "",
    "published_date": "2021-05-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Simple and Controllable Music Generation",
    "normalized_title": "simpleandcontrollablemusicgeneration",
    "doi": "10.48550/arxiv.2306.05284",
    "openalex_id": "https://openalex.org/w4380136719",
    "arxiv_id": "",
    "published_date": "2023-06-08",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "The challenge of realistic music generation: modelling raw audio at scale",
    "normalized_title": "thechallengeofrealisticmusicgeneration:modellingrawaudioatscale",
    "doi": "",
    "openalex_id": "https://openalex.org/w2962942158",
    "arxiv_id": "",
    "published_date": "2018-06-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Learning Hierarchical Discrete Linguistic Units from Visually-Grounded\\n Speech",
    "normalized_title": "learninghierarchicaldiscretelinguisticunitsfromvisually-grounded\\nspeech",
    "doi": "10.48550/arxiv.1911.09602",
    "openalex_id": "https://openalex.org/w2995680346",
    "arxiv_id": "",
    "published_date": "2019-11-21",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  },
  {
    "status": "include",
    "title": "Unsupervised Acoustic Unit Discovery for Speech Synthesis Using Discrete Latent-Variable Neural Networks",
    "normalized_title": "unsupervisedacousticunitdiscoveryforspeechsynthesisusingdiscretelatent-variableneuralnetworks",
    "doi": "10.21437/interspeech.2019-1518",
    "openalex_id": "https://openalex.org/w2936295285",
    "arxiv_id": "",
    "published_date": "2019-09-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:16:54.789730+00:00",
    "round": 2
  }
]