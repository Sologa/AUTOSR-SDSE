[
  {
    "status": "include",
    "title": "Recent Advances in Discrete Speech Tokens: A Review",
    "normalized_title": "recentadvancesindiscretespeechtokens:areview",
    "doi": "10.48550/arxiv.2502.06490",
    "openalex_id": "",
    "arxiv_id": "2502.06490",
    "published_date": "2025-02-10",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Self-supervised speech unit discovery from articulatory and acoustic features using VQ-VAE",
    "normalized_title": "self-supervisedspeechunitdiscoveryfromarticulatoryandacousticfeaturesusingvq-vae",
    "doi": "10.48550/arxiv.2206.08790",
    "openalex_id": "",
    "arxiv_id": "2206.08790",
    "published_date": "2022-06-17",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "A Comparative Study of Self-supervised Speech Representation Based Voice Conversion",
    "normalized_title": "acomparativestudyofself-supervisedspeechrepresentationbasedvoiceconversion",
    "doi": "10.1109/jstsp.2022.3193761",
    "openalex_id": "",
    "arxiv_id": "2207.04356",
    "published_date": "2022-07-10",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "DelightfulTTS 2: End-to-End Speech Synthesis with Adversarial Vector-Quantized Auto-Encoders",
    "normalized_title": "delightfultts2:end-to-endspeechsynthesiswithadversarialvector-quantizedauto-encoders",
    "doi": "10.48550/arxiv.2207.04646",
    "openalex_id": "",
    "arxiv_id": "2207.04646",
    "published_date": "2022-07-11",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "A Multi-Stage Multi-Codebook VQ-VAE Approach to High-Performance Neural TTS",
    "normalized_title": "amulti-stagemulti-codebookvq-vaeapproachtohigh-performanceneuraltts",
    "doi": "10.48550/arxiv.2209.10887",
    "openalex_id": "",
    "arxiv_id": "2209.10887",
    "published_date": "2022-09-22",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "CoBERT: Self-Supervised Speech Representation Learning Through Code Representation Learning",
    "normalized_title": "cobert:self-supervisedspeechrepresentationlearningthroughcoderepresentationlearning",
    "doi": "10.48550/arxiv.2210.04062",
    "openalex_id": "",
    "arxiv_id": "2210.04062",
    "published_date": "2022-10-08",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "JukeDrummer: Conditional Beat-aware Audio-domain Drum Accompaniment Generation via Transformer VQ-VAE",
    "normalized_title": "jukedrummer:conditionalbeat-awareaudio-domaindrumaccompanimentgenerationviatransformervq-vae",
    "doi": "10.48550/arxiv.2210.06007",
    "openalex_id": "",
    "arxiv_id": "2210.06007",
    "published_date": "2022-10-12",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Towards High-Quality Neural TTS for Low-Resource Languages by Learning Compact Speech Representations",
    "normalized_title": "towardshigh-qualityneuralttsforlow-resourcelanguagesbylearningcompactspeechrepresentations",
    "doi": "10.48550/arxiv.2210.15131",
    "openalex_id": "",
    "arxiv_id": "2210.15131",
    "published_date": "2022-10-27",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "token2vec: A Joint Self-Supervised Pre-training Framework Using Unpaired Speech and Text",
    "normalized_title": "token2vec:ajointself-supervisedpre-trainingframeworkusingunpairedspeechandtext",
    "doi": "10.48550/arxiv.2210.16755",
    "openalex_id": "",
    "arxiv_id": "2210.16755",
    "published_date": "2022-10-30",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SpeechLMScore: Evaluating speech generation using speech language model",
    "normalized_title": "speechlmscore:evaluatingspeechgenerationusingspeechlanguagemodel",
    "doi": "10.48550/arxiv.2212.04559",
    "openalex_id": "",
    "arxiv_id": "2212.04559",
    "published_date": "2022-12-08",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "BEATs: Audio Pre-Training with Acoustic Tokenizers",
    "normalized_title": "beats:audiopre-trainingwithacoustictokenizers",
    "doi": "10.48550/arxiv.2212.09058",
    "openalex_id": "",
    "arxiv_id": "2212.09058",
    "published_date": "2022-12-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Analysing Discrete Self Supervised Speech Representation for Spoken Language Modeling",
    "normalized_title": "analysingdiscreteselfsupervisedspeechrepresentationforspokenlanguagemodeling",
    "doi": "10.1109/icassp49357.2023.10097097",
    "openalex_id": "",
    "arxiv_id": "2301.00591",
    "published_date": "2023-01-02",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers",
    "normalized_title": "neuralcodeclanguagemodelsarezero-shottexttospeechsynthesizers",
    "doi": "10.48550/arxiv.2301.02111",
    "openalex_id": "",
    "arxiv_id": "2301.02111",
    "published_date": "2023-01-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "InstructTTS: Modelling Expressive TTS in Discrete Latent Space with Natural Language Style Prompt",
    "normalized_title": "instructtts:modellingexpressivettsindiscretelatentspacewithnaturallanguagestyleprompt",
    "doi": "10.48550/arxiv.2301.13662",
    "openalex_id": "",
    "arxiv_id": "2301.13662",
    "published_date": "2023-01-31",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Speak, Read and Prompt: High-Fidelity Text-to-Speech with Minimal Supervision",
    "normalized_title": "speak,readandprompt:high-fidelitytext-to-speechwithminimalsupervision",
    "doi": "10.48550/arxiv.2302.03540",
    "openalex_id": "",
    "arxiv_id": "2302.03540",
    "published_date": "2023-02-07",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech",
    "normalized_title": "avectorquantizedapproachfortexttospeechsynthesisonreal-worldspontaneousspeech",
    "doi": "10.48550/arxiv.2302.04215",
    "openalex_id": "",
    "arxiv_id": "2302.04215",
    "published_date": "2023-02-08",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Speech Enhancement with Multi-granularity Vector Quantization",
    "normalized_title": "speechenhancementwithmulti-granularityvectorquantization",
    "doi": "10.48550/arxiv.2302.08342",
    "openalex_id": "",
    "arxiv_id": "2302.08342",
    "published_date": "2023-02-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "FoundationTTS: Text-to-Speech for ASR Customization with Generative Language Model",
    "normalized_title": "foundationtts:text-to-speechforasrcustomizationwithgenerativelanguagemodel",
    "doi": "10.48550/arxiv.2303.02939",
    "openalex_id": "",
    "arxiv_id": "2303.02939",
    "published_date": "2023-03-06",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec Language Modeling",
    "normalized_title": "speakforeignlanguageswithyourownvoice:cross-lingualneuralcodeclanguagemodeling",
    "doi": "10.48550/arxiv.2303.03926",
    "openalex_id": "",
    "arxiv_id": "2303.03926",
    "published_date": "2023-03-07",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "A vector quantized masked autoencoder for audiovisual speech emotion recognition",
    "normalized_title": "avectorquantizedmaskedautoencoderforaudiovisualspeechemotionrecognition",
    "doi": "10.1016/j.cviu.2025.104362",
    "openalex_id": "",
    "arxiv_id": "2305.03568",
    "published_date": "2023-05-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "A multimodal dynamical variational autoencoder for audiovisual speech representation learning",
    "normalized_title": "amultimodaldynamicalvariationalautoencoderforaudiovisualspeechrepresentationlearning",
    "doi": "10.1016/j.neunet.2024.106120",
    "openalex_id": "",
    "arxiv_id": "2305.03582",
    "published_date": "2023-05-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SoundStorm: Efficient Parallel Audio Generation",
    "normalized_title": "soundstorm:efficientparallelaudiogeneration",
    "doi": "10.48550/arxiv.2305.09636",
    "openalex_id": "",
    "arxiv_id": "2305.09636",
    "published_date": "2023-05-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Make-A-Voice: Unified Voice Synthesis With Discrete Representation",
    "normalized_title": "make-a-voice:unifiedvoicesynthesiswithdiscreterepresentation",
    "doi": "10.48550/arxiv.2305.19269",
    "openalex_id": "",
    "arxiv_id": "2305.19269",
    "published_date": "2023-05-30",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "UniCATS: A Unified Context-Aware Text-to-Speech Framework with Contextual VQ-Diffusion and Vocoding",
    "normalized_title": "unicats:aunifiedcontext-awaretext-to-speechframeworkwithcontextualvq-diffusionandvocoding",
    "doi": "10.1609/aaai.v38i16.29747",
    "openalex_id": "",
    "arxiv_id": "2306.07547",
    "published_date": "2023-06-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Pushing the Limits of Unsupervised Unit Discovery for SSL Speech Representation",
    "normalized_title": "pushingthelimitsofunsupervisedunitdiscoveryforsslspeechrepresentation",
    "doi": "10.48550/arxiv.2306.08920",
    "openalex_id": "",
    "arxiv_id": "2306.08920",
    "published_date": "2023-06-15",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "LM-VC: Zero-shot Voice Conversion via Speech Generation based on Language Models",
    "normalized_title": "lm-vc:zero-shotvoiceconversionviaspeechgenerationbasedonlanguagemodels",
    "doi": "10.48550/arxiv.2306.10521",
    "openalex_id": "",
    "arxiv_id": "2306.10521",
    "published_date": "2023-06-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "VampNet: Music Generation via Masked Acoustic Token Modeling",
    "normalized_title": "vampnet:musicgenerationviamaskedacoustictokenmodeling",
    "doi": "10.48550/arxiv.2307.04686",
    "openalex_id": "",
    "arxiv_id": "2307.04686",
    "published_date": "2023-07-10",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SpeechTokenizer: Unified Speech Tokenizer for Speech Large Language Models",
    "normalized_title": "speechtokenizer:unifiedspeechtokenizerforspeechlargelanguagemodels",
    "doi": "10.48550/arxiv.2308.16692",
    "openalex_id": "",
    "arxiv_id": "2308.16692",
    "published_date": "2023-08-31",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "QS-TTS: Towards Semi-Supervised Text-to-Speech Synthesis via Vector-Quantized Self-Supervised Speech Representation Learning",
    "normalized_title": "qs-tts:towardssemi-supervisedtext-to-speechsynthesisviavector-quantizedself-supervisedspeechrepresentationlearning",
    "doi": "10.48550/arxiv.2309.00126",
    "openalex_id": "",
    "arxiv_id": "2309.00126",
    "published_date": "2023-08-31",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "RepCodec: A Speech Representation Codec for Speech Tokenization",
    "normalized_title": "repcodec:aspeechrepresentationcodecforspeechtokenization",
    "doi": "10.48550/arxiv.2309.00169",
    "openalex_id": "",
    "arxiv_id": "2309.00169",
    "published_date": "2023-08-31",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Direct Text to Speech Translation System using Acoustic Units",
    "normalized_title": "directtexttospeechtranslationsystemusingacousticunits",
    "doi": "10.1109/lsp.2023.3313513",
    "openalex_id": "",
    "arxiv_id": "2309.07478",
    "published_date": "2023-09-14",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Voxtlm: unified decoder-only models for consolidating speech recognition/synthesis and speech/text continuation tasks",
    "normalized_title": "voxtlm:unifieddecoder-onlymodelsforconsolidatingspeechrecognition/synthesisandspeech/textcontinuationtasks",
    "doi": "10.48550/arxiv.2309.07937",
    "openalex_id": "",
    "arxiv_id": "2309.07937",
    "published_date": "2023-09-14",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Improving Language Model-Based Zero-Shot Text-to-Speech Synthesis with Multi-Scale Acoustic Prompts",
    "normalized_title": "improvinglanguagemodel-basedzero-shottext-to-speechsynthesiswithmulti-scaleacousticprompts",
    "doi": "10.48550/arxiv.2309.11977",
    "openalex_id": "",
    "arxiv_id": "2309.11977",
    "published_date": "2023-09-21",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Towards General-Purpose Text-Instruction-Guided Voice Conversion",
    "normalized_title": "towardsgeneral-purposetext-instruction-guidedvoiceconversion",
    "doi": "10.48550/arxiv.2309.14324",
    "openalex_id": "",
    "arxiv_id": "2309.14324",
    "published_date": "2023-09-25",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Vec-Tok Speech: speech vectorization and tokenization for neural speech generation",
    "normalized_title": "vec-tokspeech:speechvectorizationandtokenizationforneuralspeechgeneration",
    "doi": "10.48550/arxiv.2310.07246",
    "openalex_id": "",
    "arxiv_id": "2310.07246",
    "published_date": "2023-10-11",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Low-latency Speech Enhancement via Speech Token Generation",
    "normalized_title": "low-latencyspeechenhancementviaspeechtokengeneration",
    "doi": "10.48550/arxiv.2310.08981",
    "openalex_id": "",
    "arxiv_id": "2310.08981",
    "published_date": "2023-10-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Composer Style-specific Symbolic Music Generation Using Vector Quantized Discrete Diffusion Models",
    "normalized_title": "composerstyle-specificsymbolicmusicgenerationusingvectorquantizeddiscretediffusionmodels",
    "doi": "10.48550/arxiv.2310.14044",
    "openalex_id": "",
    "arxiv_id": "2310.14044",
    "published_date": "2023-10-21",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Acoustic BPE for Speech Generation with Discrete Tokens",
    "normalized_title": "acousticbpeforspeechgenerationwithdiscretetokens",
    "doi": "10.48550/arxiv.2310.14580",
    "openalex_id": "",
    "arxiv_id": "2310.14580",
    "published_date": "2023-10-23",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Transduce and Speak: Neural Transducer for Text-to-Speech with Semantic Token Prediction",
    "normalized_title": "transduceandspeak:neuraltransducerfortext-to-speechwithsemantictokenprediction",
    "doi": "10.48550/arxiv.2311.02898",
    "openalex_id": "",
    "arxiv_id": "2311.02898",
    "published_date": "2023-11-06",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Loss Masking Is Not Needed in Decoder-only Transformer for Discrete-token-based ASR",
    "normalized_title": "lossmaskingisnotneededindecoder-onlytransformerfordiscrete-token-basedasr",
    "doi": "10.48550/arxiv.2311.04534",
    "openalex_id": "",
    "arxiv_id": "2311.04534",
    "published_date": "2023-11-08",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SEF-VC: Speaker Embedding Free Zero-Shot Voice Conversion with Cross Attention",
    "normalized_title": "sef-vc:speakerembeddingfreezero-shotvoiceconversionwithcrossattention",
    "doi": "10.48550/arxiv.2312.08676",
    "openalex_id": "https://openalex.org/w4392902857",
    "arxiv_id": "2312.08676",
    "published_date": "2023-12-14",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "SELM: Speech Enhancement Using Discrete Tokens and Language Models",
    "normalized_title": "selm:speechenhancementusingdiscretetokensandlanguagemodels",
    "doi": "10.48550/arxiv.2312.09747",
    "openalex_id": "",
    "arxiv_id": "2312.09747",
    "published_date": "2023-12-15",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Utilizing Neural Transducers for Two-Stage Text-to-Speech via Semantic Token Prediction",
    "normalized_title": "utilizingneuraltransducersfortwo-stagetext-to-speechviasemantictokenprediction",
    "doi": "10.48550/arxiv.2401.01498",
    "openalex_id": "",
    "arxiv_id": "2401.01498",
    "published_date": "2024-01-03",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Predicting positive transfer for improved low-resource speech recognition using acoustic pseudo-tokens",
    "normalized_title": "predictingpositivetransferforimprovedlow-resourcespeechrecognitionusingacousticpseudo-tokens",
    "doi": "10.48550/arxiv.2402.02302",
    "openalex_id": "",
    "arxiv_id": "2402.02302",
    "published_date": "2024-02-03",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "BASE TTS: Lessons from building a billion-parameter Text-to-Speech model on 100K hours of data",
    "normalized_title": "basetts:lessonsfrombuildingabillion-parametertext-to-speechmodelon100khoursofdata",
    "doi": "10.48550/arxiv.2402.08093",
    "openalex_id": "",
    "arxiv_id": "2402.08093",
    "published_date": "2024-02-12",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "MobileSpeech: A Fast and High-Fidelity Framework for Mobile Zero-Shot Text-to-Speech",
    "normalized_title": "mobilespeech:afastandhigh-fidelityframeworkformobilezero-shottext-to-speech",
    "doi": "10.48550/arxiv.2402.09378",
    "openalex_id": "",
    "arxiv_id": "2402.09378",
    "published_date": "2024-02-14",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Language-Codec: Bridging Discrete Codec Representations and Speech Language Models",
    "normalized_title": "language-codec:bridgingdiscretecodecrepresentationsandspeechlanguagemodels",
    "doi": "10.48550/arxiv.2402.12208",
    "openalex_id": "",
    "arxiv_id": "2402.12208",
    "published_date": "2024-02-19",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "The X-LANCE Technical Report for Interspeech 2024 Speech Processing Using Discrete Speech Unit Challenge",
    "normalized_title": "thex-lancetechnicalreportforinterspeech2024speechprocessingusingdiscretespeechunitchallenge",
    "doi": "10.48550/arxiv.2404.06079",
    "openalex_id": "",
    "arxiv_id": "2404.06079",
    "published_date": "2024-04-09",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "ESC: Efficient Speech Coding with Cross-Scale Residual Vector Quantized Transformers",
    "normalized_title": "esc:efficientspeechcodingwithcross-scaleresidualvectorquantizedtransformers",
    "doi": "10.48550/arxiv.2404.19441",
    "openalex_id": "",
    "arxiv_id": "2404.19441",
    "published_date": "2024-04-30",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "C3LLM: Conditional Multimodal Content Generation Using Large Language Models",
    "normalized_title": "c3llm:conditionalmultimodalcontentgenerationusinglargelanguagemodels",
    "doi": "10.48550/arxiv.2405.16136",
    "openalex_id": "",
    "arxiv_id": "2405.16136",
    "published_date": "2024-05-25",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Generative Pre-trained Speech Language Model with Efficient Hierarchical Transformer",
    "normalized_title": "generativepre-trainedspeechlanguagemodelwithefficienthierarchicaltransformer",
    "doi": "10.48550/arxiv.2406.00976",
    "openalex_id": "",
    "arxiv_id": "2406.00976",
    "published_date": "2024-06-03",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "MaskSR: Masked Language Model for Full-band Speech Restoration",
    "normalized_title": "masksr:maskedlanguagemodelforfull-bandspeechrestoration",
    "doi": "10.48550/arxiv.2406.02092",
    "openalex_id": "",
    "arxiv_id": "2406.02092",
    "published_date": "2024-06-04",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Addressing Index Collapse of Large-Codebook Speech Tokenizer with Dual-Decoding Product-Quantized Variational Auto-Encoder",
    "normalized_title": "addressingindexcollapseoflarge-codebookspeechtokenizerwithdual-decodingproduct-quantizedvariationalauto-encoder",
    "doi": "10.48550/arxiv.2406.02940",
    "openalex_id": "",
    "arxiv_id": "2406.02940",
    "published_date": "2024-06-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Improving Audio Codec-based Zero-Shot Text-to-Speech Synthesis with Multi-Modal Context and Large Language Model",
    "normalized_title": "improvingaudiocodec-basedzero-shottext-to-speechsynthesiswithmulti-modalcontextandlargelanguagemodel",
    "doi": "10.48550/arxiv.2406.03706",
    "openalex_id": "",
    "arxiv_id": "2406.03706",
    "published_date": "2024-06-06",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Discrete Multimodal Transformers with a Pretrained Large Language Model for Mixed-Supervision Speech Processing",
    "normalized_title": "discretemultimodaltransformerswithapretrainedlargelanguagemodelformixed-supervisionspeechprocessing",
    "doi": "10.48550/arxiv.2406.06582",
    "openalex_id": "",
    "arxiv_id": "2406.06582",
    "published_date": "2024-06-04",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "VALL-E R: Robust and Efficient Zero-Shot Text-to-Speech Synthesis via Monotonic Alignment",
    "normalized_title": "vall-er:robustandefficientzero-shottext-to-speechsynthesisviamonotonicalignment",
    "doi": "10.48550/arxiv.2406.07855",
    "openalex_id": "",
    "arxiv_id": "2406.07855",
    "published_date": "2024-06-12",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "How Should We Extract Discrete Audio Tokens from Self-Supervised Models?",
    "normalized_title": "howshouldweextractdiscreteaudiotokensfromself-supervisedmodels?",
    "doi": "10.48550/arxiv.2406.10735",
    "openalex_id": "",
    "arxiv_id": "2406.10735",
    "published_date": "2024-06-15",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "NAST: Noise Aware Speech Tokenization for Speech Language Models",
    "normalized_title": "nast:noiseawarespeechtokenizationforspeechlanguagemodels",
    "doi": "10.48550/arxiv.2406.11037",
    "openalex_id": "",
    "arxiv_id": "2406.11037",
    "published_date": "2024-06-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "DASB - Discrete Audio and Speech Benchmark",
    "normalized_title": "dasb-discreteaudioandspeechbenchmark",
    "doi": "10.48550/arxiv.2406.14294",
    "openalex_id": "",
    "arxiv_id": "2406.14294",
    "published_date": "2024-06-20",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "High Fidelity Text-to-Speech Via Discrete Tokens Using Token Transducer and Group Masked Language Model",
    "normalized_title": "highfidelitytext-to-speechviadiscretetokensusingtokentransducerandgroupmaskedlanguagemodel",
    "doi": "10.48550/arxiv.2406.17310",
    "openalex_id": "",
    "arxiv_id": "2406.17310",
    "published_date": "2024-06-25",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "On the Effectiveness of Acoustic BPE in Decoder-Only TTS",
    "normalized_title": "ontheeffectivenessofacousticbpeindecoder-onlytts",
    "doi": "10.48550/arxiv.2407.03892",
    "openalex_id": "",
    "arxiv_id": "2407.03892",
    "published_date": "2024-07-04",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens",
    "normalized_title": "cosyvoice:ascalablemultilingualzero-shottext-to-speechsynthesizerbasedonsupervisedsemantictokens",
    "doi": "10.48550/arxiv.2407.05407",
    "openalex_id": "",
    "arxiv_id": "2407.05407",
    "published_date": "2024-07-07",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "dMel: Speech Tokenization made Simple",
    "normalized_title": "dmel:speechtokenizationmadesimple",
    "doi": "10.48550/arxiv.2407.15835",
    "openalex_id": "",
    "arxiv_id": "2407.15835",
    "published_date": "2024-07-22",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "VoxInstruct: Expressive Human Instruction-to-Speech Generation with Unified Multilingual Codec Language Modelling",
    "normalized_title": "voxinstruct:expressivehumaninstruction-to-speechgenerationwithunifiedmultilingualcodeclanguagemodelling",
    "doi": "10.1145/3664647.3681680",
    "openalex_id": "",
    "arxiv_id": "2408.15676",
    "published_date": "2024-08-28",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Enabling Beam Search for Language Model-Based Text-to-Speech Synthesis",
    "normalized_title": "enablingbeamsearchforlanguagemodel-basedtext-to-speechsynthesis",
    "doi": "10.48550/arxiv.2408.16373",
    "openalex_id": "",
    "arxiv_id": "2408.16373",
    "published_date": "2024-08-29",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Codec Does Matter: Exploring the Semantic Shortcoming of Codec for Audio Language Model",
    "normalized_title": "codecdoesmatter:exploringthesemanticshortcomingofcodecforaudiolanguagemodel",
    "doi": "10.48550/arxiv.2408.17175",
    "openalex_id": "",
    "arxiv_id": "2408.17175",
    "published_date": "2024-08-30",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer",
    "normalized_title": "maskgct:zero-shottext-to-speechwithmaskedgenerativecodectransformer",
    "doi": "10.48550/arxiv.2409.00750",
    "openalex_id": "",
    "arxiv_id": "2409.00750",
    "published_date": "2024-09-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "STAB: Speech Tokenizer Assessment Benchmark",
    "normalized_title": "stab:speechtokenizerassessmentbenchmark",
    "doi": "10.48550/arxiv.2409.02384",
    "openalex_id": "",
    "arxiv_id": "2409.02384",
    "published_date": "2024-09-04",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "FireRedTTS: A Foundation Text-To-Speech Framework for Industry-Level Generative Speech Applications",
    "normalized_title": "fireredtts:afoundationtext-to-speechframeworkforindustry-levelgenerativespeechapplications",
    "doi": "10.48550/arxiv.2409.03283",
    "openalex_id": "",
    "arxiv_id": "2409.03283",
    "published_date": "2024-09-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "LAST: Language Model Aware Speech Tokenization",
    "normalized_title": "last:languagemodelawarespeechtokenization",
    "doi": "10.48550/arxiv.2409.03701",
    "openalex_id": "",
    "arxiv_id": "2409.03701",
    "published_date": "2024-09-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Investigating Neural Audio Codecs for Speech Language Model-Based Speech Generation",
    "normalized_title": "investigatingneuralaudiocodecsforspeechlanguagemodel-basedspeechgeneration",
    "doi": "10.48550/arxiv.2409.04016",
    "openalex_id": "",
    "arxiv_id": "2409.04016",
    "published_date": "2024-09-06",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Disentangling the Prosody and Semantic Information with Pre-trained Model for In-Context Learning based Zero-Shot Voice Conversion",
    "normalized_title": "disentanglingtheprosodyandsemanticinformationwithpre-trainedmodelforin-contextlearningbasedzero-shotvoiceconversion",
    "doi": "10.48550/arxiv.2409.05004",
    "openalex_id": "",
    "arxiv_id": "2409.05004",
    "published_date": "2024-09-08",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE",
    "normalized_title": "probtalk3d:non-deterministicemotioncontrollablespeech-driven3dfacialanimationsynthesisusingvq-vae",
    "doi": "10.1145/3677388.3696320",
    "openalex_id": "",
    "arxiv_id": "2409.07966",
    "published_date": "2024-09-12",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "NDVQ: Robust Neural Audio Codec with Normal Distribution-Based Vector Quantization",
    "normalized_title": "ndvq:robustneuralaudiocodecwithnormaldistribution-basedvectorquantization",
    "doi": "10.48550/arxiv.2409.12717",
    "openalex_id": "",
    "arxiv_id": "2409.12717",
    "published_date": "2024-09-19",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "EMOVA: Empowering Language Models to See, Hear and Speak with Vivid Emotions",
    "normalized_title": "emova:empoweringlanguagemodelstosee,hearandspeakwithvividemotions",
    "doi": "10.48550/arxiv.2409.18042",
    "openalex_id": "",
    "arxiv_id": "2409.18042",
    "published_date": "2024-09-26",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Moshi: a speech-text foundation model for real-time dialogue",
    "normalized_title": "moshi:aspeech-textfoundationmodelforreal-timedialogue",
    "doi": "10.48550/arxiv.2410.00037",
    "openalex_id": "",
    "arxiv_id": "2410.00037",
    "published_date": "2024-09-17",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Textless Streaming Speech-to-Speech Translation using Semantic Speech Tokens",
    "normalized_title": "textlessstreamingspeech-to-speechtranslationusingsemanticspeechtokens",
    "doi": "10.48550/arxiv.2410.03298",
    "openalex_id": "",
    "arxiv_id": "2410.03298",
    "published_date": "2024-10-04",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Variable Bitrate Residual Vector Quantization for Audio Coding",
    "normalized_title": "variablebitrateresidualvectorquantizationforaudiocoding",
    "doi": "10.48550/arxiv.2410.06016",
    "openalex_id": "",
    "arxiv_id": "2410.06016",
    "published_date": "2024-10-08",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Sylber: Syllabic Embedding Representation of Speech from Raw Audio",
    "normalized_title": "sylber:syllabicembeddingrepresentationofspeechfromrawaudio",
    "doi": "10.48550/arxiv.2410.07168",
    "openalex_id": "",
    "arxiv_id": "2410.07168",
    "published_date": "2024-10-09",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Low Bitrate High-Quality RVQGAN-based Discrete Speech Tokenizer",
    "normalized_title": "lowbitratehigh-qualityrvqgan-baseddiscretespeechtokenizer",
    "doi": "10.21437/interspeech.2024-2366",
    "openalex_id": "",
    "arxiv_id": "2410.08325",
    "published_date": "2024-10-10",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "ERVQ: Enhanced Residual Vector Quantization with Intra-and-Inter-Codebook Optimization for Neural Audio Codecs",
    "normalized_title": "ervq:enhancedresidualvectorquantizationwithintra-and-inter-codebookoptimizationforneuralaudiocodecs",
    "doi": "10.48550/arxiv.2410.12359",
    "openalex_id": "",
    "arxiv_id": "2410.12359",
    "published_date": "2024-10-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "DM-Codec: Distilling Multimodal Representations for Speech Tokenization",
    "normalized_title": "dm-codec:distillingmultimodalrepresentationsforspeechtokenization",
    "doi": "10.48550/arxiv.2410.15017",
    "openalex_id": "",
    "arxiv_id": "2410.15017",
    "published_date": "2024-10-19",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "LSCodec: Low-Bitrate and Speaker-Decoupled Discrete Speech Codec",
    "normalized_title": "lscodec:low-bitrateandspeaker-decoupleddiscretespeechcodec",
    "doi": "10.48550/arxiv.2410.15764",
    "openalex_id": "",
    "arxiv_id": "2410.15764",
    "published_date": "2024-10-21",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "DC-Spin: A Speaker-invariant Speech Tokenizer for Spoken Language Models",
    "normalized_title": "dc-spin:aspeaker-invariantspeechtokenizerforspokenlanguagemodels",
    "doi": "10.48550/arxiv.2410.24177",
    "openalex_id": "",
    "arxiv_id": "2410.24177",
    "published_date": "2024-10-31",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "A Comparative Study of Discrete Speech Tokens for Semantic-Related Tasks with Large Language Models",
    "normalized_title": "acomparativestudyofdiscretespeechtokensforsemantic-relatedtaskswithlargelanguagemodels",
    "doi": "10.48550/arxiv.2411.08742",
    "openalex_id": "",
    "arxiv_id": "2411.08742",
    "published_date": "2024-11-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "BEST-STD: Bidirectional Mamba-Enhanced Speech Tokenization for Spoken Term Detection",
    "normalized_title": "best-std:bidirectionalmamba-enhancedspeechtokenizationforspokentermdetection",
    "doi": "10.48550/arxiv.2411.14100",
    "openalex_id": "",
    "arxiv_id": "2411.14100",
    "published_date": "2024-11-21",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "VQalAttent: a Transparent Speech Generation Pipeline based on Transformer-learned VQ-VAE Latent Space",
    "normalized_title": "vqalattent:atransparentspeechgenerationpipelinebasedontransformer-learnedvq-vaelatentspace",
    "doi": "10.48550/arxiv.2411.14642",
    "openalex_id": "",
    "arxiv_id": "2411.14642",
    "published_date": "2024-11-22",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Scaling Speech-Text Pre-training with Synthetic Interleaved Data",
    "normalized_title": "scalingspeech-textpre-trainingwithsyntheticinterleaveddata",
    "doi": "10.48550/arxiv.2411.17607",
    "openalex_id": "",
    "arxiv_id": "2411.17607",
    "published_date": "2024-11-26",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "GLM-4-Voice: Towards Intelligent and Human-Like End-to-End Spoken Chatbot",
    "normalized_title": "glm-4-voice:towardsintelligentandhuman-likeend-to-endspokenchatbot",
    "doi": "10.48550/arxiv.2412.02612",
    "openalex_id": "",
    "arxiv_id": "2412.02612",
    "published_date": "2024-12-03",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models",
    "normalized_title": "cosyvoice2:scalablestreamingspeechsynthesiswithlargelanguagemodels",
    "doi": "10.48550/arxiv.2412.10117",
    "openalex_id": "",
    "arxiv_id": "2412.10117",
    "published_date": "2024-12-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Whisper-GPT: A Hybrid Representation Audio Large Language Model",
    "normalized_title": "whisper-gpt:ahybridrepresentationaudiolargelanguagemodel",
    "doi": "10.48550/arxiv.2412.11449",
    "openalex_id": "",
    "arxiv_id": "2412.11449",
    "published_date": "2024-12-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SLAM-Omni: Timbre-Controllable Voice Interaction System with Single-Stage Training",
    "normalized_title": "slam-omni:timbre-controllablevoiceinteractionsystemwithsingle-stagetraining",
    "doi": "10.48550/arxiv.2412.15649",
    "openalex_id": "",
    "arxiv_id": "2412.15649",
    "published_date": "2024-12-20",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Causal Speech Enhancement with Predicting Semantics based on Quantized Self-supervised Learning Features",
    "normalized_title": "causalspeechenhancementwithpredictingsemanticsbasedonquantizedself-supervisedlearningfeatures",
    "doi": "10.48550/arxiv.2412.19248",
    "openalex_id": "",
    "arxiv_id": "2412.19248",
    "published_date": "2024-12-26",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SECodec: Structural Entropy-based Compressive Speech Representation Codec for Speech Language Models",
    "normalized_title": "secodec:structuralentropy-basedcompressivespeechrepresentationcodecforspeechlanguagemodels",
    "doi": "10.48550/arxiv.2501.00018",
    "openalex_id": "",
    "arxiv_id": "2501.00018",
    "published_date": "2024-12-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "MARS6: A Small and Robust Hierarchical-Codec Text-to-Speech Model",
    "normalized_title": "mars6:asmallandrobusthierarchical-codectext-to-speechmodel",
    "doi": "10.48550/arxiv.2501.05787",
    "openalex_id": "",
    "arxiv_id": "2501.05787",
    "published_date": "2025-01-10",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Optimized Self-supervised Training with BEST-RQ for Speech Recognition",
    "normalized_title": "optimizedself-supervisedtrainingwithbest-rqforspeechrecognition",
    "doi": "10.48550/arxiv.2501.16131",
    "openalex_id": "",
    "arxiv_id": "2501.16131",
    "published_date": "2025-01-27",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "GenSE: Generative Speech Enhancement via Language Models using Hierarchical Modeling",
    "normalized_title": "gense:generativespeechenhancementvialanguagemodelsusinghierarchicalmodeling",
    "doi": "10.48550/arxiv.2502.02942",
    "openalex_id": "",
    "arxiv_id": "2502.02942",
    "published_date": "2025-02-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Metis: A Foundation Speech Generation Model with Masked Generative Pre-training",
    "normalized_title": "metis:afoundationspeechgenerationmodelwithmaskedgenerativepre-training",
    "doi": "10.48550/arxiv.2502.03128",
    "openalex_id": "",
    "arxiv_id": "2502.03128",
    "published_date": "2025-02-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "IndexTTS: An Industrial-Level Controllable and Efficient Zero-Shot Text-To-Speech System",
    "normalized_title": "indextts:anindustrial-levelcontrollableandefficientzero-shottext-to-speechsystem",
    "doi": "10.48550/arxiv.2502.05512",
    "openalex_id": "",
    "arxiv_id": "2502.05512",
    "published_date": "2025-02-08",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Balancing Speech Understanding and Generation Using Continual Pre-training for Codec-based Speech LLM",
    "normalized_title": "balancingspeechunderstandingandgenerationusingcontinualpre-trainingforcodec-basedspeechllm",
    "doi": "10.48550/arxiv.2502.16897",
    "openalex_id": "",
    "arxiv_id": "2502.16897",
    "published_date": "2025-02-24",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Baichuan-Audio: A Unified Framework for End-to-End Speech Interaction",
    "normalized_title": "baichuan-audio:aunifiedframeworkforend-to-endspeechinteraction",
    "doi": "10.48550/arxiv.2502.17239",
    "openalex_id": "",
    "arxiv_id": "2502.17239",
    "published_date": "2025-02-24",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "LLaSE-G1: Incentivizing Generalization Capability for LLaMA-based Speech Enhancement",
    "normalized_title": "llase-g1:incentivizinggeneralizationcapabilityforllama-basedspeechenhancement",
    "doi": "10.48550/arxiv.2503.00493",
    "openalex_id": "",
    "arxiv_id": "2503.00493",
    "published_date": "2025-03-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Spark-TTS: An Efficient LLM-Based Text-to-Speech Model with Single-Stream Decoupled Speech Tokens",
    "normalized_title": "spark-tts:anefficientllm-basedtext-to-speechmodelwithsingle-streamdecoupledspeechtokens",
    "doi": "10.48550/arxiv.2503.01710",
    "openalex_id": "",
    "arxiv_id": "2503.01710",
    "published_date": "2025-03-03",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Universal Speech Token Learning via Low-Bitrate Neural Codec and Pretrained Representations",
    "normalized_title": "universalspeechtokenlearningvialow-bitrateneuralcodecandpretrainedrepresentations",
    "doi": "10.1109/jstsp.2024.3488557",
    "openalex_id": "",
    "arxiv_id": "2503.12115",
    "published_date": "2025-03-15",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Shushing! Let's Imagine an Authentic Speech from the Silent Video",
    "normalized_title": "shushing!let'simagineanauthenticspeechfromthesilentvideo",
    "doi": "10.48550/arxiv.2503.14928",
    "openalex_id": "",
    "arxiv_id": "2503.14928",
    "published_date": "2025-03-19",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "FireRedTTS-1S: An Upgraded Streamable Foundation Text-to-Speech System",
    "normalized_title": "fireredtts-1s:anupgradedstreamablefoundationtext-to-speechsystem",
    "doi": "10.48550/arxiv.2503.20499",
    "openalex_id": "",
    "arxiv_id": "2503.20499",
    "published_date": "2025-03-26",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Pseudo-Autoregressive Neural Codec Language Models for Efficient Zero-Shot Text-to-Speech Synthesis",
    "normalized_title": "pseudo-autoregressiveneuralcodeclanguagemodelsforefficientzero-shottext-to-speechsynthesis",
    "doi": "10.48550/arxiv.2504.10352",
    "openalex_id": "",
    "arxiv_id": "2504.10352",
    "published_date": "2025-04-14",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SimulS2S-LLM: Unlocking Simultaneous Inference of Speech LLMs for Speech-to-Speech Translation",
    "normalized_title": "simuls2s-llm:unlockingsimultaneousinferenceofspeechllmsforspeech-to-speechtranslation",
    "doi": "10.48550/arxiv.2504.15509",
    "openalex_id": "",
    "arxiv_id": "2504.15509",
    "published_date": "2025-04-22",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "DualCodec: A Low-Frame-Rate, Semantically-Enhanced Neural Audio Codec for Speech Generation",
    "normalized_title": "dualcodec:alow-frame-rate,semantically-enhancedneuralaudiocodecforspeechgeneration",
    "doi": "10.48550/arxiv.2505.13000",
    "openalex_id": "",
    "arxiv_id": "2505.13000",
    "published_date": "2025-05-19",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Improving Noise Robustness of LLM-based Zero-shot TTS via Discrete Acoustic Token Denoising",
    "normalized_title": "improvingnoiserobustnessofllm-basedzero-shotttsviadiscreteacoustictokendenoising",
    "doi": "10.48550/arxiv.2505.13830",
    "openalex_id": "",
    "arxiv_id": "2505.13830",
    "published_date": "2025-05-20",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "PAST: Phonetic-Acoustic Speech Tokenizer",
    "normalized_title": "past:phonetic-acousticspeechtokenizer",
    "doi": "10.48550/arxiv.2505.14470",
    "openalex_id": "",
    "arxiv_id": "2505.14470",
    "published_date": "2025-05-20",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Discrete Audio Representations for Automated Audio Captioning",
    "normalized_title": "discreteaudiorepresentationsforautomatedaudiocaptioning",
    "doi": "10.48550/arxiv.2505.14989",
    "openalex_id": "",
    "arxiv_id": "2505.14989",
    "published_date": "2025-05-21",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "EZ-VC: Easy Zero-shot Any-to-Any Voice Conversion",
    "normalized_title": "ez-vc:easyzero-shotany-to-anyvoiceconversion",
    "doi": "10.48550/arxiv.2505.16691",
    "openalex_id": "",
    "arxiv_id": "2505.16691",
    "published_date": "2025-05-22",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Impact of Frame Rates on Speech Tokenizer: A Case Study on Mandarin and English",
    "normalized_title": "impactofframeratesonspeechtokenizer:acasestudyonmandarinandenglish",
    "doi": "10.48550/arxiv.2505.17076",
    "openalex_id": "",
    "arxiv_id": "2505.17076",
    "published_date": "2025-05-20",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Exploring the Effect of Segmentation and Vocabulary Size on Speech Tokenization for Speech Language Models",
    "normalized_title": "exploringtheeffectofsegmentationandvocabularysizeonspeechtokenizationforspeechlanguagemodels",
    "doi": "10.48550/arxiv.2505.17446",
    "openalex_id": "",
    "arxiv_id": "2505.17446",
    "published_date": "2025-05-23",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "VoiceStar: Robust Zero-Shot Autoregressive TTS with Duration Control and Extrapolation",
    "normalized_title": "voicestar:robustzero-shotautoregressivettswithdurationcontrolandextrapolation",
    "doi": "10.48550/arxiv.2505.19462",
    "openalex_id": "",
    "arxiv_id": "2505.19462",
    "published_date": "2025-05-26",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Speech Token Prediction via Compressed-to-fine Language Modeling for Speech Generation",
    "normalized_title": "speechtokenpredictionviacompressed-to-finelanguagemodelingforspeechgeneration",
    "doi": "10.48550/arxiv.2505.24496",
    "openalex_id": "",
    "arxiv_id": "2505.24496",
    "published_date": "2025-05-30",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "FUSE: Universal Speech Enhancement using Multi-Stage Fusion of Sparse Compression and Token Generation Models for the URGENT 2025 Challenge",
    "normalized_title": "fuse:universalspeechenhancementusingmulti-stagefusionofsparsecompressionandtokengenerationmodelsfortheurgent2025challenge",
    "doi": "10.48550/arxiv.2506.00809",
    "openalex_id": "",
    "arxiv_id": "2506.00809",
    "published_date": "2025-06-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "HASRD: Hierarchical Acoustic and Semantic Representation Disentanglement",
    "normalized_title": "hasrd:hierarchicalacousticandsemanticrepresentationdisentanglement",
    "doi": "10.48550/arxiv.2506.00843",
    "openalex_id": "",
    "arxiv_id": "2506.00843",
    "published_date": "2025-06-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "base_review",
    "updated_at": "2026-01-24T12:01:22.003612+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Pa-HuBERT: Self-Supervised Music Source Separation Via Primitive Auditory Clustering And Hidden-Unit Bert",
    "normalized_title": "pa-hubert:self-supervisedmusicsourceseparationviaprimitiveauditoryclusteringandhidden-unitbert",
    "doi": "10.1109/icasspw59220.2023.10193575",
    "openalex_id": "https://openalex.org/w4385478423",
    "arxiv_id": "",
    "published_date": "2023-06-04",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Towards Practical and Efficient Image-to-Speech Captioning with Vision-Language Pre-Training and Multi-Modal Tokens",
    "normalized_title": "towardspracticalandefficientimage-to-speechcaptioningwithvision-languagepre-trainingandmulti-modaltokens",
    "doi": "10.1109/icassp48485.2024.10446888",
    "openalex_id": "https://openalex.org/w4392904292",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "FunCodec: A Fundamental, Reproducible and Integrable Open-Source Toolkit for Neural Speech Codec",
    "normalized_title": "funcodec:afundamental,reproducibleandintegrableopen-sourcetoolkitforneuralspeechcodec",
    "doi": "10.1109/icassp48485.2024.10447523",
    "openalex_id": "https://openalex.org/w4392903389",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "ZMM-TTS: Zero-Shot Multilingual and Multispeaker Speech Synthesis Conditioned on Self-Supervised Discrete Speech Representations",
    "normalized_title": "zmm-tts:zero-shotmultilingualandmultispeakerspeechsynthesisconditionedonself-superviseddiscretespeechrepresentations",
    "doi": "10.1109/taslp.2024.3451951",
    "openalex_id": "https://openalex.org/w4402301063",
    "arxiv_id": "",
    "published_date": "2024-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "VoxtLM: Unified Decoder-Only Models for Consolidating Speech Recognition, Synthesis and Speech, Text Continuation Tasks",
    "normalized_title": "voxtlm:unifieddecoder-onlymodelsforconsolidatingspeechrecognition,synthesisandspeech,textcontinuationtasks",
    "doi": "10.1109/icassp48485.2024.10447112",
    "openalex_id": "https://openalex.org/w4392904805",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study",
    "normalized_title": "exploringspeechrecognition,translation,andunderstandingwithdiscretespeechunits:acomparativestudy",
    "doi": "10.1109/icassp48485.2024.10447929",
    "openalex_id": "https://openalex.org/w4392909068",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Speaker Adaptive Text-to-Speech With Timbre-Normalized Vector-Quantized Feature",
    "normalized_title": "speakeradaptivetext-to-speechwithtimbre-normalizedvector-quantizedfeature",
    "doi": "10.1109/taslp.2023.3308374",
    "openalex_id": "https://openalex.org/w4386133927",
    "arxiv_id": "",
    "published_date": "2023-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Fewer-Token Neural Speech Codec with Time-Invariant Codes",
    "normalized_title": "fewer-tokenneuralspeechcodecwithtime-invariantcodes",
    "doi": "10.1109/icassp48485.2024.10448454",
    "openalex_id": "https://openalex.org/w4392903006",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "TextrolSpeech: A Text Style Control Speech Corpus with Codec Language Text-to-Speech Models",
    "normalized_title": "textrolspeech:atextstylecontrolspeechcorpuswithcodeclanguagetext-to-speechmodels",
    "doi": "10.1109/icassp48485.2024.10445879",
    "openalex_id": "https://openalex.org/w4392904245",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Discrete Audio Representation as an Alternative to Mel-Spectrograms for Speaker and Speech Recognition",
    "normalized_title": "discreteaudiorepresentationasanalternativetomel-spectrogramsforspeakerandspeechrecognition",
    "doi": "10.1109/icassp48485.2024.10446998",
    "openalex_id": "https://openalex.org/w4392904154",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Yet Another Generative Model for Room Impulse Response Estimation",
    "normalized_title": "yetanothergenerativemodelforroomimpulseresponseestimation",
    "doi": "10.1109/waspaa58266.2023.10248189",
    "openalex_id": "https://openalex.org/w4386764631",
    "arxiv_id": "",
    "published_date": "2023-09-15",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Toward Joint Language Modeling for Speech Units and Text",
    "normalized_title": "towardjointlanguagemodelingforspeechunitsandtext",
    "doi": "10.18653/v1/2023.findings-emnlp.438",
    "openalex_id": "https://openalex.org/w4389518827",
    "arxiv_id": "",
    "published_date": "2023-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Generative De-Quantization for Neural Speech Codec Via Latent Diffusion",
    "normalized_title": "generativede-quantizationforneuralspeechcodecvialatentdiffusion",
    "doi": "10.1109/icassp48485.2024.10446556",
    "openalex_id": "https://openalex.org/w4392931975",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Stack-and-Delay: A New Codebook Pattern for Music Generation",
    "normalized_title": "stack-and-delay:anewcodebookpatternformusicgeneration",
    "doi": "10.1109/icassp48485.2024.10447392",
    "openalex_id": "https://openalex.org/w4392909680",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Generation-Based Target Speech Extraction with Speech Discretization and Vocoder",
    "normalized_title": "generation-basedtargetspeechextractionwithspeechdiscretizationandvocoder",
    "doi": "10.1109/icassp48485.2024.10446418",
    "openalex_id": "https://openalex.org/w4392903977",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "VQVAE Unsupervised Unit Discovery and Multi-Scale Code2Spec Inverter for Zerospeech Challenge 2019",
    "normalized_title": "vqvaeunsupervisedunitdiscoveryandmulti-scalecode2specinverterforzerospeechchallenge2019",
    "doi": "10.21437/interspeech.2019-3232",
    "openalex_id": "https://openalex.org/w2972374322",
    "arxiv_id": "",
    "published_date": "2019-09-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Speech Resynthesis from Discrete Disentangled Self-Supervised Representations",
    "normalized_title": "speechresynthesisfromdiscretedisentangledself-supervisedrepresentations",
    "doi": "10.21437/interspeech.2021-475",
    "openalex_id": "https://openalex.org/w3140429000",
    "arxiv_id": "",
    "published_date": "2021-08-27",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Any-to-One Sequence-to-Sequence Voice Conversion Using Self-Supervised Discrete Speech Representations",
    "normalized_title": "any-to-onesequence-to-sequencevoiceconversionusingself-superviseddiscretespeechrepresentations",
    "doi": "10.1109/icassp39728.2021.9415079",
    "openalex_id": "https://openalex.org/w3161695192",
    "arxiv_id": "",
    "published_date": "2021-05-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "One-Shot Voice Conversion by Vector Quantization",
    "normalized_title": "one-shotvoiceconversionbyvectorquantization",
    "doi": "10.1109/icassp40776.2020.9053854",
    "openalex_id": "https://openalex.org/w3015434413",
    "arxiv_id": "",
    "published_date": "2020-04-09",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "The Academia Sinica Systems of Voice Conversion for VCC2020",
    "normalized_title": "theacademiasinicasystemsofvoiceconversionforvcc2020",
    "doi": "10.21437/vccbc.2020-28",
    "openalex_id": "https://openalex.org/w3091890228",
    "arxiv_id": "",
    "published_date": "2020-10-30",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Hubert: How Much Can a Bad Teacher Benefit ASR Pre-Training?",
    "normalized_title": "hubert:howmuchcanabadteacherbenefitasrpre-training?",
    "doi": "10.1109/icassp39728.2021.9414460",
    "openalex_id": "https://openalex.org/w3160799772",
    "arxiv_id": "",
    "published_date": "2021-05-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units",
    "normalized_title": "hubert:self-supervisedspeechrepresentationlearningbymaskedpredictionofhiddenunits",
    "doi": "10.1109/taslp.2021.3122291",
    "openalex_id": "https://openalex.org/w3169320628",
    "arxiv_id": "",
    "published_date": "2021-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "HuBERT: Self-Supervised Speech Representation Learning by Masked\\n Prediction of Hidden Units",
    "normalized_title": "hubert:self-supervisedspeechrepresentationlearningbymasked\\npredictionofhiddenunits",
    "doi": "10.48550/arxiv.2106.07447",
    "openalex_id": "https://openalex.org/w4287119707",
    "arxiv_id": "",
    "published_date": "2021-06-14",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "VQTTS: High-Fidelity Text-to-Speech Synthesis with Self-Supervised VQ Acoustic Feature",
    "normalized_title": "vqtts:high-fidelitytext-to-speechsynthesiswithself-supervisedvqacousticfeature",
    "doi": "10.21437/interspeech.2022-489",
    "openalex_id": "https://openalex.org/w4226132755",
    "arxiv_id": "",
    "published_date": "2022-09-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations",
    "normalized_title": "vq-wav2vec:self-supervisedlearningofdiscretespeechrepresentations",
    "doi": "10.48550/arxiv.1910.05453",
    "openalex_id": "https://openalex.org/w2979476256",
    "arxiv_id": "",
    "published_date": "2019-10-12",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations",
    "normalized_title": "wav2vec2.0:aframeworkforself-supervisedlearningofspeechrepresentations",
    "doi": "10.48550/arxiv.2006.11477",
    "openalex_id": "https://openalex.org/w3036601975",
    "arxiv_id": "",
    "published_date": "2020-06-20",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "AudioLM: A Language Modeling Approach to Audio Generation",
    "normalized_title": "audiolm:alanguagemodelingapproachtoaudiogeneration",
    "doi": "10.1109/taslp.2023.3288409",
    "openalex_id": "https://openalex.org/w4381786045",
    "arxiv_id": "",
    "published_date": "2023-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers",
    "normalized_title": "naturalspeech2:latentdiffusionmodelsarenaturalandzero-shotspeechandsingingsynthesizers",
    "doi": "10.48550/arxiv.2304.09116",
    "openalex_id": "https://openalex.org/w4366460484",
    "arxiv_id": "",
    "published_date": "2023-04-18",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "w2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training",
    "normalized_title": "w2v-bert:combiningcontrastivelearningandmaskedlanguagemodelingforself-supervisedspeechpre-training",
    "doi": "10.1109/asru51503.2021.9688253",
    "openalex_id": "https://openalex.org/w4226033575",
    "arxiv_id": "",
    "published_date": "2021-12-13",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Phonetic Analysis of Self-supervised Representations of English Speech",
    "normalized_title": "phoneticanalysisofself-supervisedrepresentationsofenglishspeech",
    "doi": "10.21437/interspeech.2022-10884",
    "openalex_id": "https://openalex.org/w4297841405",
    "arxiv_id": "",
    "published_date": "2022-09-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "A Vector Quantized Masked Autoencoder for Speech Emotion Recognition",
    "normalized_title": "avectorquantizedmaskedautoencoderforspeechemotionrecognition",
    "doi": "10.1109/icasspw59220.2023.10193151",
    "openalex_id": "https://openalex.org/w4385484923",
    "arxiv_id": "",
    "published_date": "2023-06-04",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Disentangled Feature Learning for Real-Time Neural Speech Coding",
    "normalized_title": "disentangledfeaturelearningforreal-timeneuralspeechcoding",
    "doi": "10.1109/icassp49357.2023.10094723",
    "openalex_id": "https://openalex.org/w4372259964",
    "arxiv_id": "",
    "published_date": "2023-05-05",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "UnitY: Two-pass Direct Speech-to-speech Translation with Discrete Units",
    "normalized_title": "unity:two-passdirectspeech-to-speechtranslationwithdiscreteunits",
    "doi": "10.18653/v1/2023.acl-long.872",
    "openalex_id": "https://openalex.org/w4385570550",
    "arxiv_id": "",
    "published_date": "2023-01-01",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Low Bit-rate Speech Coding with VQ-VAE and a WaveNet Decoder",
    "normalized_title": "lowbit-ratespeechcodingwithvq-vaeandawavenetdecoder",
    "doi": "10.1109/icassp.2019.8683277",
    "openalex_id": "https://openalex.org/w2935711438",
    "arxiv_id": "",
    "published_date": "2019-04-16",
    "criteria_hash": "729506d3cfb76000acabe7045f7f724cf627600e4825b13586eef076dc26d334",
    "source": "snowball_review",
    "updated_at": "2026-01-24T12:06:55.355798+00:00",
    "round": 1
  }
]