openalex_id,doi,title,abstract,referenced_works,publication_date
https://openalex.org/W3204915839,https://doi.org/10.1109/taslp.2022.3180684,Unsupervised Speech Segmentation and Variable Rate Representation Learning Using Segmental Contrastive Predictive Coding,"Typically, unsupervised segmentation of speech into the phone- and word-like units are treated as separate tasks and are often done via different methods which do not fully leverage the inter-dependence of the two tasks. Here, we unify them and propose a technique that can jointly perform both, showing that these two tasks indeed benefit from each other. Recent attempts employ self-supervised learning, such as contrastive predictive coding (CPC), where the next frame is predicted given past context. However, CPC only looks at the audio signal's frame-level structure. We overcome this limitation with a segmental contrastive predictive coding (SCPC) framework to model the signal structure at a higher level, e.g., phone level. A convolutional neural network learns frame-level representation from the raw waveform via noise-contrastive estimation (NCE). A differentiable boundary detector finds variable-length segments, which are then used to optimize a segment encoder via NCE to learn segment representations. The differentiable boundary detector allows us to train frame-level and segment-level encoders jointly. Experiments show that our single model outperforms existing phone and word segmentation methods on TIMIT and Buckeye datasets. We analyze the impact of the threshold on boundary detector performance, and our results suggest that automatically learning the boundary threshold can be as effective as manually tuning that threshold. We discover that phone class impacts the boundary detection performance, and the boundaries between successive vowels or semivowels are the most difficult. Finally, we use SCPC to extract speech features at the segment level rather than at the uniformly spaced frame level (e.g., 10 ms) and produce variable rate representations that change according to the contents of the utterance. We can lower the feature extraction rate from the typical 100 Hz to as low as 14.5 Hz on average while still outperforming the hand-crafted features such as MFCC on the linear phone classification task.","['https://openalex.org/W6780218876', 'https://openalex.org/W6770506093', 'https://openalex.org/W2981857663', 'https://openalex.org/W2786608204', 'https://openalex.org/W2963620343', 'https://openalex.org/W2940544976', 'https://openalex.org/W2010188467', 'https://openalex.org/W2057007397', 'https://openalex.org/W2020607164', 'https://openalex.org/W2117041980', 'https://openalex.org/W2170659185', 'https://openalex.org/W6675022971', 'https://openalex.org/W2078769636', 'https://openalex.org/W2468716020', 'https://openalex.org/W2747192917', 'https://openalex.org/W2964169922', 'https://openalex.org/W2890718354', 'https://openalex.org/W2160815625', 'https://openalex.org/W2150769028', 'https://openalex.org/W4301204483', 'https://openalex.org/W6844194202', 'https://openalex.org/W2973049979', 'https://openalex.org/W3096656254', 'https://openalex.org/W6755207826', 'https://openalex.org/W6766673545', 'https://openalex.org/W6774314701', 'https://openalex.org/W6682948231', 'https://openalex.org/W3198782837', 'https://openalex.org/W2882319491', 'https://openalex.org/W2115867364', 'https://openalex.org/W2126377586', 'https://openalex.org/W2115197214', 'https://openalex.org/W6789826613', 'https://openalex.org/W2145410271', 'https://openalex.org/W2963137467', 'https://openalex.org/W2962799131', 'https://openalex.org/W3198134274', 'https://openalex.org/W3100270690', 'https://openalex.org/W6769196770', 'https://openalex.org/W2117126688', 'https://openalex.org/W2972794572', 'https://openalex.org/W1778492285', 'https://openalex.org/W6631526040', 'https://openalex.org/W2111732304', 'https://openalex.org/W2127141656', 'https://openalex.org/W6638749077', 'https://openalex.org/W2146444479', 'https://openalex.org/W6774456908', 'https://openalex.org/W2752796333', 'https://openalex.org/W6690026940', 'https://openalex.org/W130754613', 'https://openalex.org/W3095361818', 'https://openalex.org/W2890704021', 'https://openalex.org/W6795952400', 'https://openalex.org/W2719865699', 'https://openalex.org/W6790356757', 'https://openalex.org/W6786696081', 'https://openalex.org/W2949382160', 'https://openalex.org/W2152790380', 'https://openalex.org/W3169072315', 'https://openalex.org/W2100768664', 'https://openalex.org/W3027324582', 'https://openalex.org/W3034978746', 'https://openalex.org/W2963799213', 'https://openalex.org/W2963341956', 'https://openalex.org/W4287173589', 'https://openalex.org/W2991213871', 'https://openalex.org/W3008499099', 'https://openalex.org/W2242818861', 'https://openalex.org/W1525748279', 'https://openalex.org/W3125709657', 'https://openalex.org/W4394671563', 'https://openalex.org/W3036601975', 'https://openalex.org/W2996383576', 'https://openalex.org/W2973026522', 'https://openalex.org/W3099782249', 'https://openalex.org/W2965373594', 'https://openalex.org/W2601836666', 'https://openalex.org/W3110458199', 'https://openalex.org/W1828163288', 'https://openalex.org/W1994458317', 'https://openalex.org/W3098643042', 'https://openalex.org/W2842511635', 'https://openalex.org/W3112613336', 'https://openalex.org/W3127686677', 'https://openalex.org/W2478415332']",2022-01-01
https://openalex.org/W2890718354,https://doi.org/10.1109/icassp.2018.8462264,Phoneme Based Embedded Segmental K-Means for Unsupervised Term Discovery,"Identifying and grouping the frequently occurring word-like patterns from raw acoustic waveforms is an important task in the zero resource speech processing. Embedded segmental K-means (ES-KMeans) discovers both the word boundaries and the word types from raw data. Starting from an initial set of subword boundaries, the ES-Kmeans iteratively eliminates some of the boundaries to arrive at frequently occurring longer word patterns. Notice that the initial word boundaries will not be adjusted during the process. As a result, the performance of the ES-Kmeans critically depends on the initial subword boundaries. Originally, syllable boundaries were used to initialize ES-Kmeans. In this paper, we propose to use a phoneme segmentation method that produces boundaries closer to true boundaries for ES-KMeans initialization. The use of shorter units increases the number of initial boundaries which leads to a significant increment in the computational complexity. To reduce the computational cost, we extract compact lower dimensional embeddings from an auto-encoder. The proposed algorithm is benchmarked on Zero Resource 2017 challenge, which consists of 70 hours of unlabeled data across three languages, viz. English, French, and Mandarin. The proposed algorithm outperforms the baseline system without any language-specific parameter tuning.","['https://openalex.org/W6638159135', 'https://openalex.org/W6675022971', 'https://openalex.org/W2117041980', 'https://openalex.org/W2078769636', 'https://openalex.org/W2106284094', 'https://openalex.org/W2114347655', 'https://openalex.org/W2057007397', 'https://openalex.org/W2032943813', 'https://openalex.org/W1778492285', 'https://openalex.org/W6691362072', 'https://openalex.org/W2154093685', 'https://openalex.org/W4244165801', 'https://openalex.org/W2020944885', 'https://openalex.org/W2516890051', 'https://openalex.org/W2163922914', 'https://openalex.org/W2020607164', 'https://openalex.org/W6602092770', 'https://openalex.org/W2747192917', 'https://openalex.org/W2346964103', 'https://openalex.org/W2170659185', 'https://openalex.org/W6973666849', 'https://openalex.org/W2295297373', 'https://openalex.org/W6751832535', 'https://openalex.org/W2398490608', 'https://openalex.org/W2059652594', 'https://openalex.org/W1577418252', 'https://openalex.org/W6644682428', 'https://openalex.org/W2190506272', 'https://openalex.org/W1977556410', 'https://openalex.org/W2786608204', 'https://openalex.org/W2100768664', 'https://openalex.org/W51277926', 'https://openalex.org/W2747943889', 'https://openalex.org/W2803005441', 'https://openalex.org/W2964169922', 'https://openalex.org/W1796128977', 'https://openalex.org/W2251025892']",2018-04-01
https://openalex.org/W2971041032,https://doi.org/10.1109/taslp.2019.2937953,Exploiting Cross-Lingual Speaker and Phonetic Diversity for Unsupervised Subword Modeling,"This research addresses the problem of acoustic modeling of low-resource\nlanguages for which transcribed training data is absent. The goal is to learn\nrobust frame-level feature representations that can be used to identify and\ndistinguish subword-level speech units. The proposed feature representations\ncomprise various types of multilingual bottleneck features (BNFs) that are\nobtained via multi-task learning of deep neural networks (MTL-DNN). One of the\nkey problems is how to acquire high-quality frame labels for untranscribed\ntraining data to facilitate supervised DNN training. It is shown that learning\nof robust BNF representations can be achieved by effectively leveraging\ntranscribed speech data and well-trained automatic speech recognition (ASR)\nsystems from one or more out-of-domain (resource-rich) languages. Out-of-domain\nASR systems can be applied to perform speaker adaptation with untranscribed\ntraining data of the target language, and to decode the training speech into\nframe-level labels for DNN training. It is also found that better frame labels\ncan be generated by considering temporal dependency in speech when performing\nframe clustering. The proposed methods of feature learning are evaluated on the\nstandard task of unsupervised subword modeling in Track 1 of the ZeroSpeech\n2017 Challenge. The best performance achieved by our system is $9.7\\%$ in terms\nof across-speaker triphone minimal-pair ABX error rate, which is comparable to\nthe best systems reported recently. Lastly, our investigation reveals that the\ncloseness between target languages and out-of-domain languages and the amount\nof available training data for individual target languages could have\nsignificant impact on the goodness of learned features.\n","['https://openalex.org/W2747192917', 'https://openalex.org/W1975728937', 'https://openalex.org/W6677803786', 'https://openalex.org/W2785860501', 'https://openalex.org/W2826003142', 'https://openalex.org/W2767122664', 'https://openalex.org/W2167845555', 'https://openalex.org/W6640828828', 'https://openalex.org/W2921843068', 'https://openalex.org/W2594951208', 'https://openalex.org/W3100270690', 'https://openalex.org/W6638159135', 'https://openalex.org/W2785415724', 'https://openalex.org/W2627092829', 'https://openalex.org/W2963266252', 'https://openalex.org/W2787447541', 'https://openalex.org/W2586754519', 'https://openalex.org/W2759889345', 'https://openalex.org/W2895297209', 'https://openalex.org/W2810166208', 'https://openalex.org/W2509930204', 'https://openalex.org/W4239943352', 'https://openalex.org/W6631362777', 'https://openalex.org/W2057653135', 'https://openalex.org/W1528778941', 'https://openalex.org/W2513125788', 'https://openalex.org/W2614542633', 'https://openalex.org/W2295297373', 'https://openalex.org/W2786902352', 'https://openalex.org/W2787223168', 'https://openalex.org/W2889228998', 'https://openalex.org/W6677154653', 'https://openalex.org/W1545920196', 'https://openalex.org/W6786045457', 'https://openalex.org/W6678947187', 'https://openalex.org/W6712553779', 'https://openalex.org/W2514600732', 'https://openalex.org/W2160815625', 'https://openalex.org/W2963620343', 'https://openalex.org/W6748325621', 'https://openalex.org/W6640777149', 'https://openalex.org/W2055408826', 'https://openalex.org/W2072563337', 'https://openalex.org/W6973666849', 'https://openalex.org/W2005708641', 'https://openalex.org/W6696934422', 'https://openalex.org/W2400549570', 'https://openalex.org/W2120209245', 'https://openalex.org/W162588823', 'https://openalex.org/W2345811097']",2019-08-28
https://openalex.org/W3003750857,https://doi.org/10.1109/globalsip45357.2019.8969412,Virtual Phone Discovery for Speech Synthesis Without Text,The objective of this work is to re-synthesize speech directly from the speech signals without using any text in a different speaker's voice. The speech signals are transformed into a sequence of acoustic subword units or virtual phones which are discovered automatically from the given speech signals in an unsupervised manner. The speech signal is initially segmented into acoustically homogeneous segments through kernel-Gram segmentation using MFCC and autoencoder bottleneck features. These segments are then clustered using different clustering techniques. The cluster labels thus obtained are considered as virtual phone units which are used to transcribe the speech signals. The virtual phones for the utterances to be resynthesized are encoded as one-hot vector sequences. Deep neural network based duration model and acoustic model are trained for synthesis using these sequences. A vocoder is used to synthesize speech in target speaker's voice from the features estimated by the acoustic model. The performance evaluation is done on ZeroSpeech 2019 challenge on English and Indonesian language. The bitrate and speaker similarity were found to be better than the challenge baseline with slightly lower intelligibility due to the compact encoding.,"['https://openalex.org/W2786608204', 'https://openalex.org/W2346964103', 'https://openalex.org/W6697293080', 'https://openalex.org/W6675022971', 'https://openalex.org/W2347098582', 'https://openalex.org/W2745710152', 'https://openalex.org/W2345811097', 'https://openalex.org/W1967924372', 'https://openalex.org/W2052697931', 'https://openalex.org/W1796128977', 'https://openalex.org/W2020607164', 'https://openalex.org/W2826003142', 'https://openalex.org/W1510007267', 'https://openalex.org/W2134202996', 'https://openalex.org/W2962699523', 'https://openalex.org/W2964135678', 'https://openalex.org/W2532494225', 'https://openalex.org/W2963830550', 'https://openalex.org/W2902070858', 'https://openalex.org/W2747192917', 'https://openalex.org/W2803005441', 'https://openalex.org/W2890718354', 'https://openalex.org/W2598638573', 'https://openalex.org/W2059652594', 'https://openalex.org/W6680735885', 'https://openalex.org/W1975728937', 'https://openalex.org/W2964169922', 'https://openalex.org/W2471520273', 'https://openalex.org/W2940544976', 'https://openalex.org/W2057007397', 'https://openalex.org/W2398490608', 'https://openalex.org/W2407614114', 'https://openalex.org/W6631362777', 'https://openalex.org/W2774848319', 'https://openalex.org/W2973026522', 'https://openalex.org/W2963620343', 'https://openalex.org/W1524333225', 'https://openalex.org/W2165874743', 'https://openalex.org/W2141465109', 'https://openalex.org/W2100768664']",2019-11-01
https://openalex.org/W3169072315,https://doi.org/10.21437/interspeech.2021-1874,Segmental Contrastive Predictive Coding for Unsupervised Word Segmentation,"Automatic detection of phoneme or word-like units is one of the core objectives in zero-resource speech processing. Recent attempts employ self-supervised training methods, such as contrastive predictive coding (CPC), where the next frame is predicted given past context. However, CPC only looks at the audio signal's frame-level structure. We overcome this limitation with a segmental contrastive predictive coding (SCPC) framework that can model the signal structure at a higher level e.g. at the phoneme level. In this framework, a convolutional neural network learns frame-level representation from the raw waveform via noise-contrastive estimation (NCE). A differentiable boundary detector finds variable-length segments, which are then used to optimize a segment encoder via NCE to learn segment representations. The differentiable boundary detector allows us to train frame-level and segment-level encoders jointly. Typically, phoneme and word segmentation are treated as separate tasks. We unify them and experimentally show that our single model outperforms existing phoneme and word segmentation methods on TIMIT and Buckeye datasets. We analyze the impact of boundary threshold and when is the right time to include the segmental loss in the learning process.","['https://openalex.org/W130754613', 'https://openalex.org/W2078769636', 'https://openalex.org/W2747192917', 'https://openalex.org/W2170659185', 'https://openalex.org/W3127686677', 'https://openalex.org/W2117126688', 'https://openalex.org/W2126377586', 'https://openalex.org/W2963799213', 'https://openalex.org/W2963137467', 'https://openalex.org/W2842511635', 'https://openalex.org/W2890718354', 'https://openalex.org/W2242818861', 'https://openalex.org/W2145410271', 'https://openalex.org/W2973049979', 'https://openalex.org/W2940544976', 'https://openalex.org/W2152790380', 'https://openalex.org/W2100768664', 'https://openalex.org/W2601836666', 'https://openalex.org/W3036601975', 'https://openalex.org/W2964169922', 'https://openalex.org/W3096656254', 'https://openalex.org/W2478415332', 'https://openalex.org/W3112613336', 'https://openalex.org/W2057007397', 'https://openalex.org/W2996383576', 'https://openalex.org/W2972794572', 'https://openalex.org/W3027324582', 'https://openalex.org/W3125709657', 'https://openalex.org/W3099782249', 'https://openalex.org/W2468716020', 'https://openalex.org/W2020607164']",2021-08-27
https://openalex.org/W4391182775,https://doi.org/10.1109/mysurucon59703.2023.10396940,An Unsupervised Approach to Speech Segmentation using Auto Resonance Networks,"Automatic speech segmentation finds application in speech recognition, speaker diarization etc. However, it is challenging as it demands huge labelled data. Unsupervised approach can overcome the laborious labeling task. Auto resonance networks are one choice for unsupervised approach. Recently auto resonance networks have been used in classification problems. This work proposes an unsupervised approach for speech segmentation using auto resonance networks. The system is tested using the standard TIMIT database and a few pathological speech utterances. Results show that the speech frames belonging to the same broad class are assigned to the same cluster. The results are compared with another neural network approach, namely, self organizing maps.","['https://openalex.org/W2158056182', 'https://openalex.org/W2171631590', 'https://openalex.org/W2510796129', 'https://openalex.org/W2747192917', 'https://openalex.org/W3096656254', 'https://openalex.org/W3198134274', 'https://openalex.org/W3204915839', 'https://openalex.org/W3085861818', 'https://openalex.org/W3157070662', 'https://openalex.org/W2132663820', 'https://openalex.org/W6789826613', 'https://openalex.org/W2018363392', 'https://openalex.org/W1990517717', 'https://openalex.org/W3016551780', 'https://openalex.org/W3198482860']",2023-12-01
https://openalex.org/W4390887450,https://doi.org/10.1109/taslp.2024.3350888,Slowness Regularized Contrastive Predictive Coding for Acoustic Unit Discovery,"Self-supervised methods such as Contrastive predictive Coding (CPC) have greatly improved the quality of the unsupervised representations. These representations significantly reduce the amount of labeled data needed for downstream task performance, such as automatic speech recognition. CPC learns representations by learning to predict future frames given current frames. Based on the observation that the acoustic information, e.g., phones, changes slower than the feature extraction rate in CPC, we propose regularization techniques that impose slowness constraints on the features. Here we propose two regularization techniques: Self-expressing constraint and Left-or-Right regularization. We evaluate the proposed model on ABX and linear phone classification tasks, acoustic unit discovery, and automatic speech recognition. The regularized CPC trained on 100 hours of unlabeled data matches the performance of the baseline CPC trained on 360 hours of unlabeled data. We also show that our regularization techniques are complementary to data augmentation and can further boost the system's performance. In monolingual, cross-lingual, or multilingual settings, with/without data augmentation, regardless of the amount of data used for training, our regularized models outperformed the baseline CPC models on the ABX task.","['https://openalex.org/W2160815625', 'https://openalex.org/W2150769028', 'https://openalex.org/W4301204483', 'https://openalex.org/W2057007397', 'https://openalex.org/W2020607164', 'https://openalex.org/W2117041980', 'https://openalex.org/W2170659185', 'https://openalex.org/W6675022971', 'https://openalex.org/W2078769636', 'https://openalex.org/W2468716020', 'https://openalex.org/W2747192917', 'https://openalex.org/W2964169922', 'https://openalex.org/W2890718354', 'https://openalex.org/W6844194202', 'https://openalex.org/W2973049979', 'https://openalex.org/W6780218876', 'https://openalex.org/W3016181583', 'https://openalex.org/W6755207826', 'https://openalex.org/W6766673545', 'https://openalex.org/W3159481202', 'https://openalex.org/W4385822676', 'https://openalex.org/W3100270690', 'https://openalex.org/W3198782837', 'https://openalex.org/W3197974236', 'https://openalex.org/W3209993061', 'https://openalex.org/W6838949706', 'https://openalex.org/W3097159218', 'https://openalex.org/W2936774411', 'https://openalex.org/W3144810982', 'https://openalex.org/W2786608204', 'https://openalex.org/W2346964103', 'https://openalex.org/W2963620343', 'https://openalex.org/W2940544976', 'https://openalex.org/W6799172387', 'https://openalex.org/W2963720603', 'https://openalex.org/W1796128977', 'https://openalex.org/W6640963894', 'https://openalex.org/W2752796333', 'https://openalex.org/W3096656254', 'https://openalex.org/W3095361818', 'https://openalex.org/W2146444479', 'https://openalex.org/W6774456908', 'https://openalex.org/W3198134274', 'https://openalex.org/W4313182775', 'https://openalex.org/W3204915839', 'https://openalex.org/W2395899413', 'https://openalex.org/W4385245566', 'https://openalex.org/W2787447541', 'https://openalex.org/W3198815374']",2024-01-01
https://openalex.org/W2899069432,https://doi.org/10.1109/icassp.2019.8683639,Truly Unsupervised Acoustic Word Embeddings Using Weak Top-down Constraints in Encoder-decoder Models,"We investigate unsupervised models that can map a variable-duration speech segment to a fixed-dimensional representation. In settings where unlabelled speech is the only available resource, such acoustic word embeddings can form the basis for ""zero-resource"" speech search, discovery and indexing systems. Most existing unsupervised embedding methods still use some supervision, such as word or phoneme boundaries. Here we propose the encoder-decoder correspondence autoencoder (EncDec-CAE), which, instead of true word segments, uses automatically discovered segments: an unsupervised term discovery system finds pairs of words of the same unknown type, and the EncDec-CAE is trained to reconstruct one word given the other as input. We compare it to a standard encoder-decoder autoencoder (AE), a variational AE with a prior over its latent embedding, and downsampling. EncDec-CAE outperforms its closest competitor by 24% relative in average precision on two languages in a word discrimination task.","['https://openalex.org/W6631190155', 'https://openalex.org/W6743624039', 'https://openalex.org/W2250742840', 'https://openalex.org/W6638159135', 'https://openalex.org/W6720208624', 'https://openalex.org/W6714100551', 'https://openalex.org/W2057007397', 'https://openalex.org/W2044138293', 'https://openalex.org/W2145410271', 'https://openalex.org/W1577418252', 'https://openalex.org/W6745117592', 'https://openalex.org/W2802557066', 'https://openalex.org/W1778492285', 'https://openalex.org/W2398490608', 'https://openalex.org/W6735305794', 'https://openalex.org/W2747192917', 'https://openalex.org/W2072054026', 'https://openalex.org/W2059652594', 'https://openalex.org/W2963571336', 'https://openalex.org/W6640212811', 'https://openalex.org/W2963620343', 'https://openalex.org/W2166681504', 'https://openalex.org/W2346964103', 'https://openalex.org/W2758697525', 'https://openalex.org/W6640963894', 'https://openalex.org/W2010188467', 'https://openalex.org/W2171019095', 'https://openalex.org/W2114347655', 'https://openalex.org/W2025482506', 'https://openalex.org/W2126203737', 'https://openalex.org/W6704885441', 'https://openalex.org/W2578392894', 'https://openalex.org/W6751433836', 'https://openalex.org/W2962980711', 'https://openalex.org/W2889313720', 'https://openalex.org/W2963425185', 'https://openalex.org/W2157331557', 'https://openalex.org/W6753329955', 'https://openalex.org/W2964298108', 'https://openalex.org/W2963618559', 'https://openalex.org/W2964169922', 'https://openalex.org/W2884305338', 'https://openalex.org/W2963340922', 'https://openalex.org/W2467604901', 'https://openalex.org/W2951004968', 'https://openalex.org/W2964121744', 'https://openalex.org/W2407151108', 'https://openalex.org/W2187089797', 'https://openalex.org/W2291770225', 'https://openalex.org/W2347145335', 'https://openalex.org/W1796128977', 'https://openalex.org/W1924770834']",2019-04-17
https://openalex.org/W3044386551,https://doi.org/10.21437/interspeech.2020-3000,Self-Expressing Autoencoders for Unsupervised Spoken Term Discovery,"Unsupervised spoken term discovery consists of two tasks: finding the acoustic segment boundaries and labeling acoustically similar segments with the same labels. We perform segmentation based on the assumption that the frame feature vectors are more similar within a segment than across the segments. Therefore, for strong segmentation performance, it is crucial that the features represent the phonetic properties of a frame more than other factors of variability. We achieve this via a self-expressing autoencoder framework. It consists of a single encoder and two decoders with shared weights. The encoder projects the input features into a latent representation. One of the decoders tries to reconstruct the input from these latent representations and the other from the self-expressed version of them. We use the obtained features to segment and cluster the speech data. We evaluate the performance of the proposed method in the Zero Resource 2020 challenge unit discovery task. The proposed system consistently outperforms the baseline, demonstrating the usefulness of the method in learning representations.","['https://openalex.org/W2972794572', 'https://openalex.org/W2160815625', 'https://openalex.org/W2803005441', 'https://openalex.org/W1545920196', 'https://openalex.org/W2166637769', 'https://openalex.org/W2786608204', 'https://openalex.org/W2398490608', 'https://openalex.org/W2078769636', 'https://openalex.org/W2100768664', 'https://openalex.org/W2170659185', 'https://openalex.org/W2404799143', 'https://openalex.org/W2963620343', 'https://openalex.org/W2747192917', 'https://openalex.org/W2020607164', 'https://openalex.org/W1994458317', 'https://openalex.org/W2057007397', 'https://openalex.org/W2468716020', 'https://openalex.org/W2964169922', 'https://openalex.org/W2126203737', 'https://openalex.org/W2150769028', 'https://openalex.org/W2991213871', 'https://openalex.org/W2890718354', 'https://openalex.org/W2400549570', 'https://openalex.org/W126222424', 'https://openalex.org/W1922655562', 'https://openalex.org/W2981857663', 'https://openalex.org/W2251025892', 'https://openalex.org/W2940544976', 'https://openalex.org/W1796128977']",2020-10-25
https://openalex.org/W2406349064,https://doi.org/10.21437/interspeech.2014-228,Evaluating speech features with the minimal-pair ABX task (II): resistance to noise,"The Minimal-Pair ABX (MP-ABX) paradigm has been proposed as a method for evaluating speech features for zeroresource/unsupervised speech technologies. We apply it in a phoneme discrimination task on the Articulation Index corpus to evaluate the resistance to noise of various speech features. In Experiment 1, we evaluate the robustness to additive noise at different signal-to-noise ratios, using car and babble noise from the Aurora-4 database and white noise. In Experiment 2, we examine the robustness to different kinds of convolutional noise. In both experiments we consider two classes of techniques to induce noise resistance: smoothing of the time-frequency representation and short-term adaptation in the time-domain. We consider smoothing along the spectral axis (as in PLP) and along the time axis (as in FDLP). For short-term adaptation in the time-domain, we compare the use of a static compressive non-linearity followed by RASTA filtering to an adaptive compression scheme.","['https://openalex.org/W2160719354', 'https://openalex.org/W2407151108', 'https://openalex.org/W1571339265', 'https://openalex.org/W1991163061', 'https://openalex.org/W2089177488', 'https://openalex.org/W2117041980', 'https://openalex.org/W2096765209', 'https://openalex.org/W2406820985', 'https://openalex.org/W2062164080', 'https://openalex.org/W2980286501', 'https://openalex.org/W2054139811', 'https://openalex.org/W2090861223', 'https://openalex.org/W2137075158', 'https://openalex.org/W2025482506', 'https://openalex.org/W2232131953', 'https://openalex.org/W2041777218', 'https://openalex.org/W156237177', 'https://openalex.org/W2046331056', 'https://openalex.org/W2055408826', 'https://openalex.org/W2100768664', 'https://openalex.org/W2395899413']",2014-09-14
https://openalex.org/W2140991203,https://doi.org/10.3115/1687878.1687894,Bayesian unsupervised word segmentation with nested Pitman-Yor language modeling,"In this paper, we propose a new Bayesian model for fully unsupervised word segmentation and an efficient blocked Gibbs sampler combined with dynamic programming for inference. Our model is a nested hierarchical Pitman-Yor language model, where Pitman-Yor spelling model is embedded in the word model. We confirmed that it significantly outperforms previous reported results in both phonetic transcripts and standard datasets for Chinese and Japanese word segmentation. Our model is also considered as a way to construct an accurate word n-gram language model directly from characters of arbitrary language, without any ""word"" indications.","['https://openalex.org/W2159399018', 'https://openalex.org/W2188956218', 'https://openalex.org/W2005902041', 'https://openalex.org/W2122228338', 'https://openalex.org/W186138571', 'https://openalex.org/W2404744763', 'https://openalex.org/W2149741699', 'https://openalex.org/W263845233', 'https://openalex.org/W2126377586', 'https://openalex.org/W1934041838', 'https://openalex.org/W1998974009', 'https://openalex.org/W305655093', 'https://openalex.org/W4248373945', 'https://openalex.org/W2130416410', 'https://openalex.org/W2095907708', 'https://openalex.org/W165656722', 'https://openalex.org/W1539673959', 'https://openalex.org/W2076618452', 'https://openalex.org/W2037668034', 'https://openalex.org/W2126449874', 'https://openalex.org/W1995991622', 'https://openalex.org/W2164151151', 'https://openalex.org/W2159581406', 'https://openalex.org/W2108131731', 'https://openalex.org/W2154292407', 'https://openalex.org/W2154099718']",2009-01-01
https://openalex.org/W2126203737,https://doi.org/10.1109/asru.2009.5372931,Unsupervised spoken keyword spotting via segmental DTW on Gaussian posteriorgrams,"In this paper, we present an unsupervised learning framework to address the problem of detecting spoken keywords. Without any transcription information, a Gaussian Mixture Model is trained to label speech frames with a Gaussian posteriorgram. Given one or more spoken examples of a keyword, we use segmental dynamic time warping to compare the Gaussian posteriorgrams between keyword samples and test utterances. The keyword detection result is then obtained by ranking the distortion scores of all the test utterances. We examine the TIMIT corpus as a development set to tune the parameters in our system, and the MIT Lecture corpus for more substantial evaluation. The results demonstrate the viability and effectiveness of our unsupervised learning framework on the keyword spotting task.","['https://openalex.org/W201187342', 'https://openalex.org/W6649874456', 'https://openalex.org/W2122797512', 'https://openalex.org/W2099415988', 'https://openalex.org/W2153426278', 'https://openalex.org/W2155427043', 'https://openalex.org/W2171019095', 'https://openalex.org/W2116969213', 'https://openalex.org/W2114347655', 'https://openalex.org/W2111732304', 'https://openalex.org/W1975113979', 'https://openalex.org/W2103371184', 'https://openalex.org/W2103933358', 'https://openalex.org/W2107076535', 'https://openalex.org/W2405666970', 'https://openalex.org/W2115220208', 'https://openalex.org/W1578200545', 'https://openalex.org/W2086891622', 'https://openalex.org/W2128160875', 'https://openalex.org/W2101536075', 'https://openalex.org/W6684930139', 'https://openalex.org/W1999121090', 'https://openalex.org/W2169384404', 'https://openalex.org/W2142570735']",2009-12-01
https://openalex.org/W2346964103,https://doi.org/10.1016/j.procs.2016.04.031,The Zero Resource Speech Challenge 2015: Proposed Approaches and Results,"This paper reports on the results of the Zero Resource Speech Challenge 2015, the first unified benchmark for zero resource speech technology, which aims at the unsupervised discovery of subword and word units from raw speech. This paper discusses the motivation for the challenge, its data sets, tasks and baseline systems. We outline the ideas behind the systems that were submitted for the two challenge tracks: unsupervised subword unit modeling and spoken term discovery, and summarize their results. The results obtained by participating teams show great promise; many systems beat the provided baselines and some even perform better than comparable supervised systems.","['https://openalex.org/W2025482506', 'https://openalex.org/W2346964103', 'https://openalex.org/W2400668844', 'https://openalex.org/W2396043527', 'https://openalex.org/W2402366697', 'https://openalex.org/W2399576818', 'https://openalex.org/W2407614114', 'https://openalex.org/W2398490608', 'https://openalex.org/W1796128977', 'https://openalex.org/W2404799143', 'https://openalex.org/W2044138293', 'https://openalex.org/W2238331496', 'https://openalex.org/W2247128061', 'https://openalex.org/W2395899413', 'https://openalex.org/W2406349064', 'https://openalex.org/W2251025892', 'https://openalex.org/W2057007397', 'https://openalex.org/W2117126688', 'https://openalex.org/W2052697931', 'https://openalex.org/W2011845089', 'https://openalex.org/W2786608204']",2016-01-01
https://openalex.org/W2407614114,https://doi.org/10.21437/interspeech.2015-646,An evaluation of graph clustering methods for unsupervised term discovery,"Unsupervised term discovery (UTD) is the task of automatically identifying the repeated words and phrases in a collection of speech audio without relying on any language-specific resources. While the solution space for the task is far from fully explored, the dominant approach to date decomposes the discovery problem into two steps, where (i) segmental dynamic time warping is used to search the speech audio for repeated acoustic patterns, and (ii) these individual repetitions are partitioned into word/phrase categories using graph clustering. In this paper, we perform an unprecedented evaluation of a wide range of advanced graph clustering methods for the UTD task. We conduct our study in the evaluation framework of the Zero Resource Speech Challenge. We find that, for a range of features and languages, modularity-based clustering improves UTD performance most consistently, often by a wide margin. When paired with out-of-language deep neural net bottleneck features, we find performance near that of a high-resource UTD system.","['https://openalex.org/W66167291', 'https://openalex.org/W2164998314', 'https://openalex.org/W2047940964', 'https://openalex.org/W2059652594', 'https://openalex.org/W2060108852', 'https://openalex.org/W2025482506', 'https://openalex.org/W2151936673', 'https://openalex.org/W2168080440', 'https://openalex.org/W2786608204', 'https://openalex.org/W2052697931', 'https://openalex.org/W1539935047', 'https://openalex.org/W1991274470', 'https://openalex.org/W2132202037', 'https://openalex.org/W2089458547', 'https://openalex.org/W1967924372', 'https://openalex.org/W1580203226', 'https://openalex.org/W1545920196', 'https://openalex.org/W2036964623', 'https://openalex.org/W2072396742', 'https://openalex.org/W1983345514', 'https://openalex.org/W2018562712', 'https://openalex.org/W2401464865', 'https://openalex.org/W2124209874', 'https://openalex.org/W2062914951', 'https://openalex.org/W2294799344', 'https://openalex.org/W2131681506', 'https://openalex.org/W2057007397', 'https://openalex.org/W30845872', 'https://openalex.org/W229097380', 'https://openalex.org/W2078769636', 'https://openalex.org/W2109726592', 'https://openalex.org/W2114347655', 'https://openalex.org/W2095293504']",2015-09-06
https://openalex.org/W2020607164,https://doi.org/10.1109/icassp.2014.6855085,An auto-encoder based approach to unsupervised learning of subword units,In this paper we propose an autoencoder-based method for the unsupervised identification of subword units. We experiment with different types and architectures of autoencoders to asses what autoencoder properties are most important for this task. We first show that the encoded representation of speech produced by standard autencoders is more effective than Gaussian posteriorgrams in a spoken query classification task. Finally we evaluate the subword inventories produced by the proposed method both in terms of classification accuracy in a word classification task (with lexicon size up to 263 words) and in terms of consistency between subword transcription of different word examples of a same word type. The evaluation is carried out on Italian and American English datasets. © 2014 IEEE.,"['https://openalex.org/W6789826613', 'https://openalex.org/W2100495367', 'https://openalex.org/W7011707065', 'https://openalex.org/W6676071220', 'https://openalex.org/W2035424729', 'https://openalex.org/W2117041980', 'https://openalex.org/W2123237149', 'https://openalex.org/W6677919164', 'https://openalex.org/W6675022971', 'https://openalex.org/W2167655920', 'https://openalex.org/W1964917299', 'https://openalex.org/W6681096077', 'https://openalex.org/W2099415988', 'https://openalex.org/W2401464865', 'https://openalex.org/W2107789863', 'https://openalex.org/W2100768664', 'https://openalex.org/W2619993508', 'https://openalex.org/W3127686677', 'https://openalex.org/W2145094598', 'https://openalex.org/W2118858186', 'https://openalex.org/W2072128103', 'https://openalex.org/W2997574889', 'https://openalex.org/W2010800472']",2014-05-01
https://openalex.org/W1673310716,,A density-based algorithm for discovering clusters in large spatial Databases with Noise,"Clustering algorithms are attractive for the task of class identification in spatial databases. However, the application to large spatial databases rises the following requirements for clustering algorithms: minimal requirements of domain knowledge to determine the input parameters, discovery of clusters with arbitrary shape and good efficiency on large databases. The well-known clustering algorithms offer no solution to the combination of these requirements. In this paper, we present the new clustering algorithm DBSCAN relying on a density-based notion of clusters which is designed to discover clusters of arbitrary shape. DBSCAN requires only one input parameter and supports the user in determining an appropriate value for it. We performed an experimental evaluation of the effectiveness and efficiency of DBSCAN using synthetic data and real data of the SEQUOIA 2000 benchmark. The results of our experiments demonstrate that (1) DBSCAN is significantly more effective in discovering clusters of arbitrary shape than the well-known algorithm CLAR-ANS, and that (2) DBSCAN outperforms CLARANS by a factor of more than 100 in terms of efficiency.","['https://openalex.org/W1575476631', 'https://openalex.org/W2999729612', 'https://openalex.org/W2124199440', 'https://openalex.org/W2101103738', 'https://openalex.org/W2063296107', 'https://openalex.org/W1971784203', 'https://openalex.org/W2101616188', 'https://openalex.org/W2151135734', 'https://openalex.org/W1991688557', 'https://openalex.org/W2155356570']",1996-01-01
https://openalex.org/W2025543856,https://doi.org/10.1103/physreve.74.016110,Statistical mechanics of community detection,"Starting from a general ansatz, we show how community detection can be interpreted as finding the ground state of an infinite range spin glass. Our approach applies to weighted and directed networks alike. It contains the ad hoc introduced quality function from [J. Reichardt and S. Bornholdt, Phys. Rev. Lett. 93, 218701 (2004)] and the modularity Q as defined by Newman and Girvan [Phys. Rev. E 69, 026113 (2004)] as special cases. The community structure of the network is interpreted as the spin configuration that minimizes the energy of the spin glass with the spin states being the community indices. We elucidate the properties of the ground state configuration to give a concise definition of communities as cohesive subgroups in networks that is adaptive to the specific class of network under study. Further, we show how hierarchies and overlap in the community structure can be detected. Computationally efficient local update rules for optimization procedures to find the ground state are given. We show how the ansatz may be used to discover the community around a given node without detecting all communities in the full network and we give benchmarks for the performance of this extension. Finally, we give expectation values for the modularity of random graphs, which can be used in the assessment of statistical significance of community structure.","['https://openalex.org/W4244055225', 'https://openalex.org/W1992419399', 'https://openalex.org/W2161455936', 'https://openalex.org/W2115653324', 'https://openalex.org/W2125531986', 'https://openalex.org/W2121947440', 'https://openalex.org/W2032558547', 'https://openalex.org/W4252028749', 'https://openalex.org/W2043154233', 'https://openalex.org/W2170382142', 'https://openalex.org/W2125050594', 'https://openalex.org/W1992107140', 'https://openalex.org/W2095293504', 'https://openalex.org/W2028270345', 'https://openalex.org/W2047940964', 'https://openalex.org/W2111642621', 'https://openalex.org/W2089458547', 'https://openalex.org/W950821216', 'https://openalex.org/W2057436201', 'https://openalex.org/W2038920443', 'https://openalex.org/W2164928285', 'https://openalex.org/W1967752035', 'https://openalex.org/W2011151537', 'https://openalex.org/W2024060531', 'https://openalex.org/W2038518475', 'https://openalex.org/W2156737316', 'https://openalex.org/W1965121855', 'https://openalex.org/W2044500926', 'https://openalex.org/W124595874', 'https://openalex.org/W2497009956', 'https://openalex.org/W56346584', 'https://openalex.org/W2612166593', 'https://openalex.org/W1971788485', 'https://openalex.org/W2105423856']",2006-07-18
https://openalex.org/W2100308344,https://doi.org/10.1109/icassp.2009.4960701,Robust word boundary detection in spontaneous speech using acoustic and lexical cues,"We consider the problem of word boundary detection in spontaneous speech utterances. Acoustic features have been well explored in the literature in the context of word boundary detection; however, in spontaneous speech of Switchboard-I corpus, we found that the accuracy of word boundary detection using acoustic features is poor (F-score ~ 0.63). We propose a new feature - that captures lexical cues in the context of the word boundary detection problem. We show that including proposed lexical feature along with the usual acoustic features, the accuracy of the word boundary detection improves considerably (F-score ~ 0.81). We also demonstrate the robustness of our proposed feature in presence of different noise levels for additive white and pink noise.","['https://openalex.org/W2159751291', 'https://openalex.org/W2150125142', 'https://openalex.org/W2087596289', 'https://openalex.org/W31125100', 'https://openalex.org/W2074855560', 'https://openalex.org/W45989781', 'https://openalex.org/W1660390307', 'https://openalex.org/W2171271801']",2009-04-01
https://openalex.org/W2400549570,https://doi.org/10.1109/icassp.2016.7472622,A deep scattering spectrum — Deep Siamese network pipeline for unsupervised acoustic modeling,"Recent work has explored deep architectures for learning acoustic features in an unsupervised or weakly-supervised way for phone recognition. Here we investigate the role of the input features, and in particular we test whether standard mel-scaled filterbanks could be replaced by inherently richer representations, such as derived from an analytic scattering spectrum. We use a Siamese network using lexical side information similar to a well-performing architecture used in the Zero Resource Speech Challenge (2015), and show a substantial improvement when the filterbanks are replaced by scattering features, even though these features yield similar performance when tested without training. This shows that unsupervised and weakly-supervised architectures can benefit from richer features than the traditional ones.","['https://openalex.org/W2171590421', 'https://openalex.org/W2128160875', 'https://openalex.org/W6602180557', 'https://openalex.org/W2252172689', 'https://openalex.org/W6973666849', 'https://openalex.org/W2044138293', 'https://openalex.org/W2057007397', 'https://openalex.org/W2404799143', 'https://openalex.org/W6638159135', 'https://openalex.org/W6712202099', 'https://openalex.org/W2093231248', 'https://openalex.org/W6677154653', 'https://openalex.org/W6712444837', 'https://openalex.org/W6637061625', 'https://openalex.org/W2052697931', 'https://openalex.org/W6713745070', 'https://openalex.org/W6712553779', 'https://openalex.org/W2154833897', 'https://openalex.org/W52412328', 'https://openalex.org/W2786608204', 'https://openalex.org/W1666984270', 'https://openalex.org/W2025482506', 'https://openalex.org/W2395899413', 'https://openalex.org/W2962701684', 'https://openalex.org/W2406349064', 'https://openalex.org/W2399576818', 'https://openalex.org/W2396043527', 'https://openalex.org/W2112688413', 'https://openalex.org/W1796128977', 'https://openalex.org/W2963620343']",2016-03-01
https://openalex.org/W2100768664,,A Nonparametric Bayesian Approach to Acoustic Model Discovery,"We investigate the problem of acoustic modeling in which prior language-specific knowledge and transcribed data are unavailable. We present an unsupervised model that simultaneously segments the speech, discovers a proper set of sub-word units (e.g., phones) and learns a Hidden Markov Model (HMM) for each induced acoustic unit. Our approach is formulated as a Dirichlet process mixture model in which each mixture is an HMM that represents a sub-word unit. We apply our model to the TIMIT corpus, and the results demonstrate that our model discovers sub-word units that are highly correlated with English phones and also produces better segmentation than the state-of-the-art unsupervised baseline. We test the quality of the learned acoustic models on a spoken term detection task. Compared to the baselines, our model improves the relative precision of top hits by at least 22.1 % and outperforms a language-mismatched acoustic model. 1","['https://openalex.org/W2099415988', 'https://openalex.org/W2080972498', 'https://openalex.org/W53570656', 'https://openalex.org/W2117041980', 'https://openalex.org/W2120636621', 'https://openalex.org/W2154093685', 'https://openalex.org/W2077804127', 'https://openalex.org/W2401464865', 'https://openalex.org/W2121997342', 'https://openalex.org/W2026858810', 'https://openalex.org/W1957665339', 'https://openalex.org/W1990005915', 'https://openalex.org/W2083904075', 'https://openalex.org/W3127686677', 'https://openalex.org/W2045656233', 'https://openalex.org/W2126377586', 'https://openalex.org/W2148154194', 'https://openalex.org/W2111732304', 'https://openalex.org/W2171752983', 'https://openalex.org/W2126203737', 'https://openalex.org/W3104490327', 'https://openalex.org/W2403642609']",2012-07-08
https://openalex.org/W2121997342,https://doi.org/10.1109/icassp.2008.4518528,"Unsupervised optimal phoneme segmentation: Objectives, algorithm and comparisons","Phoneme segmentation is a fundamental problem in many speech recognition and synthesis studies. Unsupervised phoneme segmentation assumes no knowledge on linguistic contents and acoustic models, and thus poses a challenging problem. The essential question here is what is the optimal segmentation. This paper formulates the optimal segmentation problem into a probabilistic framework. Using statistics and information theory analysis, we develop three different objective functions, namely, summation of square error (SSE), log determinant (LD) and rate distortion (RD). Specially, RD function is derived from information rate distortion theory and can be related to human signal perception mechanism. We introduce a time-constrained agglomerative clustering algorithm to find the optimal segmentations. We also propose an efficient method to implement the algorithm by using integration functions. We carry out experiments on TIMIT database to compare the above three objective functions. The results show that rate distortion achieves the best performance and indicate that our method outperforms the recently published unsupervised segmentation methods.","['https://openalex.org/W2115606020', 'https://openalex.org/W2152486668', 'https://openalex.org/W2164931791', 'https://openalex.org/W2083904075', 'https://openalex.org/W6684765037', 'https://openalex.org/W2098363562', 'https://openalex.org/W2106596127', 'https://openalex.org/W6635066055', 'https://openalex.org/W1950396994', 'https://openalex.org/W2054665642', 'https://openalex.org/W4299681030', 'https://openalex.org/W1589615572', 'https://openalex.org/W2339940010', 'https://openalex.org/W2907162034', 'https://openalex.org/W1971784203', 'https://openalex.org/W3140237324', 'https://openalex.org/W2479250278', 'https://openalex.org/W2319660501', 'https://openalex.org/W2099111195', 'https://openalex.org/W2171752983', 'https://openalex.org/W1982475475', 'https://openalex.org/W2478708596']",2008-03-01
https://openalex.org/W2395899413,https://doi.org/10.21437/interspeech.2013-441,Evaluating speech features with the minimal-pair ABX task: analysis of the classical MFC/PLP pipeline,"We present a new framework for the evaluation of speech representations in zero-resource settings, that extends and complements previous work by Carlin, Jansen and Hermansky [1].In particular, we replace their Same/Different discrimination task by several Minimal-Pair ABX (MP-ABX) tasks.We explain the analytical advantages of this new framework and apply it to decompose the standard signal processing pipelines for computing PLP and MFC coefficients.This method enables us to confirm and quantify a variety of well-known and not-so-well-known results in a single framework.","['https://openalex.org/W2407151108', 'https://openalex.org/W2232131953', 'https://openalex.org/W2980286501', 'https://openalex.org/W2137075158', 'https://openalex.org/W2090861223', 'https://openalex.org/W4285719527', 'https://openalex.org/W2096765209', 'https://openalex.org/W2986535481', 'https://openalex.org/W4247807440', 'https://openalex.org/W2054139811', 'https://openalex.org/W168991039', 'https://openalex.org/W2406820985', 'https://openalex.org/W2089177488', 'https://openalex.org/W2025482506', 'https://openalex.org/W2160719354', 'https://openalex.org/W156237177', 'https://openalex.org/W48303286', 'https://openalex.org/W2400113920', 'https://openalex.org/W2117041980', 'https://openalex.org/W2100768664', 'https://openalex.org/W282666689', 'https://openalex.org/W1480485976']",2013-08-25
https://openalex.org/W2170659185,https://doi.org/10.1109/icassp.2011.5947338,Unsupervised acoustic sub-word unit detection for query-by-example spoken term detection,"In this paper we present a method for automatically generating acoustic sub-word units that can substitute conventional phone models in a query-by-example spoken term detection system. We generate the sub-word units with a modified version of our speaker diarization system. Given a speech recording, the original diarization system generates a set of speaker models in an unsupervised manner without the need for training or development data. Modifying the diarization system to process the speech of a single speaker and decreasing the minimum segment duration constraint allows us to detect speaker-dependent sub-word units. For the task of query-by-example spoken term detection, we show that the pro posed system performs well on both broadcast and non-broadcast recordings, unlike a conventional phone-based system trained solely on broadcast data. A mean average precision of 0.28 and 0.38 was obtained for experiments on broadcast news and on a set of war veteran interviews, respectively.","['https://openalex.org/W1591300715', 'https://openalex.org/W6628911050', 'https://openalex.org/W2103360771', 'https://openalex.org/W6601311673', 'https://openalex.org/W6647712556', 'https://openalex.org/W2079460648', 'https://openalex.org/W1606268232', 'https://openalex.org/W2171019095', 'https://openalex.org/W2117041980', 'https://openalex.org/W6679327398', 'https://openalex.org/W6632102281', 'https://openalex.org/W2168175751', 'https://openalex.org/W2130408113', 'https://openalex.org/W1583620810', 'https://openalex.org/W1482605500', 'https://openalex.org/W2187637362', 'https://openalex.org/W1988540447', 'https://openalex.org/W1556474518', 'https://openalex.org/W2168561756', 'https://openalex.org/W30845872', 'https://openalex.org/W1534656595']",2011-05-01
https://openalex.org/W2117041980,https://doi.org/10.3115/1557690.1557736,Unsupervised learning of acoustic sub-word units,"Accurate unsupervised learning of phonemes of a language directly from speech is demonstrated via an algorithm for joint unsupervised learning of the topology and parameters of a hidden Markov model (HMM); states and short state-sequences through this HMM correspond to the learnt sub-word units. The algorithm, originally proposed for unsupervised learning of allophonic variations within a given phoneme set, has been adapted to learn without any knowledge of the phonemes. An evaluation methodology is also proposed, whereby the state-sequence that aligns to a test utterance is transduced in an automatic manner to a phoneme-sequence and compared to its manual transcription. Over 85% phoneme recognition accuracy is demonstrated for speaker-dependent learning from fluent, large-vocabulary speech.","['https://openalex.org/W4298166701', 'https://openalex.org/W3034729383', 'https://openalex.org/W2101536075', 'https://openalex.org/W1971081490', 'https://openalex.org/W1949782964', 'https://openalex.org/W1918599710']",2008-01-01
https://openalex.org/W2160815625,https://doi.org/10.1109/msp.2012.2205597,Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups,"Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models (GMMs) to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over HMM states as output. Deep neural networks (DNNs) that have many hidden layers and are trained using new methods have been shown to outperform GMMs on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition.","['https://openalex.org/W6676071220', 'https://openalex.org/W1981678206', 'https://openalex.org/W6675321185', 'https://openalex.org/W2118595744', 'https://openalex.org/W6681419218', 'https://openalex.org/W6633713915', 'https://openalex.org/W2114016253', 'https://openalex.org/W2501000458', 'https://openalex.org/W2024539680', 'https://openalex.org/W2155273149', 'https://openalex.org/W2022011789', 'https://openalex.org/W2105099419', 'https://openalex.org/W2089177488', 'https://openalex.org/W2071489795', 'https://openalex.org/W1647054946', 'https://openalex.org/W2122514667', 'https://openalex.org/W2110871230', 'https://openalex.org/W2140372979', 'https://openalex.org/W2053280194', 'https://openalex.org/W1970996882', 'https://openalex.org/W2003123121', 'https://openalex.org/W6844641610', 'https://openalex.org/W2012897754', 'https://openalex.org/W2084514013', 'https://openalex.org/W2116064496', 'https://openalex.org/W2136922672', 'https://openalex.org/W6601785968', 'https://openalex.org/W2106051978', 'https://openalex.org/W2165119652', 'https://openalex.org/W2131700150', 'https://openalex.org/W2172097686', 'https://openalex.org/W6608133726', 'https://openalex.org/W2102017903', 'https://openalex.org/W2096635587', 'https://openalex.org/W6675994261', 'https://openalex.org/W6688386640', 'https://openalex.org/W6681096077', 'https://openalex.org/W2149600041', 'https://openalex.org/W42107399', 'https://openalex.org/W2027915610', 'https://openalex.org/W6630035193', 'https://openalex.org/W1993882792', 'https://openalex.org/W1498436455', 'https://openalex.org/W6631943919', 'https://openalex.org/W2132424367', 'https://openalex.org/W2100495367', 'https://openalex.org/W1994197834', 'https://openalex.org/W2090861223', 'https://openalex.org/W2168171912', 'https://openalex.org/W2032210463', 'https://openalex.org/W2069976350', 'https://openalex.org/W2165712214', 'https://openalex.org/W6617368339', 'https://openalex.org/W1877570817', 'https://openalex.org/W6678457041', 'https://openalex.org/W2160306971', 'https://openalex.org/W6697318756', 'https://openalex.org/W2147768505', 'https://openalex.org/W1964420823', 'https://openalex.org/W6608710415', 'https://openalex.org/W6711962127', 'https://openalex.org/W2107789863', 'https://openalex.org/W2997574889', 'https://openalex.org/W1553004968', 'https://openalex.org/W44815768', 'https://openalex.org/W2141778357', 'https://openalex.org/W2907162034', 'https://openalex.org/W2105153012', 'https://openalex.org/W3146320432', 'https://openalex.org/W587794757', 'https://openalex.org/W2151660570', 'https://openalex.org/W4299681030', 'https://openalex.org/W1504869774', 'https://openalex.org/W2125234026', 'https://openalex.org/W196761320', 'https://openalex.org/W1533861849', 'https://openalex.org/W2145094598', 'https://openalex.org/W299739017', 'https://openalex.org/W217970951', 'https://openalex.org/W2139622435', 'https://openalex.org/W2296748324', 'https://openalex.org/W2394932179', 'https://openalex.org/W2014641584', 'https://openalex.org/W2103359087', 'https://openalex.org/W1562289873', 'https://openalex.org/W2218318129']",2012-10-19
https://openalex.org/W1796128977,https://doi.org/10.21437/interspeech.2015-644,A comparison of neural network methods for unsupervised representation learning on the zero resource speech challenge,"The success of supervised deep neural networks (DNNs) in speech recognition cannot be transferred to zero-resource languages where the requisite transcriptions are unavailable. We investigate unsupervised neural network based methods for learning frame-level representations. Good frame representations eliminate differences in accent, gender, channel characteristics, and other factors to model subword units for withinand acrossspeaker phonetic discrimination. We enhance the correspondence autoencoder (cAE) and show that it can transform Mel Frequency Cepstral Coefficients (MFCCs) into more effective frame representations given a set of matched word pairs from an unsupervised term discovery (UTD) system. The cAE combines the feature extraction power of autoencoders with the weak supervision signal from UTD pairs to better approximate the extrinsic task’s objective during training. We use the Zero Resource Speech Challenge’s minimal triphone pair ABX discrimination task to evaluate our methods. Optimizing a cAE architecture on English and applying it to a zero-resource language, Xitsonga, we obtain a relative error rate reduction of 35% compared to the original MFCCs. We also show that Xitsonga frame representations extracted from the bottleneck layer of a supervised DNN trained on English can be further enhanced by the cAE, yielding a relative error rate reduction of 39%.","['https://openalex.org/W2044138293', 'https://openalex.org/W2107878631', 'https://openalex.org/W2112688413', 'https://openalex.org/W1606347560', 'https://openalex.org/W2002318609', 'https://openalex.org/W2786608204', 'https://openalex.org/W2057007397', 'https://openalex.org/W2026369565', 'https://openalex.org/W66167291', 'https://openalex.org/W2146502635', 'https://openalex.org/W2100495367', 'https://openalex.org/W2395899413', 'https://openalex.org/W2017257315', 'https://openalex.org/W2145094598', 'https://openalex.org/W2148154194', 'https://openalex.org/W2407151108', 'https://openalex.org/W2052697931', 'https://openalex.org/W3028642772', 'https://openalex.org/W2145410271', 'https://openalex.org/W2020607164', 'https://openalex.org/W4285719527', 'https://openalex.org/W2025768430', 'https://openalex.org/W1524333225', 'https://openalex.org/W1545920196', 'https://openalex.org/W2406349064']",2015-09-06
https://openalex.org/W2399576818,https://doi.org/10.21437/interspeech.2015-642,Parallel inference of dirichlet process Gaussian mixture models for unsupervised acoustic modeling: a feasibility study,"We adopt a Dirichlet process Gaussian mixture model (DPGMM) for unsupervised acoustic modeling and represent speech frames with Gaussian posteriorgrams. The model performs unsupervised clustering on untranscribed data, and each Gaussian component can be considered as a cluster of sounds from various speakers. The model infers its model complexity (i.e. the number of Gaussian components) from the data. For computation efficiency, we use a parallel sampler for the model inference. Our experiments are conducted on the corpus provided by the zero resource speech challenge. Experimental results show that the unsupervised DPGMM posteriorgrams obviously outperformMFCC, and perform comparably to the posteriorgrams derived from language-mismatched phoneme recognizers in terms of the error rate of ABX discrimination test. The error rates can be further reduced by the fusion of these two kinds of posteriorgrams.","['https://openalex.org/W2406349064', 'https://openalex.org/W2119187236', 'https://openalex.org/W2106284094', 'https://openalex.org/W2114347655', 'https://openalex.org/W2049142189', 'https://openalex.org/W2125534887', 'https://openalex.org/W2127498532', 'https://openalex.org/W2151967501', 'https://openalex.org/W66167291', 'https://openalex.org/W2125247927', 'https://openalex.org/W2395899413', 'https://openalex.org/W2079460648', 'https://openalex.org/W1967924372', 'https://openalex.org/W2020607164', 'https://openalex.org/W2213520355', 'https://openalex.org/W2399363370', 'https://openalex.org/W2126203737', 'https://openalex.org/W2406820985', 'https://openalex.org/W2117041980', 'https://openalex.org/W2100768664', 'https://openalex.org/W1997505733', 'https://openalex.org/W2170659185', 'https://openalex.org/W2078769636', 'https://openalex.org/W2052697931', 'https://openalex.org/W2171019095', 'https://openalex.org/W2065136108', 'https://openalex.org/W1503398984', 'https://openalex.org/W2168319451', 'https://openalex.org/W2044138293', 'https://openalex.org/W2080972498', 'https://openalex.org/W1975728937', 'https://openalex.org/W2162021827', 'https://openalex.org/W1833498382', 'https://openalex.org/W1545920196', 'https://openalex.org/W2154085905', 'https://openalex.org/W2128032727', 'https://openalex.org/W2110589736']",2015-09-06
