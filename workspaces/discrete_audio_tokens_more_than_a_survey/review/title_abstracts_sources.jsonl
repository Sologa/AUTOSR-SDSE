{"key": "itakura1968analysis", "title": "{Analysis synthesis telephony based on the maximum likelihood method}", "source": null, "source_id": null, "match_status": "missing", "abstract_present": false, "abstract_source": "missing", "abstract_source_reason": "missing:abstract_unavailable"}
{"key": "atal1970speech", "title": "Speech Analysis and Synthesis by Linear Prediction of the Speech Wave", "source": "semantic_scholar", "source_id": "d738cfd0354ec9e70849057d5c2f20524a81e55a", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "schroeder1985code", "title": "Code-excited linear prediction(CELP): High-quality speech at very low bit rates", "source": "semantic_scholar", "source_id": "02876a3eb2ffe88cadfbc9ac779f272ccdc6f91a", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "tian2025espnet", "title": "ESPnet-SpeechLM: An Open Speech Language Model Toolkit", "source": "semantic_scholar", "source_id": "6245784c904ca849d4ac5b92de4878ee633997dd", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "hayashi2020discretalk", "title": "DiscreTalk: Text-to-Speech as a Machine Translation Problem", "source": "arxiv", "source_id": "2005.05525v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "vqvae2017", "title": "Neural Discrete Representation Learning", "source": "arxiv", "source_id": "1711.00937v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zeghidour2021soundstream", "title": "SoundStream: An End-to-End Neural Audio Codec", "source": "arxiv", "source_id": "2107.03312v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "shi2024versa", "title": "VERSA: A Versatile Evaluation Toolkit for Speech, Audio, and Music", "source": "arxiv", "source_id": "2412.17667v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wu2024towards", "title": "Towards audio language modeling -- an overview", "source": "arxiv", "source_id": "2402.13236v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "jiang2023disentangled", "title": "Disentangled Feature Learning for Real-Time Neural Speech Coding", "source": "arxiv", "source_id": "2211.11960v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "lakhotia2021generative", "title": "On Generative Spoken Language Modeling from Raw Audio", "source": "semantic_scholar", "source_id": "7c39adb2049e79951dd6b92c970abaa4d81819b1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "wu2023speechgen", "title": "SpeechGen: Unlocking the Generative Power of Speech Language Models with Prompts", "source": "arxiv", "source_id": "2306.02207v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zhen2020psychoacoustic", "title": "Psychoacoustic Calibration of Loss Functions for Efficient End-to-End Neural Audio Coding", "source": "arxiv", "source_id": "2101.00054v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "garbacea2019low", "title": "Low Bit-Rate Speech Coding with VQ-VAE and a WaveNet Decoder", "source": "arxiv", "source_id": "1910.06464v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "jang2024personalized", "title": "Personalized Neural Speech Codec", "source": "arxiv", "source_id": "2404.00791v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "Kleijn2018wavenet", "title": "Wavenet based low rate speech coding", "source": "arxiv", "source_id": "1712.01120v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "valin2019real", "title": "A Real-Time Wideband Neural Vocoder at 1.6 kb/s Using LPCNet", "source": "arxiv", "source_id": "1903.12087v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "valin2019lpcnet", "title": "LPCNET: Improving Neural Speech Synthesis through Linear Prediction", "source": "semantic_scholar", "source_id": "da7329db3e14cb7301e9ce95a131136bd85e24ba", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "yang2023neural", "title": "Neural Feature Predictor and Discriminative Residual Coding for Low-Bitrate Speech Coding", "source": "arxiv", "source_id": "2211.02506v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "Jang2016Gumbel", "title": "Categorical Reparameterization with Gumbel-Softmax", "source": "arxiv", "source_id": "1611.01144v5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "maddison2016concrete", "title": "The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables", "source": "arxiv", "source_id": "1611.00712v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "della2025focalcodec", "title": "FocalCodec: Low-Bitrate Speech Coding via Focal Modulation Networks", "source": "arxiv", "source_id": "2502.04465v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "petermann2021harp", "title": "HARP-Net: Hyper-Autoencoded Reconstruction Propagation for Scalable Neural Audio Coding", "source": "arxiv", "source_id": "2107.10843v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "Jiang2022EndtoEndNS", "title": "End-to-End Neural Speech Coding for Real-Time Communications", "source": "arxiv", "source_id": "2201.09429v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wu2024codecslt", "title": "Codec-SUPERB @ SLT 2024: A lightweight benchmark for neural audio codec models", "source": "arxiv", "source_id": "2409.14085v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "yang2021source", "title": "Source-Aware Neural Speech Coding for Noisy Speech Compression", "source": "arxiv", "source_id": "2008.12889v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "omran2023disentangling", "title": "Disentangling speech from surroundings with neural embeddings", "source": "arxiv", "source_id": "2203.15578v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "Ji2024LanguageCodecRT", "title": "Language-Codec: Bridging Discrete Codec Representations and Speech Language Models", "source": "arxiv", "source_id": "2402.12208", "match_status": "exact_id", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_id"}
{"key": "Pan2024PSCodecAS", "title": "PSCodec: A Series of High-Fidelity Low-bitrate Neural Speech Codecs Leveraging Prompt Encoders", "source": "arxiv", "source_id": "2404.02702v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "yang24h_interspeech", "title": "Genhancer: High-Fidelity Speech Enhancement via Generative Modeling on Discrete Codec Tokens", "source": "semantic_scholar", "source_id": "ed6b910c45a0ab819c98b5fd4f9b8e4ca2ac7482", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "xue24lowlatency", "title": "Low-latency Speech Enhancement via Speech Token Generation", "source": "arxiv", "source_id": "2310.08981v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "Ahn2024HILCodecHA", "title": "HILCodec: High-Fidelity and Lightweight Neural Audio Codec", "source": "arxiv", "source_id": "2405.04752v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "Ye2024CodecDM", "title": "Codec Does Matter: Exploring the Semantic Shortcoming of Codec for Audio Language Model", "source": "arxiv", "source_id": "2408.17175v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "Guo2024AddressingIC", "title": "Addressing Index Collapse of Large-Codebook Speech Tokenizer with Dual-Decoding Product-Quantized Variational Auto-Encoder", "source": "arxiv", "source_id": "2406.02940v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "Zhou2024WMCodecEN", "title": "WMCodec: End-to-End Neural Speech Codec with Deep Watermarking for Authenticity Verification", "source": "arxiv", "source_id": "2409.12121v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "Wu2024TS3CodecTS", "title": "TS3-Codec: Transformer-Based Simple Streaming Single Codec", "source": "arxiv", "source_id": "2411.18803v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "Jiang2024MDCTCodecAL", "title": "MDCTCodec: A Lightweight MDCT-based Neural Audio Codec towards High Sampling Rate and Low Bitrate Scenarios", "source": "arxiv", "source_id": "2411.00464v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "Guo2024LSCodecLA", "title": "LSCodec: Low-Bitrate and Speaker-Decoupled Discrete Speech Codec", "source": "arxiv", "source_id": "2410.15764v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zaiem2023icassp", "title": "Fine-tuning Strategies for Faster Inference using Speech Self-Supervised Models: A Comparative Study", "source": "arxiv", "source_id": "2303.06740v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "yang2021superb", "title": "SUPERB: Speech processing Universal PERformance Benchmark", "source": "arxiv", "source_id": "2105.01051v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "Rabiner:1993dq", "title": "Fundamentals of speech recognition", "source": "semantic_scholar", "source_id": "2392e94df520e707e8b1422311bfdc552954dea9", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "busso2008iemocap", "title": "IEMOCAP: interactive emotional dyadic motion capture database", "source": "semantic_scholar", "source_id": "5cf0d213f3253cd46673d955209f8463db73cc51", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "lecun2015deep", "title": "Deep Learning", "source": "arxiv", "source_id": "1807.07987v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "GoodBengCour16", "title": "Deep Learning", "source": "arxiv", "source_id": "1807.07987v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "geminiteam2023gemini", "title": "Gemini: A Family of Highly Capable Multimodal Models", "source": "arxiv", "source_id": "2312.11805v5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wu2025esi", "title": "Towards Efficient Speech-Text Jointly Decoding within One Speech Language Model", "source": "arxiv", "source_id": "2506.04518v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "kumar2023high", "title": "High-Fidelity Audio Compression with Improved RVQGAN", "source": "arxiv", "source_id": "2306.06546v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zhang2023speechtokenizer", "title": "SpeechTokenizer: Unified Speech Tokenizer for Speech Large Language Models", "source": "arxiv", "source_id": "2308.16692v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wu2023audiodec", "title": "AudioDec: An Open-source Streaming High-fidelity Neural Audio Codec", "source": "arxiv", "source_id": "2305.16608v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "yang2023hifi", "title": "HiFi-Codec: Group-residual Vector quantization for High Fidelity Audio Codec", "source": "arxiv", "source_id": "2305.02765v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "du2023funcodec", "title": "FunCodec: A Fundamental, Reproducible and Integrable Open-source Toolkit for Neural Speech Codec", "source": "arxiv", "source_id": "2309.07405v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "borsos2023audiolm", "title": "AudioLM: a Language Modeling Approach to Audio Generation", "source": "arxiv", "source_id": "2209.03143v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "rubenstein2023audiopalm", "title": "AudioPaLM: A Large Language Model That Can Speak and Listen", "source": "arxiv", "source_id": "2306.12925v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wang2024viola", "title": "VioLA: Conditional Language Models for Speech Recognition, Synthesis, and Translation", "source": "semantic_scholar", "source_id": "66fd85f42596fcd018d517a4bf6acc75100e59da", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "sicherman2023analysing", "title": "Analysing Discrete Self Supervised Speech Representation for Spoken Language Modeling", "source": "arxiv", "source_id": "2301.00591v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "arora2025landscape", "title": "On The Landscape of Spoken Language Models: A Comprehensive Survey", "source": "arxiv", "source_id": "2504.08528v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chen2023lauragpt", "title": "LauraGPT: Listen, Attend, Understand, and Regenerate Audio with GPT", "source": "arxiv", "source_id": "2310.04673v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "borsos2023soundstorm", "title": "SoundStorm: Efficient Parallel Audio Generation", "source": "arxiv", "source_id": "2305.09636v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wang2023viola", "title": "VioLA: Unified Codec Language Models for Speech Recognition, Synthesis, and Translation", "source": "arxiv", "source_id": "2305.16107v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wang2023speechx", "title": "SpeechX: Neural Codec Language Model as a Versatile Speech Transformer", "source": "arxiv", "source_id": "2308.06873v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "kreuk2022audiogen", "title": "AudioGen: Textually Guided Audio Generation", "source": "arxiv", "source_id": "2209.15352v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "desplanques2020ecapa", "title": "ECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation in TDNN Based Speaker Verification", "source": "arxiv", "source_id": "2005.07143v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "ardila2019common", "title": "Common Voice: A Massively-Multilingual Speech Corpus", "source": "arxiv", "source_id": "1912.06670v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "agostinelli2023musiclm", "title": "MusicLM: Generating Music From Text", "source": "arxiv", "source_id": "2301.11325v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "yang2023uniaudio", "title": "UniAudio: Towards Universal Audio Generation with Large Language Models", "source": "semantic_scholar", "source_id": "61632c78b26ca366b5a1c8cbf3d0f50981126e8e", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "wells2022phonetic", "title": "Phonetic Analysis of Self-supervised Representations of English Speech", "source": "semantic_scholar", "source_id": "fc5c506887b53d0e132cb6a4fb239c92cd5c9830", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "polyak2021speech", "title": "Speech Resynthesis from Discrete Disentangled Self-Supervised Representations", "source": "arxiv", "source_id": "2104.00355v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "du2025codecfake", "title": "CodecFake+: A Large-Scale Neural Audio Codec-Based Deepfake Speech Dataset", "source": "arxiv", "source_id": "2501.08238", "match_status": "exact_id", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_id"}
{"key": "touvron2023llama", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models", "source": "arxiv", "source_id": "2307.09288v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "defossez2024moshi", "title": "Moshi: a speech-text foundation model for real-time dialogue", "source": "arxiv", "source_id": "2410.00037v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "kharitonov2021text", "title": "Text-Free Prosody-Aware Generative Spoken Language Modeling", "source": "arxiv", "source_id": "2109.03264v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "nguyen2023generative", "title": "Generative Spoken Dialogue Language Modeling", "source": "arxiv", "source_id": "2203.16502v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "popuri2022enhanced", "title": "Enhanced Direct Speech-to-Speech Translation Using Self-supervised Pre-training and Data Augmentation", "source": "arxiv", "source_id": "2204.02967v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "inaguma2022unity", "title": "UnitY: Two-pass Direct Speech-to-speech Translation with Discrete Units", "source": "arxiv", "source_id": "2212.08055v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chang2022speechprompt", "title": "SpeechPrompt: An Exploration of Prompt Tuning on Generative Spoken Language Model for Speech Processing Tasks", "source": "arxiv", "source_id": "2203.16773v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chang2023speechprompt", "title": "SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks", "source": "arxiv", "source_id": "2303.00733v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "hsu2023exploration", "title": "An Exploration of In-Context Learning for Speech Language Model", "source": "semantic_scholar", "source_id": "d628f3c65e0c8c3024d9ff0678d44383fc9fe27c", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "kuan2023towards", "title": "Towards General-Purpose Text-Instruction-Guided Voice Conversion", "source": "arxiv", "source_id": "2309.14324v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zeng2024glm", "title": "GLM-4-Voice: Towards Intelligent and Human-Like End-to-End Spoken Chatbot", "source": "arxiv", "source_id": "2412.02612", "match_status": "exact_id", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_id"}
{"key": "huang2023dynamic", "title": "Dynamic-SUPERB: Towards A Dynamic, Collaborative, and Comprehensive Instruction-Tuning Benchmark for Speech", "source": "arxiv", "source_id": "2309.09510v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "huang2024dynamic", "title": "Dynamic-SUPERB Phase-2: A Collaboratively Expanding Benchmark for Measuring the Capabilities of Spoken Language Models with 180 Tasks", "source": "arxiv", "source_id": "2411.05361v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "xu2025qwen2", "title": "Qwen2.5-Omni Technical Report", "source": "arxiv", "source_id": "2503.20215", "match_status": "exact_id", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_id"}
{"key": "liu2023pre", "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing", "source": "arxiv", "source_id": "2107.13586v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "lester2021power", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning", "source": "arxiv", "source_id": "2104.08691v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chang2023exploring", "title": "Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study", "source": "arxiv", "source_id": "2309.15800v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wang2023selm", "title": "SELM: Speech Enhancement Using Discrete Tokens and Language Models", "source": "arxiv", "source_id": "2312.09747v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wu2024codec", "title": "Codec-SUPERB: An In-Depth Analysis of Sound Codec Models", "source": "arxiv", "source_id": "2402.13071v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zhang2023dub", "title": "DUB: Discrete Unit Back-translation for Speech Translation", "source": "arxiv", "source_id": "2305.11411v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wu2024toksing", "title": "TokSing: Singing Voice Synthesis based on Discrete Tokens", "source": "arxiv", "source_id": "2406.08416v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "yip2024towards", "title": "Towards Audio Codec-based Speech Separation", "source": "arxiv", "source_id": "2406.12434v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chung2021w2v", "title": "W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training", "source": "arxiv", "source_id": "2108.06209v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "hsu2021hubert", "title": "HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units", "source": "arxiv", "source_id": "2106.07447v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chen2022wavlm", "title": "WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing", "source": "arxiv", "source_id": "2110.13900v5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "baevski2020wav2vec", "title": "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations", "source": "arxiv", "source_id": "2006.11477v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chang2023exploration", "title": "Exploration of Efficient End-to-End ASR using Discretized Input from Self-Supervised Learning", "source": "arxiv", "source_id": "2305.18108v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "pasad2023comparative", "title": "Comparative layer-wise analysis of self-supervised speech models", "source": "arxiv", "source_id": "2211.03929v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "goodfellow2020generative", "title": "Generative Adversarial Networks", "source": "arxiv", "source_id": "1406.2661v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "kong2020hifigan", "title": "HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis", "source": "arxiv", "source_id": "2010.05646v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "oord2016wavenet", "title": "WaveNet: A Generative Model for Raw Audio", "source": "arxiv", "source_id": "1609.03499v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "prenger2018waveglow", "title": "WaveGlow: A Flow-based Generative Network for Speech Synthesis", "source": "arxiv", "source_id": "1811.00002v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "transformer", "title": "Attention Is All You Need", "source": "arxiv", "source_id": "1706.03762v7", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "somos", "title": "SOMOS: The Samsung Open MOS Dataset for the Evaluation of Neural Text-to-Speech Synthesis", "source": "arxiv", "source_id": "2204.03040v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "yang2023towards", "title": "Towards Universal Speech Discrete Tokens: A Case Study for ASR and TTS", "source": "arxiv", "source_id": "2309.07377v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wang2021dwer", "title": "Sequential Multi-Frame Neural Beamforming for Speech Separation and Enhancement", "source": "arxiv", "source_id": "1911.07953v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wichern2019wham", "title": "WHAM!: Extending Speech Separation to Noisy Environments", "source": "arxiv", "source_id": "1907.01160v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "le2019sdr", "title": "SDR - half-baked or well done?", "source": "arxiv", "source_id": "1811.02508v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "ljspeech17", "title": "{The {LJ} Speech Dataset}", "source": "keithito", "source_id": "https://keithito.com/LJ-Speech-Dataset/", "match_status": "fuzzy_title", "abstract_present": true, "abstract_source": "keithito", "abstract_source_reason": "keithito:fuzzy_title"}
{"key": "srivastava2014dropout", "title": "Dropout: a simple way to prevent neural networks from overfitting", "source": "semantic_scholar", "source_id": "34f25a8704614163c4095b3ee2fc969b60de4698", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "nagrani2017voxceleb", "title": "VoxCeleb: a large-scale speaker identification dataset", "source": "arxiv", "source_id": "1706.08612v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "1360861705599880960", "title": "UTMOS: UTokyo-SaruLab System for VoiceMOS Challenge 2022", "source": "arxiv", "source_id": "2204.02152v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zaiem2025speech", "title": "Speech Self-Supervised Representations Benchmarking: a Case for Larger Probing Heads", "source": "arxiv", "source_id": "2308.14456v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "defossez2022high", "title": "High Fidelity Neural Audio Compression", "source": "arxiv", "source_id": "2210.13438v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "DevlinCLT19", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "source": "arxiv", "source_id": "1810.04805v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "newell2020useful", "title": "How Useful is Self-Supervised Pretraining for Visual Tasks?", "source": "arxiv", "source_id": "2003.14323v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "liu2021self", "title": "Self-supervised Learning: Generative or Contrastive", "source": "arxiv", "source_id": "2006.08218v5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "JMLR:v24:22-1144", "title": "PaLM: Scaling Language Modeling with Pathways", "source": "arxiv", "source_id": "2204.02311v5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "liu2023gpt", "title": "GPT Understands, Too", "source": "arxiv", "source_id": "2103.10385v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "speechbrain_ravanelli", "title": "Open-Source Conversational AI with SpeechBrain 1.0", "source": "arxiv", "source_id": "2407.00463v5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wang2024evaluating", "title": "Evaluating Text-to-Speech Synthesis from a Large Discrete Token-based Speech Language Model", "source": "arxiv", "source_id": "2405.09768v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wang2023neural", "title": "Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers", "source": "arxiv", "source_id": "2301.02111v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "kharitonov2023speak", "title": "Speak, Read and Prompt: High-Fidelity Text-to-Speech with Minimal Supervision", "source": "arxiv", "source_id": "2302.03540v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "shi2021discretization", "title": "Discretization and Re-synthesis: an alternative method to solve the Cocktail Party Problem", "source": "arxiv", "source_id": "2112.09382v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "erdogan2023tokensplit", "title": "TokenSplit: Using Discrete Speech Representations for Direct, Refined, and Transcript-Conditioned Speech Separation and Recognition", "source": "arxiv", "source_id": "2308.10415v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "puvvada2023discrete", "title": "Discrete Audio Representation as an Alternative to Mel-Spectrograms for Speaker and Speech Recognition", "source": "semantic_scholar", "source_id": "c78d2a875f6cfd3a7b70c8d4c03a828894146892", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "wu2024codecfake", "title": "CodecFake: Enhancing Anti-Spoofing Models Against Deepfake Audios from Codec-Based Speech Synthesis Systems", "source": "arxiv", "source_id": "2406.07237v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "ren2024emo", "title": "EMO-Codec: An In-Depth Look at Emotion Preservation capacity of Legacy and Neural Codec Models With Subjective and Objective Evaluations", "source": "arxiv", "source_id": "2407.15458v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "mousavi2024", "title": "How Should We Extract Discrete Audio Tokens from Self-Supervised Models?", "source": "semantic_scholar", "source_id": "40875b1e950fe6636ef277df4ed6d501f4933307", "match_status": "fuzzy_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:fuzzy_title"}
{"key": "korvas_2014", "title": "\"Free {E}nglish and {C}zech telephone speech corpus shared under the {CC}-{BY}-{SA} 3.0 license\"", "source": "lrec_conf", "source_id": "lrec2014:535", "match_status": "exact_title", "abstract_present": true, "abstract_source": "lrec_conf", "abstract_source_reason": "lrec_conf:exact_title"}
{"key": "han2020contextnet", "title": "ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context", "source": "arxiv", "source_id": "2005.03191v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "snyder2018x", "title": "X-Vectors: Robust DNN Embeddings for Speaker Recognition", "source": "semantic_scholar", "source_id": "389cd9824428be98a710f5f4de67121a70c15fd3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "wang2018additive", "title": "Additive Margin Softmax for Face Verification", "source": "arxiv", "source_id": "1801.05599v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "bastianelli2020slurp", "title": "SLURP: A Spoken Language Understanding Resource Package", "source": "arxiv", "source_id": "2011.13205v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "warden2017speech", "title": "Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition", "source": "arxiv", "source_id": "1804.03209v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "tacotron2", "title": "Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions", "source": "arxiv", "source_id": "1712.05884v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "guided-attention", "title": "Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention", "source": "arxiv", "source_id": "1710.08969v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "levenshtein", "title": "Binary codes capable of correcting deletions, insertions, and reversals", "source": "semantic_scholar", "source_id": "b2f8876482c97e804bb50a5e2433881ae31d0cdd", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "dwer", "title": "Sequential Multi-Frame Neural Beamforming for Speech Separation and Enhancement", "source": "arxiv", "source_id": "1911.07953", "match_status": "exact_id", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_id"}
{"key": "abouelenin2025phi", "title": "Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs", "source": "arxiv", "source_id": "2503.01743v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chang2024speechprompt", "title": "SpeechPrompt: Prompting Speech Language Models for Speech Processing Tasks", "source": "arxiv", "source_id": "2408.13040v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "cp-decomposition", "title": "The Expression of a Tensor or a Polyadic as a Sum of Products", "source": "semantic_scholar", "source_id": "5265853dd172f6afe0ff1e820a0cc7bd0e58c765", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "dubey2024icassp", "title": "ICASSP 2023 Deep Noise Suppression Challenge", "source": "arxiv", "source_id": "2303.11510v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "gemmeke2017audio", "title": "Audio Set: An ontology and human-labeled dataset for audio events", "source": "semantic_scholar", "source_id": "5ba2218b708ca64ab556e39d5997202e012717d5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "fonseca2021fsd50k", "title": "FSD50K: An Open Dataset of Human-Labeled Sound Events", "source": "arxiv", "source_id": "2010.00475v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "bogdanov2019mtg", "title": "The MTG-Jamendo Dataset for Automatic Music Tagging", "source": "semantic_scholar", "source_id": "23037085b0815455e6d47333089b925c8c0e21d5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "mysore2014can", "title": "Can we Automatically Transform Speech Recorded on Common Consumer Devices in Real-World Environments into Professional Production Quality Speech?â€”A Dataset, Insights, and Challenges", "source": "semantic_scholar", "source_id": "5aa5d627f4741eaeec41d59efe6589e71a3080c6", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "vctk2017", "title": "CSTR VCTK Corpus: English Multi-speaker Corpus for CSTR Voice Cloning Toolkit (version 0.92)", "source": "semantic_scholar", "source_id": "df40f83f5420f73b22562f3554e1e3bd4a5c1ef5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "reddy2022dnsmos", "title": "DNSMOS P.835: A Non-Intrusive Perceptual Objective Speech Quality Metric to Evaluate Noise Suppressors", "source": "arxiv", "source_id": "2110.01763v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "valentinibotinhao2016voicebank", "title": "Investigating RNN-based speech enhancement methods for noise-robust Text-to-Speech", "source": "semantic_scholar", "source_id": "0764300b1ba8c29e25e748c1df2851feba8ea1b6", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "cosentino2020librimix", "title": "LibriMix: An Open-Source Dataset for Generalizable Speech Separation", "source": "arxiv", "source_id": "2005.11262v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "gulati_conformer", "title": "Conformer: Convolution-augmented Transformer for Speech Recognition", "source": "arxiv", "source_id": "2005.08100v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zhan2024anygpt", "title": "AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling", "source": "arxiv", "source_id": "2402.12226v5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "xin2024bigcodec", "title": "BigCodec: Pushing the Limits of Low-Bitrate Neural Speech Codec", "source": "arxiv", "source_id": "2409.05377v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "niu2024ndvq", "title": "NDVQ: Robust Neural Audio Codec with Normal Distribution-Based Vector Quantization", "source": "arxiv", "source_id": "2409.12717v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "siuzdak2024snac", "title": "SNAC: Multi-Scale Neural Audio Codec", "source": "arxiv", "source_id": "2410.14411v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chiu2022bestrq", "title": "Self-supervised Learning with Random-projection Quantizer for Speech Recognition", "source": "arxiv", "source_id": "2202.01855v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zhang2023googleusm", "title": "Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages", "source": "arxiv", "source_id": "2303.01037v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "langman2024spectral", "title": "Spectral Codecs: Improving Non-Autoregressive Speech Synthesis with Spectrogram-Based Audio Codecs", "source": "arxiv", "source_id": "2406.05298", "match_status": "exact_id", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_id"}
{"key": "gu2024esc", "title": "ESC: Efficient Speech Coding with Cross-Scale Residual Vector Quantized Transformers", "source": "arxiv", "source_id": "2404.19441v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "tang2024singomd", "title": "SingOMD: Singing Oriented Multi-resolution Discrete Representation Construction from Speech Models", "source": "semantic_scholar", "source_id": "b7359944a3a8d9a8a6d4acd83e7a507a4da1094a", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "shi2024mmm", "title": "MMM: Multi-Layer Multi-Residual Multi-Stream Discrete Speech Representation from Self-supervised Learning Model", "source": "arxiv", "source_id": "2406.09869v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "messica2024nast", "title": "NAST: Noise Aware Speech Tokenization for Speech Language Models", "source": "arxiv", "source_id": "2406.11037v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chen-etal-2024-towards-robust", "title": "Towards Robust Speech Representation Learning for Thousands of Languages", "source": "arxiv", "source_id": "2407.00837v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zhang2023speechgpt", "title": "SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities", "source": "arxiv", "source_id": "2305.11000v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "valin2012definition", "title": "Definition of the Opus Audio Codec.", "source": "rfc_editor", "source_id": "RFC6716", "match_status": "fuzzy_title", "abstract_present": true, "abstract_source": "rfc_editor", "abstract_source_reason": "rfc_editor:fuzzy_title"}
{"key": "dietz2015overview", "title": "Overview of the EVS codec architecture", "source": "semantic_scholar", "source_id": "d63c953aa3a7327202d7af9baeda6fd0a646d5a5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "fma_dataset", "title": "FMA: A Dataset For Music Analysis", "source": "arxiv", "source_id": "1612.01840v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "evans2025stable", "title": "Stable Audio Open", "source": "arxiv", "source_id": "2407.14358v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "van2022comparison", "title": "A Comparison of Discrete and Soft Speech Units for Improved Voice Conversion", "source": "arxiv", "source_id": "2111.02392v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "guo2024socodec", "title": "SoCodec: A Semantic-Ordered Multi-Stream Speech Codec for Efficient Language Model Based Text-to-Speech Synthesis", "source": "arxiv", "source_id": "2409.00933v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "casanova2024lfsc", "title": "Low Frame-rate Speech Codec: a Codec Designed for Fast High-quality Speech LLM Training and Inference", "source": "arxiv", "source_id": "2409.12117v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "ren2024ticodec", "title": "Fewer-token Neural Speech Codec with Time-invariant Codes", "source": "arxiv", "source_id": "2310.00014v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "parker2024scaling", "title": "Scaling Transformers for Low-Bitrate High-Quality Speech Coding", "source": "arxiv", "source_id": "2411.19842v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "bai2024dmel", "title": "dMel: Speech Tokenization made Simple", "source": "arxiv", "source_id": "2407.15835", "match_status": "exact_id", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_id"}
{"key": "ai2024apcodec", "title": "APCodec: A Neural Audio Codec with Parallel Amplitude and Phase Spectrum Encoding and Decoding", "source": "arxiv", "source_id": "2402.10533v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "kolbaek2017multitalker", "title": "Multitalker Speech Separation With Utterance-Level Permutation Invariant Training of Deep Recurrent Neural Networks", "source": "semantic_scholar", "source_id": "256ad591c6fd5269fc6f88b9715bf379f210f53d", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "piczak2015esc", "title": "ESC: Dataset for Environmental Sound Classification", "source": "semantic_scholar", "source_id": "99e6f700d374e34c8376f1f43af994b278924f28", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "tzanetakis2002musical", "title": "Musical genre classification of audio signals", "source": "semantic_scholar", "source_id": "7ab881283270e427b05c6e9469562ff39dd6282a", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "li2023mert", "title": "MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training", "source": "arxiv", "source_id": "2306.00107v5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "kong2020panns", "title": "PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition", "source": "arxiv", "source_id": "1912.10211v5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wang2022usb", "title": "USB: A Unified Semi-supervised Learning Benchmark for Classification", "source": "arxiv", "source_id": "2208.07204v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "mousavi2024dasb", "title": "DASB - Discrete Audio and Speech Benchmark", "source": "arxiv", "source_id": "2406.14294v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wang2023lmvc", "title": "LM-VC: Zero-shot Voice Conversion via Speech Generation based on Language Models", "source": "arxiv", "source_id": "2306.10521v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "maimon2023speaking", "title": "Speaking Style Conversion in the Waveform Domain Using Discrete Self-Supervised Units", "source": "arxiv", "source_id": "2212.09730v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wang2024streamvoice", "title": "StreamVoice: Streamable Context-Aware Language Modeling for Real-time Zero-Shot Voice Conversion", "source": "arxiv", "source_id": "2401.11053v5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "shi2024espnet", "title": "ESPnet-Codec: Comprehensive Training and Evaluation of Neural Codecs for Audio, Music, and Speech", "source": "arxiv", "source_id": "2409.15897v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "vashishth2024stab", "title": "STAB: Speech Tokenizer Assessment Benchmark", "source": "arxiv", "source_id": "2409.02384v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zen2019libritts", "title": "LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech", "source": "semantic_scholar", "source_id": "2789b6c84ba1422746246685001accba5563e7c1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "7178964", "title": "Librispeech: An ASR corpus based on public domain audio books", "source": "semantic_scholar", "source_id": "34038d9424ce602d7ac917a4e582d977725d4393", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "lam2023efficient", "title": "Efficient Neural Music Generation", "source": "arxiv", "source_id": "2305.15719v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "rouard2024audio", "title": "Audio Conditioning for Music Generation via Discrete Bottleneck Features", "source": "arxiv", "source_id": "2407.12563v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chen2024musicldm", "title": "MusicLDM: Enhancing Novelty in Text-to-Music Generation Using Beat-Synchronous Mixup Strategies", "source": "arxiv", "source_id": "2308.01546v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "yang2024generative", "title": "Generative De-Quantization for Neural Speech Codec via Latent Diffusion", "source": "arxiv", "source_id": "2311.08330v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "li2024single", "title": "Single-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation", "source": "arxiv", "source_id": "2406.07422v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "huang2023repcodec", "title": "RepCodec: A Speech Representation Codec for Speech Tokenization", "source": "semantic_scholar", "source_id": "8b6c00246a0ae34f097aa64af7d9cb35b2b43a30", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "siuzdak2023vocos", "title": "Vocos: Closing the gap between time-domain and Fourier-based neural vocoders for high-quality audio synthesis", "source": "arxiv", "source_id": "2306.00814v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "kang2024libriheavy", "title": "Libriheavy: a 50,000 hours ASR corpus with punctuation casing and context", "source": "arxiv", "source_id": "2309.08105v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "maimon2024suite", "title": "Salmon: A Suite for Acoustic Language Model Evaluation", "source": "arxiv", "source_id": "2409.07437v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "LMCodec", "title": "Towards Codec-LM Co-design for Neural Codec Language Models", "source": "semantic_scholar", "source_id": "9ae0d46500c36c58533ad0b456f517d0b4da17b4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "bie2024learning", "title": "Learning Source Disentanglement in Neural Audio Codec", "source": "arxiv", "source_id": "2409.11228v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "liu2024semanticodec", "title": "SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General Sound", "source": "arxiv", "source_id": "2405.00233v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "jiang22_interspeech", "title": "Cross-Scale Vector Quantization for Scalable Neural Speech Coding", "source": "arxiv", "source_id": "2207.03067v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "yang2024qwen2", "title": "Qwen2 Technical Report", "source": "arxiv", "source_id": "2407.10671v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "huang2022mulan", "title": "MuLan: A Joint Embedding of Music Audio and Natural Language", "source": "arxiv", "source_id": "2208.12415v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "turetzky_last_2024", "title": "LAST: Language Model Aware Speech Tokenization", "source": "arxiv", "source_id": "2409.03701v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "nguyen2024spiritlminterleavedspokenwritten", "title": "SpiRit-LM: Interleaved Spoken and Written Language Model", "source": "semantic_scholar", "source_id": "7547e30ba98a0217f07a6bb9fc393902bbc89269", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "nguyen2020zeroresourcespeechbenchmark", "title": "The Zero Resource Speech Benchmark 2021: Metrics and baselines for unsupervised spoken language modeling", "source": "arxiv", "source_id": "2011.11588v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "manilow2019cutting", "title": "Cutting Music Source Separation Some Slakh: A Dataset to Study the Impact of Training Data Quality and Quantity", "source": "arxiv", "source_id": "1909.08494v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "arnault2020urban", "title": "Urban Sound Classification : striving towards a fair comparison", "source": "arxiv", "source_id": "2010.11805v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wisdom2021s", "title": "Whatâ€™s all the Fuss about Free Universal Sound Separation Data?", "source": "semantic_scholar", "source_id": "1932eb0e2ede027909ef42bfa065d9983824e0a9", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "hershey2016deep", "title": "Deep clustering: Discriminative embeddings for segmentation and separation", "source": "arxiv", "source_id": "1508.04306v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "liu2024revisiting", "title": "Revisiting Self-supervised Learning of Speech Representation from a Mutual Information Perspective", "source": "arxiv", "source_id": "2401.08833v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chung2025kad", "title": "KAD: No More FAD! An Effective and Efficient Evaluation Metric for Audio Generation", "source": "arxiv", "source_id": "2502.15602v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "fadtk", "title": "Adapting Frechet Audio Distance for Generative Music Evaluation", "source": "arxiv", "source_id": "2311.01616v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "koutini2021passt", "title": "Efficient Training of Audio Transformers with Patchout", "source": "arxiv", "source_id": "2110.05069v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "san2023discrete", "title": "From Discrete Tokens to High-Fidelity Audio Using Multi-Band Diffusion", "source": "arxiv", "source_id": "2308.02560v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "yang2023diffsound", "title": "Diffsound: Discrete Diffusion Model for Text-to-sound Generation", "source": "arxiv", "source_id": "2207.09983v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wu2023large", "title": "Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation", "source": "arxiv", "source_id": "2211.06687v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "huang2023make", "title": "Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion Models", "source": "arxiv", "source_id": "2301.12661v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "audiocaps", "title": "AudioCaps: Generating Captions for Audios in The Wild", "source": "semantic_scholar", "source_id": "c4798919e74411d87f7745840e45b8bcf61128ff", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "macs", "title": "Diversity and Bias in Audio Captioning Datasets", "source": "semantic_scholar", "source_id": "2ee853d36dced58204983c1bb108c14d3310cd2c", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "liu2023audioldm", "title": "AudioLDM: Text-to-Audio Generation with Latent Diffusion Models", "source": "semantic_scholar", "source_id": "fa0f3d8aa20e8987dbc7a516d5399cfa3dc97b1b", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "liu2024audioldm2", "title": "AudioLDM 2: Learning Holistic Audio Generation With Self-Supervised Pretraining", "source": "semantic_scholar", "source_id": "33de773be1733347a01cb07a5bb1b6cdfa956a47", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "wang2024v2a", "title": "V2A-Mapper: A Lightweight Solution for Vision-to-Audio Generation by Connecting Foundation Models", "source": "arxiv", "source_id": "2308.09300v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "pascual2024masked", "title": "Masked Generative Video-to-Audio Transformers with Enhanced Synchronicity", "source": "arxiv", "source_id": "2407.10387v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zhang2024foleycrafter", "title": "FoleyCrafter: Bring Silent Videos to Life with Lifelike and Synchronized Sounds", "source": "arxiv", "source_id": "2407.01494v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "dong2023clipsonic", "title": "CLIPSonic: Text-to-Audio Synthesis with Unlabeled Videos and Pretrained Language-Vision Models", "source": "arxiv", "source_id": "2306.09635v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "jeong2024read", "title": "Read, Watch and Scream! Sound Generation from Text and Video", "source": "arxiv", "source_id": "2407.05551v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chen2024video", "title": "Video-Guided Foley Sound Generation with Multimodal Controls", "source": "arxiv", "source_id": "2411.17698v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "saito2024soundctm", "title": "{Sound{CTM}: Uniting Score-based and Consistency Models for Text-to-Sound Generation}", "source": "github", "source_id": "sony/soundctm", "match_status": "fuzzy_title", "abstract_present": true, "abstract_source": "github", "abstract_source_reason": "github:fuzzy_title"}
{"key": "wang2025frieren", "title": "Frieren: Efficient Video-to-Audio Generation Network with Rectified Flow Matching", "source": "arxiv", "source_id": "2406.00320v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "luo2023diff", "title": "Diff-Foley: Synchronized Video-to-Audio Synthesis with Latent Diffusion Models", "source": "arxiv", "source_id": "2306.17203v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "sheffer2023hear", "title": "I Hear Your True Colors: Image Guided Audio Generation", "source": "arxiv", "source_id": "2211.03089v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "raffel2020exploring", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "source": "arxiv", "source_id": "1910.10683v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "peng2024survey", "title": "A Survey on Speech Large Language Models for Understanding", "source": "arxiv", "source_id": "2410.18908", "match_status": "exact_id", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_id"}
{"key": "cui2024recent", "title": "Recent Advances in Speech Language Models: A Survey", "source": "arxiv", "source_id": "2410.03751v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "ji2024wavchat", "title": "WavChat: A Survey of Spoken Dialogue Models", "source": "arxiv", "source_id": "2411.13577v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "latif2023sparks", "title": "Sparks of Large Audio Models: A Survey and Outlook", "source": "arxiv", "source_id": "2308.12792v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "dunbar2021zero", "title": "The Zero Resource Speech Challenge 2021: Spoken language modelling", "source": "arxiv", "source_id": "2104.14700v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "lin2024alignslm", "title": "Align-SLM: Textless Spoken Language Models with Reinforcement Learning from AI Feedback", "source": "arxiv", "source_id": "2411.01834v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "radford2023robust", "title": "Robust Speech Recognition via Large-Scale Weak Supervision", "source": "arxiv", "source_id": "2212.04356v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "mostafazadeh2016corpus", "title": "A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense Stories", "source": "semantic_scholar", "source_id": "85b68477a6e031d88b963833e15a4b4fc6855264", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "yang2024uniaudio", "title": "UniAudio 1.5: Large Language Model-driven Audio Codec is A Few-shot Audio Task Learner", "source": "semantic_scholar", "source_id": "33672a1ef7bb4722902a53c77e30ec92b338a94c", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "park2024long", "title": "Long-Form Speech Generation with Spoken Language Models", "source": "arxiv", "source_id": "2412.18603v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "dhariwal2020jukebox", "title": "Jukebox: A Generative Model for Music", "source": "arxiv", "source_id": "2005.00341v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "ziv2024masked", "title": "Masked Audio Generation using a Single Non-Autoregressive Transformer", "source": "arxiv", "source_id": "2401.04577v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "garcia2023vampnet", "title": "VampNet: Music Generation via Masked Acoustic Token Modeling", "source": "arxiv", "source_id": "2307.04686v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "gu2021efficiently", "title": "Efficiently Modeling Long Sequences with Structured State Spaces", "source": "arxiv", "source_id": "2111.00396v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "elmakies2025unsupervised", "title": "Unsupervised Speech Segmentation: A General Approach Using Speech Language Models", "source": "arxiv", "source_id": "2501.03711v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "salmonn", "title": "SALMONN: Towards Generic Hearing Abilities for Large Language Models", "source": "arxiv", "source_id": "2310.13289v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "qwen_audio", "title": "Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models", "source": "arxiv", "source_id": "2311.07919v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "maimon2025slamming", "title": "Slamming: Training a Speech Language Model on One GPU in a Day", "source": "arxiv", "source_id": "2502.15814v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "shi2021aishell", "title": "AISHELL-3: A Multi-Speaker Mandarin TTS Corpus", "source": "semantic_scholar", "source_id": "a6387132862d1270b1a0b7ec8352b1773ec2e990", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "shi2021highland", "title": "Highland Puebla Nahuatl Speech Translation Corpus for Endangered Language Documentation", "source": "semantic_scholar", "source_id": "59f3e3cad309eb4965d67773d68bc2f91b2e376f", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "shi2021leveraging", "title": "Leveraging End-to-End ASR for Endangered Language Documentation: An Empirical Study on YolÃ³xochitl Mixtec", "source": "semantic_scholar", "source_id": "8c4d1e81c277f71cd9e3c9a0af356203c7948dca", "match_status": "fuzzy_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:fuzzy_title"}
{"key": "huang2021multi", "title": "Multi-Singer: Fast Multi-Singer Singing Voice Vocoder With A Large-Scale Corpus", "source": "arxiv", "source_id": "2112.10358v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "dai2023singstyle111", "title": "SingStyle111: A Multilingual Singing Dataset With Style Transfer", "source": "semantic_scholar", "source_id": "0cab8f24dec845c4b8e64e97dd4a92a1b6338ea1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "zhang2022m4singer", "title": "M4Singer: A Multi-Style, Multi-Singer and Musical Score Provided Mandarin Singing Corpus", "source": "semantic_scholar", "source_id": "9441b35773ec51c19eb5c028a46705a3f3f732d5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "ogawa2021tohoku", "title": "Tohoku Kiritan singing database: A singing database for statistical parametric singing synthesis using Japanese pop songs", "source": "semantic_scholar", "source_id": "f6781f89263f0e30070bfad392de76681653379c", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "wang2022opencpop", "title": "Opencpop: A High-Quality Open Source Chinese Popular Song Corpus for Singing Voice Synthesis", "source": "arxiv", "source_id": "2201.07429v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "shi2024singing", "title": "Singing Voice Data Scaling-up: An Introduction to ACE-Opencpop and ACE-KiSing", "source": "arxiv", "source_id": "2401.17619v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "koguchi2020pjs", "title": "PJS: phoneme-balanced Japanese singing voice corpus", "source": "arxiv", "source_id": "2006.02959v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "takamichi2020jsut", "title": "JSUT and JVS: Free Japanese voice corpora for accelerating speech synthesis research", "source": "semantic_scholar", "source_id": "aa9b455bb5b16f49a3cfdb3239303e250c41f10f", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "amith_yoloxochitl_mixtec", "title": "{Audio corpus of YoloxÃ³chitl Mixtec with accompanying time-coded transcriptions in ELAN}", "source": null, "source_id": null, "match_status": "missing", "abstract_present": false, "abstract_source": "missing", "abstract_source_reason": "missing:abstract_unavailable"}
{"key": "amith_audio_corpus_sierra", "title": "{Audio corpus of Sierra Nororiental and Sierra Norte de Puebla Nahuat(l) with accompanying time-code transcriptions in ELAN}", "source": null, "source_id": null, "match_status": "missing", "abstract_present": false, "abstract_source": "missing", "abstract_source_reason": "missing:abstract_unavailable"}
{"key": "amith_totonac", "title": "{Audio corpus of Totonac recordings from northern Puebla and adjacent areas of Veracruz}", "source": null, "source_id": null, "match_status": "missing", "abstract_present": false, "abstract_source": "missing", "abstract_source_reason": "missing:abstract_unavailable"}
{"key": "kuhn2014daps", "title": "DAPS: Intelligent delay-aware packet scheduling for multipath transport", "source": "semantic_scholar", "source_id": "b9f0e3ffa0d102ffd9aca268b1a7e024b89fc66a", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "yamagishi2019cstr", "title": "CSTR VCTK Corpus: English Multi-speaker Corpus for CSTR Voice Cloning Toolkit (version 0.92)", "source": "semantic_scholar", "source_id": "df40f83f5420f73b22562f3554e1e3bd4a5c1ef5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "yan2023espnet", "title": "ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit", "source": "arxiv", "source_id": "2304.04596v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "vincent2006bss", "title": "Performance measurement in blind audio source separation", "source": "semantic_scholar", "source_id": "29de8281b8cbc764d605a20d00b818eba6d47da1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "allal2024SmolLM", "title": "{SmolLM - blazingly fast and remarkably powerful}", "source": "github", "source_id": "huggingface/smollm", "match_status": "fuzzy_title", "abstract_present": true, "abstract_source": "github", "abstract_source_reason": "github:fuzzy_title"}
{"key": "rouard2022hybrid", "title": "Hybrid Transformers for Music Source Separation", "source": "arxiv", "source_id": "2211.08553v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "LuoY2019conv-tasnet", "title": "Conv-TasNet: Surpassing Ideal Time-Frequency Magnitude Masking for Speech Separation", "source": "arxiv", "source_id": "1809.07454v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "Saijo2024_TFLoco", "title": "TF-Locoformer: Transformer with Local Modeling by Convolution for Speech Separation and Enhancement", "source": "arxiv", "source_id": "2408.03440v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "Kavalerov2019UniversalSS", "title": "Universal Sound Separation", "source": "arxiv", "source_id": "1905.03330v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "espnet", "title": "ESPnet: End-to-End Speech Processing Toolkit", "source": "arxiv", "source_id": "1804.00015v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "mars6", "title": "MARS6: A Small and Robust Hierarchical-Codec Text-to-Speech Model", "source": "arxiv", "source_id": "2501.05787v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "simplespeech", "title": "SimpleSpeech: Towards Simple and Efficient Text-to-Speech with Scalar Latent Transformer Diffusion Models", "source": "arxiv", "source_id": "2406.02328v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "cuervo2024scalingpropertiesspeechlanguag", "title": "Scaling Properties of Speech Language Models", "source": "arxiv", "source_id": "2404.00685v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "hassid2023textually", "title": "Textually Pretrained Speech Language Models", "source": "arxiv", "source_id": "2305.13009v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "copet2024musicgen", "title": "Simple and Controllable Music Generation", "source": "arxiv", "source_id": "2306.05284v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "wolf2020huggingfacestransformersstateoftheartnatural", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing", "source": "arxiv", "source_id": "1910.03771v5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "ji2024wavtokenizer", "title": "WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling", "source": "arxiv", "source_id": "2408.16532v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "gpt", "title": "Language Models are Few-Shot Learners", "source": "arxiv", "source_id": "2005.14165v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "bark2023", "title": "{Bark: Text-Prompted Generative Audio Model}", "source": "github", "source_id": "suno-ai/bark", "match_status": "fuzzy_title", "abstract_present": true, "abstract_source": "github", "abstract_source_reason": "github:fuzzy_title"}
{"key": "guo2025recent", "title": "Recent Advances in Discrete Speech Tokens: A Review", "source": "arxiv", "source_id": "2502.06490v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zaiem2023speech", "title": "Speech Self-Supervised Representation Benchmarking: Are We Doing it Right?", "source": "arxiv", "source_id": "2306.00452v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "watanabe2023tree", "title": "Tree-Structured Parzen Estimator: Understanding Its Algorithm Components and Their Roles for Better Empirical Performance", "source": "arxiv", "source_id": "2304.11127v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "xavier_bouthillier_2022_0_2_6", "title": "{{Epistimio/orion: Asynchronous Distributed Hyperparameter Optimization}}", "source": "github", "source_id": "Epistimio/orion", "match_status": "fuzzy_title", "abstract_present": true, "abstract_source": "github", "abstract_source_reason": "github:fuzzy_title"}
{"key": "mentzer2023finite", "title": "Finite Scalar Quantization: VQ-VAE Made Simple", "source": "arxiv", "source_id": "2309.15505v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "du2024cosyvoiceAS", "title": "CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens", "source": "arxiv", "source_id": "2407.05407v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "du2024cosyvoice", "title": "CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models", "source": "arxiv", "source_id": "2412.10117v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "tong2023improving", "title": "Improving and generalizing flow-based generative models with minibatch optimal transport", "source": "arxiv", "source_id": "2302.00482v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "ho2020denoising", "title": "Denoising Diffusion Probabilistic Models", "source": "arxiv", "source_id": "2006.11239v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "rombach2022high", "title": "High-Resolution Image Synthesis with Latent Diffusion Models", "source": "arxiv", "source_id": "2112.10752v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "kim2024neural", "title": "Neural Speech and Audio Coding: Modern AI Technology Meets Traditional Codecs", "source": "arxiv", "source_id": "2408.06954", "match_status": "exact_id", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_id"}
{"key": "anees2024speech", "title": "Speech coding techniques and challenges: a comprehensive literature survey", "source": "semantic_scholar", "source_id": "ba02cf95af70c5e29e26ad4db7f59360e85a3786", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "shannon1948mathematical", "title": "A Mathematical Theory of Communication", "source": "semantic_scholar", "source_id": "6d12a1d23b21a9b170118a56386552bc5d4727de", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "nyquist1928certain", "title": "Certain Topics in Telegraph Transmission Theory", "source": "semantic_scholar", "source_id": "db0172576316dc748aea82e8f13fb4719ac933d5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "o1988linear", "title": "{Linear predictive coding}", "source": "openalex", "source_id": null, "match_status": "exact_title", "abstract_present": true, "abstract_source": "openalex", "abstract_source_reason": "openalex:exact_title"}
{"key": "wang2003modified", "title": "Modified Discrete Cosine Transform: Its Implications for Audio Coding and Error Concealment", "source": "semantic_scholar", "source_id": "042aa1735de37d4b17972b795c412d572e0b32c9", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "noll1997mpeg", "title": "MPEG digital audio coding", "source": "semantic_scholar", "source_id": "64dd904dc1a8eeb84dae812335a4d46b202f7f4b", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "painter2000perceptual", "title": "Perceptual coding of digital audio", "source": "semantic_scholar", "source_id": "ecf98b58e733badb55d9b6a449b943dbf58342fb", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "jage2016celp", "title": "CELP and MELP speech coding techniques", "source": "semantic_scholar", "source_id": "3f58e96c1b528458a5a9a629920f1bf6cda84793", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "maimon2025scaling", "title": "Scaling Analysis of Interleaved Speech-Text Language Models", "source": "arxiv", "source_id": "2504.02398v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "qwen2025qwen25technicalreport", "title": "Qwen2.5 Technical Report", "source": "arxiv", "source_id": "2412.15115v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "cuervo2025textspeechlanguagemodelsimproved", "title": "Late Fusion and Multi-Level Fission Amplify Cross-Modal Transfer in Text-Speech LMs", "source": "arxiv", "source_id": "2503.06211", "match_status": "exact_id", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_id"}
{"key": "kharitonov2022textfreeprosodyawaregenerativespoken", "title": "Text-Free Prosody-Aware Generative Spoken Language Modeling", "source": "arxiv", "source_id": "2109.03264v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "agustsson2017soft", "title": "Soft-to-Hard Vector Quantization for End-to-End Learning Compressible Representations", "source": "arxiv", "source_id": "1704.00648v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "kankanahalli2018end", "title": "End-to-End Optimized Speech Coding with Deep Neural Networks", "source": "arxiv", "source_id": "1710.09064v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "choi2024selfsupervisedspeechrepresentationsphonetic", "title": "Self-Supervised Speech Representations are More Phonetic than Semantic", "source": "arxiv", "source_id": "2406.08619v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "grattafiori2024llama3herdmodels", "title": "The Llama 3 Herd of Models", "source": "arxiv", "source_id": "2407.21783v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "radhakrishnan2023whispering", "title": "Whispering LLaMA: A Cross-Modal Generative Error Correction Framework for Speech Recognition", "source": "arxiv", "source_id": "2310.06434v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "libritts-alignments", "title": "{LibriTTS-Phones-and-Mel}", "source": "huggingface", "source_id": "cdminix/libritts-phones-and-mel", "match_status": "fuzzy_title", "abstract_present": true, "abstract_source": "huggingface", "abstract_source_reason": "huggingface:fuzzy_title"}
{"key": "ren2019fastspeech", "title": "FastSpeech: Fast, Robust and Controllable Text to Speech", "source": "arxiv", "source_id": "1905.09263v5", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "morise2016world", "title": "WORLD: A Vocoder-Based High-Quality Speech Synthesis System for Real-Time Applications", "source": "semantic_scholar", "source_id": "ba91dabec842d507a647aab97ad224b4abdc1635", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "ren2020fastspeech", "title": "FastSpeech 2: Fast and High-Quality End-to-End Text to Speech", "source": "arxiv", "source_id": "2006.04558v8", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "kim2021conditional", "title": "Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech", "source": "arxiv", "source_id": "2106.06103v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "ju2024naturalspeech", "title": "NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models", "source": "arxiv", "source_id": "2403.03100v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "mcauliffe2017montreal", "title": "Montreal Forced Aligner: Trainable Text-Speech Alignment Using Kaldi", "source": "semantic_scholar", "source_id": "9e8b06c60722fee06d7f01d4eeaf3ae81e0247d7", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "har2025past", "title": "PAST: Phonetic-Acoustic Speech Tokenizer", "source": "arxiv", "source_id": "2505.14470v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "10889092", "title": "What Are They Doing? Joint Audio-Speech Co-Reasoning", "source": "arxiv", "source_id": "2409.14526v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zengscaling", "title": "Scaling Speech-Text Pre-training with Synthetic Interleaved Data", "source": "arxiv", "source_id": "2411.17607v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "yosha2025stresstest", "title": "StressTest: Can YOUR Speech LM Handle the Stress?", "source": "arxiv", "source_id": "2505.22765v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "mousavi2025listen", "title": "LiSTEN: Learning Soft Token Embeddings for Neural Audio LLMs", "source": "arxiv", "source_id": "2505.18517v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "kumar2024sila", "title": "SILA: Signal-to-Language Augmentation for Enhanced Control in Text-to-Audio Generation", "source": "arxiv", "source_id": "2412.09789v1", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "chen2025video", "title": "Video-Guided Foley Sound Generation with Multimodal Controls", "source": "arxiv", "source_id": "2411.17698v4", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "international1993coding", "title": "{Coding of moving pictures and associated audio for digital storage media at up to about 1.5 Mbit/s}", "source": "bsi", "source_id": "https://knowledge.bsigroup.com/products/information-technology-coding-of-moving-pictures-and-associated-audio-for-digital-storage-media-at-up-to-about-1-5-mbit-s-compliance-testing", "match_status": "fuzzy_title", "abstract_present": true, "abstract_source": "bsi", "abstract_source_reason": "bsi:fuzzy_title"}
{"key": "6530580", "title": "MPEG Unified Speech and Audio Coding", "source": "semantic_scholar", "source_id": "9d0ea1deb125e736478c6a07c89519c40eb7f154", "match_status": "exact_title", "abstract_present": true, "abstract_source": "semantic_scholar", "abstract_source_reason": "semantic_scholar:exact_title"}
{"key": "devlin2019bert", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "source": "arxiv", "source_id": "1810.04805v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "turetzky2024last", "title": "LAST: Language Model Aware Speech Tokenization", "source": "arxiv", "source_id": "2409.03701v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "zheng2025ervq", "title": "ERVQ: Enhanced Residual Vector Quantization with Intra-and-Inter-Codebook Optimization for Neural Audio Codecs", "source": "arxiv", "source_id": "2410.12359v2", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
{"key": "esser2021taming", "title": "Taming Transformers for High-Resolution Image Synthesis", "source": "arxiv", "source_id": "2012.09841v3", "match_status": "exact_title", "abstract_present": true, "abstract_source": "arxiv", "abstract_source_reason": "arxiv:exact_title"}
