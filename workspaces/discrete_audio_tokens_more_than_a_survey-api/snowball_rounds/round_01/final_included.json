[
  {
    "status": "include",
    "title": "Recent Advances in Discrete Speech Tokens: A Review",
    "normalized_title": "recentadvancesindiscretespeechtokens:areview",
    "doi": "10.48550/arxiv.2502.06490",
    "openalex_id": "",
    "arxiv_id": "2502.06490",
    "published_date": "2025-02-10",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Personalized Acoustic Modeling by Weakly Supervised Multi-Task Deep Learning using Acoustic Tokens Discovered from Unlabeled Data",
    "normalized_title": "personalizedacousticmodelingbyweaklysupervisedmulti-taskdeeplearningusingacoustictokensdiscoveredfromunlabeleddata",
    "doi": "10.1109/icassp.2017.7953141",
    "openalex_id": "",
    "arxiv_id": "1706.07793",
    "published_date": "2017-06-23",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "u-HuBERT: Unified Mixed-Modal Speech Pretraining And Zero-Shot Transfer to Unlabeled Modality",
    "normalized_title": "u-hubert:unifiedmixed-modalspeechpretrainingandzero-shottransfertounlabeledmodality",
    "doi": "10.48550/arxiv.2207.07036",
    "openalex_id": "",
    "arxiv_id": "2207.07036",
    "published_date": "2022-07-14",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "token2vec: A Joint Self-Supervised Pre-training Framework Using Unpaired Speech and Text",
    "normalized_title": "token2vec:ajointself-supervisedpre-trainingframeworkusingunpairedspeechandtext",
    "doi": "10.48550/arxiv.2210.16755",
    "openalex_id": "",
    "arxiv_id": "2210.16755",
    "published_date": "2022-10-30",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "BEATs: Audio Pre-Training with Acoustic Tokenizers",
    "normalized_title": "beats:audiopre-trainingwithacoustictokenizers",
    "doi": "10.48550/arxiv.2212.09058",
    "openalex_id": "",
    "arxiv_id": "2212.09058",
    "published_date": "2022-12-18",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers",
    "normalized_title": "neuralcodeclanguagemodelsarezero-shottexttospeechsynthesizers",
    "doi": "10.48550/arxiv.2301.02111",
    "openalex_id": "",
    "arxiv_id": "2301.02111",
    "published_date": "2023-01-05",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "InstructTTS: Modelling Expressive TTS in Discrete Latent Space with Natural Language Style Prompt",
    "normalized_title": "instructtts:modellingexpressivettsindiscretelatentspacewithnaturallanguagestyleprompt",
    "doi": "10.48550/arxiv.2301.13662",
    "openalex_id": "",
    "arxiv_id": "2301.13662",
    "published_date": "2023-01-31",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Speak, Read and Prompt: High-Fidelity Text-to-Speech with Minimal Supervision",
    "normalized_title": "speak,readandprompt:high-fidelitytext-to-speechwithminimalsupervision",
    "doi": "10.48550/arxiv.2302.03540",
    "openalex_id": "",
    "arxiv_id": "2302.03540",
    "published_date": "2023-02-07",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Speech Enhancement with Multi-granularity Vector Quantization",
    "normalized_title": "speechenhancementwithmulti-granularityvectorquantization",
    "doi": "10.48550/arxiv.2302.08342",
    "openalex_id": "",
    "arxiv_id": "2302.08342",
    "published_date": "2023-02-16",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "FoundationTTS: Text-to-Speech for ASR Customization with Generative Language Model",
    "normalized_title": "foundationtts:text-to-speechforasrcustomizationwithgenerativelanguagemodel",
    "doi": "10.48550/arxiv.2303.02939",
    "openalex_id": "",
    "arxiv_id": "2303.02939",
    "published_date": "2023-03-06",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec Language Modeling",
    "normalized_title": "speakforeignlanguageswithyourownvoice:cross-lingualneuralcodeclanguagemodeling",
    "doi": "10.48550/arxiv.2303.03926",
    "openalex_id": "",
    "arxiv_id": "2303.03926",
    "published_date": "2023-03-07",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Cocktail HuBERT: Generalized Self-Supervised Pre-training for Mixture and Single-Source Speech",
    "normalized_title": "cocktailhubert:generalizedself-supervisedpre-trainingformixtureandsingle-sourcespeech",
    "doi": "10.48550/arxiv.2303.11131",
    "openalex_id": "",
    "arxiv_id": "2303.11131",
    "published_date": "2023-03-20",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Unsupervised Speech Representation Pooling Using Vector Quantization",
    "normalized_title": "unsupervisedspeechrepresentationpoolingusingvectorquantization",
    "doi": "10.48550/arxiv.2304.03940",
    "openalex_id": "",
    "arxiv_id": "2304.03940",
    "published_date": "2023-04-08",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "A vector quantized masked autoencoder for audiovisual speech emotion recognition",
    "normalized_title": "avectorquantizedmaskedautoencoderforaudiovisualspeechemotionrecognition",
    "doi": "10.1016/j.cviu.2025.104362",
    "openalex_id": "",
    "arxiv_id": "2305.03568",
    "published_date": "2023-05-05",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SoundStorm: Efficient Parallel Audio Generation",
    "normalized_title": "soundstorm:efficientparallelaudiogeneration",
    "doi": "10.48550/arxiv.2305.09636",
    "openalex_id": "",
    "arxiv_id": "2305.09636",
    "published_date": "2023-05-16",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Efficient Neural Music Generation",
    "normalized_title": "efficientneuralmusicgeneration",
    "doi": "10.48550/arxiv.2305.15719",
    "openalex_id": "",
    "arxiv_id": "2305.15719",
    "published_date": "2023-05-25",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Make-A-Voice: Unified Voice Synthesis With Discrete Representation",
    "normalized_title": "make-a-voice:unifiedvoicesynthesiswithdiscreterepresentation",
    "doi": "10.48550/arxiv.2305.19269",
    "openalex_id": "",
    "arxiv_id": "2305.19269",
    "published_date": "2023-05-30",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "UniCATS: A Unified Context-Aware Text-to-Speech Framework with Contextual VQ-Diffusion and Vocoding",
    "normalized_title": "unicats:aunifiedcontext-awaretext-to-speechframeworkwithcontextualvq-diffusionandvocoding",
    "doi": "10.1609/aaai.v38i16.29747",
    "openalex_id": "",
    "arxiv_id": "2306.07547",
    "published_date": "2023-06-13",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Pushing the Limits of Unsupervised Unit Discovery for SSL Speech Representation",
    "normalized_title": "pushingthelimitsofunsupervisedunitdiscoveryforsslspeechrepresentation",
    "doi": "10.48550/arxiv.2306.08920",
    "openalex_id": "",
    "arxiv_id": "2306.08920",
    "published_date": "2023-06-15",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "LM-VC: Zero-shot Voice Conversion via Speech Generation based on Language Models",
    "normalized_title": "lm-vc:zero-shotvoiceconversionviaspeechgenerationbasedonlanguagemodels",
    "doi": "10.48550/arxiv.2306.10521",
    "openalex_id": "",
    "arxiv_id": "2306.10521",
    "published_date": "2023-06-18",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SpeechX: Neural Codec Language Model as a Versatile Speech Transformer",
    "normalized_title": "speechx:neuralcodeclanguagemodelasaversatilespeechtransformer",
    "doi": "10.48550/arxiv.2308.06873",
    "openalex_id": "",
    "arxiv_id": "2308.06873",
    "published_date": "2023-08-14",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "TokenSplit: Using Discrete Speech Representations for Direct, Refined, and Transcript-Conditioned Speech Separation and Recognition",
    "normalized_title": "tokensplit:usingdiscretespeechrepresentationsfordirect,refined,andtranscript-conditionedspeechseparationandrecognition",
    "doi": "10.48550/arxiv.2308.10415",
    "openalex_id": "",
    "arxiv_id": "2308.10415",
    "published_date": "2023-08-21",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SpeechTokenizer: Unified Speech Tokenizer for Speech Large Language Models",
    "normalized_title": "speechtokenizer:unifiedspeechtokenizerforspeechlargelanguagemodels",
    "doi": "10.48550/arxiv.2308.16692",
    "openalex_id": "",
    "arxiv_id": "2308.16692",
    "published_date": "2023-08-31",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "RepCodec: A Speech Representation Codec for Speech Tokenization",
    "normalized_title": "repcodec:aspeechrepresentationcodecforspeechtokenization",
    "doi": "10.48550/arxiv.2309.00169",
    "openalex_id": "",
    "arxiv_id": "2309.00169",
    "published_date": "2023-08-31",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Voxtlm: unified decoder-only models for consolidating speech recognition/synthesis and speech/text continuation tasks",
    "normalized_title": "voxtlm:unifieddecoder-onlymodelsforconsolidatingspeechrecognition/synthesisandspeech/textcontinuationtasks",
    "doi": "10.48550/arxiv.2309.07937",
    "openalex_id": "",
    "arxiv_id": "2309.07937",
    "published_date": "2023-09-14",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Improving Language Model-Based Zero-Shot Text-to-Speech Synthesis with Multi-Scale Acoustic Prompts",
    "normalized_title": "improvinglanguagemodel-basedzero-shottext-to-speechsynthesiswithmulti-scaleacousticprompts",
    "doi": "10.48550/arxiv.2309.11977",
    "openalex_id": "",
    "arxiv_id": "2309.11977",
    "published_date": "2023-09-21",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Towards General-Purpose Text-Instruction-Guided Voice Conversion",
    "normalized_title": "towardsgeneral-purposetext-instruction-guidedvoiceconversion",
    "doi": "10.48550/arxiv.2309.14324",
    "openalex_id": "",
    "arxiv_id": "2309.14324",
    "published_date": "2023-09-25",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Vec-Tok Speech: speech vectorization and tokenization for neural speech generation",
    "normalized_title": "vec-tokspeech:speechvectorizationandtokenizationforneuralspeechgeneration",
    "doi": "10.48550/arxiv.2310.07246",
    "openalex_id": "",
    "arxiv_id": "2310.07246",
    "published_date": "2023-10-11",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Low-latency Speech Enhancement via Speech Token Generation",
    "normalized_title": "low-latencyspeechenhancementviaspeechtokengeneration",
    "doi": "10.48550/arxiv.2310.08981",
    "openalex_id": "",
    "arxiv_id": "2310.08981",
    "published_date": "2023-10-13",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SD-HuBERT: Sentence-Level Self-Distillation Induces Syllabic Organization in HuBERT",
    "normalized_title": "sd-hubert:sentence-levelself-distillationinducessyllabicorganizationinhubert",
    "doi": "10.48550/arxiv.2310.10803",
    "openalex_id": "",
    "arxiv_id": "2310.10803",
    "published_date": "2023-10-16",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Acoustic BPE for Speech Generation with Discrete Tokens",
    "normalized_title": "acousticbpeforspeechgenerationwithdiscretetokens",
    "doi": "10.48550/arxiv.2310.14580",
    "openalex_id": "",
    "arxiv_id": "2310.14580",
    "published_date": "2023-10-23",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Transduce and Speak: Neural Transducer for Text-to-Speech with Semantic Token Prediction",
    "normalized_title": "transduceandspeak:neuraltransducerfortext-to-speechwithsemantictokenprediction",
    "doi": "10.48550/arxiv.2311.02898",
    "openalex_id": "",
    "arxiv_id": "2311.02898",
    "published_date": "2023-11-06",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Loss Masking Is Not Needed in Decoder-only Transformer for Discrete-token-based ASR",
    "normalized_title": "lossmaskingisnotneededindecoder-onlytransformerfordiscrete-token-basedasr",
    "doi": "10.48550/arxiv.2311.04534",
    "openalex_id": "",
    "arxiv_id": "2311.04534",
    "published_date": "2023-11-08",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Utilizing Neural Transducers for Two-Stage Text-to-Speech via Semantic Token Prediction",
    "normalized_title": "utilizingneuraltransducersfortwo-stagetext-to-speechviasemantictokenprediction",
    "doi": "10.48550/arxiv.2401.01498",
    "openalex_id": "",
    "arxiv_id": "2401.01498",
    "published_date": "2024-01-03",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "ELLA-V: Stable Neural Codec Language Modeling with Alignment-guided Sequence Reordering",
    "normalized_title": "ella-v:stableneuralcodeclanguagemodelingwithalignment-guidedsequencereordering",
    "doi": "10.48550/arxiv.2401.07333",
    "openalex_id": "",
    "arxiv_id": "2401.07333",
    "published_date": "2024-01-14",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Predicting positive transfer for improved low-resource speech recognition using acoustic pseudo-tokens",
    "normalized_title": "predictingpositivetransferforimprovedlow-resourcespeechrecognitionusingacousticpseudo-tokens",
    "doi": "10.48550/arxiv.2402.02302",
    "openalex_id": "",
    "arxiv_id": "2402.02302",
    "published_date": "2024-02-03",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "BASE TTS: Lessons from building a billion-parameter Text-to-Speech model on 100K hours of data",
    "normalized_title": "basetts:lessonsfrombuildingabillion-parametertext-to-speechmodelon100khoursofdata",
    "doi": "10.48550/arxiv.2402.08093",
    "openalex_id": "",
    "arxiv_id": "2402.08093",
    "published_date": "2024-02-12",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Language-Codec: Bridging Discrete Codec Representations and Speech Language Models",
    "normalized_title": "language-codec:bridgingdiscretecodecrepresentationsandspeechlanguagemodels",
    "doi": "10.48550/arxiv.2402.12208",
    "openalex_id": "",
    "arxiv_id": "2402.12208",
    "published_date": "2024-02-19",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Text-guided HuBERT: Self-Supervised Speech Pre-training via Generative Adversarial Networks",
    "normalized_title": "text-guidedhubert:self-supervisedspeechpre-trainingviagenerativeadversarialnetworks",
    "doi": "10.48550/arxiv.2402.15725",
    "openalex_id": "",
    "arxiv_id": "2402.15725",
    "published_date": "2024-02-24",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Phonetic and Lexical Discovery of a Canine Language using HuBERT",
    "normalized_title": "phoneticandlexicaldiscoveryofacaninelanguageusinghubert",
    "doi": "10.48550/arxiv.2402.15985",
    "openalex_id": "",
    "arxiv_id": "2402.15985",
    "published_date": "2024-02-25",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild",
    "normalized_title": "voicecraft:zero-shotspeecheditingandtext-to-speechinthewild",
    "doi": "10.48550/arxiv.2403.16973",
    "openalex_id": "",
    "arxiv_id": "2403.16973",
    "published_date": "2024-03-25",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Scaling Properties of Speech Language Models",
    "normalized_title": "scalingpropertiesofspeechlanguagemodels",
    "doi": "10.18653/v1/2024.emnlp-main.21",
    "openalex_id": "",
    "arxiv_id": "2404.00685",
    "published_date": "2024-03-31",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "CLaM-TTS: Improving Neural Codec Language Model for Zero-Shot Text-to-Speech",
    "normalized_title": "clam-tts:improvingneuralcodeclanguagemodelforzero-shottext-to-speech",
    "doi": "10.48550/arxiv.2404.02781",
    "openalex_id": "",
    "arxiv_id": "2404.02781",
    "published_date": "2024-04-03",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "The X-LANCE Technical Report for Interspeech 2024 Speech Processing Using Discrete Speech Unit Challenge",
    "normalized_title": "thex-lancetechnicalreportforinterspeech2024speechprocessingusingdiscretespeechunitchallenge",
    "doi": "10.48550/arxiv.2404.06079",
    "openalex_id": "",
    "arxiv_id": "2404.06079",
    "published_date": "2024-04-09",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "ESC: Efficient Speech Coding with Cross-Scale Residual Vector Quantized Transformers",
    "normalized_title": "esc:efficientspeechcodingwithcross-scaleresidualvectorquantizedtransformers",
    "doi": "10.48550/arxiv.2404.19441",
    "openalex_id": "",
    "arxiv_id": "2404.19441",
    "published_date": "2024-04-30",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Evaluating Text-to-Speech Synthesis from a Large Discrete Token-based Speech Language Model",
    "normalized_title": "evaluatingtext-to-speechsynthesisfromalargediscretetoken-basedspeechlanguagemodel",
    "doi": "10.48550/arxiv.2405.09768",
    "openalex_id": "",
    "arxiv_id": "2405.09768",
    "published_date": "2024-05-16",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "C3LLM: Conditional Multimodal Content Generation Using Large Language Models",
    "normalized_title": "c3llm:conditionalmultimodalcontentgenerationusinglargelanguagemodels",
    "doi": "10.48550/arxiv.2405.16136",
    "openalex_id": "",
    "arxiv_id": "2405.16136",
    "published_date": "2024-05-25",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Generative Pre-trained Speech Language Model with Efficient Hierarchical Transformer",
    "normalized_title": "generativepre-trainedspeechlanguagemodelwithefficienthierarchicaltransformer",
    "doi": "10.48550/arxiv.2406.00976",
    "openalex_id": "",
    "arxiv_id": "2406.00976",
    "published_date": "2024-06-03",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "MaskSR: Masked Language Model for Full-band Speech Restoration",
    "normalized_title": "masksr:maskedlanguagemodelforfull-bandspeechrestoration",
    "doi": "10.48550/arxiv.2406.02092",
    "openalex_id": "",
    "arxiv_id": "2406.02092",
    "published_date": "2024-06-04",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Addressing Index Collapse of Large-Codebook Speech Tokenizer with Dual-Decoding Product-Quantized Variational Auto-Encoder",
    "normalized_title": "addressingindexcollapseoflarge-codebookspeechtokenizerwithdual-decodingproduct-quantizedvariationalauto-encoder",
    "doi": "10.48550/arxiv.2406.02940",
    "openalex_id": "",
    "arxiv_id": "2406.02940",
    "published_date": "2024-06-05",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Improving Audio Codec-based Zero-Shot Text-to-Speech Synthesis with Multi-Modal Context and Large Language Model",
    "normalized_title": "improvingaudiocodec-basedzero-shottext-to-speechsynthesiswithmulti-modalcontextandlargelanguagemodel",
    "doi": "10.48550/arxiv.2406.03706",
    "openalex_id": "",
    "arxiv_id": "2406.03706",
    "published_date": "2024-06-06",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Boosting Diffusion Model for Spectrogram Up-sampling in Text-to-speech: An Empirical Study",
    "normalized_title": "boostingdiffusionmodelforspectrogramup-samplingintext-to-speech:anempiricalstudy",
    "doi": "10.48550/arxiv.2406.04633",
    "openalex_id": "",
    "arxiv_id": "2406.04633",
    "published_date": "2024-06-07",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "VALL-E 2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers",
    "normalized_title": "vall-e2:neuralcodeclanguagemodelsarehumanparityzero-shottexttospeechsynthesizers",
    "doi": "10.48550/arxiv.2406.05370",
    "openalex_id": "",
    "arxiv_id": "2406.05370",
    "published_date": "2024-06-08",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Discrete Multimodal Transformers with a Pretrained Large Language Model for Mixed-Supervision Speech Processing",
    "normalized_title": "discretemultimodaltransformerswithapretrainedlargelanguagemodelformixed-supervisionspeechprocessing",
    "doi": "10.48550/arxiv.2406.06582",
    "openalex_id": "",
    "arxiv_id": "2406.06582",
    "published_date": "2024-06-04",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "VALL-E R: Robust and Efficient Zero-Shot Text-to-Speech Synthesis via Monotonic Alignment",
    "normalized_title": "vall-er:robustandefficientzero-shottext-to-speechsynthesisviamonotonicalignment",
    "doi": "10.48550/arxiv.2406.07855",
    "openalex_id": "",
    "arxiv_id": "2406.07855",
    "published_date": "2024-06-12",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "CoLM-DSR: Leveraging Neural Codec Language Modeling for Multi-Modal Dysarthric Speech Reconstruction",
    "normalized_title": "colm-dsr:leveragingneuralcodeclanguagemodelingformulti-modaldysarthricspeechreconstruction",
    "doi": "10.48550/arxiv.2406.08336",
    "openalex_id": "",
    "arxiv_id": "2406.08336",
    "published_date": "2024-06-12",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "How Should We Extract Discrete Audio Tokens from Self-Supervised Models?",
    "normalized_title": "howshouldweextractdiscreteaudiotokensfromself-supervisedmodels?",
    "doi": "10.48550/arxiv.2406.10735",
    "openalex_id": "",
    "arxiv_id": "2406.10735",
    "published_date": "2024-06-15",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "NAST: Noise Aware Speech Tokenization for Speech Language Models",
    "normalized_title": "nast:noiseawarespeechtokenizationforspeechlanguagemodels",
    "doi": "10.48550/arxiv.2406.11037",
    "openalex_id": "",
    "arxiv_id": "2406.11037",
    "published_date": "2024-06-16",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Children's Speech Recognition through Discrete Token Enhancement",
    "normalized_title": "children'sspeechrecognitionthroughdiscretetokenenhancement",
    "doi": "10.48550/arxiv.2406.13431",
    "openalex_id": "",
    "arxiv_id": "2406.13431",
    "published_date": "2024-06-19",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "DASB - Discrete Audio and Speech Benchmark",
    "normalized_title": "dasb-discreteaudioandspeechbenchmark",
    "doi": "10.48550/arxiv.2406.14294",
    "openalex_id": "",
    "arxiv_id": "2406.14294",
    "published_date": "2024-06-20",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "High Fidelity Text-to-Speech Via Discrete Tokens Using Token Transducer and Group Masked Language Model",
    "normalized_title": "highfidelitytext-to-speechviadiscretetokensusingtokentransducerandgroupmaskedlanguagemodel",
    "doi": "10.48550/arxiv.2406.17310",
    "openalex_id": "",
    "arxiv_id": "2406.17310",
    "published_date": "2024-06-25",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "On the Effectiveness of Acoustic BPE in Decoder-Only TTS",
    "normalized_title": "ontheeffectivenessofacousticbpeindecoder-onlytts",
    "doi": "10.48550/arxiv.2407.03892",
    "openalex_id": "",
    "arxiv_id": "2407.03892",
    "published_date": "2024-07-04",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens",
    "normalized_title": "cosyvoice:ascalablemultilingualzero-shottext-to-speechsynthesizerbasedonsupervisedsemantictokens",
    "doi": "10.48550/arxiv.2407.05407",
    "openalex_id": "",
    "arxiv_id": "2407.05407",
    "published_date": "2024-07-07",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "dMel: Speech Tokenization made Simple",
    "normalized_title": "dmel:speechtokenizationmadesimple",
    "doi": "10.48550/arxiv.2407.15835",
    "openalex_id": "",
    "arxiv_id": "2407.15835",
    "published_date": "2024-07-22",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Enabling Beam Search for Language Model-Based Text-to-Speech Synthesis",
    "normalized_title": "enablingbeamsearchforlanguagemodel-basedtext-to-speechsynthesis",
    "doi": "10.48550/arxiv.2408.16373",
    "openalex_id": "",
    "arxiv_id": "2408.16373",
    "published_date": "2024-08-29",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Codec Does Matter: Exploring the Semantic Shortcoming of Codec for Audio Language Model",
    "normalized_title": "codecdoesmatter:exploringthesemanticshortcomingofcodecforaudiolanguagemodel",
    "doi": "10.48550/arxiv.2408.17175",
    "openalex_id": "",
    "arxiv_id": "2408.17175",
    "published_date": "2024-08-30",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer",
    "normalized_title": "maskgct:zero-shottext-to-speechwithmaskedgenerativecodectransformer",
    "doi": "10.48550/arxiv.2409.00750",
    "openalex_id": "",
    "arxiv_id": "2409.00750",
    "published_date": "2024-09-01",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "vec2wav 2.0: Advancing Voice Conversion via Discrete Token Vocoders",
    "normalized_title": "vec2wav2.0:advancingvoiceconversionviadiscretetokenvocoders",
    "doi": "10.48550/arxiv.2409.01995",
    "openalex_id": "",
    "arxiv_id": "2409.01995",
    "published_date": "2024-09-03",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "STAB: Speech Tokenizer Assessment Benchmark",
    "normalized_title": "stab:speechtokenizerassessmentbenchmark",
    "doi": "10.48550/arxiv.2409.02384",
    "openalex_id": "",
    "arxiv_id": "2409.02384",
    "published_date": "2024-09-04",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "FireRedTTS: A Foundation Text-To-Speech Framework for Industry-Level Generative Speech Applications",
    "normalized_title": "fireredtts:afoundationtext-to-speechframeworkforindustry-levelgenerativespeechapplications",
    "doi": "10.48550/arxiv.2409.03283",
    "openalex_id": "",
    "arxiv_id": "2409.03283",
    "published_date": "2024-09-05",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "LAST: Language Model Aware Speech Tokenization",
    "normalized_title": "last:languagemodelawarespeechtokenization",
    "doi": "10.48550/arxiv.2409.03701",
    "openalex_id": "",
    "arxiv_id": "2409.03701",
    "published_date": "2024-09-05",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Investigating Neural Audio Codecs for Speech Language Model-Based Speech Generation",
    "normalized_title": "investigatingneuralaudiocodecsforspeechlanguagemodel-basedspeechgeneration",
    "doi": "10.48550/arxiv.2409.04016",
    "openalex_id": "",
    "arxiv_id": "2409.04016",
    "published_date": "2024-09-06",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Disentangling the Prosody and Semantic Information with Pre-trained Model for In-Context Learning based Zero-Shot Voice Conversion",
    "normalized_title": "disentanglingtheprosodyandsemanticinformationwithpre-trainedmodelforin-contextlearningbasedzero-shotvoiceconversion",
    "doi": "10.48550/arxiv.2409.05004",
    "openalex_id": "",
    "arxiv_id": "2409.05004",
    "published_date": "2024-09-08",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Joint Semantic Knowledge Distillation and Masked Acoustic Modeling for Full-band Speech Restoration with Improved Intelligibility",
    "normalized_title": "jointsemanticknowledgedistillationandmaskedacousticmodelingforfull-bandspeechrestorationwithimprovedintelligibility",
    "doi": "10.48550/arxiv.2409.09357",
    "openalex_id": "",
    "arxiv_id": "2409.09357",
    "published_date": "2024-09-14",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Self-Supervised Syllable Discovery Based on Speaker-Disentangled HuBERT",
    "normalized_title": "self-supervisedsyllablediscoverybasedonspeaker-disentangledhubert",
    "doi": "10.48550/arxiv.2409.10103",
    "openalex_id": "",
    "arxiv_id": "2409.10103",
    "published_date": "2024-09-16",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Single-stage TTS with Masked Audio Token Modeling and Semantic Knowledge Distillation",
    "normalized_title": "single-stagettswithmaskedaudiotokenmodelingandsemanticknowledgedistillation",
    "doi": "10.48550/arxiv.2409.11003",
    "openalex_id": "",
    "arxiv_id": "2409.11003",
    "published_date": "2024-09-17",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Learning Source Disentanglement in Neural Audio Codec",
    "normalized_title": "learningsourcedisentanglementinneuralaudiocodec",
    "doi": "10.48550/arxiv.2409.11228",
    "openalex_id": "",
    "arxiv_id": "2409.11228",
    "published_date": "2024-09-17",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Speaking from Coarse to Fine: Improving Neural Codec Language Model via Multi-Scale Speech Coding and Generation",
    "normalized_title": "speakingfromcoarsetofine:improvingneuralcodeclanguagemodelviamulti-scalespeechcodingandgeneration",
    "doi": "10.48550/arxiv.2409.11630",
    "openalex_id": "",
    "arxiv_id": "2409.11630",
    "published_date": "2024-09-18",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "NDVQ: Robust Neural Audio Codec with Normal Distribution-Based Vector Quantization",
    "normalized_title": "ndvq:robustneuralaudiocodecwithnormaldistribution-basedvectorquantization",
    "doi": "10.48550/arxiv.2409.12717",
    "openalex_id": "",
    "arxiv_id": "2409.12717",
    "published_date": "2024-09-19",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "ESPnet-Codec: Comprehensive Training and Evaluation of Neural Codecs for Audio, Music, and Speech",
    "normalized_title": "espnet-codec:comprehensivetrainingandevaluationofneuralcodecsforaudio,music,andspeech",
    "doi": "10.48550/arxiv.2409.15897",
    "openalex_id": "",
    "arxiv_id": "2409.15897",
    "published_date": "2024-09-24",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Analyzing and Mitigating Inconsistency in Discrete Audio Tokens for Neural Codec Language Models",
    "normalized_title": "analyzingandmitigatinginconsistencyindiscreteaudiotokensforneuralcodeclanguagemodels",
    "doi": "10.48550/arxiv.2409.19283",
    "openalex_id": "",
    "arxiv_id": "2409.19283",
    "published_date": "2024-09-28",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Moshi: a speech-text foundation model for real-time dialogue",
    "normalized_title": "moshi:aspeech-textfoundationmodelforreal-timedialogue",
    "doi": "10.48550/arxiv.2410.00037",
    "openalex_id": "",
    "arxiv_id": "2410.00037",
    "published_date": "2024-09-17",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Textless Streaming Speech-to-Speech Translation using Semantic Speech Tokens",
    "normalized_title": "textlessstreamingspeech-to-speechtranslationusingsemanticspeechtokens",
    "doi": "10.48550/arxiv.2410.03298",
    "openalex_id": "",
    "arxiv_id": "2410.03298",
    "published_date": "2024-10-04",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "HALL-E: Hierarchical Neural Codec Language Model for Minute-Long Zero-Shot Text-to-Speech Synthesis",
    "normalized_title": "hall-e:hierarchicalneuralcodeclanguagemodelforminute-longzero-shottext-to-speechsynthesis",
    "doi": "10.48550/arxiv.2410.04380",
    "openalex_id": "",
    "arxiv_id": "2410.04380",
    "published_date": "2024-10-06",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Variable Bitrate Residual Vector Quantization for Audio Coding",
    "normalized_title": "variablebitrateresidualvectorquantizationforaudiocoding",
    "doi": "10.48550/arxiv.2410.06016",
    "openalex_id": "",
    "arxiv_id": "2410.06016",
    "published_date": "2024-10-08",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Sylber: Syllabic Embedding Representation of Speech from Raw Audio",
    "normalized_title": "sylber:syllabicembeddingrepresentationofspeechfromrawaudio",
    "doi": "10.48550/arxiv.2410.07168",
    "openalex_id": "",
    "arxiv_id": "2410.07168",
    "published_date": "2024-10-09",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Low Bitrate High-Quality RVQGAN-based Discrete Speech Tokenizer",
    "normalized_title": "lowbitratehigh-qualityrvqgan-baseddiscretespeechtokenizer",
    "doi": "10.21437/interspeech.2024-2366",
    "openalex_id": "",
    "arxiv_id": "2410.08325",
    "published_date": "2024-10-10",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Code Drift: Towards Idempotent Neural Audio Codecs",
    "normalized_title": "codedrift:towardsidempotentneuralaudiocodecs",
    "doi": "10.1109/icassp49660.2025.10890096",
    "openalex_id": "",
    "arxiv_id": "2410.11025",
    "published_date": "2024-10-14",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "ERVQ: Enhanced Residual Vector Quantization with Intra-and-Inter-Codebook Optimization for Neural Audio Codecs",
    "normalized_title": "ervq:enhancedresidualvectorquantizationwithintra-and-inter-codebookoptimizationforneuralaudiocodecs",
    "doi": "10.48550/arxiv.2410.12359",
    "openalex_id": "",
    "arxiv_id": "2410.12359",
    "published_date": "2024-10-16",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SNAC: Multi-Scale Neural Audio Codec",
    "normalized_title": "snac:multi-scaleneuralaudiocodec",
    "doi": "10.48550/arxiv.2410.14411",
    "openalex_id": "",
    "arxiv_id": "2410.14411",
    "published_date": "2024-10-18",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "DM-Codec: Distilling Multimodal Representations for Speech Tokenization",
    "normalized_title": "dm-codec:distillingmultimodalrepresentationsforspeechtokenization",
    "doi": "10.48550/arxiv.2410.15017",
    "openalex_id": "",
    "arxiv_id": "2410.15017",
    "published_date": "2024-10-19",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "LSCodec: Low-Bitrate and Speaker-Decoupled Discrete Speech Codec",
    "normalized_title": "lscodec:low-bitrateandspeaker-decoupleddiscretespeechcodec",
    "doi": "10.48550/arxiv.2410.15764",
    "openalex_id": "",
    "arxiv_id": "2410.15764",
    "published_date": "2024-10-21",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "A Closer Look at Neural Codec Resynthesis: Bridging the Gap between Codec and Waveform Generation",
    "normalized_title": "acloserlookatneuralcodecresynthesis:bridgingthegapbetweencodecandwaveformgeneration",
    "doi": "10.48550/arxiv.2410.22448",
    "openalex_id": "",
    "arxiv_id": "2410.22448",
    "published_date": "2024-10-29",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "DC-Spin: A Speaker-invariant Speech Tokenizer for Spoken Language Models",
    "normalized_title": "dc-spin:aspeaker-invariantspeechtokenizerforspokenlanguagemodels",
    "doi": "10.48550/arxiv.2410.24177",
    "openalex_id": "",
    "arxiv_id": "2410.24177",
    "published_date": "2024-10-31",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "A Comparative Study of Discrete Speech Tokens for Semantic-Related Tasks with Large Language Models",
    "normalized_title": "acomparativestudyofdiscretespeechtokensforsemantic-relatedtaskswithlargelanguagemodels",
    "doi": "10.48550/arxiv.2411.08742",
    "openalex_id": "",
    "arxiv_id": "2411.08742",
    "published_date": "2024-11-13",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "BEST-STD: Bidirectional Mamba-Enhanced Speech Tokenization for Spoken Term Detection",
    "normalized_title": "best-std:bidirectionalmamba-enhancedspeechtokenizationforspokentermdetection",
    "doi": "10.48550/arxiv.2411.14100",
    "openalex_id": "",
    "arxiv_id": "2411.14100",
    "published_date": "2024-11-21",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Scaling Speech-Text Pre-training with Synthetic Interleaved Data",
    "normalized_title": "scalingspeech-textpre-trainingwithsyntheticinterleaveddata",
    "doi": "10.48550/arxiv.2411.17607",
    "openalex_id": "",
    "arxiv_id": "2411.17607",
    "published_date": "2024-11-26",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models",
    "normalized_title": "cosyvoice2:scalablestreamingspeechsynthesiswithlargelanguagemodels",
    "doi": "10.48550/arxiv.2412.10117",
    "openalex_id": "",
    "arxiv_id": "2412.10117",
    "published_date": "2024-12-13",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Whisper-GPT: A Hybrid Representation Audio Large Language Model",
    "normalized_title": "whisper-gpt:ahybridrepresentationaudiolargelanguagemodel",
    "doi": "10.48550/arxiv.2412.11449",
    "openalex_id": "",
    "arxiv_id": "2412.11449",
    "published_date": "2024-12-16",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SLAM-Omni: Timbre-Controllable Voice Interaction System with Single-Stage Training",
    "normalized_title": "slam-omni:timbre-controllablevoiceinteractionsystemwithsingle-stagetraining",
    "doi": "10.48550/arxiv.2412.15649",
    "openalex_id": "",
    "arxiv_id": "2412.15649",
    "published_date": "2024-12-20",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Interleaved Speech-Text Language Models for Simple Streaming Text-to-Speech Synthesis",
    "normalized_title": "interleavedspeech-textlanguagemodelsforsimplestreamingtext-to-speechsynthesis",
    "doi": "10.48550/arxiv.2412.16102",
    "openalex_id": "",
    "arxiv_id": "2412.16102",
    "published_date": "2024-12-20",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Causal Speech Enhancement with Predicting Semantics based on Quantized Self-supervised Learning Features",
    "normalized_title": "causalspeechenhancementwithpredictingsemanticsbasedonquantizedself-supervisedlearningfeatures",
    "doi": "10.48550/arxiv.2412.19248",
    "openalex_id": "",
    "arxiv_id": "2412.19248",
    "published_date": "2024-12-26",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Phone-purity Guided Discrete Tokens for Dysarthric Speech Recognition",
    "normalized_title": "phone-purityguideddiscretetokensfordysarthricspeechrecognition",
    "doi": "10.48550/arxiv.2501.04379",
    "openalex_id": "",
    "arxiv_id": "2501.04379",
    "published_date": "2025-01-08",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "MARS6: A Small and Robust Hierarchical-Codec Text-to-Speech Model",
    "normalized_title": "mars6:asmallandrobusthierarchical-codectext-to-speechmodel",
    "doi": "10.48550/arxiv.2501.05787",
    "openalex_id": "",
    "arxiv_id": "2501.05787",
    "published_date": "2025-01-10",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "GenSE: Generative Speech Enhancement via Language Models using Hierarchical Modeling",
    "normalized_title": "gense:generativespeechenhancementvialanguagemodelsusinghierarchicalmodeling",
    "doi": "10.48550/arxiv.2502.02942",
    "openalex_id": "",
    "arxiv_id": "2502.02942",
    "published_date": "2025-02-05",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Metis: A Foundation Speech Generation Model with Masked Generative Pre-training",
    "normalized_title": "metis:afoundationspeechgenerationmodelwithmaskedgenerativepre-training",
    "doi": "10.48550/arxiv.2502.03128",
    "openalex_id": "",
    "arxiv_id": "2502.03128",
    "published_date": "2025-02-05",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "GenVC: Self-Supervised Zero-Shot Voice Conversion",
    "normalized_title": "genvc:self-supervisedzero-shotvoiceconversion",
    "doi": "10.48550/arxiv.2502.04519",
    "openalex_id": "",
    "arxiv_id": "2502.04519",
    "published_date": "2025-02-06",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Koel-TTS: Enhancing LLM based Speech Generation with Preference Alignment and Classifier Free Guidance",
    "normalized_title": "koel-tts:enhancingllmbasedspeechgenerationwithpreferencealignmentandclassifierfreeguidance",
    "doi": "10.48550/arxiv.2502.05236",
    "openalex_id": "",
    "arxiv_id": "2502.05236",
    "published_date": "2025-02-07",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Balancing Speech Understanding and Generation Using Continual Pre-training for Codec-based Speech LLM",
    "normalized_title": "balancingspeechunderstandingandgenerationusingcontinualpre-trainingforcodec-basedspeechllm",
    "doi": "10.48550/arxiv.2502.16897",
    "openalex_id": "",
    "arxiv_id": "2502.16897",
    "published_date": "2025-02-24",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Spark-TTS: An Efficient LLM-Based Text-to-Speech Model with Single-Stream Decoupled Speech Tokens",
    "normalized_title": "spark-tts:anefficientllm-basedtext-to-speechmodelwithsingle-streamdecoupledspeechtokens",
    "doi": "10.48550/arxiv.2503.01710",
    "openalex_id": "",
    "arxiv_id": "2503.01710",
    "published_date": "2025-03-03",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "On the Relation Between Speech Quality and Quantized Latent Representations of Neural Codecs",
    "normalized_title": "ontherelationbetweenspeechqualityandquantizedlatentrepresentationsofneuralcodecs",
    "doi": "10.48550/arxiv.2503.03304",
    "openalex_id": "",
    "arxiv_id": "2503.03304",
    "published_date": "2025-03-05",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "MMS-LLaMA: Efficient LLM-based Audio-Visual Speech Recognition with Minimal Multimodal Speech Tokens",
    "normalized_title": "mms-llama:efficientllm-basedaudio-visualspeechrecognitionwithminimalmultimodalspeechtokens",
    "doi": "10.48550/arxiv.2503.11315",
    "openalex_id": "",
    "arxiv_id": "2503.11315",
    "published_date": "2025-03-14",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Universal Speech Token Learning via Low-Bitrate Neural Codec and Pretrained Representations",
    "normalized_title": "universalspeechtokenlearningvialow-bitrateneuralcodecandpretrainedrepresentations",
    "doi": "10.1109/jstsp.2024.3488557",
    "openalex_id": "",
    "arxiv_id": "2503.12115",
    "published_date": "2025-03-15",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Shushing! Let's Imagine an Authentic Speech from the Silent Video",
    "normalized_title": "shushing!let'simagineanauthenticspeechfromthesilentvideo",
    "doi": "10.48550/arxiv.2503.14928",
    "openalex_id": "",
    "arxiv_id": "2503.14928",
    "published_date": "2025-03-19",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "FireRedTTS-1S: An Upgraded Streamable Foundation Text-to-Speech System",
    "normalized_title": "fireredtts-1s:anupgradedstreamablefoundationtext-to-speechsystem",
    "doi": "10.48550/arxiv.2503.20499",
    "openalex_id": "",
    "arxiv_id": "2503.20499",
    "published_date": "2025-03-26",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "TASTE: Text-Aligned Speech Tokenization and Embedding for Spoken Language Modeling",
    "normalized_title": "taste:text-alignedspeechtokenizationandembeddingforspokenlanguagemodeling",
    "doi": "10.48550/arxiv.2504.07053",
    "openalex_id": "",
    "arxiv_id": "2504.07053",
    "published_date": "2025-04-09",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Pseudo-Autoregressive Neural Codec Language Models for Efficient Zero-Shot Text-to-Speech Synthesis",
    "normalized_title": "pseudo-autoregressiveneuralcodeclanguagemodelsforefficientzero-shottext-to-speechsynthesis",
    "doi": "10.48550/arxiv.2504.10352",
    "openalex_id": "",
    "arxiv_id": "2504.10352",
    "published_date": "2025-04-14",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "GOAT-TTS: Expressive and Realistic Speech Generation via A Dual-Branch LLM",
    "normalized_title": "goat-tts:expressiveandrealisticspeechgenerationviaadual-branchllm",
    "doi": "10.48550/arxiv.2504.12339",
    "openalex_id": "",
    "arxiv_id": "2504.12339",
    "published_date": "2025-04-15",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "SimulS2S-LLM: Unlocking Simultaneous Inference of Speech LLMs for Speech-to-Speech Translation",
    "normalized_title": "simuls2s-llm:unlockingsimultaneousinferenceofspeechllmsforspeech-to-speechtranslation",
    "doi": "10.48550/arxiv.2504.15509",
    "openalex_id": "",
    "arxiv_id": "2504.15509",
    "published_date": "2025-04-22",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Improving Noise Robustness of LLM-based Zero-shot TTS via Discrete Acoustic Token Denoising",
    "normalized_title": "improvingnoiserobustnessofllm-basedzero-shotttsviadiscreteacoustictokendenoising",
    "doi": "10.48550/arxiv.2505.13830",
    "openalex_id": "",
    "arxiv_id": "2505.13830",
    "published_date": "2025-05-20",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "PAST: Phonetic-Acoustic Speech Tokenizer",
    "normalized_title": "past:phonetic-acousticspeechtokenizer",
    "doi": "10.48550/arxiv.2505.14470",
    "openalex_id": "",
    "arxiv_id": "2505.14470",
    "published_date": "2025-05-20",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Discrete Audio Representations for Automated Audio Captioning",
    "normalized_title": "discreteaudiorepresentationsforautomatedaudiocaptioning",
    "doi": "10.48550/arxiv.2505.14989",
    "openalex_id": "",
    "arxiv_id": "2505.14989",
    "published_date": "2025-05-21",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Discrete Tokens Exhibit Interlanguage Speech Intelligibility Benefit: an Analytical Study Towards Accent-robust ASR Only with Native Speech Data",
    "normalized_title": "discretetokensexhibitinterlanguagespeechintelligibilitybenefit:ananalyticalstudytowardsaccent-robustasronlywithnativespeechdata",
    "doi": "10.48550/arxiv.2505.16182",
    "openalex_id": "",
    "arxiv_id": "2505.16182",
    "published_date": "2025-05-22",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Impact of Frame Rates on Speech Tokenizer: A Case Study on Mandarin and English",
    "normalized_title": "impactofframeratesonspeechtokenizer:acasestudyonmandarinandenglish",
    "doi": "10.48550/arxiv.2505.17076",
    "openalex_id": "",
    "arxiv_id": "2505.17076",
    "published_date": "2025-05-20",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Exploring the Effect of Segmentation and Vocabulary Size on Speech Tokenization for Speech Language Models",
    "normalized_title": "exploringtheeffectofsegmentationandvocabularysizeonspeechtokenizationforspeechlanguagemodels",
    "doi": "10.48550/arxiv.2505.17446",
    "openalex_id": "",
    "arxiv_id": "2505.17446",
    "published_date": "2025-05-23",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Audio Jailbreak Attacks: Exposing Vulnerabilities in SpeechGPT in a White-Box Framework",
    "normalized_title": "audiojailbreakattacks:exposingvulnerabilitiesinspeechgptinawhite-boxframework",
    "doi": "10.48550/arxiv.2505.18864",
    "openalex_id": "",
    "arxiv_id": "2505.18864",
    "published_date": "2025-05-24",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "DS-Codec: Dual-Stage Training with Mirror-to-NonMirror Architecture Switching for Speech Codec",
    "normalized_title": "ds-codec:dual-stagetrainingwithmirror-to-nonmirrorarchitectureswitchingforspeechcodec",
    "doi": "10.48550/arxiv.2505.24314",
    "openalex_id": "",
    "arxiv_id": "2505.24314",
    "published_date": "2025-05-30",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Speech Token Prediction via Compressed-to-fine Language Modeling for Speech Generation",
    "normalized_title": "speechtokenpredictionviacompressed-to-finelanguagemodelingforspeechgeneration",
    "doi": "10.48550/arxiv.2505.24496",
    "openalex_id": "",
    "arxiv_id": "2505.24496",
    "published_date": "2025-05-30",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "FUSE: Universal Speech Enhancement using Multi-Stage Fusion of Sparse Compression and Token Generation Models for the URGENT 2025 Challenge",
    "normalized_title": "fuse:universalspeechenhancementusingmulti-stagefusionofsparsecompressionandtokengenerationmodelsfortheurgent2025challenge",
    "doi": "10.48550/arxiv.2506.00809",
    "openalex_id": "",
    "arxiv_id": "2506.00809",
    "published_date": "2025-06-01",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "HASRD: Hierarchical Acoustic and Semantic Representation Disentanglement",
    "normalized_title": "hasrd:hierarchicalacousticandsemanticrepresentationdisentanglement",
    "doi": "10.48550/arxiv.2506.00843",
    "openalex_id": "",
    "arxiv_id": "2506.00843",
    "published_date": "2025-06-01",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "base_review",
    "updated_at": "2026-01-07T18:15:18.216239+00:00",
    "round": 0
  },
  {
    "status": "include",
    "title": "Unsupervised Discovery of Structured Acoustic Tokens With Applications to Spoken Term Detection",
    "normalized_title": "unsuperviseddiscoveryofstructuredacoustictokenswithapplicationstospokentermdetection",
    "doi": "10.1109/taslp.2017.2778948",
    "openalex_id": "https://openalex.org/w2768580149",
    "arxiv_id": "",
    "published_date": "2017-11-30",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "ReVISE: Self-Supervised Speech Resynthesis with Visual Input for Universal and Generalized Speech Regeneration",
    "normalized_title": "revise:self-supervisedspeechresynthesiswithvisualinputforuniversalandgeneralizedspeechregeneration",
    "doi": "10.1109/cvpr52729.2023.01802",
    "openalex_id": "https://openalex.org/w4386076005",
    "arxiv_id": "",
    "published_date": "2023-06-01",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Toward Joint Language Modeling for Speech Units and Text",
    "normalized_title": "towardjointlanguagemodelingforspeechunitsandtext",
    "doi": "10.18653/v1/2023.findings-emnlp.438",
    "openalex_id": "https://openalex.org/w4389518827",
    "arxiv_id": "",
    "published_date": "2023-01-01",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Pa-HuBERT: Self-Supervised Music Source Separation Via Primitive Auditory Clustering And Hidden-Unit Bert",
    "normalized_title": "pa-hubert:self-supervisedmusicsourceseparationviaprimitiveauditoryclusteringandhidden-unitbert",
    "doi": "10.1109/icasspw59220.2023.10193575",
    "openalex_id": "https://openalex.org/w4385478423",
    "arxiv_id": "",
    "published_date": "2023-06-04",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities",
    "normalized_title": "speechgpt:empoweringlargelanguagemodelswithintrinsiccross-modalconversationalabilities",
    "doi": "10.18653/v1/2023.findings-emnlp.1055",
    "openalex_id": "https://openalex.org/w4389524500",
    "arxiv_id": "",
    "published_date": "2023-01-01",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "FunCodec: A Fundamental, Reproducible and Integrable Open-Source Toolkit for Neural Speech Codec",
    "normalized_title": "funcodec:afundamental,reproducibleandintegrableopen-sourcetoolkitforneuralspeechcodec",
    "doi": "10.1109/icassp48485.2024.10447523",
    "openalex_id": "https://openalex.org/w4392903389",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "VoxtLM: Unified Decoder-Only Models for Consolidating Speech Recognition, Synthesis and Speech, Text Continuation Tasks",
    "normalized_title": "voxtlm:unifieddecoder-onlymodelsforconsolidatingspeechrecognition,synthesisandspeech,textcontinuationtasks",
    "doi": "10.1109/icassp48485.2024.10447112",
    "openalex_id": "https://openalex.org/w4392904805",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "ZMM-TTS: Zero-Shot Multilingual and Multispeaker Speech Synthesis Conditioned on Self-Supervised Discrete Speech Representations",
    "normalized_title": "zmm-tts:zero-shotmultilingualandmultispeakerspeechsynthesisconditionedonself-superviseddiscretespeechrepresentations",
    "doi": "10.1109/taslp.2024.3451951",
    "openalex_id": "https://openalex.org/w4402301063",
    "arxiv_id": "",
    "published_date": "2024-01-01",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study",
    "normalized_title": "exploringspeechrecognition,translation,andunderstandingwithdiscretespeechunits:acomparativestudy",
    "doi": "10.1109/icassp48485.2024.10447929",
    "openalex_id": "https://openalex.org/w4392909068",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Speaker Adaptive Text-to-Speech With Timbre-Normalized Vector-Quantized Feature",
    "normalized_title": "speakeradaptivetext-to-speechwithtimbre-normalizedvector-quantizedfeature",
    "doi": "10.1109/taslp.2023.3308374",
    "openalex_id": "https://openalex.org/w4386133927",
    "arxiv_id": "",
    "published_date": "2023-01-01",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Fewer-Token Neural Speech Codec with Time-Invariant Codes",
    "normalized_title": "fewer-tokenneuralspeechcodecwithtime-invariantcodes",
    "doi": "10.1109/icassp48485.2024.10448454",
    "openalex_id": "https://openalex.org/w4392903006",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "TextrolSpeech: A Text Style Control Speech Corpus with Codec Language Text-to-Speech Models",
    "normalized_title": "textrolspeech:atextstylecontrolspeechcorpuswithcodeclanguagetext-to-speechmodels",
    "doi": "10.1109/icassp48485.2024.10445879",
    "openalex_id": "https://openalex.org/w4392904245",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "SELM: Speech Enhancement using Discrete Tokens and Language Models",
    "normalized_title": "selm:speechenhancementusingdiscretetokensandlanguagemodels",
    "doi": "10.1109/icassp48485.2024.10447464",
    "openalex_id": "https://openalex.org/w4392909571",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Discrete Audio Representation as an Alternative to Mel-Spectrograms for Speaker and Speech Recognition",
    "normalized_title": "discreteaudiorepresentationasanalternativetomel-spectrogramsforspeakerandspeechrecognition",
    "doi": "10.1109/icassp48485.2024.10446998",
    "openalex_id": "https://openalex.org/w4392904154",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Minimally-Supervised Speech Synthesis with Conditional Diffusion Model and Language Model: A Comparative Study of Semantic Coding",
    "normalized_title": "minimally-supervisedspeechsynthesiswithconditionaldiffusionmodelandlanguagemodel:acomparativestudyofsemanticcoding",
    "doi": "10.1109/icassp48485.2024.10446203",
    "openalex_id": "https://openalex.org/w4392903524",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Yet Another Generative Model for Room Impulse Response Estimation",
    "normalized_title": "yetanothergenerativemodelforroomimpulseresponseestimation",
    "doi": "10.1109/waspaa58266.2023.10248189",
    "openalex_id": "https://openalex.org/w4386764631",
    "arxiv_id": "",
    "published_date": "2023-09-15",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Generative De-Quantization for Neural Speech Codec Via Latent Diffusion",
    "normalized_title": "generativede-quantizationforneuralspeechcodecvialatentdiffusion",
    "doi": "10.1109/icassp48485.2024.10446556",
    "openalex_id": "https://openalex.org/w4392931975",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "High-Fidelity Speech Synthesis with Minimal Supervision: All Using Diffusion Models",
    "normalized_title": "high-fidelityspeechsynthesiswithminimalsupervision:allusingdiffusionmodels",
    "doi": "10.1109/icassp48485.2024.10448495",
    "openalex_id": "https://openalex.org/w4392931282",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Generating Stereophonic Music with Single-Stage Language Models",
    "normalized_title": "generatingstereophonicmusicwithsingle-stagelanguagemodels",
    "doi": "10.1109/icassp48485.2024.10446643",
    "openalex_id": "https://openalex.org/w4392902968",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Generation-Based Target Speech Extraction with Speech Discretization and Vocoder",
    "normalized_title": "generation-basedtargetspeechextractionwithspeechdiscretizationandvocoder",
    "doi": "10.1109/icassp48485.2024.10446418",
    "openalex_id": "https://openalex.org/w4392903977",
    "arxiv_id": "",
    "published_date": "2024-03-18",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "VQTTS: High-Fidelity Text-to-Speech Synthesis with Self-Supervised VQ Acoustic Feature",
    "normalized_title": "vqtts:high-fidelitytext-to-speechsynthesiswithself-supervisedvqacousticfeature",
    "doi": "10.21437/interspeech.2022-489",
    "openalex_id": "https://openalex.org/w4226132755",
    "arxiv_id": "",
    "published_date": "2022-09-16",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units",
    "normalized_title": "hubert:self-supervisedspeechrepresentationlearningbymaskedpredictionofhiddenunits",
    "doi": "10.1109/taslp.2021.3122291",
    "openalex_id": "https://openalex.org/w3169320628",
    "arxiv_id": "",
    "published_date": "2021-01-01",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Speech Resynthesis from Discrete Disentangled Self-Supervised Representations",
    "normalized_title": "speechresynthesisfromdiscretedisentangledself-supervisedrepresentations",
    "doi": "10.21437/interspeech.2021-475",
    "openalex_id": "https://openalex.org/w3140429000",
    "arxiv_id": "",
    "published_date": "2021-08-27",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations",
    "normalized_title": "vq-wav2vec:self-supervisedlearningofdiscretespeechrepresentations",
    "doi": "10.48550/arxiv.1910.05453",
    "openalex_id": "https://openalex.org/w2979476256",
    "arxiv_id": "",
    "published_date": "2019-10-12",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers",
    "normalized_title": "naturalspeech2:latentdiffusionmodelsarenaturalandzero-shotspeechandsingingsynthesizers",
    "doi": "10.48550/arxiv.2304.09116",
    "openalex_id": "https://openalex.org/w4366460484",
    "arxiv_id": "",
    "published_date": "2023-04-18",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations",
    "normalized_title": "wav2vec2.0:aframeworkforself-supervisedlearningofspeechrepresentations",
    "doi": "10.48550/arxiv.2006.11477",
    "openalex_id": "https://openalex.org/w3036601975",
    "arxiv_id": "",
    "published_date": "2020-06-20",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "w2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training",
    "normalized_title": "w2v-bert:combiningcontrastivelearningandmaskedlanguagemodelingforself-supervisedspeechpre-training",
    "doi": "10.1109/asru51503.2021.9688253",
    "openalex_id": "https://openalex.org/w4226033575",
    "arxiv_id": "",
    "published_date": "2021-12-13",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "AudioLM: A Language Modeling Approach to Audio Generation",
    "normalized_title": "audiolm:alanguagemodelingapproachtoaudiogeneration",
    "doi": "10.1109/taslp.2023.3288409",
    "openalex_id": "https://openalex.org/w4381786045",
    "arxiv_id": "",
    "published_date": "2023-01-01",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "A Vector Quantized Masked Autoencoder for Speech Emotion Recognition",
    "normalized_title": "avectorquantizedmaskedautoencoderforspeechemotionrecognition",
    "doi": "10.1109/icasspw59220.2023.10193151",
    "openalex_id": "https://openalex.org/w4385484923",
    "arxiv_id": "",
    "published_date": "2023-06-04",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Unsupervised spoken term detection with spoken queries by multi-level acoustic patterns with varying model granularity",
    "normalized_title": "unsupervisedspokentermdetectionwithspokenqueriesbymulti-levelacousticpatternswithvaryingmodelgranularity",
    "doi": "10.1109/icassp.2014.6855121",
    "openalex_id": "https://openalex.org/w2105016867",
    "arxiv_id": "",
    "published_date": "2014-05-01",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Unsupervised discovery of linguistic structure including two-level acoustic patterns using three cascaded stages of iterative optimization",
    "normalized_title": "unsuperviseddiscoveryoflinguisticstructureincludingtwo-levelacousticpatternsusingthreecascadedstagesofiterativeoptimization",
    "doi": "10.1109/icassp.2013.6639239",
    "openalex_id": "https://openalex.org/w2116422968",
    "arxiv_id": "",
    "published_date": "2013-05-01",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Towards unsupervised training of speaker independent acoustic models",
    "normalized_title": "towardsunsupervisedtrainingofspeakerindependentacousticmodels",
    "doi": "10.21437/interspeech.2011-184",
    "openalex_id": "https://openalex.org/w2401464865",
    "arxiv_id": "",
    "published_date": "2011-08-27",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Unsupervised Pattern Discovery in Speech",
    "normalized_title": "unsupervisedpatterndiscoveryinspeech",
    "doi": "10.1109/tasl.2007.909282",
    "openalex_id": "https://openalex.org/w2114347655",
    "arxiv_id": "",
    "published_date": "2007-12-20",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Disentangled Feature Learning for Real-Time Neural Speech Coding",
    "normalized_title": "disentangledfeaturelearningforreal-timeneuralspeechcoding",
    "doi": "10.1109/icassp49357.2023.10094723",
    "openalex_id": "https://openalex.org/w4372259964",
    "arxiv_id": "",
    "published_date": "2023-05-05",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Direct Speech-to-Speech Translation With Discrete Units",
    "normalized_title": "directspeech-to-speechtranslationwithdiscreteunits",
    "doi": "10.18653/v1/2022.acl-long.235",
    "openalex_id": "https://openalex.org/w3180374548",
    "arxiv_id": "",
    "published_date": "2022-01-01",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "UnitY: Two-pass Direct Speech-to-speech Translation with Discrete Units",
    "normalized_title": "unity:two-passdirectspeech-to-speechtranslationwithdiscreteunits",
    "doi": "10.18653/v1/2023.acl-long.872",
    "openalex_id": "https://openalex.org/w4385570550",
    "arxiv_id": "",
    "published_date": "2023-01-01",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  },
  {
    "status": "include",
    "title": "Low Bit-rate Speech Coding with VQ-VAE and a WaveNet Decoder",
    "normalized_title": "lowbit-ratespeechcodingwithvq-vaeandawavenetdecoder",
    "doi": "10.1109/icassp.2019.8683277",
    "openalex_id": "https://openalex.org/w2935711438",
    "arxiv_id": "",
    "published_date": "2019-04-16",
    "criteria_hash": "f84221d054a803ad95a17603644a25baad70b61eee481db03ed19d5879ab99fc",
    "source": "snowball_review",
    "updated_at": "2026-01-07T18:20:46.013649+00:00",
    "round": 1
  }
]