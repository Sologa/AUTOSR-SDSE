# 關鍵詞抽取流程與提示詞

> 提示詞原文為英文，本頁提供中文翻譯以利閱讀；實際程式呼叫仍使用英文模板與佔位符。

## LLM 管線流程
- **逐篇解析 → 聚合**：每份 PDF 透過 `LLMService.read_pdf` 取得部分 JSON；若發生錯誤會改呼叫 provider 的 `fallback_read_pdf`。蒐集到的所有 JSON 之後交由 `LLMService.chat` 聚合，若解析或驗證失敗則改用 `_fallback_aggregate_per_paper_outputs` 在本地整併。
- **共通前置作業**：先以 `_collect_paper_metadata` 下載 arXiv 中繼資料、透過 `_resolved_anchor_variants` 推導錨點詞，並在 `test_artifacts/keyword_extractor_live/keyword_extractor_usage_*.json` 紀錄 LLM 用量。

## 提示詞來源與佔位符
- **生成提示**：必須存在於 `resources/LLM/prompts/keyword_extractor/generate_search_terms.md`。程式會依 `ExtractParams` 替換 `<<max_queries>>`、`<<category_list>>`、`<<anchor_guidance>>` 等佔位符，並插入動態生成的論文中繼資料區塊。
- **聚合提示**：必須存在於 `resources/LLM/prompts/keyword_extractor/aggregate_terms.md`，同樣替換 `<<topic_hint>>`、`<<anchor_policy>>`、`<<partial_json_list>>` 等內容，並附上統一的中繼資料。若檔案缺失會直接拋出 `FileNotFoundError`。

### generate_search_terms.md（預設生成提示）
```markdown
- 角色：學術搜尋策略設計師與系統性評論分析師
- 背景：使用者上傳一篇或多篇綜述論文（PDF），你的目標是萃取高品質的檢索詞，並輸出符合後續系統性評論流程的 JSON。
- 專業設定：你擅長為文獻回顧設計具證據基礎且可重現的檢索策略，優先考慮去重、清晰度與涵蓋率。
- 技能：系統性回顧方法學、分類導向的詞彙萃取、布林查詢合成、同義詞統整與去重、精煉理由撰寫。
- 目標：產出僅含 JSON 的輸出，內容需包含錨點詞、分類後的檢索詞與逐字複製的論文中繼資料。所有欄位都必須以 PDF 與提供的中繼資料為依據。
- 限制：
  - 僅能使用上傳的 PDF 或附加的中繼資料區塊中的資訊。
  - 完整複製每篇論文的標題與摘要，不得改寫或截斷。
  - 優先納入多篇論文共同支持的詞彙；僅由單篇支持的詞需標示較低信心。
  - 每則理由限制 20 個字以內；若可取得頁碼須標註，否則使用 "page": "n/a"。
  - 總建議檢索詞數量需 ≤ <<max_queries>>（預設 50）。
  - 嚴格輸出有效 JSON，不得有額外文字。
- 流程：
  1) 檢視提供的論文中繼資料（見下方區塊），確認標準識別碼、標題、摘要、出版年份與網址。
  2) 閱讀 PDF，辨識核心任務或主題；提出 2–4 個與中繼資料指引一致的 anchor_terms。
  3) 為每篇論文依分類整理候選詞：<<category_list>>。
     <<category_coverage_note>>（若某分類不足 3 個術語，請與最接近的分類合併，避免留下單一項目；每個詞彙維持 1–3 個英文單字，不得出現底線或完整句子。）
  - 若既有分類不足以描述重要議題，最多可新增兩個新的 snake_case 分類並提供代表性術語。
  4) 進行標準化與整併：詞形還原、去重、統整相關詞。
  5) 為 `detected_keywords` 蒐集支持證據（引用 + 頁碼，若無則標示 "n/a"）。
  6) 依據中繼資料調整 `papers` 內容：維持順序、逐字複製標題與摘要，並填入帶有證據的 `detected_keywords`。
- 執行時覆寫（目前請求）：
  - topic_hint: <<topic_hint>>
  - language: <<language>>
  - include_ethics: <<include_ethics>>
  - max_queries: <<max_queries>>
  - seed_anchors: <<seed_anchors_info>>
  - custom_categories: <<custom_categories_info>>
  - exclude_terms: <<exclude_terms_info>>
  - anchor_terms: <<anchor_guidance>>
- 提供的論文中繼資料（逐字保留標題與摘要並維持順序）：
<<paper_metadata_block>>
- 輸出格式（嚴格 JSON，不得包含額外文字）：
{
  "topic": "<<topic_or_inferred>>",
  "anchor_terms": ["…", "…"],
  "search_terms": {
    "<分類>": ["…"],
    "<分類>": ["…"]
  },
  "papers": [
    {
      "id": "<穩定的短識別碼>",
      "source_id": "arXiv:<識別碼>",
      "title": "<逐字複製標題>",
      "abstract": "<逐字複製摘要>",
      "year": "<YYYY 或 unknown>",
      "source_url": "<https://arxiv.org/abs/...>",
      "detected_keywords": [
        {
          "term": "…",
          "category": "<分類標籤>",
          "evidence": {"quote": "…", "page": "n/a|<頁碼>"},
          "confidence": 0.0
        }
      ]
    }
  ]
}
- 範例（僅示意，請依實際資料覆寫內容）：
```json
{
  "topic": "對話摘要挑戰示例",
  "anchor_terms": [
    "dialogue summarization",
    "dialog summarization",
    "conversation summarization"
  ],
  "search_terms": {
    "core_concepts": ["technique", "dataset", "evaluation"],
    "technical_terms": ["language model", "semantic representation", "information extraction"],
    "advanced_concepts": ["topic segmentation", "personalization"],
    "implementation": ["automatic", "training"],
    "subdomains": ["meeting summarization", "customer service summarization"],
    "ethical": ["privacy", "cost"]
  },
  "papers": [
    {
      "id": "cads_taxonomy_2025",
      "source_id": "arXiv:2501.01234",
      "title": "CADS: A Systematic Review of Abstractive Dialogue Summarization",
      "abstract": "我們彙整 2019–2024 年間的 133 篇對話摘要論文，依六大挑戰（language、structure、comprehension、speaker、salience、factuality）分類並對應常用技術、資料集與評估指標。",
      "year": "2025",
      "source_url": "https://arxiv.org/abs/2501.01234",
      "detected_keywords": [
        {
          "term": "language challenge",
          "category": "core_concepts",
          "evidence": {"quote": "文章探討口語化對話的語言挑戰與相關處理策略。", "page": "n/a"},
          "confidence": 0.6
        },
        {
          "term": "meeting summarization",
          "category": "subdomains",
          "evidence": {"quote": "文中列舉 AMI、ICSI 等常見的會議摘要資料集。", "page": "n/a"},
          "confidence": 0.5
        }
      ]
    }
  ]
}
```
- 注意：
  - 維持 "papers" 的順序與中繼資料一致。
  - 不得新增額外頂層欄位，需遵守上述架構。
  - 保持查詢多樣性，重用中繼資料指引中的錨點變體。
```


### aggregate_terms.md（預設聚合提示）
```markdown
- 角色：檢索詞聚合者
- 背景：你會拿到多篇綜述 PDF 獨立產生的 JSON，各自包含候選詞與佐證。你的任務是把它們合併成符合生成器綱要的單一 JSON，同時保留標準化的中繼資料。
- 主題焦點：<<topic_hint>>
- 錨點政策：<<anchor_policy>>
- 限制：
  - 保留證據，對每個詞彙留下最有力的引用並計算跨論文的支持度（每個詞最多保留 2 段引用）。
  - 合併詞形或拼字變化，使各分類下的詞清單保持去重與規範化。
  - 完整複製標題、摘要、年份與網址，不得改寫。
  - 確保 "papers" 的順序與提供資料一致。
  - 僅輸出有效 JSON。
- 流程：
  1) 載入所有輸入 JSON。
  2) 標準化：轉成小寫、詞形還原、移除標點，並將變體映射到正規形式。
  3) 合併：整合各分類的詞彙與證據，保留最高信心值並維持去重後的清單。
  4) 重建 anchor_terms（挑選全域權重前 2–4 名），並確認 search_terms 覆蓋輸入提供的分類集合；<<category_coverage_note>>。
  <<additional_category_note>>
  5) 依照中繼資料同步 `papers`，保留證據並避免新增額外的頂層欄位。
- 提供的中繼資料（逐字複製，並保留順序）：
<<paper_metadata_block>>
- 輸出：與 generate_search_terms.md 相同的綱要。

輸入占位符：
<<partial_json_list>>
```
